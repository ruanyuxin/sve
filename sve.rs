// This code is automatically generated. DO NOT MODIFY.
//
// Instead, modify `crates/stdarch-gen2/spec/` and run the following command to re-generate this file:
//
// ```
// cargo run --bin=stdarch-gen2 -- crates/stdarch-gen2/spec
// ```
#![allow(improper_ctypes)]
#![feature(unchecked_shifts)]
#[cfg(test)]
#![feature(adt_const_params)]
#![feature(link_llvm_intrinsics)]
use stdarch_test::assert_instr;

use super::*;
use crate::core_arch::arch::aarch64::*;

use super::*;
#[allow(improper_ctypes)]
use crate::marker::ConstParamTy;
//use std::intrinsics::simd::simd_reinterpret;

#[derive(Copy, PartialEq, Debug)]
#[rustc_scalable_vector(2)]
#[allow(non_camel_case_types)]
pub struct svbool_t(bool);

impl Clone for svbool_t {
    fn clone(&self) -> Self {
        *self // 简单的复制自身
    }
}
/*macro_rules! static_assert_range {
    ($value:expr, $min:expr, $max:expr) => {
        const _: () = if $value < $min || $value > $max {
            panic!("Value {} is out of range. Expected between {} and {}", $value, $min, $max);
        } else {
            ()
        };
    };
}*/
macro_rules! static_assert_range {
    ($val:expr, $min:expr, $max:expr) => {{
        const _: [(); $val as usize - $min as usize] = [(); 0]; // 紧凑的范围断言
    }};
}

// === 基本数据类型定义 ===

#[derive(Copy, Clone, PartialEq, Debug)]
#[rustc_scalable_vector(16)]
#[allow(non_camel_case_types)]
pub struct svint8_t(i8);

#[derive(Copy, Clone, PartialEq, Debug)]
#[rustc_scalable_vector(16)]
#[allow(non_camel_case_types)]
pub struct svuint8_t(u8);

#[derive(Copy, Clone, PartialEq, Debug)]
#[rustc_scalable_vector(8)]
#[allow(non_camel_case_types)]
pub struct svint16_t(i16);

#[derive(Copy, Clone, PartialEq, Debug)]
#[rustc_scalable_vector(8)]
#[allow(non_camel_case_types)]
pub struct svuint16_t(u16);

#[derive(Copy, Clone, PartialEq, Debug)]
#[rustc_scalable_vector(4)]
#[allow(non_camel_case_types)]
pub struct svfloat32_t(f32);

#[derive(Copy, Clone, PartialEq, Debug)]
#[rustc_scalable_vector(4)]
#[allow(non_camel_case_types)]
pub struct svint32_t(i32);

#[derive(Copy, Clone, PartialEq, Debug)]
#[rustc_scalable_vector(4)]
#[allow(non_camel_case_types)]
pub struct svuint32_t(u32);

#[derive(Copy, Clone, PartialEq, Debug)]
#[rustc_scalable_vector(2)]
#[allow(non_camel_case_types)]
pub struct svfloat64_t(f64);

#[derive(Copy, Clone, PartialEq, Debug)]
#[rustc_scalable_vector(2)]
#[allow(non_camel_case_types)]
pub struct svint64_t(i64);

#[derive(Copy, Clone, PartialEq, Debug)]
#[rustc_scalable_vector(2)]
#[allow(non_camel_case_types)]
pub struct svuint64_t(u64);

// === 多向量数据类型定义 ===

#[derive(Copy, Clone, PartialEq, Debug)]
#[rustc_scalable_vector(32)]
#[allow(non_camel_case_types)]
pub struct svint8x2_t(i8);

#[derive(Copy, Clone, PartialEq, Debug)]
#[rustc_scalable_vector(32)]
#[allow(non_camel_case_types)]
pub struct svuint8x2_t(u8);

#[derive(Copy, Clone, PartialEq, Debug)]
#[rustc_scalable_vector(16)]
#[allow(non_camel_case_types)]
pub struct svint16x2_t(i16);

#[derive(Copy, Clone, PartialEq, Debug)]
#[rustc_scalable_vector(16)]
#[allow(non_camel_case_types)]
pub struct svuint16x2_t(u16);

#[derive(Copy, Clone, PartialEq, Debug)]
#[rustc_scalable_vector(8)]
#[allow(non_camel_case_types)]
pub struct svfloat32x2_t(f32);

#[derive(Copy, Clone, PartialEq, Debug)]
#[rustc_scalable_vector(8)]
#[allow(non_camel_case_types)]
pub struct svint32x2_t(i32);

#[derive(Copy, Clone, PartialEq, Debug)]
#[rustc_scalable_vector(8)]
#[allow(non_camel_case_types)]
pub struct svuint32x2_t(u32);

#[derive(Copy, Clone, PartialEq, Debug)]
#[rustc_scalable_vector(4)]
#[allow(non_camel_case_types)]
pub struct svfloat64x2_t(f64);

#[derive(Copy, Clone, PartialEq, Debug)]
#[rustc_scalable_vector(4)]
#[allow(non_camel_case_types)]
pub struct svint64x2_t(i64);

#[derive(Copy, Clone, PartialEq, Debug)]
#[rustc_scalable_vector(4)]
#[allow(non_camel_case_types)]
pub struct svuint64x2_t(u64);

#[derive(Copy, Clone, PartialEq, Debug)]
#[rustc_scalable_vector(48)]
#[allow(non_camel_case_types)]
pub struct svint8x3_t(i8);

#[derive(Copy, Clone, PartialEq, Debug)]
#[rustc_scalable_vector(48)]
#[allow(non_camel_case_types)]
pub struct svuint8x3_t(u8);

#[derive(Copy, Clone, PartialEq, Debug)]
#[rustc_scalable_vector(24)]
#[allow(non_camel_case_types)]
pub struct svint16x3_t(i16);

#[derive(Copy, Clone, PartialEq, Debug)]
#[rustc_scalable_vector(24)]
#[allow(non_camel_case_types)]
pub struct svuint16x3_t(u16);

#[derive(Copy, Clone, PartialEq, Debug)]
#[rustc_scalable_vector(12)]
#[allow(non_camel_case_types)]
pub struct svfloat32x3_t(f32);

#[derive(Copy, Clone, PartialEq, Debug)]
#[rustc_scalable_vector(12)]
#[allow(non_camel_case_types)]
pub struct svint32x3_t(i32);

#[derive(Copy, Clone, PartialEq, Debug)]
#[rustc_scalable_vector(12)]
#[allow(non_camel_case_types)]
pub struct svuint32x3_t(u32);

#[derive(Copy, Clone, PartialEq, Debug)]
#[rustc_scalable_vector(6)]
#[allow(non_camel_case_types)]
pub struct svfloat64x3_t(f64);

#[derive(Copy, Clone, PartialEq, Debug)]
#[rustc_scalable_vector(6)]
#[allow(non_camel_case_types)]
pub struct svint64x3_t(i64);

#[derive(Copy, Clone, PartialEq, Debug)]
#[rustc_scalable_vector(6)]
#[allow(non_camel_case_types)]
pub struct svuint64x3_t(u64);

#[derive(Copy, Clone, PartialEq, Debug)]
#[rustc_scalable_vector(64)]
#[allow(non_camel_case_types)]
pub struct svint8x4_t(i8);

#[derive(Copy, Clone, PartialEq, Debug)]
#[rustc_scalable_vector(64)]
#[allow(non_camel_case_types)]
pub struct svuint8x4_t(u8);

#[derive(Copy, Clone, PartialEq, Debug)]
#[rustc_scalable_vector(32)]
#[allow(non_camel_case_types)]
pub struct svint16x4_t(i16);

#[derive(Copy, Clone, PartialEq, Debug)]
#[rustc_scalable_vector(32)]
#[allow(non_camel_case_types)]
pub struct svuint16x4_t(u16);

#[derive(Copy, Clone, PartialEq, Debug)]
#[rustc_scalable_vector(16)]
#[allow(non_camel_case_types)]
pub struct svfloat32x4_t(f32);

#[derive(Copy, Clone, PartialEq, Debug)]
#[rustc_scalable_vector(16)]
#[allow(non_camel_case_types)]
pub struct svint32x4_t(i32);

#[derive(Copy, Clone, PartialEq, Debug)]
#[rustc_scalable_vector(16)]
#[allow(non_camel_case_types)]
pub struct svuint32x4_t(u32);

#[derive(Copy, Clone, PartialEq, Debug)]
#[rustc_scalable_vector(8)]
#[allow(non_camel_case_types)]
pub struct svfloat64x4_t(f64);

#[derive(Copy, Clone, PartialEq, Debug)]
#[rustc_scalable_vector(8)]
#[allow(non_camel_case_types)]
pub struct svint64x4_t(i64);

#[derive(Copy, Clone, PartialEq, Debug)]
#[rustc_scalable_vector(8)]
#[allow(non_camel_case_types)]
pub struct svuint64x4_t(u64);

// === 内部数据类型定义 ===

#[derive(Copy, Clone, PartialEq, Debug)]
#[rustc_scalable_vector(2)]
#[allow(non_camel_case_types)]
pub(super) struct nxv2i8(i8);

#[derive(Copy, Clone, PartialEq, Debug)]
#[rustc_scalable_vector(4)]
#[allow(non_camel_case_types)]
pub(super) struct nxv4i8(i8);

#[derive(Copy, Clone, PartialEq, Debug)]
#[rustc_scalable_vector(8)]
#[allow(non_camel_case_types)]
pub(super) struct nxv8i8(i8);

#[derive(Copy, Clone, PartialEq, Debug)]
#[rustc_scalable_vector(2)]
#[allow(non_camel_case_types)]
pub(super) struct nxv2i16(i16);

#[derive(Copy, Clone, PartialEq, Debug)]
#[rustc_scalable_vector(4)]
#[allow(non_camel_case_types)]
pub(super) struct nxv4i16(i16);

#[derive(Copy, Clone, PartialEq, Debug)]
#[rustc_scalable_vector(2)]
#[allow(non_camel_case_types)]
pub(super) struct nxv2i32(i32);

#[derive(Copy, Clone, PartialEq, Debug)]
#[rustc_scalable_vector(2)]
#[allow(non_camel_case_types)]
pub(super) struct nxv2u8(u8);

#[derive(Copy, Clone, PartialEq, Debug)]
#[rustc_scalable_vector(4)]
#[allow(non_camel_case_types)]
pub(super) struct nxv4u8(u8);

#[derive(Copy, Clone, PartialEq, Debug)]
#[rustc_scalable_vector(8)]
#[allow(non_camel_case_types)]
pub(super) struct nxv8u8(u8);

#[derive(Copy, Clone, PartialEq, Debug)]
#[rustc_scalable_vector(2)]
#[allow(non_camel_case_types)]
pub(super) struct nxv2u16(u16);

#[derive(Copy, Clone, PartialEq, Debug)]
#[rustc_scalable_vector(4)]
#[allow(non_camel_case_types)]
pub(super) struct nxv4u16(u16);

#[derive(Copy, Clone, PartialEq, Debug)]
#[rustc_scalable_vector(2)]
#[allow(non_camel_case_types)]
pub(super) struct nxv2u32(u32);

// === 内部谓词类型定义 ===

#[derive(Copy, Clone, PartialEq, Debug)]
#[rustc_scalable_vector(2)]
#[allow(non_camel_case_types)]
pub(super) struct svbool2_t(bool);

#[derive(Copy, Clone, PartialEq, Debug)]
#[rustc_scalable_vector(4)]
#[allow(non_camel_case_types)]
pub(super) struct svbool4_t(bool);

#[derive(Copy, Clone, PartialEq, Debug)]
#[rustc_scalable_vector(8)]
#[allow(non_camel_case_types)]
pub(super) struct svbool8_t(bool);

// === FFI 绑定 ===

// svbool_t 相关函数
#[inline(never)]
#[target_feature(enable = "sve")]
pub unsafe fn svptrue_b8() -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ptrue.nxv16i1")]
        fn _svptrue_b8() -> svbool_t;
    }
    _svptrue_b8()
}

#[inline(never)]
#[target_feature(enable = "sve")]
pub unsafe fn svptrue_b16() -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ptrue.nxv8i1")]
        fn _svptrue_b16() -> svbool_t;
    }
    _svptrue_b16()
}

#[inline(never)]
#[target_feature(enable = "sve")]
pub unsafe fn svptrue_b32() -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ptrue.nxv4i1")]
        fn _svptrue_b32() -> svbool_t;
    }
    _svptrue_b32()
}

#[inline(never)]
#[target_feature(enable = "sve")]
pub unsafe fn svptrue_b64() -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ptrue.nxv2i1")]
        fn _svptrue_b64() -> svbool_t;
    }
    _svptrue_b64()
}

// svint8_t 相关函数
#[inline(never)]
#[target_feature(enable = "sve")]
pub unsafe fn svdup_n_s8(value: i8) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.dup.x.nxv16i8")]
        fn _svdup_n_s8(value: i8) -> svint8_t;
    }
    _svdup_n_s8(value)
}

#[inline(never)]
#[target_feature(enable = "sve")]
pub unsafe fn svsel_s8(pg: svbool_t, t: svint8_t, f: svint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sel.nxv16i8")]
        fn _svsel_s8(pg: svbool_t, t: svint8_t, f: svint8_t) -> svint8_t;
    }
    _svsel_s8(pg, t, f)
}

// svuint8_t 相关函数
#[inline(never)]
#[target_feature(enable = "sve")]
pub unsafe fn svdup_n_u8(value: u8) -> svuint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.dup.x.nxv16i8")]
        fn _svdup_n_u8(value: u8) -> svuint8_t;
    }
    _svdup_n_u8(value)
}

#[inline(never)]
#[target_feature(enable = "sve")]
pub unsafe fn svsel_u8(pg: svbool_t, t: svuint8_t, f: svuint8_t) -> svuint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sel.nxv16i8")]
        fn _svsel_u8(pg: svbool_t, t: svuint8_t, f: svuint8_t) -> svuint8_t;
    }
    _svsel_u8(pg, t, f)
}

// svint16_t 相关函数
#[inline(never)]
#[target_feature(enable = "sve")]
pub unsafe fn svdup_n_s16(value: i16) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.dup.x.nxv8i16")]
        fn _svdup_n_s16(value: i16) -> svint16_t;
    }
    _svdup_n_s16(value)
}

#[inline(never)]
#[target_feature(enable = "sve")]
pub unsafe fn svsel_s16(pg: svbool_t, t: svint16_t, f: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sel.nxv8i16")]
        fn _svsel_s16(pg: svbool_t, t: svint16_t, f: svint16_t) -> svint16_t;
    }
    _svsel_s16(pg, t, f)
}

// svuint16_t 相关函数
#[inline(never)]
#[target_feature(enable = "sve")]
pub unsafe fn svdup_n_u16(value: u16) -> svuint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.dup.x.nxv8i16")]
        fn _svdup_n_u16(value: u16) -> svuint16_t;
    }
    _svdup_n_u16(value)
}

#[inline(never)]
#[target_feature(enable = "sve")]
pub unsafe fn svsel_u16(pg: svbool_t, t: svuint16_t, f: svuint16_t) -> svuint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sel.nxv8i16")]
        fn _svsel_u16(pg: svbool_t, t: svuint16_t, f: svuint16_t) -> svuint16_t;
    }
    _svsel_u16(pg, t, f)
}

// svfloat32_t 相关函数
#[inline(never)]
#[target_feature(enable = "sve")]
pub unsafe fn svdup_n_f32(value: f32) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.dup.x.nxv4f32")]
        fn _svdup_n_f32(value: f32) -> svfloat32_t;
    }
    _svdup_n_f32(value)
}

#[inline(never)]
#[target_feature(enable = "sve")]
pub unsafe fn svsel_f32(pg: svbool_t, t: svfloat32_t, f: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sel.nxv4f32")]
        fn _svsel_f32(pg: svbool_t, t: svfloat32_t, f: svfloat32_t) -> svfloat32_t;
    }
    _svsel_f32(pg, t, f)
}

// svint32_t 相关函数
#[inline(never)]
#[target_feature(enable = "sve")]
pub unsafe fn svdup_n_s32(value: i32) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.dup.x.nxv4i32")]
        fn _svdup_n_s32(value: i32) -> svint32_t;
    }
    _svdup_n_s32(value)
}

#[inline(never)]
#[target_feature(enable = "sve")]
pub unsafe fn svsel_s32(pg: svbool_t, t: svint32_t, f: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sel.nxv4i32")]
        fn _svsel_s32(pg: svbool_t, t: svint32_t, f: svint32_t) -> svint32_t;
    }
    _svsel_s32(pg, t, f)
}

// svuint32_t 相关函数
#[inline(never)]
#[target_feature(enable = "sve")]
pub unsafe fn svdup_n_u32(value: u32) -> svuint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.dup.x.nxv4i32")]
        fn _svdup_n_u32(value: u32) -> svuint32_t;
    }
    _svdup_n_u32(value)
}

#[inline(never)]
#[target_feature(enable = "sve")]
pub unsafe fn svsel_u32(pg: svbool_t, t: svuint32_t, f: svuint32_t) -> svuint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sel.nxv4i32")]
        fn _svsel_u32(pg: svbool_t, t: svuint32_t, f: svuint32_t) -> svuint32_t;
    }
    _svsel_u32(pg, t, f)
}

// svfloat64_t 相关函数
#[inline(never)]
#[target_feature(enable = "sve")]
pub unsafe fn svdup_n_f64(value: f64) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.dup.x.nxv2f64")]
        fn _svdup_n_f64(value: f64) -> svfloat64_t;
    }
    _svdup_n_f64(value)
}

#[inline(never)]
#[target_feature(enable = "sve")]
pub unsafe fn svsel_f64(pg: svbool_t, t: svfloat64_t, f: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sel.nxv2f64")]
        fn _svsel_f64(pg: svbool_t, t: svfloat64_t, f: svfloat64_t) -> svfloat64_t;
    }
    _svsel_f64(pg, t, f)
}

// svint64_t 相关函数
#[inline(never)]
#[target_feature(enable = "sve")]
pub unsafe fn svdup_n_s64(value: i64) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.dup.x.nxv2i64")]
        fn _svdup_n_s64(value: i64) -> svint64_t;
    }
    _svdup_n_s64(value)
}

#[inline(never)]
#[target_feature(enable = "sve")]
pub unsafe fn svsel_s64(pg: svbool_t, t: svint64_t, f: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sel.nxv2i64")]
        fn _svsel_s64(pg: svbool_t, t: svint64_t, f: svint64_t) -> svint64_t;
    }
    _svsel_s64(pg, t, f)
}

// svuint64_t 相关函数
#[inline(never)]
#[target_feature(enable = "sve")]
pub unsafe fn svdup_n_u64(value: u64) -> svuint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.dup.x.nxv2i64")]
        fn _svdup_n_u64(value: u64) -> svuint64_t;
    }
    _svdup_n_u64(value)
}

#[inline(never)]
#[target_feature(enable = "sve")]
pub unsafe fn svsel_u64(pg: svbool_t, t: svuint64_t, f: svuint64_t) -> svuint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sel.nxv2i64")]
        fn _svsel_u64(pg: svbool_t, t: svuint64_t, f: svuint64_t) -> svuint64_t;
    }
    _svsel_u64(pg, t, f)
}

// 多向量类型的 dup 和 sel 函数（示例，实际需要更多）
#[inline(never)]
#[target_feature(enable = "sve")]
pub unsafe fn svdup_n_s8x2(value: i8) -> svint8x2_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.dup.x.nxv32i8")]
        fn _svdup_n_s8x2(value: i8) -> svint8x2_t;
    }
    _svdup_n_s8x2(value)
}

#[inline(never)]
#[target_feature(enable = "sve")]
pub unsafe fn svsel_s8x2(pg: svbool_t, t: svint8x2_t, f: svint8x2_t) -> svint8x2_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sel.nxv32i8")]
        fn _svsel_s8x2(pg: svbool_t, t: svint8x2_t, f: svint8x2_t) -> svint8x2_t;
    }
    _svsel_s8x2(pg, t, f)
}

// 其他多向量类型的函数类似，需要为每种类型提供相应的实现

// === 枚举类型定义 ===

#[repr(i32)]
#[allow(non_camel_case_types)]
#[derive(Clone, Copy, PartialEq, Eq, ConstParamTy, Debug)]
#[non_exhaustive]
pub enum svpattern {
    SV_POW2 = 0,
    SV_VL1 = 1,
    SV_VL2 = 2,
    SV_VL3 = 3,
    SV_VL4 = 4,
    SV_VL5 = 5,
    SV_VL6 = 6,
    SV_VL7 = 7,
    SV_VL8 = 8,
    SV_VL16 = 9,
    SV_VL32 = 10,
    SV_VL64 = 11,
    SV_VL128 = 12,
    SV_VL256 = 13,
    SV_MUL4 = 29,
    SV_MUL3 = 30,
    SV_ALL = 31,
}

#[repr(i32)]
#[allow(non_camel_case_types)]
#[derive(Clone, Copy, PartialEq, Eq, ConstParamTy, Debug)]
#[non_exhaustive]
pub enum svprfop {
    SV_PLDL1KEEP = 0,
    SV_PLDL1STRM = 1,
    SV_PLDL2KEEP = 2,
    SV_PLDL2STRM = 3,
    SV_PLDL3KEEP = 4,
    SV_PLDL3STRM = 5,
    SV_PSTL1KEEP = 8,
    SV_PSTL1STRM = 9,
    SV_PSTL2KEEP = 10,
    SV_PSTL2STRM = 11,
    SV_PSTL3KEEP = 12,
    SV_PSTL3STRM = 13,
}

pub trait AsUnsigned {
    type Unsigned: ?Sized;
    unsafe fn as_unsigned(self) -> Self::Unsigned;
}

pub trait AsSigned {
    type Signed: ?Sized;
    unsafe fn as_signed(self) -> Self::Signed;
}

impl AsUnsigned for svint8_t {
    type Unsigned = svuint8_t;

    #[inline]
    #[target_feature(enable = "sve")]
    unsafe fn as_unsigned(self) -> svuint8_t {
        svuint8_t(self.0 as u8)
    }
}

impl AsSigned for svuint8_t {
    type Signed = svint8_t;

    #[inline]
    #[target_feature(enable = "sve")]
    unsafe fn as_signed(self) -> svint8_t {
        svint8_t(self.0 as i8)
    }
}

impl AsUnsigned for svint16_t {
    type Unsigned = svuint16_t;

    #[inline]
    #[target_feature(enable = "sve")]
    unsafe fn as_unsigned(self) -> svuint16_t {
        svuint16_t(self.0 as u16)
    }
}

impl AsSigned for svuint16_t {
    type Signed = svint16_t;

    #[inline]
    #[target_feature(enable = "sve")]
    unsafe fn as_signed(self) -> svint16_t {
        svint16_t(self.0 as i16)
    }
}

impl AsUnsigned for svint32_t {
    type Unsigned = svuint32_t;

    #[inline]
    #[target_feature(enable = "sve")]
    unsafe fn as_unsigned(self) -> svuint32_t {
        svuint32_t(self.0 as u32)
    }
}

impl AsSigned for svuint32_t {
    type Signed = svint32_t;

    #[inline]
    #[target_feature(enable = "sve")]
    unsafe fn as_signed(self) -> svint32_t {
        svint32_t(self.0 as i32)
    }
}

impl AsUnsigned for svint64_t {
    type Unsigned = svuint64_t;

    #[inline]
    #[target_feature(enable = "sve")]
    unsafe fn as_unsigned(self) -> svuint64_t {
        svuint64_t(self.0 as u64)
    }
}

impl AsSigned for svuint64_t {
    type Signed = svint64_t;

    #[inline]
    #[target_feature(enable = "sve")]
    unsafe fn as_signed(self) -> svint64_t {
        svint64_t(self.0 as i64)
    }
}

impl AsUnsigned for svuint8_t {
    type Unsigned = svuint8_t;

    #[inline]
    #[target_feature(enable = "sve")]
    unsafe fn as_unsigned(self) -> svuint8_t {
        self
    }
}

// impl AsSigned for svuint8_t {
//     type Signed = svint8_t;

//     #[inline]
//     #[target_feature(enable = "sve")]
//     unsafe fn as_signed(self) -> svint8_t {
//         svint8_t(self.0 as i8)
//     }
// }

impl AsUnsigned for svuint16_t {
    type Unsigned = svuint16_t;

    #[inline]
    #[target_feature(enable = "sve")]
    unsafe fn as_unsigned(self) -> svuint16_t {
        self
    }
}

// impl AsSigned for svuint16_t {
//     type Signed = svint16_t;

//     #[inline]
//     #[target_feature(enable = "sve")]
//     unsafe fn as_signed(self) -> svint16_t {
//         svint16_t(self.0 as i16)
//     }
// }

impl AsUnsigned for svuint32_t {
    type Unsigned = svuint32_t;

    #[inline]
    #[target_feature(enable = "sve")]
    unsafe fn as_unsigned(self) -> svuint32_t {
        self
    }
}

// impl AsSigned for svuint32_t {
//     type Signed = svint32_t;

//     #[inline]
//     #[target_feature(enable = "sve")]
//     unsafe fn as_signed(self) -> svint32_t {
//         svint32_t(self.0 as i32)
//     }
// }

impl AsUnsigned for svuint64_t {
    type Unsigned = svuint64_t;

    #[inline]
    #[target_feature(enable = "sve")]
    unsafe fn as_unsigned(self) -> svuint64_t {
        self
    }
}

// impl AsSigned for svuint64_t {
//     type Signed = svint64_t;

//     #[inline]
//     #[target_feature(enable = "sve")]
//     unsafe fn as_signed(self) -> svint64_t {
//         svint64_t(self.0 as i64)
//     }
// }

impl AsUnsigned for nxv2i8 {
    type Unsigned = nxv2u8;

    #[inline]
    #[target_feature(enable = "sve")]
    unsafe fn as_unsigned(self) -> nxv2u8 {
        nxv2u8(self.0 as u8) // 将 i8 转换为 u8
    }
}

impl AsUnsigned for nxv4i8 {
    type Unsigned = nxv4u8;

    #[inline]
    #[target_feature(enable = "sve")]
    unsafe fn as_unsigned(self) -> nxv4u8 {
        nxv4u8(self.0 as u8) // 将 i8 转换为 u8
    }
}

impl AsUnsigned for nxv8i8 {
    type Unsigned = nxv8u8;

    #[inline]
    #[target_feature(enable = "sve")]
    unsafe fn as_unsigned(self) -> nxv8u8 {
        nxv8u8(self.0 as u8) // 将 i8 转换为 u8
    }
}

impl AsUnsigned for nxv2i16 {
    type Unsigned = nxv2u16;

    #[inline]
    #[target_feature(enable = "sve")]
    unsafe fn as_unsigned(self) -> nxv2u16 {
        nxv2u16(self.0 as u16) // 将 i16 转换为 u16
    }
}

impl AsUnsigned for nxv4i16 {
    type Unsigned = nxv4u16;

    #[inline]
    #[target_feature(enable = "sve")]
    unsafe fn as_unsigned(self) -> nxv4u16 {
        nxv4u16(self.0 as u16) // 将 i16 转换为 u16
    }
}

impl AsUnsigned for nxv2i32 {
    type Unsigned = nxv2u32;

    #[inline]
    #[target_feature(enable = "sve")]
    unsafe fn as_unsigned(self) -> nxv2u32 {
        nxv2u32(self.0 as u32) // 将 i32 转换为 u32
    }
}

impl AsUnsigned for nxv2u8 {
    type Unsigned = nxv2u8;

    #[inline]
    #[target_feature(enable = "sve")]
    unsafe fn as_unsigned(self) -> nxv2u8 {
        self // 无需转换
    }
}

impl AsUnsigned for nxv4u8 {
    type Unsigned = nxv4u8;

    #[inline]
    #[target_feature(enable = "sve")]
    unsafe fn as_unsigned(self) -> nxv4u8 {
        self // 无需转换
    }
}

impl AsUnsigned for nxv8u8 {
    type Unsigned = nxv8u8;

    #[inline]
    #[target_feature(enable = "sve")]
    unsafe fn as_unsigned(self) -> nxv8u8 {
        self // 无需转换
    }
}

impl AsUnsigned for nxv2u16 {
    type Unsigned = nxv2u16;

    #[inline]
    #[target_feature(enable = "sve")]
    unsafe fn as_unsigned(self) -> nxv2u16 {
        self // 无需转换
    }
}

impl AsUnsigned for nxv4u16 {
    type Unsigned = nxv4u16;

    #[inline]
    #[target_feature(enable = "sve")]
    unsafe fn as_unsigned(self) -> nxv4u16 {
        self // 无需转换
    }
}

impl AsUnsigned for nxv2u32 {
    type Unsigned = nxv2u32;

    #[inline]
    #[target_feature(enable = "sve")]
    unsafe fn as_unsigned(self) -> nxv2u32 {
        self // 无需转换
    }
}

impl AsSigned for *const u8 {
    type Signed = *const i8;

    #[inline]
    unsafe fn as_signed(self) -> Self::Signed {
        self as *const i8 // 将 *const u8 转换为 *const i8
    }
}

impl AsSigned for *const u16 {
    type Signed = *const i16;

    #[inline]
    unsafe fn as_signed(self) -> Self::Signed {
        self as *const i16 // 将 *const u16 转换为 *const i16
    }
}

impl AsSigned for *const u32 {
    type Signed = *const i32;

    #[inline]
    unsafe fn as_signed(self) -> Self::Signed {
        self as *const i32 // 将 *const u32 转换为 *const i32
    }
}

impl AsSigned for *const u64 {
    type Signed = *const i64;

    #[inline]
    unsafe fn as_signed(self) -> Self::Signed {
        self as *const i64 // 将 *const u64 转换为 *const i64
    }
}

impl AsUnsigned for i8 {
    type Unsigned = u8;

    #[inline]
    unsafe fn as_unsigned(self) -> u8 {
        self as u8
    }
}

impl AsUnsigned for i16 {
    type Unsigned = u16;

    #[inline]
    unsafe fn as_unsigned(self) -> u16 {
        self as u16
    }
}

impl AsUnsigned for i32 {
    type Unsigned = u32;

    #[inline]
    unsafe fn as_unsigned(self) -> u32 {
        self as u32
    }
}

impl AsUnsigned for i64 {
    type Unsigned = u64;

    #[inline]
    unsafe fn as_unsigned(self) -> u64 {
        self as u64
    }
}

impl AsUnsigned for svint8x2_t {
    type Unsigned = svuint8x2_t;

    #[inline]
    unsafe fn as_unsigned(self) -> svuint8x2_t {
        svuint8x2_t(self.0 as u8)
    }
}

impl AsUnsigned for svint16x2_t {
    type Unsigned = svuint16x2_t;

    #[inline]
    unsafe fn as_unsigned(self) -> svuint16x2_t {
        svuint16x2_t(self.0 as u16)
    }
}

impl AsUnsigned for svint32x2_t {
    type Unsigned = svuint32x2_t;

    #[inline]
    unsafe fn as_unsigned(self) -> svuint32x2_t {
        svuint32x2_t(self.0 as u32)
    }
}

impl AsUnsigned for svint64x2_t {
    type Unsigned = svuint64x2_t;

    #[inline]
    unsafe fn as_unsigned(self) -> svuint64x2_t {
        svuint64x2_t(self.0 as u64)
    }
}

impl AsUnsigned for svint8x3_t {
    type Unsigned = svuint8x3_t;

    #[inline]
    unsafe fn as_unsigned(self) -> svuint8x3_t {
        svuint8x3_t(self.0 as u8)
    }
}

impl AsUnsigned for svint16x3_t {
    type Unsigned = svuint16x3_t;

    #[inline]
    unsafe fn as_unsigned(self) -> svuint16x3_t {
        svuint16x3_t(self.0 as u16)
    }
}

impl AsUnsigned for svint32x3_t {
    type Unsigned = svuint32x3_t;

    #[inline]
    unsafe fn as_unsigned(self) -> svuint32x3_t {
        svuint32x3_t(self.0 as u32)
    }
}

impl AsUnsigned for svint64x3_t {
    type Unsigned = svuint64x3_t;

    #[inline]
    unsafe fn as_unsigned(self) -> svuint64x3_t {
        svuint64x3_t(self.0 as u64)
    }
}

impl AsUnsigned for svint8x4_t {
    type Unsigned = svuint8x4_t;

    #[inline]
    unsafe fn as_unsigned(self) -> svuint8x4_t {
        svuint8x4_t(self.0 as u8)
    }
}

impl AsUnsigned for svint16x4_t {
    type Unsigned = svuint16x4_t;

    #[inline]
    unsafe fn as_unsigned(self) -> svuint16x4_t {
        svuint16x4_t(self.0 as u16)
    }
}

impl AsUnsigned for svint32x4_t {
    type Unsigned = svuint32x4_t;

    #[inline]
    unsafe fn as_unsigned(self) -> svuint32x4_t {
        svuint32x4_t(self.0 as u32)
    }
}

impl AsUnsigned for svint64x4_t {
    type Unsigned = svuint64x4_t;

    #[inline]
    unsafe fn as_unsigned(self) -> svuint64x4_t {
        svuint64x4_t(self.0 as u64)
    }
}

impl AsUnsigned for svuint8x2_t {
    type Unsigned = svuint8x2_t;

    #[inline]
    unsafe fn as_unsigned(self) -> svuint8x2_t {
        svuint8x2_t(self.0)  // 已经是 u8 类型，所以直接返回
    }
}

impl AsUnsigned for svuint16x2_t {
    type Unsigned = svuint16x2_t;

    #[inline]
    unsafe fn as_unsigned(self) -> svuint16x2_t {
        svuint16x2_t(self.0)  // 已经是 u16 类型，所以直接返回
    }
}

impl AsUnsigned for svuint32x2_t {
    type Unsigned = svuint32x2_t;

    #[inline]
    unsafe fn as_unsigned(self) -> svuint32x2_t {
        svuint32x2_t(self.0)  // 已经是 u32 类型，所以直接返回
    }
}

impl AsUnsigned for svuint64x2_t {
    type Unsigned = svuint64x2_t;

    #[inline]
    unsafe fn as_unsigned(self) -> svuint64x2_t {
        svuint64x2_t(self.0)  // 已经是 u64 类型，所以直接返回
    }
}

impl AsUnsigned for svuint8x3_t {
    type Unsigned = svuint8x3_t;

    #[inline]
    unsafe fn as_unsigned(self) -> svuint8x3_t {
        svuint8x3_t(self.0)  // 已经是 u8 类型，所以直接返回
    }
}

impl AsUnsigned for svuint16x3_t {
    type Unsigned = svuint16x3_t;

    #[inline]
    unsafe fn as_unsigned(self) -> svuint16x3_t {
        svuint16x3_t(self.0)  // 已经是 u16 类型，所以直接返回
    }
}

impl AsUnsigned for svuint32x3_t {
    type Unsigned = svuint32x3_t;

    #[inline]
    unsafe fn as_unsigned(self) -> svuint32x3_t {
        svuint32x3_t(self.0)  // 已经是 u32 类型，所以直接返回
    }
}

impl AsUnsigned for svuint64x3_t {
    type Unsigned = svuint64x3_t;

    #[inline]
    unsafe fn as_unsigned(self) -> svuint64x3_t {
        svuint64x3_t(self.0)  // 已经是 u64 类型，所以直接返回
    }
}

impl AsUnsigned for svuint8x4_t {
    type Unsigned = svuint8x4_t;

    #[inline]
    unsafe fn as_unsigned(self) -> svuint8x4_t {
        svuint8x4_t(self.0)  // 已经是 u8 类型，所以直接返回
    }
}

impl AsUnsigned for svuint16x4_t {
    type Unsigned = svuint16x4_t;

    #[inline]
    unsafe fn as_unsigned(self) -> svuint16x4_t {
        svuint16x4_t(self.0)  // 已经是 u16 类型，所以直接返回
    }
}

impl AsUnsigned for svuint32x4_t {
    type Unsigned = svuint32x4_t;

    #[inline]
    unsafe fn as_unsigned(self) -> svuint32x4_t {
        svuint32x4_t(self.0)  // 已经是 u32 类型，所以直接返回
    }
}

impl AsUnsigned for svuint64x4_t {
    type Unsigned = svuint64x4_t;

    #[inline]
    unsafe fn as_unsigned(self) -> svuint64x4_t {
        svuint64x4_t(self.0)  // 已经是 u64 类型，所以直接返回
    }
}

impl AsSigned for svuint8x2_t {
    type Signed = svint8x2_t;
    #[inline]
    unsafe fn as_signed(self) -> svint8x2_t {
        svint8x2_t(self.0 as i8)
    }
}

impl AsSigned for svuint8x3_t {
    type Signed = svint8x3_t;
    #[inline]
    unsafe fn as_signed(self) -> svint8x3_t {
        svint8x3_t(self.0 as i8)
    }
}

impl AsSigned for svuint8x4_t {
    type Signed = svint8x4_t;
    #[inline]
    unsafe fn as_signed(self) -> svint8x4_t {
        svint8x4_t(self.0 as i8)
    }
}

impl AsSigned for svuint16x2_t {
    type Signed = svint16x2_t;
    #[inline]
    unsafe fn as_signed(self) -> svint16x2_t {
        svint16x2_t(self.0 as i16)
    }
}

impl AsSigned for svuint16x3_t {
    type Signed = svint16x3_t;
    #[inline]
    unsafe fn as_signed(self) -> svint16x3_t {
        svint16x3_t(self.0 as i16)
    }
}

impl AsSigned for svuint16x4_t {
    type Signed = svint16x4_t;
    #[inline]
    unsafe fn as_signed(self) -> svint16x4_t {
        svint16x4_t(self.0 as i16)
    }
}

impl AsSigned for svuint32x2_t {
    type Signed = svint32x2_t;
    #[inline]
    unsafe fn as_signed(self) -> svint32x2_t {
        svint32x2_t(self.0 as i32)
    }
}

impl AsSigned for svuint32x3_t {
    type Signed = svint32x3_t;
    #[inline]
    unsafe fn as_signed(self) -> svint32x3_t {
        svint32x3_t(self.0 as i32)
    }
}

impl AsSigned for svuint32x4_t {
    type Signed = svint32x4_t;
    #[inline]
    unsafe fn as_signed(self) -> svint32x4_t {
        svint32x4_t(self.0 as i32)
    }
}

impl AsSigned for svuint64x2_t {
    type Signed = svint64x2_t;
    #[inline]
    unsafe fn as_signed(self) -> svint64x2_t {
        svint64x2_t(self.0 as i64)
    }
}

impl AsSigned for svuint64x3_t {
    type Signed = svint64x3_t;
    #[inline]
    unsafe fn as_signed(self) -> svint64x3_t {
        svint64x3_t(self.0 as i64)
    }
}

impl AsSigned for svuint64x4_t {
    type Signed = svint64x4_t;
    #[inline]
    unsafe fn as_signed(self) -> svint64x4_t {
        svint64x4_t(self.0 as i64)
    }
}

impl AsSigned for u8 {
    type Signed = i8;

    unsafe fn as_signed(self) -> Self::Signed {
        self as i8
    }
}

impl AsSigned for u16 {
    type Signed = i16;

    unsafe fn as_signed(self) -> Self::Signed {
        self as i16
    }
}

impl AsSigned for u32 {
    type Signed = i32;

    unsafe fn as_signed(self) -> Self::Signed {
        self as i32
    }
}

impl AsSigned for u64 {
    type Signed = i64;

    unsafe fn as_signed(self) -> Self::Signed {
        self as i64
    }
}

impl From<svbool_t> for svbool8_t {
    fn from(val: svbool_t) -> Self {
        // 将 svbool_t 转换为 svbool8_t，这里假设将 val 的值放入 svbool8_t 中。
        svbool8_t(val.0) // 根据实际的实现进行转换
    }
}

impl From<svbool8_t> for svbool_t {
    fn from(val: svbool8_t) -> Self {
        // 将 svbool8_t 转换为 svbool_t
        svbool_t(val.0) // 假设 val.0 是布尔值
    }
}

impl From<svbool_t> for svbool4_t {
    fn from(val: svbool_t) -> Self {
        // 将 svbool_t 转换为 svbool4_t
        svbool4_t(val.0) // 根据实际的实现进行转换
    }
}

impl From<svbool4_t> for svbool_t {
    fn from(val: svbool4_t) -> Self {
        // 将 svbool4_t 转换为 svbool_t
        svbool_t(val.0) // 假设 val.0 是布尔值
    }
}

impl From<svbool_t> for svbool2_t {
    fn from(val: svbool_t) -> Self {
        // 将 svbool_t 转换为 svbool2_t
        svbool2_t(val.0) // 根据实际的实现进行转换
    }
}

impl From<svbool2_t> for svbool_t {
    fn from(val: svbool2_t) -> Self {
        // 将 svbool2_t 转换为 svbool_t
        svbool_t(val.0) // 假设 val.0 是布尔值
    }
}

#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(and))]
pub fn svand_b_z(pg: svbool_t, op1: svbool_t, op2: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.and.z.nvx16i1")]
        fn _svand_b_z(pg: svbool_t, op1: svbool_t, op2: svbool_t) -> svbool_t;
    }
    unsafe { _svand_b_z(pg, op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cls))]
pub unsafe fn svcls_s32_m(inactive: svuint32_t, pg: svbool_t, op: svint32_t) -> svuint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cls.nxv4i32")]
        fn _svcls_s32_m(inactive: svint32_t, pg: svbool4_t, op: svint32_t) -> svint32_t;
    }
    unsafe { _svcls_s32_m(inactive.as_signed(), pg.into(), op).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cls))]
pub unsafe fn svcls_s32_x(pg: svbool_t, op: svint32_t) -> svuint32_t {
    unsafe { svcls_s32_m(op.as_unsigned(), pg, op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cls))]
pub unsafe fn svcls_s32_z(pg: svbool_t, op: svint32_t) -> svuint32_t {
    svcls_s32_m(svdup_n_u32(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cls))]
pub unsafe fn svcls_s64_m(inactive: svuint64_t, pg: svbool_t, op: svint64_t) -> svuint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cls.nxv2i64")]
        fn _svcls_s64_m(inactive: svint64_t, pg: svbool2_t, op: svint64_t) -> svint64_t;
    }
    unsafe { _svcls_s64_m(inactive.as_signed(), pg.into(), op).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cls))]
pub unsafe fn svcls_s64_x(pg: svbool_t, op: svint64_t) -> svuint64_t {
    unsafe { svcls_s64_m(op.as_unsigned(), pg, op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cls))]
pub unsafe fn svcls_s64_z(pg: svbool_t, op: svint64_t) -> svuint64_t {
    svcls_s64_m(svdup_n_u64(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clz))]
pub unsafe fn svclz_s8_m(inactive: svuint8_t, pg: svbool_t, op: svint8_t) -> svuint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.clz.nxv16i8")]
        fn _svclz_s8_m(inactive: svint8_t, pg: svbool_t, op: svint8_t) -> svint8_t;
    }
    unsafe { _svclz_s8_m(inactive.as_signed(), pg, op).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clz))]
pub unsafe fn svclz_s8_x(pg: svbool_t, op: svint8_t) -> svuint8_t {
    unsafe { svclz_s8_m(op.as_unsigned(), pg, op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clz))]
pub unsafe fn svclz_s8_z(pg: svbool_t, op: svint8_t) -> svuint8_t {
    svclz_s8_m(svdup_n_u8(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clz))]
pub unsafe fn svclz_s16_m(inactive: svuint16_t, pg: svbool_t, op: svint16_t) -> svuint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.clz.nxv8i16")]
        fn _svclz_s16_m(inactive: svint16_t, pg: svbool8_t, op: svint16_t) -> svint16_t;
    }
    unsafe { _svclz_s16_m(inactive.as_signed(), pg.into(), op).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clz))]
pub unsafe fn svclz_s16_x(pg: svbool_t, op: svint16_t) -> svuint16_t {
    unsafe { svclz_s16_m(op.as_unsigned(), pg, op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clz))]
pub unsafe fn svclz_s16_z(pg: svbool_t, op: svint16_t) -> svuint16_t {
    svclz_s16_m(svdup_n_u16(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clz))]
pub unsafe fn svclz_s32_m(inactive: svuint32_t, pg: svbool_t, op: svint32_t) -> svuint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.clz.nxv4i32")]
        fn _svclz_s32_m(inactive: svint32_t, pg: svbool4_t, op: svint32_t) -> svint32_t;
    }
    unsafe { _svclz_s32_m(inactive.as_signed(), pg.into(), op).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clz))]
pub unsafe fn svclz_s32_x(pg: svbool_t, op: svint32_t) -> svuint32_t {
    unsafe { svclz_s32_m(op.as_unsigned(), pg, op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clz))]
pub unsafe fn svclz_s32_z(pg: svbool_t, op: svint32_t) -> svuint32_t {
    svclz_s32_m(svdup_n_u32(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clz))]
pub unsafe fn svclz_s64_m(inactive: svuint64_t, pg: svbool_t, op: svint64_t) -> svuint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.clz.nxv2i64")]
        fn _svclz_s64_m(inactive: svint64_t, pg: svbool2_t, op: svint64_t) -> svint64_t;
    }
    unsafe { _svclz_s64_m(inactive.as_signed(), pg.into(), op).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clz))]
pub unsafe fn svclz_s64_x(pg: svbool_t, op: svint64_t) -> svuint64_t {
    unsafe { svclz_s64_m(op.as_unsigned(), pg, op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clz))]
pub unsafe fn svclz_s64_z(pg: svbool_t, op: svint64_t) -> svuint64_t {
    svclz_s64_m(svdup_n_u64(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clz))]
pub unsafe fn svclz_u8_m(inactive: svuint8_t, pg: svbool_t, op: svuint8_t) -> svuint8_t {
    unsafe { svclz_s8_m(inactive, pg, op.as_signed()) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clz))]
pub unsafe fn svclz_u8_x(pg: svbool_t, op: svuint8_t) -> svuint8_t {
    svclz_u8_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clz))]
pub unsafe fn svclz_u8_z(pg: svbool_t, op: svuint8_t) -> svuint8_t {
    svclz_u8_m(svdup_n_u8(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clz))]
pub unsafe fn svclz_u16_m(inactive: svuint16_t, pg: svbool_t, op: svuint16_t) -> svuint16_t {
    unsafe { svclz_s16_m(inactive, pg, op.as_signed()) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clz))]
pub unsafe fn svclz_u16_x(pg: svbool_t, op: svuint16_t) -> svuint16_t {
    svclz_u16_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clz))]
pub unsafe fn svclz_u16_z(pg: svbool_t, op: svuint16_t) -> svuint16_t {
    svclz_u16_m(svdup_n_u16(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clz))]
pub unsafe fn svclz_u32_m(inactive: svuint32_t, pg: svbool_t, op: svuint32_t) -> svuint32_t {
    unsafe { svclz_s32_m(inactive, pg, op.as_signed()) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clz))]
pub unsafe fn svclz_u32_x(pg: svbool_t, op: svuint32_t) -> svuint32_t {
    svclz_u32_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clz))]
pub unsafe fn svclz_u32_z(pg: svbool_t, op: svuint32_t) -> svuint32_t {
    svclz_u32_m(svdup_n_u32(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clz))]
pub unsafe fn svclz_u64_m(inactive: svuint64_t, pg: svbool_t, op: svuint64_t) -> svuint64_t {
    unsafe { svclz_s64_m(inactive, pg, op.as_signed()) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clz))]
pub unsafe fn svclz_u64_x(pg: svbool_t, op: svuint64_t) -> svuint64_t {
    svclz_u64_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clz))]
pub unsafe fn svclz_u64_z(pg: svbool_t, op: svuint64_t) -> svuint64_t {
    svclz_u64_m(svdup_n_u64(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcmla, IMM_ROTATION = 90))]
pub unsafe fn svcmla_f32_m<const IMM_ROTATION: i32>(
    pg: svbool_t,
    op1: svfloat32_t,
    op2: svfloat32_t,
    op3: svfloat32_t,
) -> svfloat32_t {
    static_assert!(
        IMM_ROTATION == 0 || IMM_ROTATION == 90 || IMM_ROTATION == 180 || IMM_ROTATION == 270
    );
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fcmla.nxv4f32")]
        fn _svcmla_f32_m(
            pg: svbool4_t,
            op1: svfloat32_t,
            op2: svfloat32_t,
            op3: svfloat32_t,
            imm_rotation: i32,
        ) -> svfloat32_t;
    }
    unsafe { _svcmla_f32_m(pg.into(), op1, op2, op3, IMM_ROTATION) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcmla, IMM_ROTATION = 90))]
pub unsafe fn svcmla_f32_x<const IMM_ROTATION: i32>(
    pg: svbool_t,
    op1: svfloat32_t,
    op2: svfloat32_t,
    op3: svfloat32_t,
) -> svfloat32_t {
    svcmla_f32_m::<IMM_ROTATION>(pg, op1, op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcmla, IMM_ROTATION = 90))]
pub unsafe fn svcmla_f32_z<const IMM_ROTATION: i32>(
    pg: svbool_t,
    op1: svfloat32_t,
    op2: svfloat32_t,
    op3: svfloat32_t,
) -> svfloat32_t {
    svcmla_f32_m::<IMM_ROTATION>(pg.clone(), svsel_f32(pg, op1, svdup_n_f32(0.0)), op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcmla, IMM_ROTATION = 90))]
pub unsafe fn svcmla_f64_m<const IMM_ROTATION: i32>(
    pg: svbool_t,
    op1: svfloat64_t,
    op2: svfloat64_t,
    op3: svfloat64_t,
) -> svfloat64_t {
    static_assert!(
        IMM_ROTATION == 0 || IMM_ROTATION == 90 || IMM_ROTATION == 180 || IMM_ROTATION == 270
    );
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fcmla.nxv2f64")]
        fn _svcmla_f64_m(
            pg: svbool2_t,
            op1: svfloat64_t,
            op2: svfloat64_t,
            op3: svfloat64_t,
            imm_rotation: i32,
        ) -> svfloat64_t;
    }
    unsafe { _svcmla_f64_m(pg.into(), op1, op2, op3, IMM_ROTATION) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcmla, IMM_ROTATION = 90))]
pub unsafe fn svcmla_f64_x<const IMM_ROTATION: i32>(
    pg: svbool_t,
    op1: svfloat64_t,
    op2: svfloat64_t,
    op3: svfloat64_t,
) -> svfloat64_t {
    svcmla_f64_m::<IMM_ROTATION>(pg, op1, op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcmla, IMM_ROTATION = 90))]
pub unsafe fn svcmla_f64_z<const IMM_ROTATION: i32>(
    pg: svbool_t,
    op1: svfloat64_t,
    op2: svfloat64_t,
    op3: svfloat64_t,
) -> svfloat64_t {
    svcmla_f64_m::<IMM_ROTATION>(pg.clone(), svsel_f64(pg, op1, svdup_n_f64(0.0)), op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcmla, IMM_INDEX = 0, IMM_ROTATION = 90))]
pub unsafe fn svcmla_lane_f32<const IMM_INDEX: i32, const IMM_ROTATION: i32>(
    op1: svfloat32_t,
    op2: svfloat32_t,
    op3: svfloat32_t,
) -> svfloat32_t {
    static_assert_range!(IMM_INDEX, 0, 1);
    static_assert!(
        IMM_ROTATION == 0 || IMM_ROTATION == 90 || IMM_ROTATION == 180 || IMM_ROTATION == 270
    );
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.fcmla.lane.x.nxv4f32"
        )]
        fn _svcmla_lane_f32(
            op1: svfloat32_t,
            op2: svfloat32_t,
            op3: svfloat32_t,
            imm_index: i32,
            imm_rotation: i32,
        ) -> svfloat32_t;
    }
    unsafe { _svcmla_lane_f32(op1, op2, op3, IMM_INDEX, IMM_ROTATION) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcmeq))]
pub unsafe fn svcmpeq_f32(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fcmpeq.nxv4f32")]
        fn _svcmpeq_f32(pg: svbool4_t, op1: svfloat32_t, op2: svfloat32_t) -> svbool4_t;
    }
    unsafe { _svcmpeq_f32(pg.into(), op1, op2).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcmeq))]
pub unsafe fn svcmpeq_n_f32(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svbool_t {
    svcmpeq_f32(pg, op1, svdup_n_f32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcmeq))]
pub unsafe fn svcmpeq_f64(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fcmpeq.nxv2f64")]
        fn _svcmpeq_f64(pg: svbool2_t, op1: svfloat64_t, op2: svfloat64_t) -> svbool2_t;
    }
    unsafe { _svcmpeq_f64(pg.into(), op1, op2).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcmeq))]
pub unsafe fn svcmpeq_n_f64(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svbool_t {
    svcmpeq_f64(pg, op1, svdup_n_f64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpeq))]
pub unsafe fn svcmpeq_s8(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cmpeq.nxv16i8")]
        fn _svcmpeq_s8(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svbool_t;
    }
    unsafe { _svcmpeq_s8(pg, op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpeq))]
pub unsafe fn svcmpeq_n_s8(pg: svbool_t, op1: svint8_t, op2: i8) -> svbool_t {
    svcmpeq_s8(pg, op1, svdup_n_s8(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpeq))]
pub unsafe fn svcmpeq_s16(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cmpeq.nxv8i16")]
        fn _svcmpeq_s16(pg: svbool8_t, op1: svint16_t, op2: svint16_t) -> svbool8_t;
    }
    unsafe { _svcmpeq_s16(pg.into(), op1, op2).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpeq))]
pub unsafe fn svcmpeq_n_s16(pg: svbool_t, op1: svint16_t, op2: i16) -> svbool_t {
    svcmpeq_s16(pg, op1, svdup_n_s16(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpeq))]
pub unsafe fn svcmpeq_s32(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cmpeq.nxv4i32")]
        fn _svcmpeq_s32(pg: svbool4_t, op1: svint32_t, op2: svint32_t) -> svbool4_t;
    }
    unsafe { _svcmpeq_s32(pg.into(), op1, op2).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpeq))]
pub unsafe fn svcmpeq_n_s32(pg: svbool_t, op1: svint32_t, op2: i32) -> svbool_t {
    svcmpeq_s32(pg, op1, svdup_n_s32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpeq))]
pub unsafe fn svcmpeq_s64(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cmpeq.nxv2i64")]
        fn _svcmpeq_s64(pg: svbool2_t, op1: svint64_t, op2: svint64_t) -> svbool2_t;
    }
    unsafe { _svcmpeq_s64(pg.into(), op1, op2).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpeq))]
pub unsafe fn svcmpeq_n_s64(pg: svbool_t, op1: svint64_t, op2: i64) -> svbool_t {
    svcmpeq_s64(pg, op1, svdup_n_s64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpeq))]
pub unsafe fn svcmpeq_u8(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svbool_t {
    unsafe { svcmpeq_s8(pg, op1.as_signed(), op2.as_signed()) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpeq))]
pub unsafe fn svcmpeq_n_u8(pg: svbool_t, op1: svuint8_t, op2: u8) -> svbool_t {
    svcmpeq_u8(pg, op1, svdup_n_u8(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpeq))]
pub unsafe fn svcmpeq_u16(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svbool_t {
    unsafe { svcmpeq_s16(pg, op1.as_signed(), op2.as_signed()) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpeq))]
pub unsafe fn svcmpeq_n_u16(pg: svbool_t, op1: svuint16_t, op2: u16) -> svbool_t {
    svcmpeq_u16(pg, op1, svdup_n_u16(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpeq))]
pub unsafe fn svcmpeq_u32(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svbool_t {
    unsafe { svcmpeq_s32(pg, op1.as_signed(), op2.as_signed()) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpeq))]
pub unsafe fn svcmpeq_n_u32(pg: svbool_t, op1: svuint32_t, op2: u32) -> svbool_t {
    svcmpeq_u32(pg, op1, svdup_n_u32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpeq))]
pub unsafe fn svcmpeq_u64(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svbool_t {
    unsafe { svcmpeq_s64(pg, op1.as_signed(), op2.as_signed()) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpeq))]
pub unsafe fn svcmpeq_n_u64(pg: svbool_t, op1: svuint64_t, op2: u64) -> svbool_t {
    svcmpeq_u64(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpeq))]
pub unsafe fn svcmpeq_wide_s8(pg: svbool_t, op1: svint8_t, op2: svint64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.cmpeq.wide.nxv16i8"
        )]
        fn _svcmpeq_wide_s8(pg: svbool_t, op1: svint8_t, op2: svint64_t) -> svbool_t;
    }
    unsafe { _svcmpeq_wide_s8(pg, op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpeq))]
pub unsafe fn svcmpeq_wide_n_s8(pg: svbool_t, op1: svint8_t, op2: i64) -> svbool_t {
    svcmpeq_wide_s8(pg, op1, svdup_n_s64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpeq))]
pub unsafe fn svcmpeq_wide_s16(pg: svbool_t, op1: svint16_t, op2: svint64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.cmpeq.wide.nxv8i16"
        )]
        fn _svcmpeq_wide_s16(pg: svbool8_t, op1: svint16_t, op2: svint64_t) -> svbool8_t;
    }
    unsafe { _svcmpeq_wide_s16(pg.into(), op1, op2).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpeq))]
pub unsafe fn svcmpeq_wide_n_s16(pg: svbool_t, op1: svint16_t, op2: i64) -> svbool_t {
    svcmpeq_wide_s16(pg, op1, svdup_n_s64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpeq))]
pub unsafe fn svcmpeq_wide_s32(pg: svbool_t, op1: svint32_t, op2: svint64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.cmpeq.wide.nxv4i32"
        )]
        fn _svcmpeq_wide_s32(pg: svbool4_t, op1: svint32_t, op2: svint64_t) -> svbool4_t;
    }
    unsafe { _svcmpeq_wide_s32(pg.into(), op1, op2).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpeq))]
pub unsafe fn svcmpeq_wide_n_s32(pg: svbool_t, op1: svint32_t, op2: i64) -> svbool_t {
    svcmpeq_wide_s32(pg, op1, svdup_n_s64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcmge))]
pub unsafe fn svcmpge_f32(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fcmpge.nxv4f32")]
        fn _svcmpge_f32(pg: svbool4_t, op1: svfloat32_t, op2: svfloat32_t) -> svbool4_t;
    }
    unsafe { _svcmpge_f32(pg.into(), op1, op2).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcmge))]
pub unsafe fn svcmpge_n_f32(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svbool_t {
    svcmpge_f32(pg, op1, svdup_n_f32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcmge))]
pub unsafe fn svcmpge_f64(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fcmpge.nxv2f64")]
        fn _svcmpge_f64(pg: svbool2_t, op1: svfloat64_t, op2: svfloat64_t) -> svbool2_t;
    }
    unsafe { _svcmpge_f64(pg.into(), op1, op2).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcmge))]
pub unsafe fn svcmpge_n_f64(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svbool_t {
    svcmpge_f64(pg, op1, svdup_n_f64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpge))]
pub unsafe fn svcmpge_s8(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cmpge.nxv16i8")]
        fn _svcmpge_s8(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svbool_t;
    }
    unsafe { _svcmpge_s8(pg, op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpge))]
pub unsafe fn svcmpge_n_s8(pg: svbool_t, op1: svint8_t, op2: i8) -> svbool_t {
    svcmpge_s8(pg, op1, svdup_n_s8(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpge))]
pub unsafe fn svcmpge_s16(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cmpge.nxv8i16")]
        fn _svcmpge_s16(pg: svbool8_t, op1: svint16_t, op2: svint16_t) -> svbool8_t;
    }
    unsafe { _svcmpge_s16(pg.into(), op1, op2).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpge))]
pub unsafe fn svcmpge_n_s16(pg: svbool_t, op1: svint16_t, op2: i16) -> svbool_t {
    svcmpge_s16(pg, op1, svdup_n_s16(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpge))]
pub unsafe fn svcmpge_s32(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cmpge.nxv4i32")]
        fn _svcmpge_s32(pg: svbool4_t, op1: svint32_t, op2: svint32_t) -> svbool4_t;
    }
    unsafe { _svcmpge_s32(pg.into(), op1, op2).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpge))]
pub unsafe fn svcmpge_n_s32(pg: svbool_t, op1: svint32_t, op2: i32) -> svbool_t {
    svcmpge_s32(pg, op1, svdup_n_s32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpge))]
pub unsafe fn svcmpge_s64(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cmpge.nxv2i64")]
        fn _svcmpge_s64(pg: svbool2_t, op1: svint64_t, op2: svint64_t) -> svbool2_t;
    }
    unsafe { _svcmpge_s64(pg.into(), op1, op2).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpge))]
pub unsafe fn svcmpge_n_s64(pg: svbool_t, op1: svint64_t, op2: i64) -> svbool_t {
    svcmpge_s64(pg, op1, svdup_n_s64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphs))]
pub unsafe fn svcmpge_u8(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cmphs.nxv16i8")]
        fn _svcmpge_u8(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svbool_t;
    }
    unsafe { _svcmpge_u8(pg, op1.as_signed(), op2.as_signed()) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphs))]
pub unsafe fn svcmpge_n_u8(pg: svbool_t, op1: svuint8_t, op2: u8) -> svbool_t {
    svcmpge_u8(pg, op1, svdup_n_u8(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphs))]
pub unsafe fn svcmpge_u16(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cmphs.nxv8i16")]
        fn _svcmpge_u16(pg: svbool8_t, op1: svint16_t, op2: svint16_t) -> svbool8_t;
    }
    unsafe { _svcmpge_u16(pg.into(), op1.as_signed(), op2.as_signed()).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphs))]
pub unsafe fn svcmpge_n_u16(pg: svbool_t, op1: svuint16_t, op2: u16) -> svbool_t {
    svcmpge_u16(pg, op1, svdup_n_u16(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphs))]
pub unsafe fn svcmpge_u32(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cmphs.nxv4i32")]
        fn _svcmpge_u32(pg: svbool4_t, op1: svint32_t, op2: svint32_t) -> svbool4_t;
    }
    unsafe { _svcmpge_u32(pg.into(), op1.as_signed(), op2.as_signed()).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphs))]
pub unsafe fn svcmpge_n_u32(pg: svbool_t, op1: svuint32_t, op2: u32) -> svbool_t {
    svcmpge_u32(pg, op1, svdup_n_u32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphs))]
pub unsafe fn svcmpge_u64(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cmphs.nxv2i64")]
        fn _svcmpge_u64(pg: svbool2_t, op1: svint64_t, op2: svint64_t) -> svbool2_t;
    }
    unsafe { _svcmpge_u64(pg.into(), op1.as_signed(), op2.as_signed()).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphs))]
pub unsafe fn svcmpge_n_u64(pg: svbool_t, op1: svuint64_t, op2: u64) -> svbool_t {
    svcmpge_u64(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpge))]
pub unsafe fn svcmpge_wide_s8(pg: svbool_t, op1: svint8_t, op2: svint64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.cmpge.wide.nxv16i8"
        )]
        fn _svcmpge_wide_s8(pg: svbool_t, op1: svint8_t, op2: svint64_t) -> svbool_t;
    }
    unsafe { _svcmpge_wide_s8(pg, op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpge))]
pub unsafe fn svcmpge_wide_n_s8(pg: svbool_t, op1: svint8_t, op2: i64) -> svbool_t {
    svcmpge_wide_s8(pg, op1, svdup_n_s64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpge))]
pub unsafe fn svcmpge_wide_s16(pg: svbool_t, op1: svint16_t, op2: svint64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.cmpge.wide.nxv8i16"
        )]
        fn _svcmpge_wide_s16(pg: svbool8_t, op1: svint16_t, op2: svint64_t) -> svbool8_t;
    }
    unsafe { _svcmpge_wide_s16(pg.into(), op1, op2).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpge))]
pub unsafe fn svcmpge_wide_n_s16(pg: svbool_t, op1: svint16_t, op2: i64) -> svbool_t {
    svcmpge_wide_s16(pg, op1, svdup_n_s64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpge))]
pub unsafe fn svcmpge_wide_s32(pg: svbool_t, op1: svint32_t, op2: svint64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.cmpge.wide.nxv4i32"
        )]
        fn _svcmpge_wide_s32(pg: svbool4_t, op1: svint32_t, op2: svint64_t) -> svbool4_t;
    }
    unsafe { _svcmpge_wide_s32(pg.into(), op1, op2).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpge))]
pub unsafe fn svcmpge_wide_n_s32(pg: svbool_t, op1: svint32_t, op2: i64) -> svbool_t {
    svcmpge_wide_s32(pg, op1, svdup_n_s64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphs))]
pub unsafe fn svcmpge_wide_u8(pg: svbool_t, op1: svuint8_t, op2: svuint64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.cmphs.wide.nxv16i8"
        )]
        fn _svcmpge_wide_u8(pg: svbool_t, op1: svint8_t, op2: svint64_t) -> svbool_t;
    }
    unsafe { _svcmpge_wide_u8(pg, op1.as_signed(), op2.as_signed()) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphs))]
pub unsafe fn svcmpge_wide_n_u8(pg: svbool_t, op1: svuint8_t, op2: u64) -> svbool_t {
    svcmpge_wide_u8(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphs))]
pub unsafe fn svcmpge_wide_u16(pg: svbool_t, op1: svuint16_t, op2: svuint64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.cmphs.wide.nxv8i16"
        )]
        fn _svcmpge_wide_u16(pg: svbool8_t, op1: svint16_t, op2: svint64_t) -> svbool8_t;
    }
    unsafe { _svcmpge_wide_u16(pg.into(), op1.as_signed(), op2.as_signed()).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphs))]
pub unsafe fn svcmpge_wide_n_u16(pg: svbool_t, op1: svuint16_t, op2: u64) -> svbool_t {
    svcmpge_wide_u16(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphs))]
pub unsafe fn svcmpge_wide_u32(pg: svbool_t, op1: svuint32_t, op2: svuint64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.cmphs.wide.nxv4i32"
        )]
        fn _svcmpge_wide_u32(pg: svbool4_t, op1: svint32_t, op2: svint64_t) -> svbool4_t;
    }
    unsafe { _svcmpge_wide_u32(pg.into(), op1.as_signed(), op2.as_signed()).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphs))]
pub unsafe fn svcmpge_wide_n_u32(pg: svbool_t, op1: svuint32_t, op2: u64) -> svbool_t {
    svcmpge_wide_u32(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcmgt))]
pub unsafe fn svcmpgt_f32(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fcmpgt.nxv4f32")]
        fn _svcmpgt_f32(pg: svbool4_t, op1: svfloat32_t, op2: svfloat32_t) -> svbool4_t;
    }
    unsafe { _svcmpgt_f32(pg.into(), op1, op2).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcmgt))]
pub unsafe fn svcmpgt_n_f32(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svbool_t {
    svcmpgt_f32(pg, op1, svdup_n_f32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcmgt))]
pub unsafe fn svcmpgt_f64(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fcmpgt.nxv2f64")]
        fn _svcmpgt_f64(pg: svbool2_t, op1: svfloat64_t, op2: svfloat64_t) -> svbool2_t;
    }
    unsafe { _svcmpgt_f64(pg.into(), op1, op2).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcmgt))]
pub unsafe fn svcmpgt_n_f64(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svbool_t {
    svcmpgt_f64(pg, op1, svdup_n_f64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpgt))]
pub unsafe fn svcmpgt_s8(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cmpgt.nxv16i8")]
        fn _svcmpgt_s8(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svbool_t;
    }
    unsafe { _svcmpgt_s8(pg, op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpgt))]
pub unsafe fn svcmpgt_n_s8(pg: svbool_t, op1: svint8_t, op2: i8) -> svbool_t {
    svcmpgt_s8(pg, op1, svdup_n_s8(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpgt))]
pub unsafe fn svcmpgt_s16(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cmpgt.nxv8i16")]
        fn _svcmpgt_s16(pg: svbool8_t, op1: svint16_t, op2: svint16_t) -> svbool8_t;
    }
    unsafe { _svcmpgt_s16(pg.into(), op1, op2).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpgt))]
pub unsafe fn svcmpgt_n_s16(pg: svbool_t, op1: svint16_t, op2: i16) -> svbool_t {
    svcmpgt_s16(pg, op1, svdup_n_s16(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpgt))]
pub unsafe fn svcmpgt_s32(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cmpgt.nxv4i32")]
        fn _svcmpgt_s32(pg: svbool4_t, op1: svint32_t, op2: svint32_t) -> svbool4_t;
    }
    unsafe { _svcmpgt_s32(pg.into(), op1, op2).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpgt))]
pub unsafe fn svcmpgt_n_s32(pg: svbool_t, op1: svint32_t, op2: i32) -> svbool_t {
    svcmpgt_s32(pg, op1, svdup_n_s32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpgt))]
pub unsafe fn svcmpgt_s64(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cmpgt.nxv2i64")]
        fn _svcmpgt_s64(pg: svbool2_t, op1: svint64_t, op2: svint64_t) -> svbool2_t;
    }
    unsafe { _svcmpgt_s64(pg.into(), op1, op2).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpgt))]
pub unsafe fn svcmpgt_n_s64(pg: svbool_t, op1: svint64_t, op2: i64) -> svbool_t {
    svcmpgt_s64(pg, op1, svdup_n_s64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphi))]
pub unsafe fn svcmpgt_u8(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cmphi.nxv16i8")]
        fn _svcmpgt_u8(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svbool_t;
    }
    unsafe { _svcmpgt_u8(pg, op1.as_signed(), op2.as_signed()) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphi))]
pub unsafe fn svcmpgt_n_u8(pg: svbool_t, op1: svuint8_t, op2: u8) -> svbool_t {
    svcmpgt_u8(pg, op1, svdup_n_u8(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphi))]
pub unsafe fn svcmpgt_u16(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cmphi.nxv8i16")]
        fn _svcmpgt_u16(pg: svbool8_t, op1: svint16_t, op2: svint16_t) -> svbool8_t;
    }
    unsafe { _svcmpgt_u16(pg.into(), op1.as_signed(), op2.as_signed()).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphi))]
pub unsafe fn svcmpgt_n_u16(pg: svbool_t, op1: svuint16_t, op2: u16) -> svbool_t {
    svcmpgt_u16(pg, op1, svdup_n_u16(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphi))]
pub unsafe fn svcmpgt_u32(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cmphi.nxv4i32")]
        fn _svcmpgt_u32(pg: svbool4_t, op1: svint32_t, op2: svint32_t) -> svbool4_t;
    }
    unsafe { _svcmpgt_u32(pg.into(), op1.as_signed(), op2.as_signed()).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphi))]
pub unsafe fn svcmpgt_n_u32(pg: svbool_t, op1: svuint32_t, op2: u32) -> svbool_t {
    svcmpgt_u32(pg, op1, svdup_n_u32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphi))]
pub unsafe fn svcmpgt_u64(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cmphi.nxv2i64")]
        fn _svcmpgt_u64(pg: svbool2_t, op1: svint64_t, op2: svint64_t) -> svbool2_t;
    }
    unsafe { _svcmpgt_u64(pg.into(), op1.as_signed(), op2.as_signed()).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphi))]
pub unsafe fn svcmpgt_n_u64(pg: svbool_t, op1: svuint64_t, op2: u64) -> svbool_t {
    svcmpgt_u64(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpgt))]
pub unsafe fn svcmpgt_wide_s8(pg: svbool_t, op1: svint8_t, op2: svint64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.cmpgt.wide.nxv16i8"
        )]
        fn _svcmpgt_wide_s8(pg: svbool_t, op1: svint8_t, op2: svint64_t) -> svbool_t;
    }
    unsafe { _svcmpgt_wide_s8(pg, op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpgt))]
pub unsafe fn svcmpgt_wide_n_s8(pg: svbool_t, op1: svint8_t, op2: i64) -> svbool_t {
    svcmpgt_wide_s8(pg, op1, svdup_n_s64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpgt))]
pub unsafe fn svcmpgt_wide_s16(pg: svbool_t, op1: svint16_t, op2: svint64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.cmpgt.wide.nxv8i16"
        )]
        fn _svcmpgt_wide_s16(pg: svbool8_t, op1: svint16_t, op2: svint64_t) -> svbool8_t;
    }
    unsafe { _svcmpgt_wide_s16(pg.into(), op1, op2).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpgt))]
pub unsafe fn svcmpgt_wide_n_s16(pg: svbool_t, op1: svint16_t, op2: i64) -> svbool_t {
    svcmpgt_wide_s16(pg, op1, svdup_n_s64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpgt))]
pub unsafe fn svcmpgt_wide_s32(pg: svbool_t, op1: svint32_t, op2: svint64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.cmpgt.wide.nxv4i32"
        )]
        fn _svcmpgt_wide_s32(pg: svbool4_t, op1: svint32_t, op2: svint64_t) -> svbool4_t;
    }
    unsafe { _svcmpgt_wide_s32(pg.into(), op1, op2).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpgt))]
pub unsafe fn svcmpgt_wide_n_s32(pg: svbool_t, op1: svint32_t, op2: i64) -> svbool_t {
    svcmpgt_wide_s32(pg, op1, svdup_n_s64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphi))]
pub unsafe fn svcmpgt_wide_u8(pg: svbool_t, op1: svuint8_t, op2: svuint64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.cmphi.wide.nxv16i8"
        )]
        fn _svcmpgt_wide_u8(pg: svbool_t, op1: svint8_t, op2: svint64_t) -> svbool_t;
    }
    unsafe { _svcmpgt_wide_u8(pg, op1.as_signed(), op2.as_signed()) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphi))]
pub unsafe fn svcmpgt_wide_n_u8(pg: svbool_t, op1: svuint8_t, op2: u64) -> svbool_t {
    svcmpgt_wide_u8(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphi))]
pub unsafe fn svcmpgt_wide_u16(pg: svbool_t, op1: svuint16_t, op2: svuint64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.cmphi.wide.nxv8i16"
        )]
        fn _svcmpgt_wide_u16(pg: svbool8_t, op1: svint16_t, op2: svint64_t) -> svbool8_t;
    }
    unsafe { _svcmpgt_wide_u16(pg.into(), op1.as_signed(), op2.as_signed()).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphi))]
pub unsafe fn svcmpgt_wide_n_u16(pg: svbool_t, op1: svuint16_t, op2: u64) -> svbool_t {
    svcmpgt_wide_u16(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphi))]
pub unsafe fn svcmpgt_wide_u32(pg: svbool_t, op1: svuint32_t, op2: svuint64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.cmphi.wide.nxv4i32"
        )]
        fn _svcmpgt_wide_u32(pg: svbool4_t, op1: svint32_t, op2: svint64_t) -> svbool4_t;
    }
    unsafe { _svcmpgt_wide_u32(pg.into(), op1.as_signed(), op2.as_signed()).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphi))]
pub unsafe fn svcmpgt_wide_n_u32(pg: svbool_t, op1: svuint32_t, op2: u64) -> svbool_t {
    svcmpgt_wide_u32(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcmge))]
pub unsafe fn svcmple_f32(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svbool_t {
    svcmpge_f32(pg, op2, op1)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcmge))]
pub unsafe fn svcmple_n_f32(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svbool_t {
    svcmple_f32(pg, op1, svdup_n_f32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcmge))]
pub unsafe fn svcmple_f64(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svbool_t {
    svcmpge_f64(pg, op2, op1)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcmge))]
pub unsafe fn svcmple_n_f64(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svbool_t {
    svcmple_f64(pg, op1, svdup_n_f64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpge))]
pub unsafe fn svcmple_s8(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svbool_t {
    svcmpge_s8(pg, op2, op1)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpge))]
pub unsafe fn svcmple_n_s8(pg: svbool_t, op1: svint8_t, op2: i8) -> svbool_t {
    svcmple_s8(pg, op1, svdup_n_s8(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpge))]
pub unsafe fn svcmple_s16(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svbool_t {
    svcmpge_s16(pg, op2, op1)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpge))]
pub unsafe fn svcmple_n_s16(pg: svbool_t, op1: svint16_t, op2: i16) -> svbool_t {
    svcmple_s16(pg, op1, svdup_n_s16(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpge))]
pub unsafe fn svcmple_s32(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svbool_t {
    svcmpge_s32(pg, op2, op1)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpge))]
pub unsafe fn svcmple_n_s32(pg: svbool_t, op1: svint32_t, op2: i32) -> svbool_t {
    svcmple_s32(pg, op1, svdup_n_s32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpge))]
pub unsafe fn svcmple_s64(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svbool_t {
    svcmpge_s64(pg, op2, op1)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpge))]
pub unsafe fn svcmple_n_s64(pg: svbool_t, op1: svint64_t, op2: i64) -> svbool_t {
    svcmple_s64(pg, op1, svdup_n_s64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphs))]
pub unsafe fn svcmple_u8(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svbool_t {
    svcmpge_u8(pg, op2, op1)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphs))]
pub unsafe fn svcmple_n_u8(pg: svbool_t, op1: svuint8_t, op2: u8) -> svbool_t {
    svcmple_u8(pg, op1, svdup_n_u8(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphs))]
pub unsafe fn svcmple_u16(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svbool_t {
    svcmpge_u16(pg, op2, op1)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphs))]
pub unsafe fn svcmple_n_u16(pg: svbool_t, op1: svuint16_t, op2: u16) -> svbool_t {
    svcmple_u16(pg, op1, svdup_n_u16(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphs))]
pub unsafe fn svcmple_u32(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svbool_t {
    svcmpge_u32(pg, op2, op1)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphs))]
pub unsafe fn svcmple_n_u32(pg: svbool_t, op1: svuint32_t, op2: u32) -> svbool_t {
    svcmple_u32(pg, op1, svdup_n_u32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphs))]
pub unsafe fn svcmple_u64(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svbool_t {
    svcmpge_u64(pg, op2, op1)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphs))]
pub unsafe fn svcmple_n_u64(pg: svbool_t, op1: svuint64_t, op2: u64) -> svbool_t {
    svcmple_u64(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmple))]
pub unsafe fn svcmple_wide_s8(pg: svbool_t, op1: svint8_t, op2: svint64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.cmple.wide.nxv16i8"
        )]
        fn _svcmple_wide_s8(pg: svbool_t, op1: svint8_t, op2: svint64_t) -> svbool_t;
    }
    unsafe { _svcmple_wide_s8(pg, op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmple))]
pub unsafe fn svcmple_wide_n_s8(pg: svbool_t, op1: svint8_t, op2: i64) -> svbool_t {
    svcmple_wide_s8(pg, op1, svdup_n_s64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmple))]
pub unsafe fn svcmple_wide_s16(pg: svbool_t, op1: svint16_t, op2: svint64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.cmple.wide.nxv8i16"
        )]
        fn _svcmple_wide_s16(pg: svbool8_t, op1: svint16_t, op2: svint64_t) -> svbool8_t;
    }
    unsafe { _svcmple_wide_s16(pg.into(), op1, op2).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmple))]
pub unsafe fn svcmple_wide_n_s16(pg: svbool_t, op1: svint16_t, op2: i64) -> svbool_t {
    svcmple_wide_s16(pg, op1, svdup_n_s64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmple))]
pub unsafe fn svcmple_wide_s32(pg: svbool_t, op1: svint32_t, op2: svint64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.cmple.wide.nxv4i32"
        )]
        fn _svcmple_wide_s32(pg: svbool4_t, op1: svint32_t, op2: svint64_t) -> svbool4_t;
    }
    unsafe { _svcmple_wide_s32(pg.into(), op1, op2).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmple))]
pub unsafe fn svcmple_wide_n_s32(pg: svbool_t, op1: svint32_t, op2: i64) -> svbool_t {
    svcmple_wide_s32(pg, op1, svdup_n_s64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpls))]
pub unsafe fn svcmple_wide_u8(pg: svbool_t, op1: svuint8_t, op2: svuint64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.cmpls.wide.nxv16i8"
        )]
        fn _svcmple_wide_u8(pg: svbool_t, op1: svint8_t, op2: svint64_t) -> svbool_t;
    }
    unsafe { _svcmple_wide_u8(pg, op1.as_signed(), op2.as_signed()) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpls))]
pub unsafe fn svcmple_wide_n_u8(pg: svbool_t, op1: svuint8_t, op2: u64) -> svbool_t {
    svcmple_wide_u8(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpls))]
pub unsafe fn svcmple_wide_u16(pg: svbool_t, op1: svuint16_t, op2: svuint64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.cmpls.wide.nxv8i16"
        )]
        fn _svcmple_wide_u16(pg: svbool8_t, op1: svint16_t, op2: svint64_t) -> svbool8_t;
    }
    unsafe { _svcmple_wide_u16(pg.into(), op1.as_signed(), op2.as_signed()).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpls))]
pub unsafe fn svcmple_wide_n_u16(pg: svbool_t, op1: svuint16_t, op2: u64) -> svbool_t {
    svcmple_wide_u16(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpls))]
pub unsafe fn svcmple_wide_u32(pg: svbool_t, op1: svuint32_t, op2: svuint64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.cmpls.wide.nxv4i32"
        )]
        fn _svcmple_wide_u32(pg: svbool4_t, op1: svint32_t, op2: svint64_t) -> svbool4_t;
    }
    unsafe { _svcmple_wide_u32(pg.into(), op1.as_signed(), op2.as_signed()).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpls))]
pub unsafe fn svcmple_wide_n_u32(pg: svbool_t, op1: svuint32_t, op2: u64) -> svbool_t {
    svcmple_wide_u32(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcmgt))]
pub unsafe fn svcmplt_f32(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svbool_t {
    svcmpgt_f32(pg, op2, op1)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcmgt))]
pub unsafe fn svcmplt_n_f32(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svbool_t {
    svcmplt_f32(pg, op1, svdup_n_f32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcmgt))]
pub unsafe fn svcmplt_f64(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svbool_t {
    svcmpgt_f64(pg, op2, op1)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcmgt))]
pub unsafe fn svcmplt_n_f64(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svbool_t {
    svcmplt_f64(pg, op1, svdup_n_f64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpgt))]
pub unsafe fn svcmplt_s8(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svbool_t {
    svcmpgt_s8(pg, op2, op1)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpgt))]
pub unsafe fn svcmplt_n_s8(pg: svbool_t, op1: svint8_t, op2: i8) -> svbool_t {
    svcmplt_s8(pg, op1, svdup_n_s8(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpgt))]
pub unsafe fn svcmplt_s16(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svbool_t {
    svcmpgt_s16(pg, op2, op1)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpgt))]
pub unsafe fn svcmplt_n_s16(pg: svbool_t, op1: svint16_t, op2: i16) -> svbool_t {
    svcmplt_s16(pg, op1, svdup_n_s16(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpgt))]
pub unsafe fn svcmplt_s32(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svbool_t {
    svcmpgt_s32(pg, op2, op1)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpgt))]
pub unsafe fn svcmplt_n_s32(pg: svbool_t, op1: svint32_t, op2: i32) -> svbool_t {
    svcmplt_s32(pg, op1, svdup_n_s32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpgt))]
pub unsafe fn svcmplt_s64(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svbool_t {
    svcmpgt_s64(pg, op2, op1)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpgt))]
pub unsafe fn svcmplt_n_s64(pg: svbool_t, op1: svint64_t, op2: i64) -> svbool_t {
    svcmplt_s64(pg, op1, svdup_n_s64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphi))]
pub unsafe fn svcmplt_u8(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svbool_t {
    svcmpgt_u8(pg, op2, op1)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphi))]
pub unsafe fn svcmplt_n_u8(pg: svbool_t, op1: svuint8_t, op2: u8) -> svbool_t {
    svcmplt_u8(pg, op1, svdup_n_u8(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphi))]
pub unsafe fn svcmplt_u16(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svbool_t {
    svcmpgt_u16(pg, op2, op1)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphi))]
pub unsafe fn svcmplt_n_u16(pg: svbool_t, op1: svuint16_t, op2: u16) -> svbool_t {
    svcmplt_u16(pg, op1, svdup_n_u16(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphi))]
pub unsafe fn svcmplt_u32(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svbool_t {
    svcmpgt_u32(pg, op2, op1)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphi))]
pub unsafe fn svcmplt_n_u32(pg: svbool_t, op1: svuint32_t, op2: u32) -> svbool_t {
    svcmplt_u32(pg, op1, svdup_n_u32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphi))]
pub unsafe fn svcmplt_u64(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svbool_t {
    svcmpgt_u64(pg, op2, op1)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphi))]
pub unsafe fn svcmplt_n_u64(pg: svbool_t, op1: svuint64_t, op2: u64) -> svbool_t {
    svcmplt_u64(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmplt))]
pub unsafe fn svcmplt_wide_s8(pg: svbool_t, op1: svint8_t, op2: svint64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.cmplt.wide.nxv16i8"
        )]
        fn _svcmplt_wide_s8(pg: svbool_t, op1: svint8_t, op2: svint64_t) -> svbool_t;
    }
    unsafe { _svcmplt_wide_s8(pg, op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmplt))]
pub unsafe fn svcmplt_wide_n_s8(pg: svbool_t, op1: svint8_t, op2: i64) -> svbool_t {
    svcmplt_wide_s8(pg, op1, svdup_n_s64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmplt))]
pub unsafe fn svcmplt_wide_s16(pg: svbool_t, op1: svint16_t, op2: svint64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.cmplt.wide.nxv8i16"
        )]
        fn _svcmplt_wide_s16(pg: svbool8_t, op1: svint16_t, op2: svint64_t) -> svbool8_t;
    }
    unsafe { _svcmplt_wide_s16(pg.into(), op1, op2).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmplt))]
pub unsafe fn svcmplt_wide_n_s16(pg: svbool_t, op1: svint16_t, op2: i64) -> svbool_t {
    svcmplt_wide_s16(pg, op1, svdup_n_s64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmplt))]
pub unsafe fn svcmplt_wide_s32(pg: svbool_t, op1: svint32_t, op2: svint64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.cmplt.wide.nxv4i32"
        )]
        fn _svcmplt_wide_s32(pg: svbool4_t, op1: svint32_t, op2: svint64_t) -> svbool4_t;
    }
    unsafe { _svcmplt_wide_s32(pg.into(), op1, op2).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmplt))]
pub unsafe fn svcmplt_wide_n_s32(pg: svbool_t, op1: svint32_t, op2: i64) -> svbool_t {
    svcmplt_wide_s32(pg, op1, svdup_n_s64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmplo))]
pub unsafe fn svcmplt_wide_u8(pg: svbool_t, op1: svuint8_t, op2: svuint64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.cmplo.wide.nxv16i8"
        )]
        fn _svcmplt_wide_u8(pg: svbool_t, op1: svint8_t, op2: svint64_t) -> svbool_t;
    }
    unsafe { _svcmplt_wide_u8(pg, op1.as_signed(), op2.as_signed()) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmplo))]
pub unsafe fn svcmplt_wide_n_u8(pg: svbool_t, op1: svuint8_t, op2: u64) -> svbool_t {
    svcmplt_wide_u8(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmplo))]
pub unsafe fn svcmplt_wide_u16(pg: svbool_t, op1: svuint16_t, op2: svuint64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.cmplo.wide.nxv8i16"
        )]
        fn _svcmplt_wide_u16(pg: svbool8_t, op1: svint16_t, op2: svint64_t) -> svbool8_t;
    }
    unsafe { _svcmplt_wide_u16(pg.into(), op1.as_signed(), op2.as_signed()).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmplo))]
pub unsafe fn svcmplt_wide_n_u16(pg: svbool_t, op1: svuint16_t, op2: u64) -> svbool_t {
    svcmplt_wide_u16(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmplo))]
pub unsafe fn svcmplt_wide_u32(pg: svbool_t, op1: svuint32_t, op2: svuint64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.cmplo.wide.nxv4i32"
        )]
        fn _svcmplt_wide_u32(pg: svbool4_t, op1: svint32_t, op2: svint64_t) -> svbool4_t;
    }
    unsafe { _svcmplt_wide_u32(pg.into(), op1.as_signed(), op2.as_signed()).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmplo))]
pub unsafe fn svcmplt_wide_n_u32(pg: svbool_t, op1: svuint32_t, op2: u64) -> svbool_t {
    svcmplt_wide_u32(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcmne))]
pub unsafe fn svcmpne_f32(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fcmpne.nxv4f32")]
        fn _svcmpne_f32(pg: svbool4_t, op1: svfloat32_t, op2: svfloat32_t) -> svbool4_t;
    }
    unsafe { _svcmpne_f32(pg.into(), op1, op2).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcmne))]
pub unsafe fn svcmpne_n_f32(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svbool_t {
    svcmpne_f32(pg, op1, svdup_n_f32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcmne))]
pub unsafe fn svcmpne_f64(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fcmpne.nxv2f64")]
        fn _svcmpne_f64(pg: svbool2_t, op1: svfloat64_t, op2: svfloat64_t) -> svbool2_t;
    }
    unsafe { _svcmpne_f64(pg.into(), op1, op2).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcmne))]
pub unsafe fn svcmpne_n_f64(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svbool_t {
    svcmpne_f64(pg, op1, svdup_n_f64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpne))]
pub unsafe fn svcmpne_s8(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cmpne.nxv16i8")]
        fn _svcmpne_s8(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svbool_t;
    }
    unsafe { _svcmpne_s8(pg, op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpne))]
pub unsafe fn svcmpne_n_s8(pg: svbool_t, op1: svint8_t, op2: i8) -> svbool_t {
    svcmpne_s8(pg, op1, svdup_n_s8(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpne))]
pub unsafe fn svcmpne_s16(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cmpne.nxv8i16")]
        fn _svcmpne_s16(pg: svbool8_t, op1: svint16_t, op2: svint16_t) -> svbool8_t;
    }
    unsafe { _svcmpne_s16(pg.into(), op1, op2).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpne))]
pub unsafe fn svcmpne_n_s16(pg: svbool_t, op1: svint16_t, op2: i16) -> svbool_t {
    svcmpne_s16(pg, op1, svdup_n_s16(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpne))]
pub unsafe fn svcmpne_s32(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cmpne.nxv4i32")]
        fn _svcmpne_s32(pg: svbool4_t, op1: svint32_t, op2: svint32_t) -> svbool4_t;
    }
    unsafe { _svcmpne_s32(pg.into(), op1, op2).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpne))]
pub unsafe fn svcmpne_n_s32(pg: svbool_t, op1: svint32_t, op2: i32) -> svbool_t {
    svcmpne_s32(pg, op1, svdup_n_s32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpne))]
pub unsafe fn svcmpne_s64(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cmpne.nxv2i64")]
        fn _svcmpne_s64(pg: svbool2_t, op1: svint64_t, op2: svint64_t) -> svbool2_t;
    }
    unsafe { _svcmpne_s64(pg.into(), op1, op2).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpne))]
pub unsafe fn svcmpne_n_s64(pg: svbool_t, op1: svint64_t, op2: i64) -> svbool_t {
    svcmpne_s64(pg, op1, svdup_n_s64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpne))]
pub unsafe fn svcmpne_u8(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svbool_t {
    unsafe { svcmpne_s8(pg, op1.as_signed(), op2.as_signed()) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpne))]
pub unsafe fn svcmpne_n_u8(pg: svbool_t, op1: svuint8_t, op2: u8) -> svbool_t {
    svcmpne_u8(pg, op1, svdup_n_u8(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpne))]
pub unsafe fn svcmpne_u16(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svbool_t {
    unsafe { svcmpne_s16(pg, op1.as_signed(), op2.as_signed()) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpne))]
pub unsafe fn svcmpne_n_u16(pg: svbool_t, op1: svuint16_t, op2: u16) -> svbool_t {
    svcmpne_u16(pg, op1, svdup_n_u16(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpne))]
pub unsafe fn svcmpne_u32(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svbool_t {
    unsafe { svcmpne_s32(pg, op1.as_signed(), op2.as_signed()) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpne))]
pub unsafe fn svcmpne_n_u32(pg: svbool_t, op1: svuint32_t, op2: u32) -> svbool_t {
    svcmpne_u32(pg, op1, svdup_n_u32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpne))]
pub unsafe fn svcmpne_u64(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svbool_t {
    unsafe { svcmpne_s64(pg, op1.as_signed(), op2.as_signed()) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpne))]
pub unsafe fn svcmpne_n_u64(pg: svbool_t, op1: svuint64_t, op2: u64) -> svbool_t {
    svcmpne_u64(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpne))]
pub unsafe fn svcmpne_wide_s8(pg: svbool_t, op1: svint8_t, op2: svint64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.cmpne.wide.nxv16i8"
        )]
        fn _svcmpne_wide_s8(pg: svbool_t, op1: svint8_t, op2: svint64_t) -> svbool_t;
    }
    unsafe { _svcmpne_wide_s8(pg, op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpne))]
pub unsafe fn svcmpne_wide_n_s8(pg: svbool_t, op1: svint8_t, op2: i64) -> svbool_t {
    svcmpne_wide_s8(pg, op1, svdup_n_s64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpne))]
pub unsafe fn svcmpne_wide_s16(pg: svbool_t, op1: svint16_t, op2: svint64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.cmpne.wide.nxv8i16"
        )]
        fn _svcmpne_wide_s16(pg: svbool8_t, op1: svint16_t, op2: svint64_t) -> svbool8_t;
    }
    unsafe { _svcmpne_wide_s16(pg.into(), op1, op2).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpne))]
pub unsafe fn svcmpne_wide_n_s16(pg: svbool_t, op1: svint16_t, op2: i64) -> svbool_t {
    svcmpne_wide_s16(pg, op1, svdup_n_s64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpne))]
pub unsafe fn svcmpne_wide_s32(pg: svbool_t, op1: svint32_t, op2: svint64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.cmpne.wide.nxv4i32"
        )]
        fn _svcmpne_wide_s32(pg: svbool4_t, op1: svint32_t, op2: svint64_t) -> svbool4_t;
    }
    unsafe { _svcmpne_wide_s32(pg.into(), op1, op2).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpne))]
pub unsafe fn svcmpne_wide_n_s32(pg: svbool_t, op1: svint32_t, op2: i64) -> svbool_t {
    svcmpne_wide_s32(pg, op1, svdup_n_s64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcmuo))]
pub unsafe fn svcmpuo_f32(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fcmpuo.nxv4f32")]
        fn _svcmpuo_f32(pg: svbool4_t, op1: svfloat32_t, op2: svfloat32_t) -> svbool4_t;
    }
    unsafe { _svcmpuo_f32(pg.into(), op1, op2).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcmuo))]
pub unsafe fn svcmpuo_n_f32(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svbool_t {
    svcmpuo_f32(pg, op1, svdup_n_f32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcmuo))]
pub unsafe fn svcmpuo_f64(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fcmpuo.nxv2f64")]
        fn _svcmpuo_f64(pg: svbool2_t, op1: svfloat64_t, op2: svfloat64_t) -> svbool2_t;
    }
    unsafe { _svcmpuo_f64(pg.into(), op1, op2).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcmuo))]
pub unsafe fn svcmpuo_n_f64(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svbool_t {
    svcmpuo_f64(pg, op1, svdup_n_f64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnot))]
pub unsafe fn svcnot_s8_m(inactive: svint8_t, pg: svbool_t, op: svint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cnot.nxv16i8")]
        fn _svcnot_s8_m(inactive: svint8_t, pg: svbool_t, op: svint8_t) -> svint8_t;
    }
    unsafe { _svcnot_s8_m(inactive, pg, op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnot))]
pub unsafe fn svcnot_s8_x(pg: svbool_t, op: svint8_t) -> svint8_t {
    svcnot_s8_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnot))]
pub unsafe fn svcnot_s8_z(pg: svbool_t, op: svint8_t) -> svint8_t {
    svcnot_s8_m(svdup_n_s8(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnot))]
pub unsafe fn svcnot_s16_m(inactive: svint16_t, pg: svbool_t, op: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cnot.nxv8i16")]
        fn _svcnot_s16_m(inactive: svint16_t, pg: svbool8_t, op: svint16_t) -> svint16_t;
    }
    unsafe { _svcnot_s16_m(inactive, pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnot))]
pub unsafe fn svcnot_s16_x(pg: svbool_t, op: svint16_t) -> svint16_t {
    svcnot_s16_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnot))]
pub unsafe fn svcnot_s16_z(pg: svbool_t, op: svint16_t) -> svint16_t {
    svcnot_s16_m(svdup_n_s16(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnot))]
pub unsafe fn svcnot_s32_m(inactive: svint32_t, pg: svbool_t, op: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cnot.nxv4i32")]
        fn _svcnot_s32_m(inactive: svint32_t, pg: svbool4_t, op: svint32_t) -> svint32_t;
    }
    unsafe { _svcnot_s32_m(inactive, pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnot))]
pub unsafe fn svcnot_s32_x(pg: svbool_t, op: svint32_t) -> svint32_t {
    svcnot_s32_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnot))]
pub unsafe fn svcnot_s32_z(pg: svbool_t, op: svint32_t) -> svint32_t {
    svcnot_s32_m(svdup_n_s32(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnot))]
pub unsafe fn svcnot_s64_m(inactive: svint64_t, pg: svbool_t, op: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cnot.nxv2i64")]
        fn _svcnot_s64_m(inactive: svint64_t, pg: svbool2_t, op: svint64_t) -> svint64_t;
    }
    unsafe { _svcnot_s64_m(inactive, pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnot))]
pub unsafe fn svcnot_s64_x(pg: svbool_t, op: svint64_t) -> svint64_t {
    svcnot_s64_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnot))]
pub unsafe fn svcnot_s64_z(pg: svbool_t, op: svint64_t) -> svint64_t {
    svcnot_s64_m(svdup_n_s64(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnot))]
pub unsafe fn svcnot_u8_m(inactive: svuint8_t, pg: svbool_t, op: svuint8_t) -> svuint8_t {
    unsafe { svcnot_s8_m(inactive.as_signed(), pg, op.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnot))]
pub unsafe fn svcnot_u8_x(pg: svbool_t, op: svuint8_t) -> svuint8_t {
    svcnot_u8_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnot))]
pub unsafe fn svcnot_u8_z(pg: svbool_t, op: svuint8_t) -> svuint8_t {
    svcnot_u8_m(svdup_n_u8(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnot))]
pub unsafe fn svcnot_u16_m(inactive: svuint16_t, pg: svbool_t, op: svuint16_t) -> svuint16_t {
    unsafe { svcnot_s16_m(inactive.as_signed(), pg, op.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnot))]
pub unsafe fn svcnot_u16_x(pg: svbool_t, op: svuint16_t) -> svuint16_t {
    svcnot_u16_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnot))]
pub unsafe fn svcnot_u16_z(pg: svbool_t, op: svuint16_t) -> svuint16_t {
    svcnot_u16_m(svdup_n_u16(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnot))]
pub unsafe fn svcnot_u32_m(inactive: svuint32_t, pg: svbool_t, op: svuint32_t) -> svuint32_t {
    unsafe { svcnot_s32_m(inactive.as_signed(), pg, op.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnot))]
pub unsafe fn svcnot_u32_x(pg: svbool_t, op: svuint32_t) -> svuint32_t {
    svcnot_u32_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnot))]
pub unsafe fn svcnot_u32_z(pg: svbool_t, op: svuint32_t) -> svuint32_t {
    svcnot_u32_m(svdup_n_u32(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnot))]
pub unsafe fn svcnot_u64_m(inactive: svuint64_t, pg: svbool_t, op: svuint64_t) -> svuint64_t {
    unsafe { svcnot_s64_m(inactive.as_signed(), pg, op.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnot))]
pub unsafe fn svcnot_u64_x(pg: svbool_t, op: svuint64_t) -> svuint64_t {
    svcnot_u64_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnot))]
pub unsafe fn svcnot_u64_z(pg: svbool_t, op: svuint64_t) -> svuint64_t {
    svcnot_u64_m(svdup_n_u64(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnt))]
pub unsafe fn svcnt_f32_m(inactive: svuint32_t, pg: svbool_t, op: svfloat32_t) -> svuint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cnt.nxv4f32")]
        fn _svcnt_f32_m(inactive: svint32_t, pg: svbool4_t, op: svfloat32_t) -> svint32_t;
    }
    unsafe { _svcnt_f32_m(inactive.as_signed(), pg.into(), op).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnt))]
pub unsafe fn svcnt_f32_x(pg: svbool_t, op: svfloat32_t) -> svuint32_t {
    unsafe { svcnt_f32_m(simd_reinterpret(op), pg, op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnt))]
pub unsafe fn svcnt_f32_z(pg: svbool_t, op: svfloat32_t) -> svuint32_t {
    svcnt_f32_m(svdup_n_u32(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnt))]
pub unsafe fn svcnt_f64_m(inactive: svuint64_t, pg: svbool_t, op: svfloat64_t) -> svuint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cnt.nxv2f64")]
        fn _svcnt_f64_m(inactive: svint64_t, pg: svbool2_t, op: svfloat64_t) -> svint64_t;
    }
    unsafe { _svcnt_f64_m(inactive.as_signed(), pg.into(), op).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnt))]
pub unsafe fn svcnt_f64_x(pg: svbool_t, op: svfloat64_t) -> svuint64_t {
    unsafe { svcnt_f64_m(simd_reinterpret(op), pg, op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnt))]
pub unsafe fn svcnt_f64_z(pg: svbool_t, op: svfloat64_t) -> svuint64_t {
    svcnt_f64_m(svdup_n_u64(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnt))]
pub unsafe fn svcnt_s8_m(inactive: svuint8_t, pg: svbool_t, op: svint8_t) -> svuint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cnt.nxv16i8")]
        fn _svcnt_s8_m(inactive: svint8_t, pg: svbool_t, op: svint8_t) -> svint8_t;
    }
    unsafe { _svcnt_s8_m(inactive.as_signed(), pg, op).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnt))]
pub unsafe fn svcnt_s8_x(pg: svbool_t, op: svint8_t) -> svuint8_t {
    unsafe { svcnt_s8_m(op.as_unsigned(), pg, op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnt))]
pub unsafe fn svcnt_s8_z(pg: svbool_t, op: svint8_t) -> svuint8_t {
    svcnt_s8_m(svdup_n_u8(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnt))]
pub unsafe fn svcnt_s16_m(inactive: svuint16_t, pg: svbool_t, op: svint16_t) -> svuint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cnt.nxv8i16")]
        fn _svcnt_s16_m(inactive: svint16_t, pg: svbool8_t, op: svint16_t) -> svint16_t;
    }
    unsafe { _svcnt_s16_m(inactive.as_signed(), pg.into(), op).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnt))]
pub unsafe fn svcnt_s16_x(pg: svbool_t, op: svint16_t) -> svuint16_t {
    unsafe { svcnt_s16_m(op.as_unsigned(), pg, op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnt))]
pub unsafe fn svcnt_s16_z(pg: svbool_t, op: svint16_t) -> svuint16_t {
    svcnt_s16_m(svdup_n_u16(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnt))]
pub unsafe fn svcnt_s32_m(inactive: svuint32_t, pg: svbool_t, op: svint32_t) -> svuint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cnt.nxv4i32")]
        fn _svcnt_s32_m(inactive: svint32_t, pg: svbool4_t, op: svint32_t) -> svint32_t;
    }
    unsafe { _svcnt_s32_m(inactive.as_signed(), pg.into(), op).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnt))]
pub unsafe fn svcnt_s32_x(pg: svbool_t, op: svint32_t) -> svuint32_t {
    unsafe { svcnt_s32_m(op.as_unsigned(), pg, op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnt))]
pub unsafe fn svcnt_s32_z(pg: svbool_t, op: svint32_t) -> svuint32_t {
    svcnt_s32_m(svdup_n_u32(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnt))]
pub unsafe fn svcnt_s64_m(inactive: svuint64_t, pg: svbool_t, op: svint64_t) -> svuint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cnt.nxv2i64")]
        fn _svcnt_s64_m(inactive: svint64_t, pg: svbool2_t, op: svint64_t) -> svint64_t;
    }
    unsafe { _svcnt_s64_m(inactive.as_signed(), pg.into(), op).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnt))]
pub unsafe fn svcnt_s64_x(pg: svbool_t, op: svint64_t) -> svuint64_t {
    unsafe { svcnt_s64_m(op.as_unsigned(), pg, op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnt))]
pub unsafe fn svcnt_s64_z(pg: svbool_t, op: svint64_t) -> svuint64_t {
    svcnt_s64_m(svdup_n_u64(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnt))]
pub unsafe fn svcnt_u8_m(inactive: svuint8_t, pg: svbool_t, op: svuint8_t) -> svuint8_t {
    unsafe { svcnt_s8_m(inactive, pg, op.as_signed()) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnt))]
pub unsafe fn svcnt_u8_x(pg: svbool_t, op: svuint8_t) -> svuint8_t {
    svcnt_u8_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnt))]
pub unsafe fn svcnt_u8_z(pg: svbool_t, op: svuint8_t) -> svuint8_t {
    svcnt_u8_m(svdup_n_u8(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnt))]
pub unsafe fn svcnt_u16_m(inactive: svuint16_t, pg: svbool_t, op: svuint16_t) -> svuint16_t {
    unsafe { svcnt_s16_m(inactive, pg, op.as_signed()) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnt))]
pub unsafe fn svcnt_u16_x(pg: svbool_t, op: svuint16_t) -> svuint16_t {
    svcnt_u16_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnt))]
pub unsafe fn svcnt_u16_z(pg: svbool_t, op: svuint16_t) -> svuint16_t {
    svcnt_u16_m(svdup_n_u16(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnt))]
pub unsafe fn svcnt_u32_m(inactive: svuint32_t, pg: svbool_t, op: svuint32_t) -> svuint32_t {
    unsafe { svcnt_s32_m(inactive, pg, op.as_signed()) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnt))]
pub unsafe fn svcnt_u32_x(pg: svbool_t, op: svuint32_t) -> svuint32_t {
    svcnt_u32_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnt))]
pub unsafe fn svcnt_u32_z(pg: svbool_t, op: svuint32_t) -> svuint32_t {
    svcnt_u32_m(svdup_n_u32(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnt))]
pub unsafe fn svcnt_u64_m(inactive: svuint64_t, pg: svbool_t, op: svuint64_t) -> svuint64_t {
    unsafe { svcnt_s64_m(inactive, pg, op.as_signed()) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnt))]
pub unsafe fn svcnt_u64_x(pg: svbool_t, op: svuint64_t) -> svuint64_t {
    svcnt_u64_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnt))]
pub unsafe fn svcnt_u64_z(pg: svbool_t, op: svuint64_t) -> svuint64_t {
    svcnt_u64_m(svdup_n_u64(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rdvl))]
pub unsafe fn svcntb() -> u64 {
    svcntb_pat::<{ svpattern::SV_ALL }>()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnth))]
pub unsafe fn svcnth() -> u64 {
    svcnth_pat::<{ svpattern::SV_ALL }>()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cntw))]
pub unsafe fn svcntw() -> u64 {
    svcntw_pat::<{ svpattern::SV_ALL }>()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cntd))]
pub unsafe fn svcntd() -> u64 {
    svcntd_pat::<{ svpattern::SV_ALL }>()
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (rdvl , PATTERN = { svpattern :: SV_ALL }))]
# [cfg_attr (test , assert_instr (cntb , PATTERN = { svpattern :: SV_MUL4 }))]
pub unsafe fn svcntb_pat<const PATTERN: svpattern>() -> u64 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cntb")]
        fn _svcntb_pat(pattern: svpattern) -> i64;
    }
    unsafe { _svcntb_pat(PATTERN).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (cnth , PATTERN = { svpattern :: SV_ALL }))]
pub unsafe fn svcnth_pat<const PATTERN: svpattern>() -> u64 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cnth")]
        fn _svcnth_pat(pattern: svpattern) -> i64;
    }
    unsafe { _svcnth_pat(PATTERN).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (cntw , PATTERN = { svpattern :: SV_ALL }))]
pub unsafe fn svcntw_pat<const PATTERN: svpattern>() -> u64 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cntw")]
        fn _svcntw_pat(pattern: svpattern) -> i64;
    }
    unsafe { _svcntw_pat(PATTERN).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (cntd , PATTERN = { svpattern :: SV_ALL }))]
pub unsafe fn svcntd_pat<const PATTERN: svpattern>() -> u64 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cntd")]
        fn _svcntd_pat(pattern: svpattern) -> i64;
    }
    unsafe { _svcntd_pat(PATTERN).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cntp))]
pub unsafe fn svcntp_b8(pg: svbool_t, op: svbool_t) -> u64 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cntp.nxv16i1")]
        fn _svcntp_b8(pg: svbool_t, op: svbool_t) -> i64;
    }
    unsafe { _svcntp_b8(pg, op).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cntp))]
pub unsafe fn svcntp_b16(pg: svbool_t, op: svbool_t) -> u64 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cntp.nxv8i1")]
        fn _svcntp_b16(pg: svbool8_t, op: svbool8_t) -> i64;
    }
    unsafe { _svcntp_b16(pg.into(), op.into()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cntp))]
pub unsafe fn svcntp_b32(pg: svbool_t, op: svbool_t) -> u64 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cntp.nxv4i1")]
        fn _svcntp_b32(pg: svbool4_t, op: svbool4_t) -> i64;
    }
    unsafe { _svcntp_b32(pg.into(), op.into()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cntp))]
pub unsafe fn svcntp_b64(pg: svbool_t, op: svbool_t) -> u64 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cntp.nxv2i1")]
        fn _svcntp_b64(pg: svbool2_t, op: svbool2_t) -> i64;
    }
    unsafe { _svcntp_b64(pg.into(), op.into()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(compact))]
pub unsafe fn svcompact_f32(pg: svbool_t, op: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.compact.nxv4f32"
        )]
        fn _svcompact_f32(pg: svbool4_t, op: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svcompact_f32(pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(compact))]
pub unsafe fn svcompact_f64(pg: svbool_t, op: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.compact.nxv2f64"
        )]
        fn _svcompact_f64(pg: svbool2_t, op: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svcompact_f64(pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(compact))]
pub unsafe fn svcompact_s32(pg: svbool_t, op: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.compact.nxv4i32"
        )]
        fn _svcompact_s32(pg: svbool4_t, op: svint32_t) -> svint32_t;
    }
    unsafe { _svcompact_s32(pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(compact))]
pub unsafe fn svcompact_s64(pg: svbool_t, op: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.compact.nxv2i64"
        )]
        fn _svcompact_s64(pg: svbool2_t, op: svint64_t) -> svint64_t;
    }
    unsafe { _svcompact_s64(pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(compact))]
pub unsafe fn svcompact_u32(pg: svbool_t, op: svuint32_t) -> svuint32_t {
    unsafe { svcompact_s32(pg, op.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(compact))]
pub unsafe fn svcompact_u64(pg: svbool_t, op: svuint64_t) -> svuint64_t {
    unsafe { svcompact_s64(pg, op.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svcreate2_f32(x0: svfloat32_t, x1: svfloat32_t) -> svfloat32x2_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.create2.nxv8f32.nxv4f32"
        )]
        fn _svcreate2_f32(x0: svfloat32_t, x1: svfloat32_t) -> svfloat32x2_t;
    }
    unsafe { _svcreate2_f32(x0, x1) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svcreate2_f64(x0: svfloat64_t, x1: svfloat64_t) -> svfloat64x2_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.create2.nxv4f64.nxv2f64"
        )]
        fn _svcreate2_f64(x0: svfloat64_t, x1: svfloat64_t) -> svfloat64x2_t;
    }
    unsafe { _svcreate2_f64(x0, x1) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svcreate2_s8(x0: svint8_t, x1: svint8_t) -> svint8x2_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.create2.nxv32i8.nxv16i8"
        )]
        fn _svcreate2_s8(x0: svint8_t, x1: svint8_t) -> svint8x2_t;
    }
    unsafe { _svcreate2_s8(x0, x1) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svcreate2_s16(x0: svint16_t, x1: svint16_t) -> svint16x2_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.create2.nxv16i16.nxv8i16"
        )]
        fn _svcreate2_s16(x0: svint16_t, x1: svint16_t) -> svint16x2_t;
    }
    unsafe { _svcreate2_s16(x0, x1) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svcreate2_s32(x0: svint32_t, x1: svint32_t) -> svint32x2_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.create2.nxv8i32.nxv4i32"
        )]
        fn _svcreate2_s32(x0: svint32_t, x1: svint32_t) -> svint32x2_t;
    }
    unsafe { _svcreate2_s32(x0, x1) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svcreate2_s64(x0: svint64_t, x1: svint64_t) -> svint64x2_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.create2.nxv4i64.nxv2i64"
        )]
        fn _svcreate2_s64(x0: svint64_t, x1: svint64_t) -> svint64x2_t;
    }
    unsafe { _svcreate2_s64(x0, x1) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svcreate2_u8(x0: svuint8_t, x1: svuint8_t) -> svuint8x2_t {
    unsafe { svcreate2_s8(x0.as_signed(), x1.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svcreate2_u16(x0: svuint16_t, x1: svuint16_t) -> svuint16x2_t {
    unsafe { svcreate2_s16(x0.as_signed(), x1.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svcreate2_u32(x0: svuint32_t, x1: svuint32_t) -> svuint32x2_t {
    unsafe { svcreate2_s32(x0.as_signed(), x1.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svcreate2_u64(x0: svuint64_t, x1: svuint64_t) -> svuint64x2_t {
    unsafe { svcreate2_s64(x0.as_signed(), x1.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svcreate3_f32(x0: svfloat32_t, x1: svfloat32_t, x2: svfloat32_t) -> svfloat32x3_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.create3.nxv12f32.nxv4f32"
        )]
        fn _svcreate3_f32(x0: svfloat32_t, x1: svfloat32_t, x2: svfloat32_t) -> svfloat32x3_t;
    }
    unsafe { _svcreate3_f32(x0, x1, x2) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svcreate3_f64(x0: svfloat64_t, x1: svfloat64_t, x2: svfloat64_t) -> svfloat64x3_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.create3.nxv6f64.nxv2f64"
        )]
        fn _svcreate3_f64(x0: svfloat64_t, x1: svfloat64_t, x2: svfloat64_t) -> svfloat64x3_t;
    }
    unsafe { _svcreate3_f64(x0, x1, x2) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svcreate3_s8(x0: svint8_t, x1: svint8_t, x2: svint8_t) -> svint8x3_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.create3.nxv48i8.nxv16i8"
        )]
        fn _svcreate3_s8(x0: svint8_t, x1: svint8_t, x2: svint8_t) -> svint8x3_t;
    }
    unsafe { _svcreate3_s8(x0, x1, x2) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svcreate3_s16(x0: svint16_t, x1: svint16_t, x2: svint16_t) -> svint16x3_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.create3.nxv24i16.nxv8i16"
        )]
        fn _svcreate3_s16(x0: svint16_t, x1: svint16_t, x2: svint16_t) -> svint16x3_t;
    }
    unsafe { _svcreate3_s16(x0, x1, x2) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svcreate3_s32(x0: svint32_t, x1: svint32_t, x2: svint32_t) -> svint32x3_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.create3.nxv12i32.nxv4i32"
        )]
        fn _svcreate3_s32(x0: svint32_t, x1: svint32_t, x2: svint32_t) -> svint32x3_t;
    }
    unsafe { _svcreate3_s32(x0, x1, x2) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svcreate3_s64(x0: svint64_t, x1: svint64_t, x2: svint64_t) -> svint64x3_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.create3.nxv6i64.nxv2i64"
        )]
        fn _svcreate3_s64(x0: svint64_t, x1: svint64_t, x2: svint64_t) -> svint64x3_t;
    }
    unsafe { _svcreate3_s64(x0, x1, x2) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svcreate3_u8(x0: svuint8_t, x1: svuint8_t, x2: svuint8_t) -> svuint8x3_t {
    unsafe { svcreate3_s8(x0.as_signed(), x1.as_signed(), x2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svcreate3_u16(x0: svuint16_t, x1: svuint16_t, x2: svuint16_t) -> svuint16x3_t {
    unsafe { svcreate3_s16(x0.as_signed(), x1.as_signed(), x2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svcreate3_u32(x0: svuint32_t, x1: svuint32_t, x2: svuint32_t) -> svuint32x3_t {
    unsafe { svcreate3_s32(x0.as_signed(), x1.as_signed(), x2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svcreate3_u64(x0: svuint64_t, x1: svuint64_t, x2: svuint64_t) -> svuint64x3_t {
    unsafe { svcreate3_s64(x0.as_signed(), x1.as_signed(), x2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svcreate4_f32(
    x0: svfloat32_t,
    x1: svfloat32_t,
    x2: svfloat32_t,
    x3: svfloat32_t,
) -> svfloat32x4_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.create4.nxv16f32.nxv4f32"
        )]
        fn _svcreate4_f32(
            x0: svfloat32_t,
            x1: svfloat32_t,
            x2: svfloat32_t,
            x3: svfloat32_t,
        ) -> svfloat32x4_t;
    }
    unsafe { _svcreate4_f32(x0, x1, x2, x3) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svcreate4_f64(
    x0: svfloat64_t,
    x1: svfloat64_t,
    x2: svfloat64_t,
    x3: svfloat64_t,
) -> svfloat64x4_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.create4.nxv8f64.nxv2f64"
        )]
        fn _svcreate4_f64(
            x0: svfloat64_t,
            x1: svfloat64_t,
            x2: svfloat64_t,
            x3: svfloat64_t,
        ) -> svfloat64x4_t;
    }
    unsafe { _svcreate4_f64(x0, x1, x2, x3) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svcreate4_s8(x0: svint8_t, x1: svint8_t, x2: svint8_t, x3: svint8_t) -> svint8x4_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.create4.nxv64i8.nxv16i8"
        )]
        fn _svcreate4_s8(x0: svint8_t, x1: svint8_t, x2: svint8_t, x3: svint8_t) -> svint8x4_t;
    }
    unsafe { _svcreate4_s8(x0, x1, x2, x3) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svcreate4_s16(x0: svint16_t, x1: svint16_t, x2: svint16_t, x3: svint16_t) -> svint16x4_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.create4.nxv32i16.nxv8i16"
        )]
        fn _svcreate4_s16(
            x0: svint16_t,
            x1: svint16_t,
            x2: svint16_t,
            x3: svint16_t,
        ) -> svint16x4_t;
    }
    unsafe { _svcreate4_s16(x0, x1, x2, x3) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svcreate4_s32(x0: svint32_t, x1: svint32_t, x2: svint32_t, x3: svint32_t) -> svint32x4_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.create4.nxv16i32.nxv4i32"
        )]
        fn _svcreate4_s32(
            x0: svint32_t,
            x1: svint32_t,
            x2: svint32_t,
            x3: svint32_t,
        ) -> svint32x4_t;
    }
    unsafe { _svcreate4_s32(x0, x1, x2, x3) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svcreate4_s64(x0: svint64_t, x1: svint64_t, x2: svint64_t, x3: svint64_t) -> svint64x4_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.create4.nxv8i64.nxv2i64"
        )]
        fn _svcreate4_s64(
            x0: svint64_t,
            x1: svint64_t,
            x2: svint64_t,
            x3: svint64_t,
        ) -> svint64x4_t;
    }
    unsafe { _svcreate4_s64(x0, x1, x2, x3) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svcreate4_u8(x0: svuint8_t, x1: svuint8_t, x2: svuint8_t, x3: svuint8_t) -> svuint8x4_t {
    unsafe {
        svcreate4_s8(
            x0.as_signed(),
            x1.as_signed(),
            x2.as_signed(),
            x3.as_signed(),
        )
        .as_unsigned()
    }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svcreate4_u16(
    x0: svuint16_t,
    x1: svuint16_t,
    x2: svuint16_t,
    x3: svuint16_t,
) -> svuint16x4_t {
    unsafe {
        svcreate4_s16(
            x0.as_signed(),
            x1.as_signed(),
            x2.as_signed(),
            x3.as_signed(),
        )
        .as_unsigned()
    }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svcreate4_u32(
    x0: svuint32_t,
    x1: svuint32_t,
    x2: svuint32_t,
    x3: svuint32_t,
) -> svuint32x4_t {
    unsafe {
        svcreate4_s32(
            x0.as_signed(),
            x1.as_signed(),
            x2.as_signed(),
            x3.as_signed(),
        )
        .as_unsigned()
    }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svcreate4_u64(
    x0: svuint64_t,
    x1: svuint64_t,
    x2: svuint64_t,
    x3: svuint64_t,
) -> svuint64x4_t {
    unsafe {
        svcreate4_s64(
            x0.as_signed(),
            x1.as_signed(),
            x2.as_signed(),
            x3.as_signed(),
        )
        .as_unsigned()
    }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcvt))]
pub unsafe fn svcvt_f32_f64_m(inactive: svfloat32_t, pg: svbool_t, op: svfloat64_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fcvt.f32f64")]
        fn _svcvt_f32_f64_m(inactive: svfloat32_t, pg: svbool2_t, op: svfloat64_t) -> svfloat32_t;
    }
    unsafe { _svcvt_f32_f64_m(inactive, pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcvt))]
pub unsafe fn svcvt_f32_f64_x(pg: svbool_t, op: svfloat64_t) -> svfloat32_t {
    unsafe { svcvt_f32_f64_m(simd_reinterpret(op), pg, op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcvt))]
pub unsafe fn svcvt_f32_f64_z(pg: svbool_t, op: svfloat64_t) -> svfloat32_t {
    svcvt_f32_f64_m(svdup_n_f32(0.0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcvt))]
pub unsafe fn svcvt_f64_f32_m(inactive: svfloat64_t, pg: svbool_t, op: svfloat32_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fcvt.f64f32")]
        fn _svcvt_f64_f32_m(inactive: svfloat64_t, pg: svbool2_t, op: svfloat32_t) -> svfloat64_t;
    }
    unsafe { _svcvt_f64_f32_m(inactive, pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcvt))]
pub unsafe fn svcvt_f64_f32_x(pg: svbool_t, op: svfloat32_t) -> svfloat64_t {
    unsafe { svcvt_f64_f32_m(simd_reinterpret(op), pg, op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcvt))]
pub unsafe fn svcvt_f64_f32_z(pg: svbool_t, op: svfloat32_t) -> svfloat64_t {
    svcvt_f64_f32_m(svdup_n_f64(0.0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(scvtf))]
pub unsafe fn svcvt_f32_s32_m(inactive: svfloat32_t, pg: svbool_t, op: svint32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.scvtf.nxv4f32.nxv4i32"
        )]
        fn _svcvt_f32_s32_m(inactive: svfloat32_t, pg: svbool4_t, op: svint32_t) -> svfloat32_t;
    }
    unsafe { _svcvt_f32_s32_m(inactive, pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(scvtf))]
pub unsafe fn svcvt_f32_s32_x(pg: svbool_t, op: svint32_t) -> svfloat32_t {
    unsafe { svcvt_f32_s32_m(simd_reinterpret(op), pg, op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(scvtf))]
pub unsafe fn svcvt_f32_s32_z(pg: svbool_t, op: svint32_t) -> svfloat32_t {
    svcvt_f32_s32_m(svdup_n_f32(0.0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(scvtf))]
pub unsafe fn svcvt_f32_s64_m(inactive: svfloat32_t, pg: svbool_t, op: svint64_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.scvtf.f32i64")]
        fn _svcvt_f32_s64_m(inactive: svfloat32_t, pg: svbool2_t, op: svint64_t) -> svfloat32_t;
    }
    unsafe { _svcvt_f32_s64_m(inactive, pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(scvtf))]
pub unsafe fn svcvt_f32_s64_x(pg: svbool_t, op: svint64_t) -> svfloat32_t {
    unsafe { svcvt_f32_s64_m(simd_reinterpret(op), pg, op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(scvtf))]
pub unsafe fn svcvt_f32_s64_z(pg: svbool_t, op: svint64_t) -> svfloat32_t {
    svcvt_f32_s64_m(svdup_n_f32(0.0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ucvtf))]
pub unsafe fn svcvt_f32_u32_m(inactive: svfloat32_t, pg: svbool_t, op: svuint32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ucvtf.nxv4f32.nxv4i32"
        )]
        fn _svcvt_f32_u32_m(inactive: svfloat32_t, pg: svbool4_t, op: svint32_t) -> svfloat32_t;
    }
    unsafe { _svcvt_f32_u32_m(inactive, pg.into(), op.as_signed()) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ucvtf))]
pub unsafe fn svcvt_f32_u32_x(pg: svbool_t, op: svuint32_t) -> svfloat32_t {
    unsafe { svcvt_f32_u32_m(simd_reinterpret(op), pg, op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ucvtf))]
pub unsafe fn svcvt_f32_u32_z(pg: svbool_t, op: svuint32_t) -> svfloat32_t {
    svcvt_f32_u32_m(svdup_n_f32(0.0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ucvtf))]
pub unsafe fn svcvt_f32_u64_m(inactive: svfloat32_t, pg: svbool_t, op: svuint64_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ucvtf.f32i64")]
        fn _svcvt_f32_u64_m(inactive: svfloat32_t, pg: svbool2_t, op: svint64_t) -> svfloat32_t;
    }
    unsafe { _svcvt_f32_u64_m(inactive, pg.into(), op.as_signed()) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ucvtf))]
pub unsafe fn svcvt_f32_u64_x(pg: svbool_t, op: svuint64_t) -> svfloat32_t {
    unsafe { svcvt_f32_u64_m(simd_reinterpret(op), pg, op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ucvtf))]
pub unsafe fn svcvt_f32_u64_z(pg: svbool_t, op: svuint64_t) -> svfloat32_t {
    svcvt_f32_u64_m(svdup_n_f32(0.0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(scvtf))]
pub unsafe fn svcvt_f64_s32_m(inactive: svfloat64_t, pg: svbool_t, op: svint32_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.scvtf.nxv2f64.nxv4i32"
        )]
        fn _svcvt_f64_s32_m(inactive: svfloat64_t, pg: svbool2_t, op: svint32_t) -> svfloat64_t;
    }
    unsafe { _svcvt_f64_s32_m(inactive, pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(scvtf))]
pub unsafe fn svcvt_f64_s32_x(pg: svbool_t, op: svint32_t) -> svfloat64_t {
    unsafe { svcvt_f64_s32_m(simd_reinterpret(op), pg, op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(scvtf))]
pub unsafe fn svcvt_f64_s32_z(pg: svbool_t, op: svint32_t) -> svfloat64_t {
    svcvt_f64_s32_m(svdup_n_f64(0.0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(scvtf))]
pub unsafe fn svcvt_f64_s64_m(inactive: svfloat64_t, pg: svbool_t, op: svint64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.scvtf.nxv2f64.nxv2i64"
        )]
        fn _svcvt_f64_s64_m(inactive: svfloat64_t, pg: svbool2_t, op: svint64_t) -> svfloat64_t;
    }
    unsafe { _svcvt_f64_s64_m(inactive, pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(scvtf))]
pub unsafe fn svcvt_f64_s64_x(pg: svbool_t, op: svint64_t) -> svfloat64_t {
    unsafe { svcvt_f64_s64_m(simd_reinterpret(op), pg, op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(scvtf))]
pub unsafe fn svcvt_f64_s64_z(pg: svbool_t, op: svint64_t) -> svfloat64_t {
    svcvt_f64_s64_m(svdup_n_f64(0.0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ucvtf))]
pub unsafe fn svcvt_f64_u32_m(inactive: svfloat64_t, pg: svbool_t, op: svuint32_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ucvtf.nxv2f64.nxv4i32"
        )]
        fn _svcvt_f64_u32_m(inactive: svfloat64_t, pg: svbool2_t, op: svint32_t) -> svfloat64_t;
    }
    unsafe { _svcvt_f64_u32_m(inactive, pg.into(), op.as_signed()) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ucvtf))]
pub unsafe fn svcvt_f64_u32_x(pg: svbool_t, op: svuint32_t) -> svfloat64_t {
    unsafe { svcvt_f64_u32_m(simd_reinterpret(op), pg, op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ucvtf))]
pub unsafe fn svcvt_f64_u32_z(pg: svbool_t, op: svuint32_t) -> svfloat64_t {
    svcvt_f64_u32_m(svdup_n_f64(0.0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ucvtf))]
pub unsafe fn svcvt_f64_u64_m(inactive: svfloat64_t, pg: svbool_t, op: svuint64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ucvtf.nxv2f64.nxv2i64"
        )]
        fn _svcvt_f64_u64_m(inactive: svfloat64_t, pg: svbool2_t, op: svint64_t) -> svfloat64_t;
    }
    unsafe { _svcvt_f64_u64_m(inactive, pg.into(), op.as_signed()) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ucvtf))]
pub unsafe fn svcvt_f64_u64_x(pg: svbool_t, op: svuint64_t) -> svfloat64_t {
    unsafe { svcvt_f64_u64_m(simd_reinterpret(op), pg, op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ucvtf))]
pub unsafe fn svcvt_f64_u64_z(pg: svbool_t, op: svuint64_t) -> svfloat64_t {
    svcvt_f64_u64_m(svdup_n_f64(0.0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcvtzs))]
pub unsafe fn svcvt_s32_f32_m(inactive: svint32_t, pg: svbool_t, op: svfloat32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fcvtzs.i32f32")]
        fn _svcvt_s32_f32_m(inactive: svint32_t, pg: svbool4_t, op: svfloat32_t) -> svint32_t;
    }
    unsafe { _svcvt_s32_f32_m(inactive, pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcvtzs))]
pub unsafe fn svcvt_s32_f32_x(pg: svbool_t, op: svfloat32_t) -> svint32_t {
    unsafe { svcvt_s32_f32_m(simd_reinterpret(op), pg, op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcvtzs))]
pub unsafe fn svcvt_s32_f32_z(pg: svbool_t, op: svfloat32_t) -> svint32_t {
    svcvt_s32_f32_m(svdup_n_s32(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcvtzs))]
pub unsafe fn svcvt_s32_f64_m(inactive: svint32_t, pg: svbool_t, op: svfloat64_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fcvtzs.i32f64")]
        fn _svcvt_s32_f64_m(inactive: svint32_t, pg: svbool2_t, op: svfloat64_t) -> svint32_t;
    }
    unsafe { _svcvt_s32_f64_m(inactive, pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcvtzs))]
pub unsafe fn svcvt_s32_f64_x(pg: svbool_t, op: svfloat64_t) -> svint32_t {
    unsafe { svcvt_s32_f64_m(simd_reinterpret(op), pg, op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcvtzs))]
pub unsafe fn svcvt_s32_f64_z(pg: svbool_t, op: svfloat64_t) -> svint32_t {
    svcvt_s32_f64_m(svdup_n_s32(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcvtzs))]
pub unsafe fn svcvt_s64_f32_m(inactive: svint64_t, pg: svbool_t, op: svfloat32_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fcvtzs.i64f32")]
        fn _svcvt_s64_f32_m(inactive: svint64_t, pg: svbool2_t, op: svfloat32_t) -> svint64_t;
    }
    unsafe { _svcvt_s64_f32_m(inactive, pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcvtzs))]
pub unsafe fn svcvt_s64_f32_x(pg: svbool_t, op: svfloat32_t) -> svint64_t {
    unsafe { svcvt_s64_f32_m(simd_reinterpret(op), pg, op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcvtzs))]
pub unsafe fn svcvt_s64_f32_z(pg: svbool_t, op: svfloat32_t) -> svint64_t {
    svcvt_s64_f32_m(svdup_n_s64(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcvtzs))]
pub unsafe fn svcvt_s64_f64_m(inactive: svint64_t, pg: svbool_t, op: svfloat64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fcvtzs.i64f64")]
        fn _svcvt_s64_f64_m(inactive: svint64_t, pg: svbool2_t, op: svfloat64_t) -> svint64_t;
    }
    unsafe { _svcvt_s64_f64_m(inactive, pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcvtzs))]
pub unsafe fn svcvt_s64_f64_x(pg: svbool_t, op: svfloat64_t) -> svint64_t {
    unsafe { svcvt_s64_f64_m(simd_reinterpret(op), pg, op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcvtzs))]
pub unsafe fn svcvt_s64_f64_z(pg: svbool_t, op: svfloat64_t) -> svint64_t {
    svcvt_s64_f64_m(svdup_n_s64(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcvtzu))]
pub unsafe fn svcvt_u32_f32_m(inactive: svuint32_t, pg: svbool_t, op: svfloat32_t) -> svuint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fcvtzu.i32f32")]
        fn _svcvt_u32_f32_m(inactive: svint32_t, pg: svbool4_t, op: svfloat32_t) -> svint32_t;
    }
    unsafe { _svcvt_u32_f32_m(inactive.as_signed(), pg.into(), op).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcvtzu))]
pub unsafe fn svcvt_u32_f32_x(pg: svbool_t, op: svfloat32_t) -> svuint32_t {
    unsafe { svcvt_u32_f32_m(simd_reinterpret(op), pg, op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcvtzu))]
pub unsafe fn svcvt_u32_f32_z(pg: svbool_t, op: svfloat32_t) -> svuint32_t {
    svcvt_u32_f32_m(svdup_n_u32(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcvtzu))]
pub unsafe fn svcvt_u32_f64_m(inactive: svuint32_t, pg: svbool_t, op: svfloat64_t) -> svuint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fcvtzu.i32f64")]
        fn _svcvt_u32_f64_m(inactive: svint32_t, pg: svbool2_t, op: svfloat64_t) -> svint32_t;
    }
    unsafe { _svcvt_u32_f64_m(inactive.as_signed(), pg.into(), op).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcvtzu))]
pub unsafe fn svcvt_u32_f64_x(pg: svbool_t, op: svfloat64_t) -> svuint32_t {
    unsafe { svcvt_u32_f64_m(simd_reinterpret(op), pg, op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcvtzu))]
pub unsafe fn svcvt_u32_f64_z(pg: svbool_t, op: svfloat64_t) -> svuint32_t {
    svcvt_u32_f64_m(svdup_n_u32(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcvtzu))]
pub unsafe fn svcvt_u64_f32_m(inactive: svuint64_t, pg: svbool_t, op: svfloat32_t) -> svuint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fcvtzu.i64f32")]
        fn _svcvt_u64_f32_m(inactive: svint64_t, pg: svbool2_t, op: svfloat32_t) -> svint64_t;
    }
    unsafe { _svcvt_u64_f32_m(inactive.as_signed(), pg.into(), op).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcvtzu))]
pub unsafe fn svcvt_u64_f32_x(pg: svbool_t, op: svfloat32_t) -> svuint64_t {
    unsafe { svcvt_u64_f32_m(simd_reinterpret(op), pg, op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcvtzu))]
pub unsafe fn svcvt_u64_f32_z(pg: svbool_t, op: svfloat32_t) -> svuint64_t {
    svcvt_u64_f32_m(svdup_n_u64(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcvtzu))]
pub unsafe fn svcvt_u64_f64_m(inactive: svuint64_t, pg: svbool_t, op: svfloat64_t) -> svuint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fcvtzu.i64f64")]
        fn _svcvt_u64_f64_m(inactive: svint64_t, pg: svbool2_t, op: svfloat64_t) -> svint64_t;
    }
    unsafe { _svcvt_u64_f64_m(inactive.as_signed(), pg.into(), op).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcvtzu))]
pub unsafe fn svcvt_u64_f64_x(pg: svbool_t, op: svfloat64_t) -> svuint64_t {
    unsafe { svcvt_u64_f64_m(simd_reinterpret(op), pg, op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcvtzu))]
pub unsafe fn svcvt_u64_f64_z(pg: svbool_t, op: svfloat64_t) -> svuint64_t {
    svcvt_u64_f64_m(svdup_n_u64(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fdiv))]
pub unsafe fn svdiv_f32_m(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fdiv.nxv4f32")]
        fn _svdiv_f32_m(pg: svbool4_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svdiv_f32_m(pg.into(), op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fdiv))]
pub unsafe fn svdiv_n_f32_m(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svfloat32_t {
    svdiv_f32_m(pg, op1, svdup_n_f32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fdiv))]
pub unsafe fn svdiv_f32_x(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    svdiv_f32_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fdiv))]
pub unsafe fn svdiv_n_f32_x(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svfloat32_t {
    svdiv_f32_x(pg, op1, svdup_n_f32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fdiv))]
pub unsafe fn svdiv_f32_z(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    svdiv_f32_m(pg.clone(), svsel_f32(pg, op1, svdup_n_f32(0.0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fdiv))]
pub unsafe fn svdiv_n_f32_z(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svfloat32_t {
    svdiv_f32_z(pg, op1, svdup_n_f32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fdiv))]
pub unsafe fn svdiv_f64_m(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fdiv.nxv2f64")]
        fn _svdiv_f64_m(pg: svbool2_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svdiv_f64_m(pg.into(), op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fdiv))]
pub unsafe fn svdiv_n_f64_m(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svfloat64_t {
    svdiv_f64_m(pg, op1, svdup_n_f64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fdiv))]
pub unsafe fn svdiv_f64_x(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    svdiv_f64_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fdiv))]
pub unsafe fn svdiv_n_f64_x(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svfloat64_t {
    svdiv_f64_x(pg, op1, svdup_n_f64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fdiv))]
pub unsafe fn svdiv_f64_z(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    svdiv_f64_m(pg.clone(), svsel_f64(pg, op1, svdup_n_f64(0.0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fdiv))]
pub unsafe fn svdiv_n_f64_z(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svfloat64_t {
    svdiv_f64_z(pg, op1, svdup_n_f64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sdiv))]
pub unsafe fn svdiv_s32_m(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sdiv.nxv4i32")]
        fn _svdiv_s32_m(pg: svbool4_t, op1: svint32_t, op2: svint32_t) -> svint32_t;
    }
    unsafe { _svdiv_s32_m(pg.into(), op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sdiv))]
pub unsafe fn svdiv_n_s32_m(pg: svbool_t, op1: svint32_t, op2: i32) -> svint32_t {
    svdiv_s32_m(pg, op1, svdup_n_s32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sdiv))]
pub unsafe fn svdiv_s32_x(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    svdiv_s32_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sdiv))]
pub unsafe fn svdiv_n_s32_x(pg: svbool_t, op1: svint32_t, op2: i32) -> svint32_t {
    svdiv_s32_x(pg, op1, svdup_n_s32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sdiv))]
pub unsafe fn svdiv_s32_z(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    svdiv_s32_m(pg.clone(), svsel_s32(pg, op1, svdup_n_s32(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sdiv))]
pub unsafe fn svdiv_n_s32_z(pg: svbool_t, op1: svint32_t, op2: i32) -> svint32_t {
    svdiv_s32_z(pg, op1, svdup_n_s32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sdiv))]
pub unsafe fn svdiv_s64_m(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sdiv.nxv2i64")]
        fn _svdiv_s64_m(pg: svbool2_t, op1: svint64_t, op2: svint64_t) -> svint64_t;
    }
    unsafe { _svdiv_s64_m(pg.into(), op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sdiv))]
pub unsafe fn svdiv_n_s64_m(pg: svbool_t, op1: svint64_t, op2: i64) -> svint64_t {
    svdiv_s64_m(pg, op1, svdup_n_s64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sdiv))]
pub unsafe fn svdiv_s64_x(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    svdiv_s64_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sdiv))]
pub unsafe fn svdiv_n_s64_x(pg: svbool_t, op1: svint64_t, op2: i64) -> svint64_t {
    svdiv_s64_x(pg, op1, svdup_n_s64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sdiv))]
pub unsafe fn svdiv_s64_z(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    svdiv_s64_m(pg.clone(), svsel_s64(pg, op1, svdup_n_s64(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sdiv))]
pub unsafe fn svdiv_n_s64_z(pg: svbool_t, op1: svint64_t, op2: i64) -> svint64_t {
    svdiv_s64_z(pg, op1, svdup_n_s64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(udiv))]
pub unsafe fn svdiv_u32_m(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.udiv.nxv4i32")]
        fn _svdiv_u32_m(pg: svbool4_t, op1: svint32_t, op2: svint32_t) -> svint32_t;
    }
    unsafe { _svdiv_u32_m(pg.into(), op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(udiv))]
pub unsafe fn svdiv_n_u32_m(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svdiv_u32_m(pg, op1, svdup_n_u32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(udiv))]
pub unsafe fn svdiv_u32_x(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    svdiv_u32_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(udiv))]
pub unsafe fn svdiv_n_u32_x(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svdiv_u32_x(pg, op1, svdup_n_u32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(udiv))]
pub unsafe fn svdiv_u32_z(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    svdiv_u32_m(pg.clone(), svsel_u32(pg, op1, svdup_n_u32(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(udiv))]
pub unsafe fn svdiv_n_u32_z(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svdiv_u32_z(pg, op1, svdup_n_u32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(udiv))]
pub unsafe fn svdiv_u64_m(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.udiv.nxv2i64")]
        fn _svdiv_u64_m(pg: svbool2_t, op1: svint64_t, op2: svint64_t) -> svint64_t;
    }
    unsafe { _svdiv_u64_m(pg.into(), op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(udiv))]
pub unsafe fn svdiv_n_u64_m(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svdiv_u64_m(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(udiv))]
pub unsafe fn svdiv_u64_x(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    svdiv_u64_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(udiv))]
pub unsafe fn svdiv_n_u64_x(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svdiv_u64_x(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(udiv))]
pub unsafe fn svdiv_u64_z(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    svdiv_u64_m(pg.clone(), svsel_u64(pg, op1, svdup_n_u64(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(udiv))]
pub unsafe fn svdiv_n_u64_z(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svdiv_u64_z(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fdivr))]
pub unsafe fn svdivr_f32_m(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fdivr.nxv4f32")]
        fn _svdivr_f32_m(pg: svbool4_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svdivr_f32_m(pg.into(), op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fdivr))]
pub unsafe fn svdivr_n_f32_m(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svfloat32_t {
    svdivr_f32_m(pg, op1, svdup_n_f32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fdivr))]
pub unsafe fn svdivr_f32_x(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    svdivr_f32_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fdivr))]
pub unsafe fn svdivr_n_f32_x(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svfloat32_t {
    svdivr_f32_x(pg, op1, svdup_n_f32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fdivr))]
pub unsafe fn svdivr_f32_z(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    svdivr_f32_m(pg.clone(), svsel_f32(pg, op1, svdup_n_f32(0.0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fdivr))]
pub unsafe fn svdivr_n_f32_z(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svfloat32_t {
    svdivr_f32_z(pg, op1, svdup_n_f32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fdivr))]
pub unsafe fn svdivr_f64_m(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fdivr.nxv2f64")]
        fn _svdivr_f64_m(pg: svbool2_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svdivr_f64_m(pg.into(), op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fdivr))]
pub unsafe fn svdivr_n_f64_m(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svfloat64_t {
    svdivr_f64_m(pg, op1, svdup_n_f64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fdivr))]
pub unsafe fn svdivr_f64_x(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    svdivr_f64_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fdivr))]
pub unsafe fn svdivr_n_f64_x(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svfloat64_t {
    svdivr_f64_x(pg, op1, svdup_n_f64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fdivr))]
pub unsafe fn svdivr_f64_z(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    svdivr_f64_m(pg.clone(), svsel_f64(pg, op1, svdup_n_f64(0.0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fdivr))]
pub unsafe fn svdivr_n_f64_z(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svfloat64_t {
    svdivr_f64_z(pg, op1, svdup_n_f64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sdivr))]
pub unsafe fn svdivr_s32_m(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sdivr.nxv4i32")]
        fn _svdivr_s32_m(pg: svbool4_t, op1: svint32_t, op2: svint32_t) -> svint32_t;
    }
    unsafe { _svdivr_s32_m(pg.into(), op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sdivr))]
pub unsafe fn svdivr_n_s32_m(pg: svbool_t, op1: svint32_t, op2: i32) -> svint32_t {
    svdivr_s32_m(pg, op1, svdup_n_s32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sdivr))]
pub unsafe fn svdivr_s32_x(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    svdivr_s32_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sdivr))]
pub unsafe fn svdivr_n_s32_x(pg: svbool_t, op1: svint32_t, op2: i32) -> svint32_t {
    svdivr_s32_x(pg, op1, svdup_n_s32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sdivr))]
pub unsafe fn svdivr_s32_z(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    svdivr_s32_m(pg.clone(), svsel_s32(pg, op1, svdup_n_s32(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sdivr))]
pub unsafe fn svdivr_n_s32_z(pg: svbool_t, op1: svint32_t, op2: i32) -> svint32_t {
    svdivr_s32_z(pg, op1, svdup_n_s32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sdivr))]
pub unsafe fn svdivr_s64_m(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sdivr.nxv2i64")]
        fn _svdivr_s64_m(pg: svbool2_t, op1: svint64_t, op2: svint64_t) -> svint64_t;
    }
    unsafe { _svdivr_s64_m(pg.into(), op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sdivr))]
pub unsafe fn svdivr_n_s64_m(pg: svbool_t, op1: svint64_t, op2: i64) -> svint64_t {
    svdivr_s64_m(pg, op1, svdup_n_s64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sdivr))]
pub unsafe fn svdivr_s64_x(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    svdivr_s64_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sdivr))]
pub unsafe fn svdivr_n_s64_x(pg: svbool_t, op1: svint64_t, op2: i64) -> svint64_t {
    svdivr_s64_x(pg, op1, svdup_n_s64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sdivr))]
pub unsafe fn svdivr_s64_z(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    svdivr_s64_m(pg.clone(), svsel_s64(pg, op1, svdup_n_s64(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sdivr))]
pub unsafe fn svdivr_n_s64_z(pg: svbool_t, op1: svint64_t, op2: i64) -> svint64_t {
    svdivr_s64_z(pg, op1, svdup_n_s64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(udivr))]
pub unsafe fn svdivr_u32_m(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.udivr.nxv4i32")]
        fn _svdivr_u32_m(pg: svbool4_t, op1: svint32_t, op2: svint32_t) -> svint32_t;
    }
    unsafe { _svdivr_u32_m(pg.into(), op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(udivr))]
pub unsafe fn svdivr_n_u32_m(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svdivr_u32_m(pg, op1, svdup_n_u32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(udivr))]
pub unsafe fn svdivr_u32_x(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    svdivr_u32_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(udivr))]
pub unsafe fn svdivr_n_u32_x(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svdivr_u32_x(pg, op1, svdup_n_u32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(udivr))]
pub unsafe fn svdivr_u32_z(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    svdivr_u32_m(pg.clone(), svsel_u32(pg, op1, svdup_n_u32(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(udivr))]
pub unsafe fn svdivr_n_u32_z(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svdivr_u32_z(pg, op1, svdup_n_u32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(udivr))]
pub unsafe fn svdivr_u64_m(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.udivr.nxv2i64")]
        fn _svdivr_u64_m(pg: svbool2_t, op1: svint64_t, op2: svint64_t) -> svint64_t;
    }
    unsafe { _svdivr_u64_m(pg.into(), op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(udivr))]
pub unsafe fn svdivr_n_u64_m(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svdivr_u64_m(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(udivr))]
pub unsafe fn svdivr_u64_x(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    svdivr_u64_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(udivr))]
pub unsafe fn svdivr_n_u64_x(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svdivr_u64_x(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(udivr))]
pub unsafe fn svdivr_u64_z(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    svdivr_u64_m(pg.clone(), svsel_u64(pg, op1, svdup_n_u64(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(udivr))]
pub unsafe fn svdivr_n_u64_z(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svdivr_u64_z(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sdot, IMM_INDEX = 0))]
pub unsafe fn svdot_lane_s32<const IMM_INDEX: i32>(
    op1: svint32_t,
    op2: svint8_t,
    op3: svint8_t,
) -> svint32_t {
    static_assert_range!(IMM_INDEX, 0, 3);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.sdot.lane.nxv4i32"
        )]
        fn _svdot_lane_s32(
            op1: svint32_t,
            op2: svint8_t,
            op3: svint8_t,
            imm_index: i32,
        ) -> svint32_t;
    }
    unsafe { _svdot_lane_s32(op1, op2, op3, IMM_INDEX) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sdot, IMM_INDEX = 0))]
pub unsafe fn svdot_lane_s64<const IMM_INDEX: i32>(
    op1: svint64_t,
    op2: svint16_t,
    op3: svint16_t,
) -> svint64_t {
    static_assert_range!(IMM_INDEX, 0, 1);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.sdot.lane.nxv2i64"
        )]
        fn _svdot_lane_s64(
            op1: svint64_t,
            op2: svint16_t,
            op3: svint16_t,
            imm_index: i32,
        ) -> svint64_t;
    }
    unsafe { _svdot_lane_s64(op1, op2, op3, IMM_INDEX) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(udot, IMM_INDEX = 0))]
pub unsafe fn svdot_lane_u32<const IMM_INDEX: i32>(
    op1: svuint32_t,
    op2: svuint8_t,
    op3: svuint8_t,
) -> svuint32_t {
    static_assert_range!(IMM_INDEX, 0, 3);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.udot.lane.nxv4i32"
        )]
        fn _svdot_lane_u32(
            op1: svint32_t,
            op2: svint8_t,
            op3: svint8_t,
            imm_index: i32,
        ) -> svint32_t;
    }
    unsafe {
        _svdot_lane_u32(op1.as_signed(), op2.as_signed(), op3.as_signed(), IMM_INDEX).as_unsigned()
    }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(udot, IMM_INDEX = 0))]
pub unsafe fn svdot_lane_u64<const IMM_INDEX: i32>(
    op1: svuint64_t,
    op2: svuint16_t,
    op3: svuint16_t,
) -> svuint64_t {
    static_assert_range!(IMM_INDEX, 0, 1);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.udot.lane.nxv2i64"
        )]
        fn _svdot_lane_u64(
            op1: svint64_t,
            op2: svint16_t,
            op3: svint16_t,
            imm_index: i32,
        ) -> svint64_t;
    }
    unsafe {
        _svdot_lane_u64(op1.as_signed(), op2.as_signed(), op3.as_signed(), IMM_INDEX).as_unsigned()
    }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sdot))]
pub unsafe fn svdot_s32(op1: svint32_t, op2: svint8_t, op3: svint8_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sdot.nxv4i32")]
        fn _svdot_s32(op1: svint32_t, op2: svint8_t, op3: svint8_t) -> svint32_t;
    }
    unsafe { _svdot_s32(op1, op2, op3) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sdot))]
pub unsafe fn svdot_n_s32(op1: svint32_t, op2: svint8_t, op3: i8) -> svint32_t {
    svdot_s32(op1, op2, svdup_n_s8(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sdot))]
pub unsafe fn svdot_s64(op1: svint64_t, op2: svint16_t, op3: svint16_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sdot.nxv2i64")]
        fn _svdot_s64(op1: svint64_t, op2: svint16_t, op3: svint16_t) -> svint64_t;
    }
    unsafe { _svdot_s64(op1, op2, op3) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sdot))]
pub unsafe fn svdot_n_s64(op1: svint64_t, op2: svint16_t, op3: i16) -> svint64_t {
    svdot_s64(op1, op2, svdup_n_s16(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(udot))]
pub unsafe fn svdot_u32(op1: svuint32_t, op2: svuint8_t, op3: svuint8_t) -> svuint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.udot.nxv4i32")]
        fn _svdot_u32(op1: svint32_t, op2: svint8_t, op3: svint8_t) -> svint32_t;
    }
    unsafe { _svdot_u32(op1.as_signed(), op2.as_signed(), op3.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(udot))]
pub unsafe fn svdot_n_u32(op1: svuint32_t, op2: svuint8_t, op3: u8) -> svuint32_t {
    svdot_u32(op1, op2, svdup_n_u8(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(udot))]
pub unsafe fn svdot_u64(op1: svuint64_t, op2: svuint16_t, op3: svuint16_t) -> svuint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.udot.nxv2i64")]
        fn _svdot_u64(op1: svint64_t, op2: svint16_t, op3: svint16_t) -> svint64_t;
    }
    unsafe { _svdot_u64(op1.as_signed(), op2.as_signed(), op3.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(udot))]
pub unsafe fn svdot_n_u64(op1: svuint64_t, op2: svuint16_t, op3: u16) -> svuint64_t {
    svdot_u64(op1, op2, svdup_n_u16(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(tbl))]
pub unsafe fn svdup_lane_f32(data: svfloat32_t, index: u32) -> svfloat32_t {
    svtbl_f32(data, svdup_n_u32(index))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(tbl))]
pub unsafe fn svdup_lane_f64(data: svfloat64_t, index: u64) -> svfloat64_t {
    svtbl_f64(data, svdup_n_u64(index))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(tbl))]
pub unsafe fn svdup_lane_s8(data: svint8_t, index: u8) -> svint8_t {
    svtbl_s8(data, svdup_n_u8(index))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(tbl))]
pub unsafe fn svdup_lane_s16(data: svint16_t, index: u16) -> svint16_t {
    svtbl_s16(data, svdup_n_u16(index))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(tbl))]
pub unsafe fn svdup_lane_s32(data: svint32_t, index: u32) -> svint32_t {
    svtbl_s32(data, svdup_n_u32(index))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(tbl))]
pub unsafe fn svdup_lane_s64(data: svint64_t, index: u64) -> svint64_t {
    svtbl_s64(data, svdup_n_u64(index))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(tbl))]
pub unsafe fn svdup_lane_u8(data: svuint8_t, index: u8) -> svuint8_t {
    svtbl_u8(data, svdup_n_u8(index))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(tbl))]
pub unsafe fn svdup_lane_u16(data: svuint16_t, index: u16) -> svuint16_t {
    svtbl_u16(data, svdup_n_u16(index))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(tbl))]
pub unsafe fn svdup_lane_u32(data: svuint32_t, index: u32) -> svuint32_t {
    svtbl_u32(data, svdup_n_u32(index))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(tbl))]
pub unsafe fn svdup_lane_u64(data: svuint64_t, index: u64) -> svuint64_t {
    svtbl_u64(data, svdup_n_u64(index))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sbfx))]
#[cfg_attr(test, assert_instr(whilelo))]
pub unsafe fn svdup_n_b8(op: bool) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.dup.x.nxv16i1")]
        fn _svdup_n_b8(op: bool) -> svbool_t;
    }
    unsafe { _svdup_n_b8(op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sbfx))]
#[cfg_attr(test, assert_instr(whilelo))]
pub unsafe fn svdup_n_b16(op: bool) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.dup.x.nxv8i1")]
        fn _svdup_n_b16(op: bool) -> svbool8_t;
    }
    unsafe { _svdup_n_b16(op).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sbfx))]
#[cfg_attr(test, assert_instr(whilelo))]
pub unsafe fn svdup_n_b32(op: bool) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.dup.x.nxv4i1")]
        fn _svdup_n_b32(op: bool) -> svbool4_t;
    }
    unsafe { _svdup_n_b32(op).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sbfx))]
#[cfg_attr(test, assert_instr(whilelo))]
pub unsafe fn svdup_n_b64(op: bool) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.dup.x.nxv2i1")]
        fn _svdup_n_b64(op: bool) -> svbool2_t;
    }
    unsafe { _svdup_n_b64(op).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub unsafe fn svdup_n_f32(op: f32) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.dup.x.nxv4f32")]
        fn _svdup_n_f32(op: f32) -> svfloat32_t;
    }
    unsafe { _svdup_n_f32(op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub unsafe fn svdup_n_f64(op: f64) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.dup.x.nxv2f64")]
        fn _svdup_n_f64(op: f64) -> svfloat64_t;
    }
    unsafe { _svdup_n_f64(op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub unsafe fn svdup_n_s8(op: i8) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.dup.x.nxv16i8")]
        fn _svdup_n_s8(op: i8) -> svint8_t;
    }
    unsafe { _svdup_n_s8(op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub unsafe fn svdup_n_s16(op: i16) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.dup.x.nxv8i16")]
        fn _svdup_n_s16(op: i16) -> svint16_t;
    }
    unsafe { _svdup_n_s16(op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub unsafe fn svdup_n_s32(op: i32) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.dup.x.nxv4i32")]
        fn _svdup_n_s32(op: i32) -> svint32_t;
    }
    unsafe { _svdup_n_s32(op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub unsafe fn svdup_n_s64(op: i64) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.dup.x.nxv2i64")]
        fn _svdup_n_s64(op: i64) -> svint64_t;
    }
    unsafe { _svdup_n_s64(op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub unsafe fn svdup_n_u8(op: u8) -> svuint8_t {
    unsafe { svdup_n_s8(op.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub unsafe fn svdup_n_u16(op: u16) -> svuint16_t {
    unsafe { svdup_n_s16(op.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub unsafe fn svdup_n_u32(op: u32) -> svuint32_t {
    unsafe { svdup_n_s32(op.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub unsafe fn svdup_n_u64(op: u64) -> svuint64_t {
    unsafe { svdup_n_s64(op.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub unsafe fn svdup_n_f32_m(inactive: svfloat32_t, pg: svbool_t, op: f32) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.dup.nxv4f32")]
        fn _svdup_n_f32_m(inactive: svfloat32_t, pg: svbool4_t, op: f32) -> svfloat32_t;
    }
    unsafe { _svdup_n_f32_m(inactive, pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub unsafe fn svdup_n_f32_x(pg: svbool_t, op: f32) -> svfloat32_t {
    svdup_n_f32_m(svdup_n_f32(0.0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub unsafe fn svdup_n_f32_z(pg: svbool_t, op: f32) -> svfloat32_t {
    svdup_n_f32_m(svdup_n_f32(0.0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub unsafe fn svdup_n_f64_m(inactive: svfloat64_t, pg: svbool_t, op: f64) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.dup.nxv2f64")]
        fn _svdup_n_f64_m(inactive: svfloat64_t, pg: svbool2_t, op: f64) -> svfloat64_t;
    }
    unsafe { _svdup_n_f64_m(inactive, pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub unsafe fn svdup_n_f64_x(pg: svbool_t, op: f64) -> svfloat64_t {
    svdup_n_f64_m(svdup_n_f64(0.0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub unsafe fn svdup_n_f64_z(pg: svbool_t, op: f64) -> svfloat64_t {
    svdup_n_f64_m(svdup_n_f64(0.0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub unsafe fn svdup_n_s8_m(inactive: svint8_t, pg: svbool_t, op: i8) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.dup.nxv16i8")]
        fn _svdup_n_s8_m(inactive: svint8_t, pg: svbool_t, op: i8) -> svint8_t;
    }
    unsafe { _svdup_n_s8_m(inactive, pg, op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub unsafe fn svdup_n_s8_x(pg: svbool_t, op: i8) -> svint8_t {
    svdup_n_s8_m(svdup_n_s8(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub unsafe fn svdup_n_s8_z(pg: svbool_t, op: i8) -> svint8_t {
    svdup_n_s8_m(svdup_n_s8(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub unsafe fn svdup_n_s16_m(inactive: svint16_t, pg: svbool_t, op: i16) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.dup.nxv8i16")]
        fn _svdup_n_s16_m(inactive: svint16_t, pg: svbool8_t, op: i16) -> svint16_t;
    }
    unsafe { _svdup_n_s16_m(inactive, pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub unsafe fn svdup_n_s16_x(pg: svbool_t, op: i16) -> svint16_t {
    svdup_n_s16_m(svdup_n_s16(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub unsafe fn svdup_n_s16_z(pg: svbool_t, op: i16) -> svint16_t {
    svdup_n_s16_m(svdup_n_s16(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub unsafe fn svdup_n_s32_m(inactive: svint32_t, pg: svbool_t, op: i32) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.dup.nxv4i32")]
        fn _svdup_n_s32_m(inactive: svint32_t, pg: svbool4_t, op: i32) -> svint32_t;
    }
    unsafe { _svdup_n_s32_m(inactive, pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub unsafe fn svdup_n_s32_x(pg: svbool_t, op: i32) -> svint32_t {
    svdup_n_s32_m(svdup_n_s32(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub unsafe fn svdup_n_s32_z(pg: svbool_t, op: i32) -> svint32_t {
    svdup_n_s32_m(svdup_n_s32(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub unsafe fn svdup_n_s64_m(inactive: svint64_t, pg: svbool_t, op: i64) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.dup.nxv2i64")]
        fn _svdup_n_s64_m(inactive: svint64_t, pg: svbool2_t, op: i64) -> svint64_t;
    }
    unsafe { _svdup_n_s64_m(inactive, pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub unsafe fn svdup_n_s64_x(pg: svbool_t, op: i64) -> svint64_t {
    svdup_n_s64_m(svdup_n_s64(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub unsafe fn svdup_n_s64_z(pg: svbool_t, op: i64) -> svint64_t {
    svdup_n_s64_m(svdup_n_s64(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub unsafe fn svdup_n_u8_m(inactive: svuint8_t, pg: svbool_t, op: u8) -> svuint8_t {
    unsafe { svdup_n_s8_m(inactive.as_signed(), pg, op.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub unsafe fn svdup_n_u8_x(pg: svbool_t, op: u8) -> svuint8_t {
    svdup_n_u8_m(svdup_n_u8(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub unsafe fn svdup_n_u8_z(pg: svbool_t, op: u8) -> svuint8_t {
    svdup_n_u8_m(svdup_n_u8(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub unsafe fn svdup_n_u16_m(inactive: svuint16_t, pg: svbool_t, op: u16) -> svuint16_t {
    unsafe { svdup_n_s16_m(inactive.as_signed(), pg, op.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub unsafe fn svdup_n_u16_x(pg: svbool_t, op: u16) -> svuint16_t {
    svdup_n_u16_m(svdup_n_u16(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub unsafe fn svdup_n_u16_z(pg: svbool_t, op: u16) -> svuint16_t {
    svdup_n_u16_m(svdup_n_u16(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub unsafe fn svdup_n_u32_m(inactive: svuint32_t, pg: svbool_t, op: u32) -> svuint32_t {
    unsafe { svdup_n_s32_m(inactive.as_signed(), pg, op.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub unsafe fn svdup_n_u32_x(pg: svbool_t, op: u32) -> svuint32_t {
    svdup_n_u32_m(svdup_n_u32(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub unsafe fn svdup_n_u32_z(pg: svbool_t, op: u32) -> svuint32_t {
    svdup_n_u32_m(svdup_n_u32(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub unsafe fn svdup_n_u64_m(inactive: svuint64_t, pg: svbool_t, op: u64) -> svuint64_t {
    unsafe { svdup_n_s64_m(inactive.as_signed(), pg, op.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub unsafe fn svdup_n_u64_x(pg: svbool_t, op: u64) -> svuint64_t {
    svdup_n_u64_m(svdup_n_u64(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub unsafe fn svdup_n_u64_z(pg: svbool_t, op: u64) -> svuint64_t {
    svdup_n_u64_m(svdup_n_u64(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(tbl))]
pub unsafe fn svdupq_lane_f32(data: svfloat32_t, index: u64) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.dupq.lane.nxv4f32"
        )]
        fn _svdupq_lane_f32(data: svfloat32_t, index: i64) -> svfloat32_t;
    }
    unsafe { _svdupq_lane_f32(data, index.as_signed()) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(tbl))]
pub unsafe fn svdupq_lane_f64(data: svfloat64_t, index: u64) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.dupq.lane.nxv2f64"
        )]
        fn _svdupq_lane_f64(data: svfloat64_t, index: i64) -> svfloat64_t;
    }
    unsafe { _svdupq_lane_f64(data, index.as_signed()) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(tbl))]
pub unsafe fn svdupq_lane_s8(data: svint8_t, index: u64) -> svint8_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.dupq.lane.nxv16i8"
        )]
        fn _svdupq_lane_s8(data: svint8_t, index: i64) -> svint8_t;
    }
    unsafe { _svdupq_lane_s8(data, index.as_signed()) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(tbl))]
pub unsafe fn svdupq_lane_s16(data: svint16_t, index: u64) -> svint16_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.dupq.lane.nxv8i16"
        )]
        fn _svdupq_lane_s16(data: svint16_t, index: i64) -> svint16_t;
    }
    unsafe { _svdupq_lane_s16(data, index.as_signed()) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(tbl))]
pub unsafe fn svdupq_lane_s32(data: svint32_t, index: u64) -> svint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.dupq.lane.nxv4i32"
        )]
        fn _svdupq_lane_s32(data: svint32_t, index: i64) -> svint32_t;
    }
    unsafe { _svdupq_lane_s32(data, index.as_signed()) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(tbl))]
pub unsafe fn svdupq_lane_s64(data: svint64_t, index: u64) -> svint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.dupq.lane.nxv2i64"
        )]
        fn _svdupq_lane_s64(data: svint64_t, index: i64) -> svint64_t;
    }
    unsafe { _svdupq_lane_s64(data, index.as_signed()) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(tbl))]
pub unsafe fn svdupq_lane_u8(data: svuint8_t, index: u64) -> svuint8_t {
    unsafe { svdupq_lane_s8(data.as_signed(), index).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(tbl))]
pub unsafe fn svdupq_lane_u16(data: svuint16_t, index: u64) -> svuint16_t {
    unsafe { svdupq_lane_s16(data.as_signed(), index).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(tbl))]
pub unsafe fn svdupq_lane_u32(data: svuint32_t, index: u64) -> svuint32_t {
    unsafe { svdupq_lane_s32(data.as_signed(), index).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(tbl))]
pub unsafe fn svdupq_lane_u64(data: svuint64_t, index: u64) -> svuint64_t {
    unsafe { svdupq_lane_s64(data.as_signed(), index).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svdupq_n_b16(
    x0: bool,
    x1: bool,
    x2: bool,
    x3: bool,
    x4: bool,
    x5: bool,
    x6: bool,
    x7: bool,
) -> svbool_t {
    let op1 = svdupq_n_s16(
        x0 as i16, x1 as i16, x2 as i16, x3 as i16, x4 as i16, x5 as i16, x6 as i16, x7 as i16,
    );
    svcmpne_wide_s16(svptrue_b16(), op1, svdup_n_s64(0))
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svdupq_n_b32(x0: bool, x1: bool, x2: bool, x3: bool) -> svbool_t {
    let op1 = svdupq_n_s32(x0 as i32, x1 as i32, x2 as i32, x3 as i32);
    svcmpne_wide_s32(svptrue_b32(), op1, svdup_n_s64(0))
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svdupq_n_b64(x0: bool, x1: bool) -> svbool_t {
    let op1 = svdupq_n_s64(x0 as i64, x1 as i64);
    svcmpne_s64(svptrue_b64(), op1, svdup_n_s64(0))
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svdupq_n_b8(
    x0: bool,
    x1: bool,
    x2: bool,
    x3: bool,
    x4: bool,
    x5: bool,
    x6: bool,
    x7: bool,
    x8: bool,
    x9: bool,
    x10: bool,
    x11: bool,
    x12: bool,
    x13: bool,
    x14: bool,
    x15: bool,
) -> svbool_t {
    let op1 = svdupq_n_s8(
        x0 as i8, x1 as i8, x2 as i8, x3 as i8, x4 as i8, x5 as i8, x6 as i8, x7 as i8, x8 as i8,
        x9 as i8, x10 as i8, x11 as i8, x12 as i8, x13 as i8, x14 as i8, x15 as i8,
    );
    svcmpne_wide_s8(svptrue_b8(), op1, svdup_n_s64(0))
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svdupq_n_f32(x0: f32, x1: f32, x2: f32, x3: f32) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.experimental.vector.insert.nxv4f32.v4f32"
        )]
        fn _svdupq_n_f32(op0: svfloat32_t, op1: float32x4_t, idx: i64) -> svfloat32_t;
    }
    unsafe {
        let op = _svdupq_n_f32(
            simd_reinterpret(()),
            crate::mem::transmute([x0, x1, x2, x3]),
            0,
        );
        svdupq_lane_f32(op, 0)
    }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svdupq_n_s32(x0: i32, x1: i32, x2: i32, x3: i32) -> svint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.experimental.vector.insert.nxv4i32.v4i32"
        )]
        fn _svdupq_n_s32(op0: svint32_t, op1: int32x4_t, idx: i64) -> svint32_t;
    }
    unsafe {
        let op = _svdupq_n_s32(
            simd_reinterpret(()),
            crate::mem::transmute([x0, x1, x2, x3]),
            0,
        );
        svdupq_lane_s32(op, 0)
    }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svdupq_n_u32(x0: u32, x1: u32, x2: u32, x3: u32) -> svuint32_t {
    unsafe {
        svdupq_n_s32(
            x0.as_signed(),
            x1.as_signed(),
            x2.as_signed(),
            x3.as_signed(),
        )
        .as_unsigned()
    }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svdupq_n_f64(x0: f64, x1: f64) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.experimental.vector.insert.nxv2f64.v2f64"
        )]
        fn _svdupq_n_f64(op0: svfloat64_t, op1: float64x2_t, idx: i64) -> svfloat64_t;
    }
    unsafe {
        let op = _svdupq_n_f64(simd_reinterpret(()), crate::mem::transmute([x0, x1]), 0);
        svdupq_lane_f64(op, 0)
    }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svdupq_n_s64(x0: i64, x1: i64) -> svint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.experimental.vector.insert.nxv2i64.v2i64"
        )]
        fn _svdupq_n_s64(op0: svint64_t, op1: int64x2_t, idx: i64) -> svint64_t;
    }
    unsafe {
        let op = _svdupq_n_s64(simd_reinterpret(()), crate::mem::transmute([x0, x1]), 0);
        svdupq_lane_s64(op, 0)
    }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svdupq_n_u64(x0: u64, x1: u64) -> svuint64_t {
    unsafe { svdupq_n_s64(x0.as_signed(), x1.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svdupq_n_s16(
    x0: i16,
    x1: i16,
    x2: i16,
    x3: i16,
    x4: i16,
    x5: i16,
    x6: i16,
    x7: i16,
) -> svint16_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.experimental.vector.insert.nxv8i16.v8i16"
        )]
        fn _svdupq_n_s16(op0: svint16_t, op1: int16x8_t, idx: i64) -> svint16_t;
    }
    unsafe {
        let op = _svdupq_n_s16(
            simd_reinterpret(()),
            crate::mem::transmute([x0, x1, x2, x3, x4, x5, x6, x7]),
            0,
        );
        svdupq_lane_s16(op, 0)
    }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svdupq_n_u16(
    x0: u16,
    x1: u16,
    x2: u16,
    x3: u16,
    x4: u16,
    x5: u16,
    x6: u16,
    x7: u16,
) -> svuint16_t {
    unsafe {
        svdupq_n_s16(
            x0.as_signed(),
            x1.as_signed(),
            x2.as_signed(),
            x3.as_signed(),
            x4.as_signed(),
            x5.as_signed(),
            x6.as_signed(),
            x7.as_signed(),
        )
        .as_unsigned()
    }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svdupq_n_s8(
    x0: i8,
    x1: i8,
    x2: i8,
    x3: i8,
    x4: i8,
    x5: i8,
    x6: i8,
    x7: i8,
    x8: i8,
    x9: i8,
    x10: i8,
    x11: i8,
    x12: i8,
    x13: i8,
    x14: i8,
    x15: i8,
) -> svint8_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.experimental.vector.insert.nxv16i8.v16i8"
        )]
        fn _svdupq_n_s8(op0: svint8_t, op1: int8x16_t, idx: i64) -> svint8_t;
    }
    unsafe {
        let op = _svdupq_n_s8(
            simd_reinterpret(()),
            crate::mem::transmute([
                x0, x1, x2, x3, x4, x5, x6, x7, x8, x9, x10, x11, x12, x13, x14, x15,
            ]),
            0,
        );
        svdupq_lane_s8(op, 0)
    }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svdupq_n_u8(
    x0: u8,
    x1: u8,
    x2: u8,
    x3: u8,
    x4: u8,
    x5: u8,
    x6: u8,
    x7: u8,
    x8: u8,
    x9: u8,
    x10: u8,
    x11: u8,
    x12: u8,
    x13: u8,
    x14: u8,
    x15: u8,
) -> svuint8_t {
    unsafe {
        svdupq_n_s8(
            x0.as_signed(),
            x1.as_signed(),
            x2.as_signed(),
            x3.as_signed(),
            x4.as_signed(),
            x5.as_signed(),
            x6.as_signed(),
            x7.as_signed(),
            x8.as_signed(),
            x9.as_signed(),
            x10.as_signed(),
            x11.as_signed(),
            x12.as_signed(),
            x13.as_signed(),
            x14.as_signed(),
            x15.as_signed(),
        )
        .as_unsigned()
    }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub unsafe fn sveor_b_z(pg: svbool_t, op1: svbool_t, op2: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.eor.z.nvx16i1")]
        fn _sveor_b_z(pg: svbool_t, op1: svbool_t, op2: svbool_t) -> svbool_t;
    }
    unsafe { _sveor_b_z(pg, op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub unsafe fn sveor_s8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.eor.nxv16i8")]
        fn _sveor_s8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t;
    }
    unsafe { _sveor_s8_m(pg, op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub unsafe fn sveor_n_s8_m(pg: svbool_t, op1: svint8_t, op2: i8) -> svint8_t {
    sveor_s8_m(pg, op1, svdup_n_s8(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub unsafe fn sveor_s8_x(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t {
    sveor_s8_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub unsafe fn sveor_n_s8_x(pg: svbool_t, op1: svint8_t, op2: i8) -> svint8_t {
    sveor_s8_x(pg, op1, svdup_n_s8(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub unsafe fn sveor_s8_z(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t {
    sveor_s8_m(pg.clone(), svsel_s8(pg, op1, svdup_n_s8(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub unsafe fn sveor_n_s8_z(pg: svbool_t, op1: svint8_t, op2: i8) -> svint8_t {
    sveor_s8_z(pg, op1, svdup_n_s8(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub unsafe fn sveor_s16_m(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.eor.nxv8i16")]
        fn _sveor_s16_m(pg: svbool8_t, op1: svint16_t, op2: svint16_t) -> svint16_t;
    }
    unsafe { _sveor_s16_m(pg.into(), op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub unsafe fn sveor_n_s16_m(pg: svbool_t, op1: svint16_t, op2: i16) -> svint16_t {
    sveor_s16_m(pg, op1, svdup_n_s16(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub unsafe fn sveor_s16_x(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svint16_t {
    sveor_s16_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub unsafe fn sveor_n_s16_x(pg: svbool_t, op1: svint16_t, op2: i16) -> svint16_t {
    sveor_s16_x(pg, op1, svdup_n_s16(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub unsafe fn sveor_s16_z(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svint16_t {
    sveor_s16_m(pg.clone(), svsel_s16(pg, op1, svdup_n_s16(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub unsafe fn sveor_n_s16_z(pg: svbool_t, op1: svint16_t, op2: i16) -> svint16_t {
    sveor_s16_z(pg, op1, svdup_n_s16(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub unsafe fn sveor_s32_m(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.eor.nxv4i32")]
        fn _sveor_s32_m(pg: svbool4_t, op1: svint32_t, op2: svint32_t) -> svint32_t;
    }
    unsafe { _sveor_s32_m(pg.into(), op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub unsafe fn sveor_n_s32_m(pg: svbool_t, op1: svint32_t, op2: i32) -> svint32_t {
    sveor_s32_m(pg, op1, svdup_n_s32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub unsafe fn sveor_s32_x(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    sveor_s32_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub unsafe fn sveor_n_s32_x(pg: svbool_t, op1: svint32_t, op2: i32) -> svint32_t {
    sveor_s32_x(pg, op1, svdup_n_s32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub unsafe fn sveor_s32_z(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    sveor_s32_m(pg.clone(), svsel_s32(pg, op1, svdup_n_s32(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub unsafe fn sveor_n_s32_z(pg: svbool_t, op1: svint32_t, op2: i32) -> svint32_t {
    sveor_s32_z(pg, op1, svdup_n_s32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub unsafe fn sveor_s64_m(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.eor.nxv2i64")]
        fn _sveor_s64_m(pg: svbool2_t, op1: svint64_t, op2: svint64_t) -> svint64_t;
    }
    unsafe { _sveor_s64_m(pg.into(), op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub unsafe fn sveor_n_s64_m(pg: svbool_t, op1: svint64_t, op2: i64) -> svint64_t {
    sveor_s64_m(pg, op1, svdup_n_s64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub unsafe fn sveor_s64_x(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    sveor_s64_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub unsafe fn sveor_n_s64_x(pg: svbool_t, op1: svint64_t, op2: i64) -> svint64_t {
    sveor_s64_x(pg, op1, svdup_n_s64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub unsafe fn sveor_s64_z(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    sveor_s64_m(pg.clone(), svsel_s64(pg, op1, svdup_n_s64(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub unsafe fn sveor_n_s64_z(pg: svbool_t, op1: svint64_t, op2: i64) -> svint64_t {
    sveor_s64_z(pg, op1, svdup_n_s64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub unsafe fn sveor_u8_m(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    unsafe { sveor_s8_m(pg, op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub unsafe fn sveor_n_u8_m(pg: svbool_t, op1: svuint8_t, op2: u8) -> svuint8_t {
    sveor_u8_m(pg, op1, svdup_n_u8(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub unsafe fn sveor_u8_x(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    sveor_u8_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub unsafe fn sveor_n_u8_x(pg: svbool_t, op1: svuint8_t, op2: u8) -> svuint8_t {
    sveor_u8_x(pg, op1, svdup_n_u8(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub unsafe fn sveor_u8_z(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    sveor_u8_m(pg.clone(), svsel_u8(pg, op1, svdup_n_u8(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub unsafe fn sveor_n_u8_z(pg: svbool_t, op1: svuint8_t, op2: u8) -> svuint8_t {
    sveor_u8_z(pg, op1, svdup_n_u8(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub unsafe fn sveor_u16_m(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    unsafe { sveor_s16_m(pg, op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub unsafe fn sveor_n_u16_m(pg: svbool_t, op1: svuint16_t, op2: u16) -> svuint16_t {
    sveor_u16_m(pg, op1, svdup_n_u16(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub unsafe fn sveor_u16_x(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    sveor_u16_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub unsafe fn sveor_n_u16_x(pg: svbool_t, op1: svuint16_t, op2: u16) -> svuint16_t {
    sveor_u16_x(pg, op1, svdup_n_u16(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub unsafe fn sveor_u16_z(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    sveor_u16_m(pg.clone(), svsel_u16(pg, op1, svdup_n_u16(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub unsafe fn sveor_n_u16_z(pg: svbool_t, op1: svuint16_t, op2: u16) -> svuint16_t {
    sveor_u16_z(pg, op1, svdup_n_u16(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub unsafe fn sveor_u32_m(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    unsafe { sveor_s32_m(pg, op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub unsafe fn sveor_n_u32_m(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    sveor_u32_m(pg, op1, svdup_n_u32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub unsafe fn sveor_u32_x(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    sveor_u32_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub unsafe fn sveor_n_u32_x(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    sveor_u32_x(pg, op1, svdup_n_u32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub unsafe fn sveor_u32_z(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    sveor_u32_m(pg.clone(), svsel_u32(pg, op1, svdup_n_u32(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub unsafe fn sveor_n_u32_z(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    sveor_u32_z(pg, op1, svdup_n_u32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub unsafe fn sveor_u64_m(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    unsafe { sveor_s64_m(pg, op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub unsafe fn sveor_n_u64_m(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    sveor_u64_m(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub unsafe fn sveor_u64_x(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    sveor_u64_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub unsafe fn sveor_n_u64_x(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    sveor_u64_x(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub unsafe fn sveor_u64_z(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    sveor_u64_m(pg.clone(), svsel_u64(pg, op1, svdup_n_u64(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub unsafe fn sveor_n_u64_z(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    sveor_u64_z(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eorv))]
pub unsafe fn sveorv_s8(pg: svbool_t, op: svint8_t) -> i8 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.eorv.nxv16i8")]
        fn _sveorv_s8(pg: svbool_t, op: svint8_t) -> i8;
    }
    unsafe { _sveorv_s8(pg, op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eorv))]
pub unsafe fn sveorv_s16(pg: svbool_t, op: svint16_t) -> i16 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.eorv.nxv8i16")]
        fn _sveorv_s16(pg: svbool8_t, op: svint16_t) -> i16;
    }
    unsafe { _sveorv_s16(pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eorv))]
pub unsafe fn sveorv_s32(pg: svbool_t, op: svint32_t) -> i32 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.eorv.nxv4i32")]
        fn _sveorv_s32(pg: svbool4_t, op: svint32_t) -> i32;
    }
    unsafe { _sveorv_s32(pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eorv))]
pub unsafe fn sveorv_s64(pg: svbool_t, op: svint64_t) -> i64 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.eorv.nxv2i64")]
        fn _sveorv_s64(pg: svbool2_t, op: svint64_t) -> i64;
    }
    unsafe { _sveorv_s64(pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eorv))]
pub unsafe fn sveorv_u8(pg: svbool_t, op: svuint8_t) -> u8 {
    unsafe { sveorv_s8(pg, op.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eorv))]
pub unsafe fn sveorv_u16(pg: svbool_t, op: svuint16_t) -> u16 {
    unsafe { sveorv_s16(pg, op.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eorv))]
pub unsafe fn sveorv_u32(pg: svbool_t, op: svuint32_t) -> u32 {
    unsafe { sveorv_s32(pg, op.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eorv))]
pub unsafe fn sveorv_u64(pg: svbool_t, op: svuint64_t) -> u64 {
    unsafe { sveorv_s64(pg, op.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fexpa))]
pub unsafe fn svexpa_f32(op: svuint32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.fexpa.x.nxv4f32 "
        )]
        fn _svexpa_f32(op: svint32_t) -> svfloat32_t;
    }
    unsafe { _svexpa_f32(op.as_signed()) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fexpa))]
pub unsafe fn svexpa_f64(op: svuint64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.fexpa.x.nxv2f64 "
        )]
        fn _svexpa_f64(op: svint64_t) -> svfloat64_t;
    }
    unsafe { _svexpa_f64(op.as_signed()) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ext, IMM3 = 1))]
pub unsafe fn svext_f32<const IMM3: i32>(op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    static_assert_range!(IMM3, 0, 63);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ext.nxv4f32")]
        fn _svext_f32(op1: svfloat32_t, op2: svfloat32_t, imm3: i32) -> svfloat32_t;
    }
    unsafe { _svext_f32(op1, op2, IMM3) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ext, IMM3 = 1))]
pub unsafe fn svext_f64<const IMM3: i32>(op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    static_assert_range!(IMM3, 0, 31);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ext.nxv2f64")]
        fn _svext_f64(op1: svfloat64_t, op2: svfloat64_t, imm3: i32) -> svfloat64_t;
    }
    unsafe { _svext_f64(op1, op2, IMM3) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ext, IMM3 = 1))]
pub unsafe fn svext_s8<const IMM3: i32>(op1: svint8_t, op2: svint8_t) -> svint8_t {
    static_assert_range!(IMM3, 0, 255);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ext.nxv16i8")]
        fn _svext_s8(op1: svint8_t, op2: svint8_t, imm3: i32) -> svint8_t;
    }
    unsafe { _svext_s8(op1, op2, IMM3) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ext, IMM3 = 1))]
pub unsafe fn svext_s16<const IMM3: i32>(op1: svint16_t, op2: svint16_t) -> svint16_t {
    static_assert_range!(IMM3, 0, 127);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ext.nxv8i16")]
        fn _svext_s16(op1: svint16_t, op2: svint16_t, imm3: i32) -> svint16_t;
    }
    unsafe { _svext_s16(op1, op2, IMM3) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ext, IMM3 = 1))]
pub unsafe fn svext_s32<const IMM3: i32>(op1: svint32_t, op2: svint32_t) -> svint32_t {
    static_assert_range!(IMM3, 0, 63);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ext.nxv4i32")]
        fn _svext_s32(op1: svint32_t, op2: svint32_t, imm3: i32) -> svint32_t;
    }
    unsafe { _svext_s32(op1, op2, IMM3) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ext, IMM3 = 1))]
pub unsafe fn svext_s64<const IMM3: i32>(op1: svint64_t, op2: svint64_t) -> svint64_t {
    static_assert_range!(IMM3, 0, 31);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ext.nxv2i64")]
        fn _svext_s64(op1: svint64_t, op2: svint64_t, imm3: i32) -> svint64_t;
    }
    unsafe { _svext_s64(op1, op2, IMM3) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ext, IMM3 = 1))]
pub unsafe fn svext_u8<const IMM3: i32>(op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    static_assert_range!(IMM3, 0, 255);
    unsafe { svext_s8::<IMM3>(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ext, IMM3 = 1))]
pub unsafe fn svext_u16<const IMM3: i32>(op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    static_assert_range!(IMM3, 0, 127);
    unsafe { svext_s16::<IMM3>(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ext, IMM3 = 1))]
pub unsafe fn svext_u32<const IMM3: i32>(op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    static_assert_range!(IMM3, 0, 63);
    unsafe { svext_s32::<IMM3>(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ext, IMM3 = 1))]
pub unsafe fn svext_u64<const IMM3: i32>(op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    static_assert_range!(IMM3, 0, 31);
    unsafe { svext_s64::<IMM3>(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sxtb))]
pub unsafe fn svextb_s16_m(inactive: svint16_t, pg: svbool_t, op: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sxtb.nxv8i16")]
        fn _svextb_s16_m(inactive: svint16_t, pg: svbool8_t, op: svint16_t) -> svint16_t;
    }
    unsafe { _svextb_s16_m(inactive, pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sxtb))]
pub unsafe fn svextb_s16_x(pg: svbool_t, op: svint16_t) -> svint16_t {
    svextb_s16_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sxtb))]
pub unsafe fn svextb_s16_z(pg: svbool_t, op: svint16_t) -> svint16_t {
    svextb_s16_m(svdup_n_s16(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sxtb))]
pub unsafe fn svextb_s32_m(inactive: svint32_t, pg: svbool_t, op: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sxtb.nxv4i32")]
        fn _svextb_s32_m(inactive: svint32_t, pg: svbool4_t, op: svint32_t) -> svint32_t;
    }
    unsafe { _svextb_s32_m(inactive, pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sxtb))]
pub unsafe fn svextb_s32_x(pg: svbool_t, op: svint32_t) -> svint32_t {
    svextb_s32_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sxtb))]
pub unsafe fn svextb_s32_z(pg: svbool_t, op: svint32_t) -> svint32_t {
    svextb_s32_m(svdup_n_s32(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sxth))]
pub unsafe fn svexth_s32_m(inactive: svint32_t, pg: svbool_t, op: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sxth.nxv4i32")]
        fn _svexth_s32_m(inactive: svint32_t, pg: svbool4_t, op: svint32_t) -> svint32_t;
    }
    unsafe { _svexth_s32_m(inactive, pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sxth))]
pub unsafe fn svexth_s32_x(pg: svbool_t, op: svint32_t) -> svint32_t {
    svexth_s32_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sxth))]
pub unsafe fn svexth_s32_z(pg: svbool_t, op: svint32_t) -> svint32_t {
    svexth_s32_m(svdup_n_s32(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sxtb))]
pub unsafe fn svextb_s64_m(inactive: svint64_t, pg: svbool_t, op: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sxtb.nxv2i64")]
        fn _svextb_s64_m(inactive: svint64_t, pg: svbool2_t, op: svint64_t) -> svint64_t;
    }
    unsafe { _svextb_s64_m(inactive, pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sxtb))]
pub unsafe fn svextb_s64_x(pg: svbool_t, op: svint64_t) -> svint64_t {
    svextb_s64_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sxtb))]
pub unsafe fn svextb_s64_z(pg: svbool_t, op: svint64_t) -> svint64_t {
    svextb_s64_m(svdup_n_s64(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sxth))]
pub unsafe fn svexth_s64_m(inactive: svint64_t, pg: svbool_t, op: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sxth.nxv2i64")]
        fn _svexth_s64_m(inactive: svint64_t, pg: svbool2_t, op: svint64_t) -> svint64_t;
    }
    unsafe { _svexth_s64_m(inactive, pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sxth))]
pub unsafe fn svexth_s64_x(pg: svbool_t, op: svint64_t) -> svint64_t {
    svexth_s64_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sxth))]
pub unsafe fn svexth_s64_z(pg: svbool_t, op: svint64_t) -> svint64_t {
    svexth_s64_m(svdup_n_s64(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sxtw))]
pub unsafe fn svextw_s64_m(inactive: svint64_t, pg: svbool_t, op: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sxtw.nxv2i64")]
        fn _svextw_s64_m(inactive: svint64_t, pg: svbool2_t, op: svint64_t) -> svint64_t;
    }
    unsafe { _svextw_s64_m(inactive, pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sxtw))]
pub unsafe fn svextw_s64_x(pg: svbool_t, op: svint64_t) -> svint64_t {
    svextw_s64_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sxtw))]
pub unsafe fn svextw_s64_z(pg: svbool_t, op: svint64_t) -> svint64_t {
    svextw_s64_m(svdup_n_s64(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uxtb))]
pub unsafe fn svextb_u16_m(inactive: svuint16_t, pg: svbool_t, op: svuint16_t) -> svuint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uxtb.nxv8i16")]
        fn _svextb_u16_m(inactive: svint16_t, pg: svbool8_t, op: svint16_t) -> svint16_t;
    }
    unsafe { _svextb_u16_m(inactive.as_signed(), pg.into(), op.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uxtb))]
pub unsafe fn svextb_u16_x(pg: svbool_t, op: svuint16_t) -> svuint16_t {
    svextb_u16_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uxtb))]
pub unsafe fn svextb_u16_z(pg: svbool_t, op: svuint16_t) -> svuint16_t {
    svextb_u16_m(svdup_n_u16(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uxtb))]
pub unsafe fn svextb_u32_m(inactive: svuint32_t, pg: svbool_t, op: svuint32_t) -> svuint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uxtb.nxv4i32")]
        fn _svextb_u32_m(inactive: svint32_t, pg: svbool4_t, op: svint32_t) -> svint32_t;
    }
    unsafe { _svextb_u32_m(inactive.as_signed(), pg.into(), op.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uxtb))]
pub unsafe fn svextb_u32_x(pg: svbool_t, op: svuint32_t) -> svuint32_t {
    svextb_u32_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uxtb))]
pub unsafe fn svextb_u32_z(pg: svbool_t, op: svuint32_t) -> svuint32_t {
    svextb_u32_m(svdup_n_u32(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uxth))]
pub unsafe fn svexth_u32_m(inactive: svuint32_t, pg: svbool_t, op: svuint32_t) -> svuint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uxth.nxv4i32")]
        fn _svexth_u32_m(inactive: svint32_t, pg: svbool4_t, op: svint32_t) -> svint32_t;
    }
    unsafe { _svexth_u32_m(inactive.as_signed(), pg.into(), op.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uxth))]
pub unsafe fn svexth_u32_x(pg: svbool_t, op: svuint32_t) -> svuint32_t {
    svexth_u32_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uxth))]
pub unsafe fn svexth_u32_z(pg: svbool_t, op: svuint32_t) -> svuint32_t {
    svexth_u32_m(svdup_n_u32(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uxtb))]
pub unsafe fn svextb_u64_m(inactive: svuint64_t, pg: svbool_t, op: svuint64_t) -> svuint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uxtb.nxv2i64")]
        fn _svextb_u64_m(inactive: svint64_t, pg: svbool2_t, op: svint64_t) -> svint64_t;
    }
    unsafe { _svextb_u64_m(inactive.as_signed(), pg.into(), op.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uxtb))]
pub unsafe fn svextb_u64_x(pg: svbool_t, op: svuint64_t) -> svuint64_t {
    svextb_u64_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uxtb))]
pub unsafe fn svextb_u64_z(pg: svbool_t, op: svuint64_t) -> svuint64_t {
    svextb_u64_m(svdup_n_u64(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uxth))]
pub unsafe fn svexth_u64_m(inactive: svuint64_t, pg: svbool_t, op: svuint64_t) -> svuint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uxth.nxv2i64")]
        fn _svexth_u64_m(inactive: svint64_t, pg: svbool2_t, op: svint64_t) -> svint64_t;
    }
    unsafe { _svexth_u64_m(inactive.as_signed(), pg.into(), op.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uxth))]
pub unsafe fn svexth_u64_x(pg: svbool_t, op: svuint64_t) -> svuint64_t {
    svexth_u64_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uxth))]
pub unsafe fn svexth_u64_z(pg: svbool_t, op: svuint64_t) -> svuint64_t {
    svexth_u64_m(svdup_n_u64(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uxtw))]
pub unsafe fn svextw_u64_m(inactive: svuint64_t, pg: svbool_t, op: svuint64_t) -> svuint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uxtw.nxv2i64")]
        fn _svextw_u64_m(inactive: svint64_t, pg: svbool2_t, op: svint64_t) -> svint64_t;
    }
    unsafe { _svextw_u64_m(inactive.as_signed(), pg.into(), op.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uxtw))]
pub unsafe fn svextw_u64_x(pg: svbool_t, op: svuint64_t) -> svuint64_t {
    svextw_u64_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uxtw))]
pub unsafe fn svextw_u64_z(pg: svbool_t, op: svuint64_t) -> svuint64_t {
    svextw_u64_m(svdup_n_u64(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svget2_f32<const IMM_INDEX: i32>(tuple: svfloat32x2_t) -> svfloat32_t {
    static_assert_range!(IMM_INDEX, 0, 1);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.get.nxv4f32.nxv8f32"
        )]
        fn _svget2_f32(tuple: svfloat32x2_t, imm_index: i32) -> svfloat32_t;
    }
    unsafe { _svget2_f32(tuple, IMM_INDEX) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svget2_f64<const IMM_INDEX: i32>(tuple: svfloat64x2_t) -> svfloat64_t {
    static_assert_range!(IMM_INDEX, 0, 1);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.get.nxv2f64.nxv4f64"
        )]
        fn _svget2_f64(tuple: svfloat64x2_t, imm_index: i32) -> svfloat64_t;
    }
    unsafe { _svget2_f64(tuple, IMM_INDEX) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svget2_s8<const IMM_INDEX: i32>(tuple: svint8x2_t) -> svint8_t {
    static_assert_range!(IMM_INDEX, 0, 1);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.get.nxv16i8.nxv32i8"
        )]
        fn _svget2_s8(tuple: svint8x2_t, imm_index: i32) -> svint8_t;
    }
    unsafe { _svget2_s8(tuple, IMM_INDEX) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svget2_s16<const IMM_INDEX: i32>(tuple: svint16x2_t) -> svint16_t {
    static_assert_range!(IMM_INDEX, 0, 1);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.get.nxv8i16.nxv16i16"
        )]
        fn _svget2_s16(tuple: svint16x2_t, imm_index: i32) -> svint16_t;
    }
    unsafe { _svget2_s16(tuple, IMM_INDEX) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svget2_s32<const IMM_INDEX: i32>(tuple: svint32x2_t) -> svint32_t {
    static_assert_range!(IMM_INDEX, 0, 1);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.get.nxv4i32.nxv8i32"
        )]
        fn _svget2_s32(tuple: svint32x2_t, imm_index: i32) -> svint32_t;
    }
    unsafe { _svget2_s32(tuple, IMM_INDEX) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svget2_s64<const IMM_INDEX: i32>(tuple: svint64x2_t) -> svint64_t {
    static_assert_range!(IMM_INDEX, 0, 1);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.get.nxv2i64.nxv4i64"
        )]
        fn _svget2_s64(tuple: svint64x2_t, imm_index: i32) -> svint64_t;
    }
    unsafe { _svget2_s64(tuple, IMM_INDEX) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svget2_u8<const IMM_INDEX: i32>(tuple: svuint8x2_t) -> svuint8_t {
    static_assert_range!(IMM_INDEX, 0, 1);
    unsafe { svget2_s8::<IMM_INDEX>(tuple.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svget2_u16<const IMM_INDEX: i32>(tuple: svuint16x2_t) -> svuint16_t {
    static_assert_range!(IMM_INDEX, 0, 1);
    unsafe { svget2_s16::<IMM_INDEX>(tuple.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svget2_u32<const IMM_INDEX: i32>(tuple: svuint32x2_t) -> svuint32_t {
    static_assert_range!(IMM_INDEX, 0, 1);
    unsafe { svget2_s32::<IMM_INDEX>(tuple.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svget2_u64<const IMM_INDEX: i32>(tuple: svuint64x2_t) -> svuint64_t {
    static_assert_range!(IMM_INDEX, 0, 1);
    unsafe { svget2_s64::<IMM_INDEX>(tuple.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svget3_f32<const IMM_INDEX: i32>(tuple: svfloat32x3_t) -> svfloat32_t {
    static_assert_range!(IMM_INDEX, 0, 2);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.get.nxv4f32.nxv12f32"
        )]
        fn _svget3_f32(tuple: svfloat32x3_t, imm_index: i32) -> svfloat32_t;
    }
    unsafe { _svget3_f32(tuple, IMM_INDEX) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svget3_f64<const IMM_INDEX: i32>(tuple: svfloat64x3_t) -> svfloat64_t {
    static_assert_range!(IMM_INDEX, 0, 2);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.get.nxv2f64.nxv6f64"
        )]
        fn _svget3_f64(tuple: svfloat64x3_t, imm_index: i32) -> svfloat64_t;
    }
    unsafe { _svget3_f64(tuple, IMM_INDEX) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svget3_s8<const IMM_INDEX: i32>(tuple: svint8x3_t) -> svint8_t {
    static_assert_range!(IMM_INDEX, 0, 2);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.get.nxv16i8.nxv48i8"
        )]
        fn _svget3_s8(tuple: svint8x3_t, imm_index: i32) -> svint8_t;
    }
    unsafe { _svget3_s8(tuple, IMM_INDEX) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svget3_s16<const IMM_INDEX: i32>(tuple: svint16x3_t) -> svint16_t {
    static_assert_range!(IMM_INDEX, 0, 2);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.get.nxv8i16.nxv24i16"
        )]
        fn _svget3_s16(tuple: svint16x3_t, imm_index: i32) -> svint16_t;
    }
    unsafe { _svget3_s16(tuple, IMM_INDEX) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svget3_s32<const IMM_INDEX: i32>(tuple: svint32x3_t) -> svint32_t {
    static_assert_range!(IMM_INDEX, 0, 2);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.get.nxv4i32.nxv12i32"
        )]
        fn _svget3_s32(tuple: svint32x3_t, imm_index: i32) -> svint32_t;
    }
    unsafe { _svget3_s32(tuple, IMM_INDEX) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svget3_s64<const IMM_INDEX: i32>(tuple: svint64x3_t) -> svint64_t {
    static_assert_range!(IMM_INDEX, 0, 2);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.get.nxv2i64.nxv6i64"
        )]
        fn _svget3_s64(tuple: svint64x3_t, imm_index: i32) -> svint64_t;
    }
    unsafe { _svget3_s64(tuple, IMM_INDEX) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svget3_u8<const IMM_INDEX: i32>(tuple: svuint8x3_t) -> svuint8_t {
    static_assert_range!(IMM_INDEX, 0, 2);
    unsafe { svget3_s8::<IMM_INDEX>(tuple.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svget3_u16<const IMM_INDEX: i32>(tuple: svuint16x3_t) -> svuint16_t {
    static_assert_range!(IMM_INDEX, 0, 2);
    unsafe { svget3_s16::<IMM_INDEX>(tuple.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svget3_u32<const IMM_INDEX: i32>(tuple: svuint32x3_t) -> svuint32_t {
    static_assert_range!(IMM_INDEX, 0, 2);
    unsafe { svget3_s32::<IMM_INDEX>(tuple.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svget3_u64<const IMM_INDEX: i32>(tuple: svuint64x3_t) -> svuint64_t {
    static_assert_range!(IMM_INDEX, 0, 2);
    unsafe { svget3_s64::<IMM_INDEX>(tuple.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svget4_f32<const IMM_INDEX: i32>(tuple: svfloat32x4_t) -> svfloat32_t {
    static_assert_range!(IMM_INDEX, 0, 3);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.get.nxv4f32.nxv16f32"
        )]
        fn _svget4_f32(tuple: svfloat32x4_t, imm_index: i32) -> svfloat32_t;
    }
    unsafe { _svget4_f32(tuple, IMM_INDEX) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svget4_f64<const IMM_INDEX: i32>(tuple: svfloat64x4_t) -> svfloat64_t {
    static_assert_range!(IMM_INDEX, 0, 3);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.get.nxv2f64.nxv8f64"
        )]
        fn _svget4_f64(tuple: svfloat64x4_t, imm_index: i32) -> svfloat64_t;
    }
    unsafe { _svget4_f64(tuple, IMM_INDEX) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svget4_s8<const IMM_INDEX: i32>(tuple: svint8x4_t) -> svint8_t {
    static_assert_range!(IMM_INDEX, 0, 3);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.get.nxv16i8.nxv64i8"
        )]
        fn _svget4_s8(tuple: svint8x4_t, imm_index: i32) -> svint8_t;
    }
    unsafe { _svget4_s8(tuple, IMM_INDEX) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svget4_s16<const IMM_INDEX: i32>(tuple: svint16x4_t) -> svint16_t {
    static_assert_range!(IMM_INDEX, 0, 3);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.get.nxv8i16.nxv32i16"
        )]
        fn _svget4_s16(tuple: svint16x4_t, imm_index: i32) -> svint16_t;
    }
    unsafe { _svget4_s16(tuple, IMM_INDEX) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svget4_s32<const IMM_INDEX: i32>(tuple: svint32x4_t) -> svint32_t {
    static_assert_range!(IMM_INDEX, 0, 3);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.get.nxv4i32.nxv16i32"
        )]
        fn _svget4_s32(tuple: svint32x4_t, imm_index: i32) -> svint32_t;
    }
    unsafe { _svget4_s32(tuple, IMM_INDEX) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svget4_s64<const IMM_INDEX: i32>(tuple: svint64x4_t) -> svint64_t {
    static_assert_range!(IMM_INDEX, 0, 3);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.get.nxv2i64.nxv8i64"
        )]
        fn _svget4_s64(tuple: svint64x4_t, imm_index: i32) -> svint64_t;
    }
    unsafe { _svget4_s64(tuple, IMM_INDEX) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svget4_u8<const IMM_INDEX: i32>(tuple: svuint8x4_t) -> svuint8_t {
    static_assert_range!(IMM_INDEX, 0, 3);
    unsafe { svget4_s8::<IMM_INDEX>(tuple.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svget4_u16<const IMM_INDEX: i32>(tuple: svuint16x4_t) -> svuint16_t {
    static_assert_range!(IMM_INDEX, 0, 3);
    unsafe { svget4_s16::<IMM_INDEX>(tuple.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svget4_u32<const IMM_INDEX: i32>(tuple: svuint32x4_t) -> svuint32_t {
    static_assert_range!(IMM_INDEX, 0, 3);
    unsafe { svget4_s32::<IMM_INDEX>(tuple.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svget4_u64<const IMM_INDEX: i32>(tuple: svuint64x4_t) -> svuint64_t {
    static_assert_range!(IMM_INDEX, 0, 3);
    unsafe { svget4_s64::<IMM_INDEX>(tuple.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(index))]
pub unsafe fn svindex_s8(base: i8, step: i8) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.index.nxv16i8")]
        fn _svindex_s8(base: i8, step: i8) -> svint8_t;
    }
    unsafe { _svindex_s8(base, step) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(index))]
pub unsafe fn svindex_s16(base: i16, step: i16) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.index.nxv8i16")]
        fn _svindex_s16(base: i16, step: i16) -> svint16_t;
    }
    unsafe { _svindex_s16(base, step) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(index))]
pub unsafe fn svindex_s32(base: i32, step: i32) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.index.nxv4i32")]
        fn _svindex_s32(base: i32, step: i32) -> svint32_t;
    }
    unsafe { _svindex_s32(base, step) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(index))]
pub unsafe fn svindex_s64(base: i64, step: i64) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.index.nxv2i64")]
        fn _svindex_s64(base: i64, step: i64) -> svint64_t;
    }
    unsafe { _svindex_s64(base, step) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(index))]
pub unsafe fn svindex_u8(base: u8, step: u8) -> svuint8_t {
    unsafe { svindex_s8(base.as_signed(), step.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(index))]
pub unsafe fn svindex_u16(base: u16, step: u16) -> svuint16_t {
    unsafe { svindex_s16(base.as_signed(), step.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(index))]
pub unsafe fn svindex_u32(base: u32, step: u32) -> svuint32_t {
    unsafe { svindex_s32(base.as_signed(), step.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(index))]
pub unsafe fn svindex_u64(base: u64, step: u64) -> svuint64_t {
    unsafe { svindex_s64(base.as_signed(), step.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(insr))]
pub unsafe fn svinsr_n_f32(op1: svfloat32_t, op2: f32) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.insr.nxv4f32")]
        fn _svinsr_n_f32(op1: svfloat32_t, op2: f32) -> svfloat32_t;
    }
    unsafe { _svinsr_n_f32(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(insr))]
pub unsafe fn svinsr_n_f64(op1: svfloat64_t, op2: f64) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.insr.nxv2f64")]
        fn _svinsr_n_f64(op1: svfloat64_t, op2: f64) -> svfloat64_t;
    }
    unsafe { _svinsr_n_f64(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(insr))]
pub unsafe fn svinsr_n_s8(op1: svint8_t, op2: i8) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.insr.nxv16i8")]
        fn _svinsr_n_s8(op1: svint8_t, op2: i8) -> svint8_t;
    }
    unsafe { _svinsr_n_s8(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(insr))]
pub unsafe fn svinsr_n_s16(op1: svint16_t, op2: i16) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.insr.nxv8i16")]
        fn _svinsr_n_s16(op1: svint16_t, op2: i16) -> svint16_t;
    }
    unsafe { _svinsr_n_s16(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(insr))]
pub unsafe fn svinsr_n_s32(op1: svint32_t, op2: i32) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.insr.nxv4i32")]
        fn _svinsr_n_s32(op1: svint32_t, op2: i32) -> svint32_t;
    }
    unsafe { _svinsr_n_s32(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(insr))]
pub unsafe fn svinsr_n_s64(op1: svint64_t, op2: i64) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.insr.nxv2i64")]
        fn _svinsr_n_s64(op1: svint64_t, op2: i64) -> svint64_t;
    }
    unsafe { _svinsr_n_s64(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(insr))]
pub unsafe fn svinsr_n_u8(op1: svuint8_t, op2: u8) -> svuint8_t {
    unsafe { svinsr_n_s8(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(insr))]
pub unsafe fn svinsr_n_u16(op1: svuint16_t, op2: u16) -> svuint16_t {
    unsafe { svinsr_n_s16(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(insr))]
pub unsafe fn svinsr_n_u32(op1: svuint32_t, op2: u32) -> svuint32_t {
    unsafe { svinsr_n_s32(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(insr))]
pub unsafe fn svinsr_n_u64(op1: svuint64_t, op2: u64) -> svuint64_t {
    unsafe { svinsr_n_s64(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lasta))]
pub unsafe fn svlasta_f32(pg: svbool_t, op: svfloat32_t) -> f32 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.lasta.nxv4f32")]
        fn _svlasta_f32(pg: svbool4_t, op: svfloat32_t) -> f32;
    }
    unsafe { _svlasta_f32(pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lasta))]
pub unsafe fn svlasta_f64(pg: svbool_t, op: svfloat64_t) -> f64 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.lasta.nxv2f64")]
        fn _svlasta_f64(pg: svbool2_t, op: svfloat64_t) -> f64;
    }
    unsafe { _svlasta_f64(pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lasta))]
pub unsafe fn svlasta_s8(pg: svbool_t, op: svint8_t) -> i8 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.lasta.nxv16i8")]
        fn _svlasta_s8(pg: svbool_t, op: svint8_t) -> i8;
    }
    unsafe { _svlasta_s8(pg, op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lasta))]
pub unsafe fn svlasta_s16(pg: svbool_t, op: svint16_t) -> i16 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.lasta.nxv8i16")]
        fn _svlasta_s16(pg: svbool8_t, op: svint16_t) -> i16;
    }
    unsafe { _svlasta_s16(pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lasta))]
pub unsafe fn svlasta_s32(pg: svbool_t, op: svint32_t) -> i32 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.lasta.nxv4i32")]
        fn _svlasta_s32(pg: svbool4_t, op: svint32_t) -> i32;
    }
    unsafe { _svlasta_s32(pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lasta))]
pub unsafe fn svlasta_s64(pg: svbool_t, op: svint64_t) -> i64 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.lasta.nxv2i64")]
        fn _svlasta_s64(pg: svbool2_t, op: svint64_t) -> i64;
    }
    unsafe { _svlasta_s64(pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lasta))]
pub unsafe fn svlasta_u8(pg: svbool_t, op: svuint8_t) -> u8 {
    unsafe { svlasta_s8(pg, op.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lasta))]
pub unsafe fn svlasta_u16(pg: svbool_t, op: svuint16_t) -> u16 {
    unsafe { svlasta_s16(pg, op.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lasta))]
pub unsafe fn svlasta_u32(pg: svbool_t, op: svuint32_t) -> u32 {
    unsafe { svlasta_s32(pg, op.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lasta))]
pub unsafe fn svlasta_u64(pg: svbool_t, op: svuint64_t) -> u64 {
    unsafe { svlasta_s64(pg, op.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lastb))]
pub unsafe fn svlastb_f32(pg: svbool_t, op: svfloat32_t) -> f32 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.lastb.nxv4f32")]
        fn _svlastb_f32(pg: svbool4_t, op: svfloat32_t) -> f32;
    }
    unsafe { _svlastb_f32(pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lastb))]
pub unsafe fn svlastb_f64(pg: svbool_t, op: svfloat64_t) -> f64 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.lastb.nxv2f64")]
        fn _svlastb_f64(pg: svbool2_t, op: svfloat64_t) -> f64;
    }
    unsafe { _svlastb_f64(pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lastb))]
pub unsafe fn svlastb_s8(pg: svbool_t, op: svint8_t) -> i8 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.lastb.nxv16i8")]
        fn _svlastb_s8(pg: svbool_t, op: svint8_t) -> i8;
    }
    unsafe { _svlastb_s8(pg, op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lastb))]
pub unsafe fn svlastb_s16(pg: svbool_t, op: svint16_t) -> i16 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.lastb.nxv8i16")]
        fn _svlastb_s16(pg: svbool8_t, op: svint16_t) -> i16;
    }
    unsafe { _svlastb_s16(pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lastb))]
pub unsafe fn svlastb_s32(pg: svbool_t, op: svint32_t) -> i32 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.lastb.nxv4i32")]
        fn _svlastb_s32(pg: svbool4_t, op: svint32_t) -> i32;
    }
    unsafe { _svlastb_s32(pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lastb))]
pub unsafe fn svlastb_s64(pg: svbool_t, op: svint64_t) -> i64 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.lastb.nxv2i64")]
        fn _svlastb_s64(pg: svbool2_t, op: svint64_t) -> i64;
    }
    unsafe { _svlastb_s64(pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lastb))]
pub unsafe fn svlastb_u8(pg: svbool_t, op: svuint8_t) -> u8 {
    unsafe { svlastb_s8(pg, op.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lastb))]
pub unsafe fn svlastb_u16(pg: svbool_t, op: svuint16_t) -> u16 {
    unsafe { svlastb_s16(pg, op.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lastb))]
pub unsafe fn svlastb_u32(pg: svbool_t, op: svuint32_t) -> u32 {
    unsafe { svlastb_s32(pg, op.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lastb))]
pub unsafe fn svlastb_u64(pg: svbool_t, op: svuint64_t) -> u64 {
    unsafe { svlastb_s64(pg, op.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1_f32(pg: svbool_t, base: *const f32) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ld1.nxv4f32")]
        fn _svld1_f32(pg: svbool4_t, base: *const f32) -> svfloat32_t;
    }
    _svld1_f32(pg.into(), base)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1d))]
pub unsafe fn svld1_f64(pg: svbool_t, base: *const f64) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ld1.nxv2f64")]
        fn _svld1_f64(pg: svbool2_t, base: *const f64) -> svfloat64_t;
    }
    _svld1_f64(pg.into(), base)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1b))]
pub unsafe fn svld1_s8(pg: svbool_t, base: *const i8) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ld1.nxv16i8")]
        fn _svld1_s8(pg: svbool_t, base: *const i8) -> svint8_t;
    }
    _svld1_s8(pg, base)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1_s16(pg: svbool_t, base: *const i16) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ld1.nxv8i16")]
        fn _svld1_s16(pg: svbool8_t, base: *const i16) -> svint16_t;
    }
    _svld1_s16(pg.into(), base)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1_s32(pg: svbool_t, base: *const i32) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ld1.nxv4i32")]
        fn _svld1_s32(pg: svbool4_t, base: *const i32) -> svint32_t;
    }
    _svld1_s32(pg.into(), base)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1d))]
pub unsafe fn svld1_s64(pg: svbool_t, base: *const i64) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ld1.nxv2i64")]
        fn _svld1_s64(pg: svbool2_t, base: *const i64) -> svint64_t;
    }
    _svld1_s64(pg.into(), base)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1b))]
pub unsafe fn svld1_u8(pg: svbool_t, base: *const u8) -> svuint8_t {
    svld1_s8(pg, base.as_signed()).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1_u16(pg: svbool_t, base: *const u16) -> svuint16_t {
    svld1_s16(pg, base.as_signed()).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1_u32(pg: svbool_t, base: *const u32) -> svuint32_t {
    svld1_s32(pg, base.as_signed()).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1d))]
pub unsafe fn svld1_u64(pg: svbool_t, base: *const u64) -> svuint64_t {
    svld1_s64(pg, base.as_signed()).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1_gather_s32index_f32(
    pg: svbool_t,
    base: *const f32,
    indices: svint32_t,
) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.sxtw.index.nxv4f32"
        )]
        fn _svld1_gather_s32index_f32(
            pg: svbool4_t,
            base: *const f32,
            indices: svint32_t,
        ) -> svfloat32_t;
    }
    _svld1_gather_s32index_f32(pg.into(), base, indices)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1_gather_s32index_s32(
    pg: svbool_t,
    base: *const i32,
    indices: svint32_t,
) -> svint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.sxtw.index.nxv4i32"
        )]
        fn _svld1_gather_s32index_s32(
            pg: svbool4_t,
            base: *const i32,
            indices: svint32_t,
        ) -> svint32_t;
    }
    _svld1_gather_s32index_s32(pg.into(), base, indices)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1_gather_s32index_u32(
    pg: svbool_t,
    base: *const u32,
    indices: svint32_t,
) -> svuint32_t {
    svld1_gather_s32index_s32(pg, base.as_signed(), indices).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1d))]
pub unsafe fn svld1_gather_s64index_f64(
    pg: svbool_t,
    base: *const f64,
    indices: svint64_t,
) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.index.nxv2f64"
        )]
        fn _svld1_gather_s64index_f64(
            pg: svbool2_t,
            base: *const f64,
            indices: svint64_t,
        ) -> svfloat64_t;
    }
    _svld1_gather_s64index_f64(pg.into(), base, indices)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1d))]
pub unsafe fn svld1_gather_s64index_s64(
    pg: svbool_t,
    base: *const i64,
    indices: svint64_t,
) -> svint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.index.nxv2i64"
        )]
        fn _svld1_gather_s64index_s64(
            pg: svbool2_t,
            base: *const i64,
            indices: svint64_t,
        ) -> svint64_t;
    }
    _svld1_gather_s64index_s64(pg.into(), base, indices)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1d))]
pub unsafe fn svld1_gather_s64index_u64(
    pg: svbool_t,
    base: *const u64,
    indices: svint64_t,
) -> svuint64_t {
    svld1_gather_s64index_s64(pg, base.as_signed(), indices).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1_gather_u32index_f32(
    pg: svbool_t,
    base: *const f32,
    indices: svuint32_t,
) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.uxtw.index.nxv4f32"
        )]
        fn _svld1_gather_u32index_f32(
            pg: svbool4_t,
            base: *const f32,
            indices: svint32_t,
        ) -> svfloat32_t;
    }
    _svld1_gather_u32index_f32(pg.into(), base, indices.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1_gather_u32index_s32(
    pg: svbool_t,
    base: *const i32,
    indices: svuint32_t,
) -> svint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.uxtw.index.nxv4i32"
        )]
        fn _svld1_gather_u32index_s32(
            pg: svbool4_t,
            base: *const i32,
            indices: svint32_t,
        ) -> svint32_t;
    }
    _svld1_gather_u32index_s32(pg.into(), base, indices.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1_gather_u32index_u32(
    pg: svbool_t,
    base: *const u32,
    indices: svuint32_t,
) -> svuint32_t {
    svld1_gather_u32index_s32(pg, base.as_signed(), indices).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1d))]
pub unsafe fn svld1_gather_u64index_f64(
    pg: svbool_t,
    base: *const f64,
    indices: svuint64_t,
) -> svfloat64_t {
    svld1_gather_s64index_f64(pg, base, indices.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1d))]
pub unsafe fn svld1_gather_u64index_s64(
    pg: svbool_t,
    base: *const i64,
    indices: svuint64_t,
) -> svint64_t {
    svld1_gather_s64index_s64(pg, base, indices.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1d))]
pub unsafe fn svld1_gather_u64index_u64(
    pg: svbool_t,
    base: *const u64,
    indices: svuint64_t,
) -> svuint64_t {
    svld1_gather_s64index_s64(pg, base.as_signed(), indices.as_signed()).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1_gather_s32offset_f32(
    pg: svbool_t,
    base: *const f32,
    offsets: svint32_t,
) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.sxtw.nxv4f32"
        )]
        fn _svld1_gather_s32offset_f32(
            pg: svbool4_t,
            base: *const f32,
            offsets: svint32_t,
        ) -> svfloat32_t;
    }
    _svld1_gather_s32offset_f32(pg.into(), base, offsets)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1_gather_s32offset_s32(
    pg: svbool_t,
    base: *const i32,
    offsets: svint32_t,
) -> svint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.sxtw.nxv4i32"
        )]
        fn _svld1_gather_s32offset_s32(
            pg: svbool4_t,
            base: *const i32,
            offsets: svint32_t,
        ) -> svint32_t;
    }
    _svld1_gather_s32offset_s32(pg.into(), base, offsets)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1_gather_s32offset_u32(
    pg: svbool_t,
    base: *const u32,
    offsets: svint32_t,
) -> svuint32_t {
    svld1_gather_s32offset_s32(pg, base.as_signed(), offsets).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1d))]
pub unsafe fn svld1_gather_s64offset_f64(
    pg: svbool_t,
    base: *const f64,
    offsets: svint64_t,
) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.nxv2f64"
        )]
        fn _svld1_gather_s64offset_f64(
            pg: svbool2_t,
            base: *const f64,
            offsets: svint64_t,
        ) -> svfloat64_t;
    }
    _svld1_gather_s64offset_f64(pg.into(), base, offsets)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1d))]
pub unsafe fn svld1_gather_s64offset_s64(
    pg: svbool_t,
    base: *const i64,
    offsets: svint64_t,
) -> svint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.nxv2i64"
        )]
        fn _svld1_gather_s64offset_s64(
            pg: svbool2_t,
            base: *const i64,
            offsets: svint64_t,
        ) -> svint64_t;
    }
    _svld1_gather_s64offset_s64(pg.into(), base, offsets)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1d))]
pub unsafe fn svld1_gather_s64offset_u64(
    pg: svbool_t,
    base: *const u64,
    offsets: svint64_t,
) -> svuint64_t {
    svld1_gather_s64offset_s64(pg, base.as_signed(), offsets).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1_gather_u32offset_f32(
    pg: svbool_t,
    base: *const f32,
    offsets: svuint32_t,
) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.uxtw.nxv4f32"
        )]
        fn _svld1_gather_u32offset_f32(
            pg: svbool4_t,
            base: *const f32,
            offsets: svint32_t,
        ) -> svfloat32_t;
    }
    _svld1_gather_u32offset_f32(pg.into(), base, offsets.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1_gather_u32offset_s32(
    pg: svbool_t,
    base: *const i32,
    offsets: svuint32_t,
) -> svint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.uxtw.nxv4i32"
        )]
        fn _svld1_gather_u32offset_s32(
            pg: svbool4_t,
            base: *const i32,
            offsets: svint32_t,
        ) -> svint32_t;
    }
    _svld1_gather_u32offset_s32(pg.into(), base, offsets.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1_gather_u32offset_u32(
    pg: svbool_t,
    base: *const u32,
    offsets: svuint32_t,
) -> svuint32_t {
    svld1_gather_u32offset_s32(pg, base.as_signed(), offsets).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1d))]
pub unsafe fn svld1_gather_u64offset_f64(
    pg: svbool_t,
    base: *const f64,
    offsets: svuint64_t,
) -> svfloat64_t {
    svld1_gather_s64offset_f64(pg, base, offsets.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1d))]
pub unsafe fn svld1_gather_u64offset_s64(
    pg: svbool_t,
    base: *const i64,
    offsets: svuint64_t,
) -> svint64_t {
    svld1_gather_s64offset_s64(pg, base, offsets.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1d))]
pub unsafe fn svld1_gather_u64offset_u64(
    pg: svbool_t,
    base: *const u64,
    offsets: svuint64_t,
) -> svuint64_t {
    svld1_gather_s64offset_s64(pg, base.as_signed(), offsets.as_signed()).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1_gather_u32base_f32(pg: svbool_t, bases: svuint32_t) -> svfloat32_t {
    svld1_gather_u32base_offset_f32(pg, bases, 0)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1_gather_u32base_s32(pg: svbool_t, bases: svuint32_t) -> svint32_t {
    svld1_gather_u32base_offset_s32(pg, bases, 0)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1_gather_u32base_u32(pg: svbool_t, bases: svuint32_t) -> svuint32_t {
    svld1_gather_u32base_offset_u32(pg, bases, 0)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1d))]
pub unsafe fn svld1_gather_u64base_f64(pg: svbool_t, bases: svuint64_t) -> svfloat64_t {
    svld1_gather_u64base_offset_f64(pg, bases, 0)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1d))]
pub unsafe fn svld1_gather_u64base_s64(pg: svbool_t, bases: svuint64_t) -> svint64_t {
    svld1_gather_u64base_offset_s64(pg, bases, 0)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1d))]
pub unsafe fn svld1_gather_u64base_u64(pg: svbool_t, bases: svuint64_t) -> svuint64_t {
    svld1_gather_u64base_offset_u64(pg, bases, 0)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1_gather_u32base_index_f32(
    pg: svbool_t,
    bases: svuint32_t,
    index: i64,
) -> svfloat32_t {
    svld1_gather_u32base_offset_f32(pg, bases, index.unchecked_shl(2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1_gather_u32base_index_s32(
    pg: svbool_t,
    bases: svuint32_t,
    index: i64,
) -> svint32_t {
    svld1_gather_u32base_offset_s32(pg, bases, index.unchecked_shl(2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1_gather_u32base_index_u32(
    pg: svbool_t,
    bases: svuint32_t,
    index: i64,
) -> svuint32_t {
    svld1_gather_u32base_offset_u32(pg, bases, index.unchecked_shl(2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1d))]
pub unsafe fn svld1_gather_u64base_index_f64(
    pg: svbool_t,
    bases: svuint64_t,
    index: i64,
) -> svfloat64_t {
    svld1_gather_u64base_offset_f64(pg, bases, index.unchecked_shl(3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1d))]
pub unsafe fn svld1_gather_u64base_index_s64(
    pg: svbool_t,
    bases: svuint64_t,
    index: i64,
) -> svint64_t {
    svld1_gather_u64base_offset_s64(pg, bases, index.unchecked_shl(3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1d))]
pub unsafe fn svld1_gather_u64base_index_u64(
    pg: svbool_t,
    bases: svuint64_t,
    index: i64,
) -> svuint64_t {
    svld1_gather_u64base_offset_u64(pg, bases, index.unchecked_shl(3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1_gather_u32base_offset_f32(
    pg: svbool_t,
    bases: svuint32_t,
    offset: i64,
) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.scalar.offset.nxv4f32.nxv4i32"
        )]
        fn _svld1_gather_u32base_offset_f32(
            pg: svbool4_t,
            bases: svint32_t,
            offset: i64,
        ) -> svfloat32_t;
    }
    _svld1_gather_u32base_offset_f32(pg.into(), bases.as_signed(), offset)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1_gather_u32base_offset_s32(
    pg: svbool_t,
    bases: svuint32_t,
    offset: i64,
) -> svint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.scalar.offset.nxv4i32.nxv4i32"
        )]
        fn _svld1_gather_u32base_offset_s32(
            pg: svbool4_t,
            bases: svint32_t,
            offset: i64,
        ) -> svint32_t;
    }
    _svld1_gather_u32base_offset_s32(pg.into(), bases.as_signed(), offset)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1_gather_u32base_offset_u32(
    pg: svbool_t,
    bases: svuint32_t,
    offset: i64,
) -> svuint32_t {
    svld1_gather_u32base_offset_s32(pg, bases, offset).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1d))]
pub unsafe fn svld1_gather_u64base_offset_f64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.scalar.offset.nxv2f64.nxv2i64"
        )]
        fn _svld1_gather_u64base_offset_f64(
            pg: svbool2_t,
            bases: svint64_t,
            offset: i64,
        ) -> svfloat64_t;
    }
    _svld1_gather_u64base_offset_f64(pg.into(), bases.as_signed(), offset)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1d))]
pub unsafe fn svld1_gather_u64base_offset_s64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
) -> svint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.scalar.offset.nxv2i64.nxv2i64"
        )]
        fn _svld1_gather_u64base_offset_s64(
            pg: svbool2_t,
            bases: svint64_t,
            offset: i64,
        ) -> svint64_t;
    }
    _svld1_gather_u64base_offset_s64(pg.into(), bases.as_signed(), offset)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1d))]
pub unsafe fn svld1_gather_u64base_offset_u64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
) -> svuint64_t {
    svld1_gather_u64base_offset_s64(pg, bases, offset).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1_vnum_f32(pg: svbool_t, base: *const f32, vnum: i64) -> svfloat32_t {
    svld1_f32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1d))]
pub unsafe fn svld1_vnum_f64(pg: svbool_t, base: *const f64, vnum: i64) -> svfloat64_t {
    svld1_f64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1b))]
pub unsafe fn svld1_vnum_s8(pg: svbool_t, base: *const i8, vnum: i64) -> svint8_t {
    svld1_s8(pg, base.offset(svcntb() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1_vnum_s16(pg: svbool_t, base: *const i16, vnum: i64) -> svint16_t {
    svld1_s16(pg, base.offset(svcnth() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1_vnum_s32(pg: svbool_t, base: *const i32, vnum: i64) -> svint32_t {
    svld1_s32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1d))]
pub unsafe fn svld1_vnum_s64(pg: svbool_t, base: *const i64, vnum: i64) -> svint64_t {
    svld1_s64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1b))]
pub unsafe fn svld1_vnum_u8(pg: svbool_t, base: *const u8, vnum: i64) -> svuint8_t {
    svld1_u8(pg, base.offset(svcntb() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1_vnum_u16(pg: svbool_t, base: *const u16, vnum: i64) -> svuint16_t {
    svld1_u16(pg, base.offset(svcnth() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1_vnum_u32(pg: svbool_t, base: *const u32, vnum: i64) -> svuint32_t {
    svld1_u32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1d))]
pub unsafe fn svld1_vnum_u64(pg: svbool_t, base: *const u64, vnum: i64) -> svuint64_t {
    svld1_u64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(ld1row))]
pub unsafe fn svld1ro_f32(pg: svbool_t, base: *const f32) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ld1ro.nxv4f32")]
        fn _svld1ro_f32(pg: svbool4_t, base: *const f32) -> svfloat32_t;
    }
    _svld1ro_f32(pg.into(), base)
}
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(ld1rod))]
pub unsafe fn svld1ro_f64(pg: svbool_t, base: *const f64) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ld1ro.nxv2f64")]
        fn _svld1ro_f64(pg: svbool2_t, base: *const f64) -> svfloat64_t;
    }
    _svld1ro_f64(pg.into(), base)
}
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(ld1rob))]
pub unsafe fn svld1ro_s8(pg: svbool_t, base: *const i8) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ld1ro.nxv16i8")]
        fn _svld1ro_s8(pg: svbool_t, base: *const i8) -> svint8_t;
    }
    _svld1ro_s8(pg, base)
}
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(ld1roh))]
pub unsafe fn svld1ro_s16(pg: svbool_t, base: *const i16) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ld1ro.nxv8i16")]
        fn _svld1ro_s16(pg: svbool8_t, base: *const i16) -> svint16_t;
    }
    _svld1ro_s16(pg.into(), base)
}
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(ld1row))]
pub unsafe fn svld1ro_s32(pg: svbool_t, base: *const i32) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ld1ro.nxv4i32")]
        fn _svld1ro_s32(pg: svbool4_t, base: *const i32) -> svint32_t;
    }
    _svld1ro_s32(pg.into(), base)
}
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(ld1rod))]
pub unsafe fn svld1ro_s64(pg: svbool_t, base: *const i64) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ld1ro.nxv2i64")]
        fn _svld1ro_s64(pg: svbool2_t, base: *const i64) -> svint64_t;
    }
    _svld1ro_s64(pg.into(), base)
}
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(ld1rob))]
pub unsafe fn svld1ro_u8(pg: svbool_t, base: *const u8) -> svuint8_t {
    svld1ro_s8(pg, base.as_signed()).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(ld1roh))]
pub unsafe fn svld1ro_u16(pg: svbool_t, base: *const u16) -> svuint16_t {
    svld1ro_s16(pg, base.as_signed()).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(ld1row))]
pub unsafe fn svld1ro_u32(pg: svbool_t, base: *const u32) -> svuint32_t {
    svld1ro_s32(pg, base.as_signed()).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(ld1rod))]
pub unsafe fn svld1ro_u64(pg: svbool_t, base: *const u64) -> svuint64_t {
    svld1ro_s64(pg, base.as_signed()).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1rqw))]
pub unsafe fn svld1rq_f32(pg: svbool_t, base: *const f32) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ld1rq.nxv4f32")]
        fn _svld1rq_f32(pg: svbool4_t, base: *const f32) -> svfloat32_t;
    }
    _svld1rq_f32(pg.into(), base)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1rqd))]
pub unsafe fn svld1rq_f64(pg: svbool_t, base: *const f64) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ld1rq.nxv2f64")]
        fn _svld1rq_f64(pg: svbool2_t, base: *const f64) -> svfloat64_t;
    }
    _svld1rq_f64(pg.into(), base)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1rqb))]
pub unsafe fn svld1rq_s8(pg: svbool_t, base: *const i8) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ld1rq.nxv16i8")]
        fn _svld1rq_s8(pg: svbool_t, base: *const i8) -> svint8_t;
    }
    _svld1rq_s8(pg, base)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1rqh))]
pub unsafe fn svld1rq_s16(pg: svbool_t, base: *const i16) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ld1rq.nxv8i16")]
        fn _svld1rq_s16(pg: svbool8_t, base: *const i16) -> svint16_t;
    }
    _svld1rq_s16(pg.into(), base)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1rqw))]
pub unsafe fn svld1rq_s32(pg: svbool_t, base: *const i32) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ld1rq.nxv4i32")]
        fn _svld1rq_s32(pg: svbool4_t, base: *const i32) -> svint32_t;
    }
    _svld1rq_s32(pg.into(), base)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1rqd))]
pub unsafe fn svld1rq_s64(pg: svbool_t, base: *const i64) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ld1rq.nxv2i64")]
        fn _svld1rq_s64(pg: svbool2_t, base: *const i64) -> svint64_t;
    }
    _svld1rq_s64(pg.into(), base)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1rqb))]
pub unsafe fn svld1rq_u8(pg: svbool_t, base: *const u8) -> svuint8_t {
    svld1rq_s8(pg, base.as_signed()).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1rqh))]
pub unsafe fn svld1rq_u16(pg: svbool_t, base: *const u16) -> svuint16_t {
    svld1rq_s16(pg, base.as_signed()).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1rqw))]
pub unsafe fn svld1rq_u32(pg: svbool_t, base: *const u32) -> svuint32_t {
    svld1rq_s32(pg, base.as_signed()).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1rqd))]
pub unsafe fn svld1rq_u64(pg: svbool_t, base: *const u64) -> svuint64_t {
    svld1rq_s64(pg, base.as_signed()).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sb))]
pub unsafe fn svld1sb_gather_s32offset_s32(
    pg: svbool_t,
    base: *const i8,
    offsets: svint32_t,
) -> svint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.sxtw.nxv4i8"
        )]
        fn _svld1sb_gather_s32offset_s32(
            pg: svbool4_t,
            base: *const i8,
            offsets: svint32_t,
        ) -> nxv4i8;
    }
    simd_cast(_svld1sb_gather_s32offset_s32(pg.into(), base, offsets))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sh))]
pub unsafe fn svld1sh_gather_s32offset_s32(
    pg: svbool_t,
    base: *const i16,
    offsets: svint32_t,
) -> svint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.sxtw.nxv4i16"
        )]
        fn _svld1sh_gather_s32offset_s32(
            pg: svbool4_t,
            base: *const i16,
            offsets: svint32_t,
        ) -> nxv4i16;
    }
    simd_cast(_svld1sh_gather_s32offset_s32(pg.into(), base, offsets))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sb))]
pub unsafe fn svld1sb_gather_s32offset_u32(
    pg: svbool_t,
    base: *const i8,
    offsets: svint32_t,
) -> svuint32_t {
    svld1sb_gather_s32offset_s32(pg, base, offsets).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sh))]
pub unsafe fn svld1sh_gather_s32offset_u32(
    pg: svbool_t,
    base: *const i16,
    offsets: svint32_t,
) -> svuint32_t {
    svld1sh_gather_s32offset_s32(pg, base, offsets).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sb))]
pub unsafe fn svld1sb_gather_s64offset_s64(
    pg: svbool_t,
    base: *const i8,
    offsets: svint64_t,
) -> svint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.nxv2i8"
        )]
        fn _svld1sb_gather_s64offset_s64(
            pg: svbool2_t,
            base: *const i8,
            offsets: svint64_t,
        ) -> nxv2i8;
    }
    simd_cast(_svld1sb_gather_s64offset_s64(pg.into(), base, offsets))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sh))]
pub unsafe fn svld1sh_gather_s64offset_s64(
    pg: svbool_t,
    base: *const i16,
    offsets: svint64_t,
) -> svint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.nxv2i16"
        )]
        fn _svld1sh_gather_s64offset_s64(
            pg: svbool2_t,
            base: *const i16,
            offsets: svint64_t,
        ) -> nxv2i16;
    }
    simd_cast(_svld1sh_gather_s64offset_s64(pg.into(), base, offsets))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sw))]
pub unsafe fn svld1sw_gather_s64offset_s64(
    pg: svbool_t,
    base: *const i32,
    offsets: svint64_t,
) -> svint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.nxv2i32"
        )]
        fn _svld1sw_gather_s64offset_s64(
            pg: svbool2_t,
            base: *const i32,
            offsets: svint64_t,
        ) -> nxv2i32;
    }
    simd_cast(_svld1sw_gather_s64offset_s64(pg.into(), base, offsets))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sb))]
pub unsafe fn svld1sb_gather_s64offset_u64(
    pg: svbool_t,
    base: *const i8,
    offsets: svint64_t,
) -> svuint64_t {
    svld1sb_gather_s64offset_s64(pg, base, offsets).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sh))]
pub unsafe fn svld1sh_gather_s64offset_u64(
    pg: svbool_t,
    base: *const i16,
    offsets: svint64_t,
) -> svuint64_t {
    svld1sh_gather_s64offset_s64(pg, base, offsets).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sw))]
pub unsafe fn svld1sw_gather_s64offset_u64(
    pg: svbool_t,
    base: *const i32,
    offsets: svint64_t,
) -> svuint64_t {
    svld1sw_gather_s64offset_s64(pg, base, offsets).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sb))]
pub unsafe fn svld1sb_gather_u32offset_s32(
    pg: svbool_t,
    base: *const i8,
    offsets: svuint32_t,
) -> svint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.uxtw.nxv4i8"
        )]
        fn _svld1sb_gather_u32offset_s32(
            pg: svbool4_t,
            base: *const i8,
            offsets: svint32_t,
        ) -> nxv4i8;
    }
    simd_cast(_svld1sb_gather_u32offset_s32(
        pg.into(),
        base,
        offsets.as_signed(),
    ))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sh))]
pub unsafe fn svld1sh_gather_u32offset_s32(
    pg: svbool_t,
    base: *const i16,
    offsets: svuint32_t,
) -> svint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.uxtw.nxv4i16"
        )]
        fn _svld1sh_gather_u32offset_s32(
            pg: svbool4_t,
            base: *const i16,
            offsets: svint32_t,
        ) -> nxv4i16;
    }
    simd_cast(_svld1sh_gather_u32offset_s32(
        pg.into(),
        base,
        offsets.as_signed(),
    ))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sb))]
pub unsafe fn svld1sb_gather_u32offset_u32(
    pg: svbool_t,
    base: *const i8,
    offsets: svuint32_t,
) -> svuint32_t {
    svld1sb_gather_u32offset_s32(pg, base, offsets).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sh))]
pub unsafe fn svld1sh_gather_u32offset_u32(
    pg: svbool_t,
    base: *const i16,
    offsets: svuint32_t,
) -> svuint32_t {
    svld1sh_gather_u32offset_s32(pg, base, offsets).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sb))]
pub unsafe fn svld1sb_gather_u64offset_s64(
    pg: svbool_t,
    base: *const i8,
    offsets: svuint64_t,
) -> svint64_t {
    svld1sb_gather_s64offset_s64(pg, base, offsets.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sh))]
pub unsafe fn svld1sh_gather_u64offset_s64(
    pg: svbool_t,
    base: *const i16,
    offsets: svuint64_t,
) -> svint64_t {
    svld1sh_gather_s64offset_s64(pg, base, offsets.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sw))]
pub unsafe fn svld1sw_gather_u64offset_s64(
    pg: svbool_t,
    base: *const i32,
    offsets: svuint64_t,
) -> svint64_t {
    svld1sw_gather_s64offset_s64(pg, base, offsets.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sb))]
pub unsafe fn svld1sb_gather_u64offset_u64(
    pg: svbool_t,
    base: *const i8,
    offsets: svuint64_t,
) -> svuint64_t {
    svld1sb_gather_s64offset_s64(pg, base, offsets.as_signed()).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sh))]
pub unsafe fn svld1sh_gather_u64offset_u64(
    pg: svbool_t,
    base: *const i16,
    offsets: svuint64_t,
) -> svuint64_t {
    svld1sh_gather_s64offset_s64(pg, base, offsets.as_signed()).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sw))]
pub unsafe fn svld1sw_gather_u64offset_u64(
    pg: svbool_t,
    base: *const i32,
    offsets: svuint64_t,
) -> svuint64_t {
    svld1sw_gather_s64offset_s64(pg, base, offsets.as_signed()).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sb))]
pub unsafe fn svld1sb_gather_u32base_offset_s32(
    pg: svbool_t,
    bases: svuint32_t,
    offset: i64,
) -> svint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.scalar.offset.nxv4i8.nxv4i32"
        )]
        fn _svld1sb_gather_u32base_offset_s32(
            pg: svbool4_t,
            bases: svint32_t,
            offset: i64,
        ) -> nxv4i8;
    }
    simd_cast(_svld1sb_gather_u32base_offset_s32(
        pg.into(),
        bases.as_signed(),
        offset,
    ))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sh))]
pub unsafe fn svld1sh_gather_u32base_offset_s32(
    pg: svbool_t,
    bases: svuint32_t,
    offset: i64,
) -> svint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.scalar.offset.nxv4i16.nxv4i32"
        )]
        fn _svld1sh_gather_u32base_offset_s32(
            pg: svbool4_t,
            bases: svint32_t,
            offset: i64,
        ) -> nxv4i16;
    }
    simd_cast(_svld1sh_gather_u32base_offset_s32(
        pg.into(),
        bases.as_signed(),
        offset,
    ))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sb))]
pub unsafe fn svld1sb_gather_u32base_offset_u32(
    pg: svbool_t,
    bases: svuint32_t,
    offset: i64,
) -> svuint32_t {
    svld1sb_gather_u32base_offset_s32(pg, bases, offset).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sh))]
pub unsafe fn svld1sh_gather_u32base_offset_u32(
    pg: svbool_t,
    bases: svuint32_t,
    offset: i64,
) -> svuint32_t {
    svld1sh_gather_u32base_offset_s32(pg, bases, offset).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sb))]
pub unsafe fn svld1sb_gather_u64base_offset_s64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
) -> svint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.scalar.offset.nxv2i8.nxv2i64"
        )]
        fn _svld1sb_gather_u64base_offset_s64(
            pg: svbool2_t,
            bases: svint64_t,
            offset: i64,
        ) -> nxv2i8;
    }
    simd_cast(_svld1sb_gather_u64base_offset_s64(
        pg.into(),
        bases.as_signed(),
        offset,
    ))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sh))]
pub unsafe fn svld1sh_gather_u64base_offset_s64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
) -> svint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.scalar.offset.nxv2i16.nxv2i64"
        )]
        fn _svld1sh_gather_u64base_offset_s64(
            pg: svbool2_t,
            bases: svint64_t,
            offset: i64,
        ) -> nxv2i16;
    }
    simd_cast(_svld1sh_gather_u64base_offset_s64(
        pg.into(),
        bases.as_signed(),
        offset,
    ))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sw))]
pub unsafe fn svld1sw_gather_u64base_offset_s64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
) -> svint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.scalar.offset.nxv2i32.nxv2i64"
        )]
        fn _svld1sw_gather_u64base_offset_s64(
            pg: svbool2_t,
            bases: svint64_t,
            offset: i64,
        ) -> nxv2i32;
    }
    simd_cast(_svld1sw_gather_u64base_offset_s64(
        pg.into(),
        bases.as_signed(),
        offset,
    ))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sb))]
pub unsafe fn svld1sb_gather_u64base_offset_u64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
) -> svuint64_t {
    svld1sb_gather_u64base_offset_s64(pg, bases, offset).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sh))]
pub unsafe fn svld1sh_gather_u64base_offset_u64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
) -> svuint64_t {
    svld1sh_gather_u64base_offset_s64(pg, bases, offset).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sw))]
pub unsafe fn svld1sw_gather_u64base_offset_u64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
) -> svuint64_t {
    svld1sw_gather_u64base_offset_s64(pg, bases, offset).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sb))]
pub unsafe fn svld1sb_gather_u32base_s32(pg: svbool_t, bases: svuint32_t) -> svint32_t {
    svld1sb_gather_u32base_offset_s32(pg, bases, 0)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sh))]
pub unsafe fn svld1sh_gather_u32base_s32(pg: svbool_t, bases: svuint32_t) -> svint32_t {
    svld1sh_gather_u32base_offset_s32(pg, bases, 0)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sb))]
pub unsafe fn svld1sb_gather_u32base_u32(pg: svbool_t, bases: svuint32_t) -> svuint32_t {
    svld1sb_gather_u32base_offset_u32(pg, bases, 0)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sh))]
pub unsafe fn svld1sh_gather_u32base_u32(pg: svbool_t, bases: svuint32_t) -> svuint32_t {
    svld1sh_gather_u32base_offset_u32(pg, bases, 0)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sb))]
pub unsafe fn svld1sb_gather_u64base_s64(pg: svbool_t, bases: svuint64_t) -> svint64_t {
    svld1sb_gather_u64base_offset_s64(pg, bases, 0)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sh))]
pub unsafe fn svld1sh_gather_u64base_s64(pg: svbool_t, bases: svuint64_t) -> svint64_t {
    svld1sh_gather_u64base_offset_s64(pg, bases, 0)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sw))]
pub unsafe fn svld1sw_gather_u64base_s64(pg: svbool_t, bases: svuint64_t) -> svint64_t {
    svld1sw_gather_u64base_offset_s64(pg, bases, 0)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sb))]
pub unsafe fn svld1sb_gather_u64base_u64(pg: svbool_t, bases: svuint64_t) -> svuint64_t {
    svld1sb_gather_u64base_offset_u64(pg, bases, 0)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sh))]
pub unsafe fn svld1sh_gather_u64base_u64(pg: svbool_t, bases: svuint64_t) -> svuint64_t {
    svld1sh_gather_u64base_offset_u64(pg, bases, 0)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sw))]
pub unsafe fn svld1sw_gather_u64base_u64(pg: svbool_t, bases: svuint64_t) -> svuint64_t {
    svld1sw_gather_u64base_offset_u64(pg, bases, 0)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sb))]
pub unsafe fn svld1sb_s16(pg: svbool_t, base: *const i8) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ld1.nxv8i8")]
        fn _svld1sb_s16(pg: svbool8_t, base: *const i8) -> nxv8i8;
    }
    simd_cast(_svld1sb_s16(pg.into(), base))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sb))]
pub unsafe fn svld1sb_s32(pg: svbool_t, base: *const i8) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ld1.nxv4i8")]
        fn _svld1sb_s32(pg: svbool4_t, base: *const i8) -> nxv4i8;
    }
    simd_cast(_svld1sb_s32(pg.into(), base))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sh))]
pub unsafe fn svld1sh_s32(pg: svbool_t, base: *const i16) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ld1.nxv4i16")]
        fn _svld1sh_s32(pg: svbool4_t, base: *const i16) -> nxv4i16;
    }
    simd_cast(_svld1sh_s32(pg.into(), base))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sb))]
pub unsafe fn svld1sb_s64(pg: svbool_t, base: *const i8) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ld1.nxv2i8")]
        fn _svld1sb_s64(pg: svbool2_t, base: *const i8) -> nxv2i8;
    }
    simd_cast(_svld1sb_s64(pg.into(), base))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sh))]
pub unsafe fn svld1sh_s64(pg: svbool_t, base: *const i16) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ld1.nxv2i16")]
        fn _svld1sh_s64(pg: svbool2_t, base: *const i16) -> nxv2i16;
    }
    simd_cast(_svld1sh_s64(pg.into(), base))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sw))]
pub unsafe fn svld1sw_s64(pg: svbool_t, base: *const i32) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ld1.nxv2i32")]
        fn _svld1sw_s64(pg: svbool2_t, base: *const i32) -> nxv2i32;
    }
    simd_cast(_svld1sw_s64(pg.into(), base))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sb))]
pub unsafe fn svld1sb_u16(pg: svbool_t, base: *const i8) -> svuint16_t {
    svld1sb_s16(pg, base).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sb))]
pub unsafe fn svld1sb_u32(pg: svbool_t, base: *const i8) -> svuint32_t {
    svld1sb_s32(pg, base).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sh))]
pub unsafe fn svld1sh_u32(pg: svbool_t, base: *const i16) -> svuint32_t {
    svld1sh_s32(pg, base).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sb))]
pub unsafe fn svld1sb_u64(pg: svbool_t, base: *const i8) -> svuint64_t {
    svld1sb_s64(pg, base).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sh))]
pub unsafe fn svld1sh_u64(pg: svbool_t, base: *const i16) -> svuint64_t {
    svld1sh_s64(pg, base).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sw))]
pub unsafe fn svld1sw_u64(pg: svbool_t, base: *const i32) -> svuint64_t {
    svld1sw_s64(pg, base).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sb))]
pub unsafe fn svld1sb_vnum_s16(pg: svbool_t, base: *const i8, vnum: i64) -> svint16_t {
    svld1sb_s16(pg, base.offset(svcnth() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sb))]
pub unsafe fn svld1sb_vnum_s32(pg: svbool_t, base: *const i8, vnum: i64) -> svint32_t {
    svld1sb_s32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sh))]
pub unsafe fn svld1sh_vnum_s32(pg: svbool_t, base: *const i16, vnum: i64) -> svint32_t {
    svld1sh_s32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sb))]
pub unsafe fn svld1sb_vnum_s64(pg: svbool_t, base: *const i8, vnum: i64) -> svint64_t {
    svld1sb_s64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sh))]
pub unsafe fn svld1sh_vnum_s64(pg: svbool_t, base: *const i16, vnum: i64) -> svint64_t {
    svld1sh_s64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sw))]
pub unsafe fn svld1sw_vnum_s64(pg: svbool_t, base: *const i32, vnum: i64) -> svint64_t {
    svld1sw_s64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sb))]
pub unsafe fn svld1sb_vnum_u16(pg: svbool_t, base: *const i8, vnum: i64) -> svuint16_t {
    svld1sb_u16(pg, base.offset(svcnth() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sb))]
pub unsafe fn svld1sb_vnum_u32(pg: svbool_t, base: *const i8, vnum: i64) -> svuint32_t {
    svld1sb_u32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sh))]
pub unsafe fn svld1sh_vnum_u32(pg: svbool_t, base: *const i16, vnum: i64) -> svuint32_t {
    svld1sh_u32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sb))]
pub unsafe fn svld1sb_vnum_u64(pg: svbool_t, base: *const i8, vnum: i64) -> svuint64_t {
    svld1sb_u64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sh))]
pub unsafe fn svld1sh_vnum_u64(pg: svbool_t, base: *const i16, vnum: i64) -> svuint64_t {
    svld1sh_u64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sw))]
pub unsafe fn svld1sw_vnum_u64(pg: svbool_t, base: *const i32, vnum: i64) -> svuint64_t {
    svld1sw_u64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sh))]
pub unsafe fn svld1sh_gather_s32index_s32(
    pg: svbool_t,
    base: *const i16,
    indices: svint32_t,
) -> svint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.sxtw.index.nxv4i16"
        )]
        fn _svld1sh_gather_s32index_s32(
            pg: svbool4_t,
            base: *const i16,
            indices: svint32_t,
        ) -> nxv4i16;
    }
    simd_cast(_svld1sh_gather_s32index_s32(pg.into(), base, indices))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sh))]
pub unsafe fn svld1sh_gather_s32index_u32(
    pg: svbool_t,
    base: *const i16,
    indices: svint32_t,
) -> svuint32_t {
    svld1sh_gather_s32index_s32(pg, base, indices).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sh))]
pub unsafe fn svld1sh_gather_s64index_s64(
    pg: svbool_t,
    base: *const i16,
    indices: svint64_t,
) -> svint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.index.nxv2i16"
        )]
        fn _svld1sh_gather_s64index_s64(
            pg: svbool2_t,
            base: *const i16,
            indices: svint64_t,
        ) -> nxv2i16;
    }
    simd_cast(_svld1sh_gather_s64index_s64(pg.into(), base, indices))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sw))]
pub unsafe fn svld1sw_gather_s64index_s64(
    pg: svbool_t,
    base: *const i32,
    indices: svint64_t,
) -> svint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.index.nxv2i32"
        )]
        fn _svld1sw_gather_s64index_s64(
            pg: svbool2_t,
            base: *const i32,
            indices: svint64_t,
        ) -> nxv2i32;
    }
    simd_cast(_svld1sw_gather_s64index_s64(pg.into(), base, indices))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sh))]
pub unsafe fn svld1sh_gather_s64index_u64(
    pg: svbool_t,
    base: *const i16,
    indices: svint64_t,
) -> svuint64_t {
    svld1sh_gather_s64index_s64(pg, base, indices).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sw))]
pub unsafe fn svld1sw_gather_s64index_u64(
    pg: svbool_t,
    base: *const i32,
    indices: svint64_t,
) -> svuint64_t {
    svld1sw_gather_s64index_s64(pg, base, indices).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sh))]
pub unsafe fn svld1sh_gather_u32index_s32(
    pg: svbool_t,
    base: *const i16,
    indices: svuint32_t,
) -> svint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.uxtw.index.nxv4i16"
        )]
        fn _svld1sh_gather_u32index_s32(
            pg: svbool4_t,
            base: *const i16,
            indices: svint32_t,
        ) -> nxv4i16;
    }
    simd_cast(_svld1sh_gather_u32index_s32(
        pg.into(),
        base,
        indices.as_signed(),
    ))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sh))]
pub unsafe fn svld1sh_gather_u32index_u32(
    pg: svbool_t,
    base: *const i16,
    indices: svuint32_t,
) -> svuint32_t {
    svld1sh_gather_u32index_s32(pg, base, indices).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sh))]
pub unsafe fn svld1sh_gather_u64index_s64(
    pg: svbool_t,
    base: *const i16,
    indices: svuint64_t,
) -> svint64_t {
    svld1sh_gather_s64index_s64(pg, base, indices.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sw))]
pub unsafe fn svld1sw_gather_u64index_s64(
    pg: svbool_t,
    base: *const i32,
    indices: svuint64_t,
) -> svint64_t {
    svld1sw_gather_s64index_s64(pg, base, indices.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sh))]
pub unsafe fn svld1sh_gather_u64index_u64(
    pg: svbool_t,
    base: *const i16,
    indices: svuint64_t,
) -> svuint64_t {
    svld1sh_gather_s64index_s64(pg, base, indices.as_signed()).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sw))]
pub unsafe fn svld1sw_gather_u64index_u64(
    pg: svbool_t,
    base: *const i32,
    indices: svuint64_t,
) -> svuint64_t {
    svld1sw_gather_s64index_s64(pg, base, indices.as_signed()).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sh))]
pub unsafe fn svld1sh_gather_u32base_index_s32(
    pg: svbool_t,
    bases: svuint32_t,
    index: i64,
) -> svint32_t {
    svld1sh_gather_u32base_offset_s32(pg, bases, index.unchecked_shl(1))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sh))]
pub unsafe fn svld1sh_gather_u32base_index_u32(
    pg: svbool_t,
    bases: svuint32_t,
    index: i64,
) -> svuint32_t {
    svld1sh_gather_u32base_offset_u32(pg, bases, index.unchecked_shl(1))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sh))]
pub unsafe fn svld1sh_gather_u64base_index_s64(
    pg: svbool_t,
    bases: svuint64_t,
    index: i64,
) -> svint64_t {
    svld1sh_gather_u64base_offset_s64(pg, bases, index.unchecked_shl(1))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sw))]
pub unsafe fn svld1sw_gather_u64base_index_s64(
    pg: svbool_t,
    bases: svuint64_t,
    index: i64,
) -> svint64_t {
    svld1sw_gather_u64base_offset_s64(pg, bases, index.unchecked_shl(2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sh))]
pub unsafe fn svld1sh_gather_u64base_index_u64(
    pg: svbool_t,
    bases: svuint64_t,
    index: i64,
) -> svuint64_t {
    svld1sh_gather_u64base_offset_u64(pg, bases, index.unchecked_shl(1))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sw))]
pub unsafe fn svld1sw_gather_u64base_index_u64(
    pg: svbool_t,
    bases: svuint64_t,
    index: i64,
) -> svuint64_t {
    svld1sw_gather_u64base_offset_u64(pg, bases, index.unchecked_shl(2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1b))]
pub unsafe fn svld1ub_gather_s32offset_s32(
    pg: svbool_t,
    base: *const u8,
    offsets: svint32_t,
) -> svint32_t {
    svld1ub_gather_s32offset_u32(pg, base, offsets).as_signed()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1uh_gather_s32offset_s32(
    pg: svbool_t,
    base: *const u16,
    offsets: svint32_t,
) -> svint32_t {
    svld1uh_gather_s32offset_u32(pg, base, offsets).as_signed()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1b))]
pub unsafe fn svld1ub_gather_s32offset_u32(
    pg: svbool_t,
    base: *const u8,
    offsets: svint32_t,
) -> svuint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.sxtw.nxv4i8"
        )]
        fn _svld1ub_gather_s32offset_u32(
            pg: svbool4_t,
            base: *const i8,
            offsets: svint32_t,
        ) -> nxv4i8;
    }
    simd_cast::<nxv4u8, _>(
        _svld1ub_gather_s32offset_u32(pg.into(), base.as_signed(), offsets).as_unsigned(),
    )
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1uh_gather_s32offset_u32(
    pg: svbool_t,
    base: *const u16,
    offsets: svint32_t,
) -> svuint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.sxtw.nxv4i16"
        )]
        fn _svld1uh_gather_s32offset_u32(
            pg: svbool4_t,
            base: *const i16,
            offsets: svint32_t,
        ) -> nxv4i16;
    }
    simd_cast::<nxv4u16, _>(
        _svld1uh_gather_s32offset_u32(pg.into(), base.as_signed(), offsets).as_unsigned(),
    )
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1b))]
pub unsafe fn svld1ub_gather_s64offset_s64(
    pg: svbool_t,
    base: *const u8,
    offsets: svint64_t,
) -> svint64_t {
    svld1ub_gather_s64offset_u64(pg, base, offsets).as_signed()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1uh_gather_s64offset_s64(
    pg: svbool_t,
    base: *const u16,
    offsets: svint64_t,
) -> svint64_t {
    svld1uh_gather_s64offset_u64(pg, base, offsets).as_signed()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1uw_gather_s64offset_s64(
    pg: svbool_t,
    base: *const u32,
    offsets: svint64_t,
) -> svint64_t {
    svld1uw_gather_s64offset_u64(pg, base, offsets).as_signed()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1b))]
pub unsafe fn svld1ub_gather_s64offset_u64(
    pg: svbool_t,
    base: *const u8,
    offsets: svint64_t,
) -> svuint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.nxv2i8"
        )]
        fn _svld1ub_gather_s64offset_u64(
            pg: svbool2_t,
            base: *const i8,
            offsets: svint64_t,
        ) -> nxv2i8;
    }
    simd_cast::<nxv2u8, _>(
        _svld1ub_gather_s64offset_u64(pg.into(), base.as_signed(), offsets).as_unsigned(),
    )
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1uh_gather_s64offset_u64(
    pg: svbool_t,
    base: *const u16,
    offsets: svint64_t,
) -> svuint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.nxv2i16"
        )]
        fn _svld1uh_gather_s64offset_u64(
            pg: svbool2_t,
            base: *const i16,
            offsets: svint64_t,
        ) -> nxv2i16;
    }
    simd_cast::<nxv2u16, _>(
        _svld1uh_gather_s64offset_u64(pg.into(), base.as_signed(), offsets).as_unsigned(),
    )
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1uw_gather_s64offset_u64(
    pg: svbool_t,
    base: *const u32,
    offsets: svint64_t,
) -> svuint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.nxv2i32"
        )]
        fn _svld1uw_gather_s64offset_u64(
            pg: svbool2_t,
            base: *const i32,
            offsets: svint64_t,
        ) -> nxv2i32;
    }
    simd_cast::<nxv2u32, _>(
        _svld1uw_gather_s64offset_u64(pg.into(), base.as_signed(), offsets).as_unsigned(),
    )
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1b))]
pub unsafe fn svld1ub_gather_u32offset_s32(
    pg: svbool_t,
    base: *const u8,
    offsets: svuint32_t,
) -> svint32_t {
    svld1ub_gather_u32offset_u32(pg, base, offsets).as_signed()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1uh_gather_u32offset_s32(
    pg: svbool_t,
    base: *const u16,
    offsets: svuint32_t,
) -> svint32_t {
    svld1uh_gather_u32offset_u32(pg, base, offsets).as_signed()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1b))]
pub unsafe fn svld1ub_gather_u32offset_u32(
    pg: svbool_t,
    base: *const u8,
    offsets: svuint32_t,
) -> svuint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.uxtw.nxv4i8"
        )]
        fn _svld1ub_gather_u32offset_u32(
            pg: svbool4_t,
            base: *const i8,
            offsets: svint32_t,
        ) -> nxv4i8;
    }
    simd_cast::<nxv4u8, _>(
        _svld1ub_gather_u32offset_u32(pg.into(), base.as_signed(), offsets.as_signed())
            .as_unsigned(),
    )
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1uh_gather_u32offset_u32(
    pg: svbool_t,
    base: *const u16,
    offsets: svuint32_t,
) -> svuint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.uxtw.nxv4i16"
        )]
        fn _svld1uh_gather_u32offset_u32(
            pg: svbool4_t,
            base: *const i16,
            offsets: svint32_t,
        ) -> nxv4i16;
    }
    simd_cast::<nxv4u16, _>(
        _svld1uh_gather_u32offset_u32(pg.into(), base.as_signed(), offsets.as_signed())
            .as_unsigned(),
    )
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1b))]
pub unsafe fn svld1ub_gather_u64offset_s64(
    pg: svbool_t,
    base: *const u8,
    offsets: svuint64_t,
) -> svint64_t {
    svld1ub_gather_s64offset_u64(pg, base, offsets.as_signed()).as_signed()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1uh_gather_u64offset_s64(
    pg: svbool_t,
    base: *const u16,
    offsets: svuint64_t,
) -> svint64_t {
    svld1uh_gather_s64offset_u64(pg, base, offsets.as_signed()).as_signed()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1uw_gather_u64offset_s64(
    pg: svbool_t,
    base: *const u32,
    offsets: svuint64_t,
) -> svint64_t {
    svld1uw_gather_s64offset_u64(pg, base, offsets.as_signed()).as_signed()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1b))]
pub unsafe fn svld1ub_gather_u64offset_u64(
    pg: svbool_t,
    base: *const u8,
    offsets: svuint64_t,
) -> svuint64_t {
    svld1ub_gather_s64offset_u64(pg, base, offsets.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1uh_gather_u64offset_u64(
    pg: svbool_t,
    base: *const u16,
    offsets: svuint64_t,
) -> svuint64_t {
    svld1uh_gather_s64offset_u64(pg, base, offsets.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1uw_gather_u64offset_u64(
    pg: svbool_t,
    base: *const u32,
    offsets: svuint64_t,
) -> svuint64_t {
    svld1uw_gather_s64offset_u64(pg, base, offsets.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1b))]
pub unsafe fn svld1ub_gather_u32base_offset_s32(
    pg: svbool_t,
    bases: svuint32_t,
    offset: i64,
) -> svint32_t {
    svld1ub_gather_u32base_offset_u32(pg, bases, offset).as_signed()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1uh_gather_u32base_offset_s32(
    pg: svbool_t,
    bases: svuint32_t,
    offset: i64,
) -> svint32_t {
    svld1uh_gather_u32base_offset_u32(pg, bases, offset).as_signed()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1b))]
pub unsafe fn svld1ub_gather_u32base_offset_u32(
    pg: svbool_t,
    bases: svuint32_t,
    offset: i64,
) -> svuint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.scalar.offset.nxv4i8.nxv4i32"
        )]
        fn _svld1ub_gather_u32base_offset_u32(
            pg: svbool4_t,
            bases: svint32_t,
            offset: i64,
        ) -> nxv4i8;
    }
    simd_cast::<nxv4u8, _>(
        _svld1ub_gather_u32base_offset_u32(pg.into(), bases.as_signed(), offset).as_unsigned(),
    )
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1uh_gather_u32base_offset_u32(
    pg: svbool_t,
    bases: svuint32_t,
    offset: i64,
) -> svuint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.scalar.offset.nxv4i16.nxv4i32"
        )]
        fn _svld1uh_gather_u32base_offset_u32(
            pg: svbool4_t,
            bases: svint32_t,
            offset: i64,
        ) -> nxv4i16;
    }
    simd_cast::<nxv4u16, _>(
        _svld1uh_gather_u32base_offset_u32(pg.into(), bases.as_signed(), offset).as_unsigned(),
    )
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1b))]
pub unsafe fn svld1ub_gather_u64base_offset_s64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
) -> svint64_t {
    svld1ub_gather_u64base_offset_u64(pg, bases, offset).as_signed()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1uh_gather_u64base_offset_s64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
) -> svint64_t {
    svld1uh_gather_u64base_offset_u64(pg, bases, offset).as_signed()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1uw_gather_u64base_offset_s64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
) -> svint64_t {
    svld1uw_gather_u64base_offset_u64(pg, bases, offset).as_signed()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1b))]
pub unsafe fn svld1ub_gather_u64base_offset_u64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
) -> svuint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.scalar.offset.nxv2i8.nxv2i64"
        )]
        fn _svld1ub_gather_u64base_offset_u64(
            pg: svbool2_t,
            bases: svint64_t,
            offset: i64,
        ) -> nxv2i8;
    }
    simd_cast::<nxv2u8, _>(
        _svld1ub_gather_u64base_offset_u64(pg.into(), bases.as_signed(), offset).as_unsigned(),
    )
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1uh_gather_u64base_offset_u64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
) -> svuint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.scalar.offset.nxv2i16.nxv2i64"
        )]
        fn _svld1uh_gather_u64base_offset_u64(
            pg: svbool2_t,
            bases: svint64_t,
            offset: i64,
        ) -> nxv2i16;
    }
    simd_cast::<nxv2u16, _>(
        _svld1uh_gather_u64base_offset_u64(pg.into(), bases.as_signed(), offset).as_unsigned(),
    )
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1uw_gather_u64base_offset_u64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
) -> svuint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.scalar.offset.nxv2i32.nxv2i64"
        )]
        fn _svld1uw_gather_u64base_offset_u64(
            pg: svbool2_t,
            bases: svint64_t,
            offset: i64,
        ) -> nxv2i32;
    }
    simd_cast::<nxv2u32, _>(
        _svld1uw_gather_u64base_offset_u64(pg.into(), bases.as_signed(), offset).as_unsigned(),
    )
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1b))]
pub unsafe fn svld1ub_gather_u32base_s32(pg: svbool_t, bases: svuint32_t) -> svint32_t {
    svld1ub_gather_u32base_offset_s32(pg, bases, 0)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1uh_gather_u32base_s32(pg: svbool_t, bases: svuint32_t) -> svint32_t {
    svld1uh_gather_u32base_offset_s32(pg, bases, 0)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1b))]
pub unsafe fn svld1ub_gather_u32base_u32(pg: svbool_t, bases: svuint32_t) -> svuint32_t {
    svld1ub_gather_u32base_offset_u32(pg, bases, 0)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1uh_gather_u32base_u32(pg: svbool_t, bases: svuint32_t) -> svuint32_t {
    svld1uh_gather_u32base_offset_u32(pg, bases, 0)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1b))]
pub unsafe fn svld1ub_gather_u64base_s64(pg: svbool_t, bases: svuint64_t) -> svint64_t {
    svld1ub_gather_u64base_offset_s64(pg, bases, 0)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1uh_gather_u64base_s64(pg: svbool_t, bases: svuint64_t) -> svint64_t {
    svld1uh_gather_u64base_offset_s64(pg, bases, 0)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1uw_gather_u64base_s64(pg: svbool_t, bases: svuint64_t) -> svint64_t {
    svld1uw_gather_u64base_offset_s64(pg, bases, 0)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1b))]
pub unsafe fn svld1ub_gather_u64base_u64(pg: svbool_t, bases: svuint64_t) -> svuint64_t {
    svld1ub_gather_u64base_offset_u64(pg, bases, 0)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1uh_gather_u64base_u64(pg: svbool_t, bases: svuint64_t) -> svuint64_t {
    svld1uh_gather_u64base_offset_u64(pg, bases, 0)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1uw_gather_u64base_u64(pg: svbool_t, bases: svuint64_t) -> svuint64_t {
    svld1uw_gather_u64base_offset_u64(pg, bases, 0)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1b))]
pub unsafe fn svld1ub_s16(pg: svbool_t, base: *const u8) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ld1.nxv8i8")]
        fn _svld1ub_s16(pg: svbool8_t, base: *const i8) -> nxv8i8;
    }
    simd_cast::<nxv8u8, _>(_svld1ub_s16(pg.into(), base.as_signed()).as_unsigned())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1b))]
pub unsafe fn svld1ub_s32(pg: svbool_t, base: *const u8) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ld1.nxv4i8")]
        fn _svld1ub_s32(pg: svbool4_t, base: *const i8) -> nxv4i8;
    }
    simd_cast::<nxv4u8, _>(_svld1ub_s32(pg.into(), base.as_signed()).as_unsigned())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1uh_s32(pg: svbool_t, base: *const u16) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ld1.nxv4i16")]
        fn _svld1uh_s32(pg: svbool4_t, base: *const i16) -> nxv4i16;
    }
    simd_cast::<nxv4u16, _>(_svld1uh_s32(pg.into(), base.as_signed()).as_unsigned())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1b))]
pub unsafe fn svld1ub_s64(pg: svbool_t, base: *const u8) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ld1.nxv2i8")]
        fn _svld1ub_s64(pg: svbool2_t, base: *const i8) -> nxv2i8;
    }
    simd_cast::<nxv2u8, _>(_svld1ub_s64(pg.into(), base.as_signed()).as_unsigned())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1uh_s64(pg: svbool_t, base: *const u16) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ld1.nxv2i16")]
        fn _svld1uh_s64(pg: svbool2_t, base: *const i16) -> nxv2i16;
    }
    simd_cast::<nxv2u16, _>(_svld1uh_s64(pg.into(), base.as_signed()).as_unsigned())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1uw_s64(pg: svbool_t, base: *const u32) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ld1.nxv2i32")]
        fn _svld1uw_s64(pg: svbool2_t, base: *const i32) -> nxv2i32;
    }
    simd_cast::<nxv2u32, _>(_svld1uw_s64(pg.into(), base.as_signed()).as_unsigned())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1b))]
pub unsafe fn svld1ub_u16(pg: svbool_t, base: *const u8) -> svuint16_t {
    svld1ub_s16(pg, base).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1b))]
pub unsafe fn svld1ub_u32(pg: svbool_t, base: *const u8) -> svuint32_t {
    svld1ub_s32(pg, base).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1uh_u32(pg: svbool_t, base: *const u16) -> svuint32_t {
    svld1uh_s32(pg, base).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1b))]
pub unsafe fn svld1ub_u64(pg: svbool_t, base: *const u8) -> svuint64_t {
    svld1ub_s64(pg, base).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1uh_u64(pg: svbool_t, base: *const u16) -> svuint64_t {
    svld1uh_s64(pg, base).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1uw_u64(pg: svbool_t, base: *const u32) -> svuint64_t {
    svld1uw_s64(pg, base).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1b))]
pub unsafe fn svld1ub_vnum_s16(pg: svbool_t, base: *const u8, vnum: i64) -> svint16_t {
    svld1ub_s16(pg, base.offset(svcnth() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1b))]
pub unsafe fn svld1ub_vnum_s32(pg: svbool_t, base: *const u8, vnum: i64) -> svint32_t {
    svld1ub_s32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1uh_vnum_s32(pg: svbool_t, base: *const u16, vnum: i64) -> svint32_t {
    svld1uh_s32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1b))]
pub unsafe fn svld1ub_vnum_s64(pg: svbool_t, base: *const u8, vnum: i64) -> svint64_t {
    svld1ub_s64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1uh_vnum_s64(pg: svbool_t, base: *const u16, vnum: i64) -> svint64_t {
    svld1uh_s64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1uw_vnum_s64(pg: svbool_t, base: *const u32, vnum: i64) -> svint64_t {
    svld1uw_s64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1b))]
pub unsafe fn svld1ub_vnum_u16(pg: svbool_t, base: *const u8, vnum: i64) -> svuint16_t {
    svld1ub_u16(pg, base.offset(svcnth() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1b))]
pub unsafe fn svld1ub_vnum_u32(pg: svbool_t, base: *const u8, vnum: i64) -> svuint32_t {
    svld1ub_u32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1uh_vnum_u32(pg: svbool_t, base: *const u16, vnum: i64) -> svuint32_t {
    svld1uh_u32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1b))]
pub unsafe fn svld1ub_vnum_u64(pg: svbool_t, base: *const u8, vnum: i64) -> svuint64_t {
    svld1ub_u64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1uh_vnum_u64(pg: svbool_t, base: *const u16, vnum: i64) -> svuint64_t {
    svld1uh_u64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1uw_vnum_u64(pg: svbool_t, base: *const u32, vnum: i64) -> svuint64_t {
    svld1uw_u64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1uh_gather_s32index_s32(
    pg: svbool_t,
    base: *const u16,
    indices: svint32_t,
) -> svint32_t {
    svld1uh_gather_s32index_u32(pg, base, indices).as_signed()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1uh_gather_s32index_u32(
    pg: svbool_t,
    base: *const u16,
    indices: svint32_t,
) -> svuint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.sxtw.index.nxv4i16"
        )]
        fn _svld1uh_gather_s32index_u32(
            pg: svbool4_t,
            base: *const i16,
            indices: svint32_t,
        ) -> nxv4i16;
    }
    simd_cast::<nxv4u16, _>(
        _svld1uh_gather_s32index_u32(pg.into(), base.as_signed(), indices).as_unsigned(),
    )
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1uh_gather_s64index_s64(
    pg: svbool_t,
    base: *const u16,
    indices: svint64_t,
) -> svint64_t {
    svld1uh_gather_s64index_u64(pg, base, indices).as_signed()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1uw_gather_s64index_s64(
    pg: svbool_t,
    base: *const u32,
    indices: svint64_t,
) -> svint64_t {
    svld1uw_gather_s64index_u64(pg, base, indices).as_signed()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1uh_gather_s64index_u64(
    pg: svbool_t,
    base: *const u16,
    indices: svint64_t,
) -> svuint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.index.nxv2i16"
        )]
        fn _svld1uh_gather_s64index_u64(
            pg: svbool2_t,
            base: *const i16,
            indices: svint64_t,
        ) -> nxv2i16;
    }
    simd_cast::<nxv2u16, _>(
        _svld1uh_gather_s64index_u64(pg.into(), base.as_signed(), indices).as_unsigned(),
    )
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1uw_gather_s64index_u64(
    pg: svbool_t,
    base: *const u32,
    indices: svint64_t,
) -> svuint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.index.nxv2i32"
        )]
        fn _svld1uw_gather_s64index_u64(
            pg: svbool2_t,
            base: *const i32,
            indices: svint64_t,
        ) -> nxv2i32;
    }
    simd_cast::<nxv2u32, _>(
        _svld1uw_gather_s64index_u64(pg.into(), base.as_signed(), indices).as_unsigned(),
    )
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1uh_gather_u32index_s32(
    pg: svbool_t,
    base: *const u16,
    indices: svuint32_t,
) -> svint32_t {
    svld1uh_gather_u32index_u32(pg, base, indices).as_signed()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1uh_gather_u32index_u32(
    pg: svbool_t,
    base: *const u16,
    indices: svuint32_t,
) -> svuint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.uxtw.index.nxv4i16"
        )]
        fn _svld1uh_gather_u32index_u32(
            pg: svbool4_t,
            base: *const i16,
            indices: svint32_t,
        ) -> nxv4i16;
    }
    simd_cast::<nxv4u16, _>(
        _svld1uh_gather_u32index_u32(pg.into(), base.as_signed(), indices.as_signed())
            .as_unsigned(),
    )
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1uh_gather_u64index_s64(
    pg: svbool_t,
    base: *const u16,
    indices: svuint64_t,
) -> svint64_t {
    svld1uh_gather_s64index_u64(pg, base, indices.as_signed()).as_signed()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1uw_gather_u64index_s64(
    pg: svbool_t,
    base: *const u32,
    indices: svuint64_t,
) -> svint64_t {
    svld1uw_gather_s64index_u64(pg, base, indices.as_signed()).as_signed()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1uh_gather_u64index_u64(
    pg: svbool_t,
    base: *const u16,
    indices: svuint64_t,
) -> svuint64_t {
    svld1uh_gather_s64index_u64(pg, base, indices.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1uw_gather_u64index_u64(
    pg: svbool_t,
    base: *const u32,
    indices: svuint64_t,
) -> svuint64_t {
    svld1uw_gather_s64index_u64(pg, base, indices.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1uh_gather_u32base_index_s32(
    pg: svbool_t,
    bases: svuint32_t,
    index: i64,
) -> svint32_t {
    svld1uh_gather_u32base_offset_s32(pg, bases, index.unchecked_shl(1))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1uh_gather_u32base_index_u32(
    pg: svbool_t,
    bases: svuint32_t,
    index: i64,
) -> svuint32_t {
    svld1uh_gather_u32base_offset_u32(pg, bases, index.unchecked_shl(1))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1uh_gather_u64base_index_s64(
    pg: svbool_t,
    bases: svuint64_t,
    index: i64,
) -> svint64_t {
    svld1uh_gather_u64base_offset_s64(pg, bases, index.unchecked_shl(1))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1uw_gather_u64base_index_s64(
    pg: svbool_t,
    bases: svuint64_t,
    index: i64,
) -> svint64_t {
    svld1uw_gather_u64base_offset_s64(pg, bases, index.unchecked_shl(2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1uh_gather_u64base_index_u64(
    pg: svbool_t,
    bases: svuint64_t,
    index: i64,
) -> svuint64_t {
    svld1uh_gather_u64base_offset_u64(pg, bases, index.unchecked_shl(1))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1uw_gather_u64base_index_u64(
    pg: svbool_t,
    bases: svuint64_t,
    index: i64,
) -> svuint64_t {
    svld1uw_gather_u64base_offset_u64(pg, bases, index.unchecked_shl(2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld2w))]
pub unsafe fn svld2_f32(pg: svbool_t, base: *const f32) -> svfloat32x2_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld2.nxv8f32.nxv4i1"
        )]
        fn _svld2_f32(pg: svbool4_t, base: *const f32) -> svfloat32x2_t;
    }
    _svld2_f32(pg.into(), base)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld2d))]
pub unsafe fn svld2_f64(pg: svbool_t, base: *const f64) -> svfloat64x2_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld2.nxv4f64.nxv2i1"
        )]
        fn _svld2_f64(pg: svbool2_t, base: *const f64) -> svfloat64x2_t;
    }
    _svld2_f64(pg.into(), base)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld2b))]
pub unsafe fn svld2_s8(pg: svbool_t, base: *const i8) -> svint8x2_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld2.nxv32i8.nxv16i1"
        )]
        fn _svld2_s8(pg: svbool_t, base: *const i8) -> svint8x2_t;
    }
    _svld2_s8(pg, base)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld2h))]
pub unsafe fn svld2_s16(pg: svbool_t, base: *const i16) -> svint16x2_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld2.nxv16i16.nxv8i1"
        )]
        fn _svld2_s16(pg: svbool8_t, base: *const i16) -> svint16x2_t;
    }
    _svld2_s16(pg.into(), base)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld2w))]
pub unsafe fn svld2_s32(pg: svbool_t, base: *const i32) -> svint32x2_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld2.nxv8i32.nxv4i1"
        )]
        fn _svld2_s32(pg: svbool4_t, base: *const i32) -> svint32x2_t;
    }
    _svld2_s32(pg.into(), base)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld2d))]
pub unsafe fn svld2_s64(pg: svbool_t, base: *const i64) -> svint64x2_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld2.nxv4i64.nxv2i1"
        )]
        fn _svld2_s64(pg: svbool2_t, base: *const i64) -> svint64x2_t;
    }
    _svld2_s64(pg.into(), base)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld2b))]
pub unsafe fn svld2_u8(pg: svbool_t, base: *const u8) -> svuint8x2_t {
    svld2_s8(pg, base.as_signed()).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld2h))]
pub unsafe fn svld2_u16(pg: svbool_t, base: *const u16) -> svuint16x2_t {
    svld2_s16(pg, base.as_signed()).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld2w))]
pub unsafe fn svld2_u32(pg: svbool_t, base: *const u32) -> svuint32x2_t {
    svld2_s32(pg, base.as_signed()).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld2d))]
pub unsafe fn svld2_u64(pg: svbool_t, base: *const u64) -> svuint64x2_t {
    svld2_s64(pg, base.as_signed()).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld2w))]
pub unsafe fn svld2_vnum_f32(pg: svbool_t, base: *const f32, vnum: i64) -> svfloat32x2_t {
    svld2_f32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld2d))]
pub unsafe fn svld2_vnum_f64(pg: svbool_t, base: *const f64, vnum: i64) -> svfloat64x2_t {
    svld2_f64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld2b))]
pub unsafe fn svld2_vnum_s8(pg: svbool_t, base: *const i8, vnum: i64) -> svint8x2_t {
    svld2_s8(pg, base.offset(svcntb() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld2h))]
pub unsafe fn svld2_vnum_s16(pg: svbool_t, base: *const i16, vnum: i64) -> svint16x2_t {
    svld2_s16(pg, base.offset(svcnth() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld2w))]
pub unsafe fn svld2_vnum_s32(pg: svbool_t, base: *const i32, vnum: i64) -> svint32x2_t {
    svld2_s32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld2d))]
pub unsafe fn svld2_vnum_s64(pg: svbool_t, base: *const i64, vnum: i64) -> svint64x2_t {
    svld2_s64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld2b))]
pub unsafe fn svld2_vnum_u8(pg: svbool_t, base: *const u8, vnum: i64) -> svuint8x2_t {
    svld2_u8(pg, base.offset(svcntb() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld2h))]
pub unsafe fn svld2_vnum_u16(pg: svbool_t, base: *const u16, vnum: i64) -> svuint16x2_t {
    svld2_u16(pg, base.offset(svcnth() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld2w))]
pub unsafe fn svld2_vnum_u32(pg: svbool_t, base: *const u32, vnum: i64) -> svuint32x2_t {
    svld2_u32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld2d))]
pub unsafe fn svld2_vnum_u64(pg: svbool_t, base: *const u64, vnum: i64) -> svuint64x2_t {
    svld2_u64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld3w))]
pub unsafe fn svld3_f32(pg: svbool_t, base: *const f32) -> svfloat32x3_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld3.nxv12f32.nxv4i1"
        )]
        fn _svld3_f32(pg: svbool4_t, base: *const f32) -> svfloat32x3_t;
    }
    _svld3_f32(pg.into(), base)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld3d))]
pub unsafe fn svld3_f64(pg: svbool_t, base: *const f64) -> svfloat64x3_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld3.nxv6f64.nxv2i1"
        )]
        fn _svld3_f64(pg: svbool2_t, base: *const f64) -> svfloat64x3_t;
    }
    _svld3_f64(pg.into(), base)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld3b))]
pub unsafe fn svld3_s8(pg: svbool_t, base: *const i8) -> svint8x3_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld3.nxv48i8.nxv16i1"
        )]
        fn _svld3_s8(pg: svbool_t, base: *const i8) -> svint8x3_t;
    }
    _svld3_s8(pg, base)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld3h))]
pub unsafe fn svld3_s16(pg: svbool_t, base: *const i16) -> svint16x3_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld3.nxv24i16.nxv8i1"
        )]
        fn _svld3_s16(pg: svbool8_t, base: *const i16) -> svint16x3_t;
    }
    _svld3_s16(pg.into(), base)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld3w))]
pub unsafe fn svld3_s32(pg: svbool_t, base: *const i32) -> svint32x3_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld3.nxv12i32.nxv4i1"
        )]
        fn _svld3_s32(pg: svbool4_t, base: *const i32) -> svint32x3_t;
    }
    _svld3_s32(pg.into(), base)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld3d))]
pub unsafe fn svld3_s64(pg: svbool_t, base: *const i64) -> svint64x3_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld3.nxv6i64.nxv2i1"
        )]
        fn _svld3_s64(pg: svbool2_t, base: *const i64) -> svint64x3_t;
    }
    _svld3_s64(pg.into(), base)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld3b))]
pub unsafe fn svld3_u8(pg: svbool_t, base: *const u8) -> svuint8x3_t {
    svld3_s8(pg, base.as_signed()).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld3h))]
pub unsafe fn svld3_u16(pg: svbool_t, base: *const u16) -> svuint16x3_t {
    svld3_s16(pg, base.as_signed()).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld3w))]
pub unsafe fn svld3_u32(pg: svbool_t, base: *const u32) -> svuint32x3_t {
    svld3_s32(pg, base.as_signed()).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld3d))]
pub unsafe fn svld3_u64(pg: svbool_t, base: *const u64) -> svuint64x3_t {
    svld3_s64(pg, base.as_signed()).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld3w))]
pub unsafe fn svld3_vnum_f32(pg: svbool_t, base: *const f32, vnum: i64) -> svfloat32x3_t {
    svld3_f32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld3d))]
pub unsafe fn svld3_vnum_f64(pg: svbool_t, base: *const f64, vnum: i64) -> svfloat64x3_t {
    svld3_f64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld3b))]
pub unsafe fn svld3_vnum_s8(pg: svbool_t, base: *const i8, vnum: i64) -> svint8x3_t {
    svld3_s8(pg, base.offset(svcntb() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld3h))]
pub unsafe fn svld3_vnum_s16(pg: svbool_t, base: *const i16, vnum: i64) -> svint16x3_t {
    svld3_s16(pg, base.offset(svcnth() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld3w))]
pub unsafe fn svld3_vnum_s32(pg: svbool_t, base: *const i32, vnum: i64) -> svint32x3_t {
    svld3_s32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld3d))]
pub unsafe fn svld3_vnum_s64(pg: svbool_t, base: *const i64, vnum: i64) -> svint64x3_t {
    svld3_s64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld3b))]
pub unsafe fn svld3_vnum_u8(pg: svbool_t, base: *const u8, vnum: i64) -> svuint8x3_t {
    svld3_u8(pg, base.offset(svcntb() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld3h))]
pub unsafe fn svld3_vnum_u16(pg: svbool_t, base: *const u16, vnum: i64) -> svuint16x3_t {
    svld3_u16(pg, base.offset(svcnth() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld3w))]
pub unsafe fn svld3_vnum_u32(pg: svbool_t, base: *const u32, vnum: i64) -> svuint32x3_t {
    svld3_u32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld3d))]
pub unsafe fn svld3_vnum_u64(pg: svbool_t, base: *const u64, vnum: i64) -> svuint64x3_t {
    svld3_u64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld4w))]
pub unsafe fn svld4_f32(pg: svbool_t, base: *const f32) -> svfloat32x4_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld4.nxv16f32.nxv4i1"
        )]
        fn _svld4_f32(pg: svbool4_t, base: *const f32) -> svfloat32x4_t;
    }
    _svld4_f32(pg.into(), base)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld4d))]
pub unsafe fn svld4_f64(pg: svbool_t, base: *const f64) -> svfloat64x4_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld4.nxv8f64.nxv2i1"
        )]
        fn _svld4_f64(pg: svbool2_t, base: *const f64) -> svfloat64x4_t;
    }
    _svld4_f64(pg.into(), base)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld4b))]
pub unsafe fn svld4_s8(pg: svbool_t, base: *const i8) -> svint8x4_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld4.nxv64i8.nxv16i1"
        )]
        fn _svld4_s8(pg: svbool_t, base: *const i8) -> svint8x4_t;
    }
    _svld4_s8(pg, base)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld4h))]
pub unsafe fn svld4_s16(pg: svbool_t, base: *const i16) -> svint16x4_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld4.nxv32i16.nxv8i1"
        )]
        fn _svld4_s16(pg: svbool8_t, base: *const i16) -> svint16x4_t;
    }
    _svld4_s16(pg.into(), base)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld4w))]
pub unsafe fn svld4_s32(pg: svbool_t, base: *const i32) -> svint32x4_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld4.nxv16i32.nxv4i1"
        )]
        fn _svld4_s32(pg: svbool4_t, base: *const i32) -> svint32x4_t;
    }
    _svld4_s32(pg.into(), base)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld4d))]
pub unsafe fn svld4_s64(pg: svbool_t, base: *const i64) -> svint64x4_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld4.nxv8i64.nxv2i1"
        )]
        fn _svld4_s64(pg: svbool2_t, base: *const i64) -> svint64x4_t;
    }
    _svld4_s64(pg.into(), base)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld4b))]
pub unsafe fn svld4_u8(pg: svbool_t, base: *const u8) -> svuint8x4_t {
    svld4_s8(pg, base.as_signed()).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld4h))]
pub unsafe fn svld4_u16(pg: svbool_t, base: *const u16) -> svuint16x4_t {
    svld4_s16(pg, base.as_signed()).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld4w))]
pub unsafe fn svld4_u32(pg: svbool_t, base: *const u32) -> svuint32x4_t {
    svld4_s32(pg, base.as_signed()).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld4d))]
pub unsafe fn svld4_u64(pg: svbool_t, base: *const u64) -> svuint64x4_t {
    svld4_s64(pg, base.as_signed()).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld4w))]
pub unsafe fn svld4_vnum_f32(pg: svbool_t, base: *const f32, vnum: i64) -> svfloat32x4_t {
    svld4_f32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld4d))]
pub unsafe fn svld4_vnum_f64(pg: svbool_t, base: *const f64, vnum: i64) -> svfloat64x4_t {
    svld4_f64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld4b))]
pub unsafe fn svld4_vnum_s8(pg: svbool_t, base: *const i8, vnum: i64) -> svint8x4_t {
    svld4_s8(pg, base.offset(svcntb() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld4h))]
pub unsafe fn svld4_vnum_s16(pg: svbool_t, base: *const i16, vnum: i64) -> svint16x4_t {
    svld4_s16(pg, base.offset(svcnth() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld4w))]
pub unsafe fn svld4_vnum_s32(pg: svbool_t, base: *const i32, vnum: i64) -> svint32x4_t {
    svld4_s32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld4d))]
pub unsafe fn svld4_vnum_s64(pg: svbool_t, base: *const i64, vnum: i64) -> svint64x4_t {
    svld4_s64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld4b))]
pub unsafe fn svld4_vnum_u8(pg: svbool_t, base: *const u8, vnum: i64) -> svuint8x4_t {
    svld4_u8(pg, base.offset(svcntb() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld4h))]
pub unsafe fn svld4_vnum_u16(pg: svbool_t, base: *const u16, vnum: i64) -> svuint16x4_t {
    svld4_u16(pg, base.offset(svcnth() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld4w))]
pub unsafe fn svld4_vnum_u32(pg: svbool_t, base: *const u32, vnum: i64) -> svuint32x4_t {
    svld4_u32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld4d))]
pub unsafe fn svld4_vnum_u64(pg: svbool_t, base: *const u64, vnum: i64) -> svuint64x4_t {
    svld4_u64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1_f32(pg: svbool_t, base: *const f32) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldff1.nxv4f32")]
        fn _svldff1_f32(pg: svbool4_t, base: *const f32) -> svfloat32_t;
    }
    _svldff1_f32(pg.into(), base)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1d))]
pub unsafe fn svldff1_f64(pg: svbool_t, base: *const f64) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldff1.nxv2f64")]
        fn _svldff1_f64(pg: svbool2_t, base: *const f64) -> svfloat64_t;
    }
    _svldff1_f64(pg.into(), base)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1b))]
pub unsafe fn svldff1_s8(pg: svbool_t, base: *const i8) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldff1.nxv16i8")]
        fn _svldff1_s8(pg: svbool_t, base: *const i8) -> svint8_t;
    }
    _svldff1_s8(pg, base)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1_s16(pg: svbool_t, base: *const i16) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldff1.nxv8i16")]
        fn _svldff1_s16(pg: svbool8_t, base: *const i16) -> svint16_t;
    }
    _svldff1_s16(pg.into(), base)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1_s32(pg: svbool_t, base: *const i32) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldff1.nxv4i32")]
        fn _svldff1_s32(pg: svbool4_t, base: *const i32) -> svint32_t;
    }
    _svldff1_s32(pg.into(), base)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1d))]
pub unsafe fn svldff1_s64(pg: svbool_t, base: *const i64) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldff1.nxv2i64")]
        fn _svldff1_s64(pg: svbool2_t, base: *const i64) -> svint64_t;
    }
    _svldff1_s64(pg.into(), base)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1b))]
pub unsafe fn svldff1_u8(pg: svbool_t, base: *const u8) -> svuint8_t {
    svldff1_s8(pg, base.as_signed()).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1_u16(pg: svbool_t, base: *const u16) -> svuint16_t {
    svldff1_s16(pg, base.as_signed()).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1_u32(pg: svbool_t, base: *const u32) -> svuint32_t {
    svldff1_s32(pg, base.as_signed()).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1d))]
pub unsafe fn svldff1_u64(pg: svbool_t, base: *const u64) -> svuint64_t {
    svldff1_s64(pg, base.as_signed()).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1_gather_s32index_f32(
    pg: svbool_t,
    base: *const f32,
    indices: svint32_t,
) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.sxtw.index.nxv4f32"
        )]
        fn _svldff1_gather_s32index_f32(
            pg: svbool4_t,
            base: *const f32,
            indices: svint32_t,
        ) -> svfloat32_t;
    }
    _svldff1_gather_s32index_f32(pg.into(), base, indices)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1_gather_s32index_s32(
    pg: svbool_t,
    base: *const i32,
    indices: svint32_t,
) -> svint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.sxtw.index.nxv4i32"
        )]
        fn _svldff1_gather_s32index_s32(
            pg: svbool4_t,
            base: *const i32,
            indices: svint32_t,
        ) -> svint32_t;
    }
    _svldff1_gather_s32index_s32(pg.into(), base, indices)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1_gather_s32index_u32(
    pg: svbool_t,
    base: *const u32,
    indices: svint32_t,
) -> svuint32_t {
    svldff1_gather_s32index_s32(pg, base.as_signed(), indices).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1d))]
pub unsafe fn svldff1_gather_s64index_f64(
    pg: svbool_t,
    base: *const f64,
    indices: svint64_t,
) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.index.nxv2f64"
        )]
        fn _svldff1_gather_s64index_f64(
            pg: svbool2_t,
            base: *const f64,
            indices: svint64_t,
        ) -> svfloat64_t;
    }
    _svldff1_gather_s64index_f64(pg.into(), base, indices)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1d))]
pub unsafe fn svldff1_gather_s64index_s64(
    pg: svbool_t,
    base: *const i64,
    indices: svint64_t,
) -> svint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.index.nxv2i64"
        )]
        fn _svldff1_gather_s64index_s64(
            pg: svbool2_t,
            base: *const i64,
            indices: svint64_t,
        ) -> svint64_t;
    }
    _svldff1_gather_s64index_s64(pg.into(), base, indices)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1d))]
pub unsafe fn svldff1_gather_s64index_u64(
    pg: svbool_t,
    base: *const u64,
    indices: svint64_t,
) -> svuint64_t {
    svldff1_gather_s64index_s64(pg, base.as_signed(), indices).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1_gather_u32index_f32(
    pg: svbool_t,
    base: *const f32,
    indices: svuint32_t,
) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.uxtw.index.nxv4f32"
        )]
        fn _svldff1_gather_u32index_f32(
            pg: svbool4_t,
            base: *const f32,
            indices: svint32_t,
        ) -> svfloat32_t;
    }
    _svldff1_gather_u32index_f32(pg.into(), base, indices.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1_gather_u32index_s32(
    pg: svbool_t,
    base: *const i32,
    indices: svuint32_t,
) -> svint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.uxtw.index.nxv4i32"
        )]
        fn _svldff1_gather_u32index_s32(
            pg: svbool4_t,
            base: *const i32,
            indices: svint32_t,
        ) -> svint32_t;
    }
    _svldff1_gather_u32index_s32(pg.into(), base, indices.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1_gather_u32index_u32(
    pg: svbool_t,
    base: *const u32,
    indices: svuint32_t,
) -> svuint32_t {
    svldff1_gather_u32index_s32(pg, base.as_signed(), indices).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1d))]
pub unsafe fn svldff1_gather_u64index_f64(
    pg: svbool_t,
    base: *const f64,
    indices: svuint64_t,
) -> svfloat64_t {
    svldff1_gather_s64index_f64(pg, base, indices.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1d))]
pub unsafe fn svldff1_gather_u64index_s64(
    pg: svbool_t,
    base: *const i64,
    indices: svuint64_t,
) -> svint64_t {
    svldff1_gather_s64index_s64(pg, base, indices.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1d))]
pub unsafe fn svldff1_gather_u64index_u64(
    pg: svbool_t,
    base: *const u64,
    indices: svuint64_t,
) -> svuint64_t {
    svldff1_gather_s64index_s64(pg, base.as_signed(), indices.as_signed()).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1_gather_s32offset_f32(
    pg: svbool_t,
    base: *const f32,
    offsets: svint32_t,
) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.sxtw.nxv4f32"
        )]
        fn _svldff1_gather_s32offset_f32(
            pg: svbool4_t,
            base: *const f32,
            offsets: svint32_t,
        ) -> svfloat32_t;
    }
    _svldff1_gather_s32offset_f32(pg.into(), base, offsets)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1_gather_s32offset_s32(
    pg: svbool_t,
    base: *const i32,
    offsets: svint32_t,
) -> svint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.sxtw.nxv4i32"
        )]
        fn _svldff1_gather_s32offset_s32(
            pg: svbool4_t,
            base: *const i32,
            offsets: svint32_t,
        ) -> svint32_t;
    }
    _svldff1_gather_s32offset_s32(pg.into(), base, offsets)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1_gather_s32offset_u32(
    pg: svbool_t,
    base: *const u32,
    offsets: svint32_t,
) -> svuint32_t {
    svldff1_gather_s32offset_s32(pg, base.as_signed(), offsets).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1d))]
pub unsafe fn svldff1_gather_s64offset_f64(
    pg: svbool_t,
    base: *const f64,
    offsets: svint64_t,
) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.nxv2f64"
        )]
        fn _svldff1_gather_s64offset_f64(
            pg: svbool2_t,
            base: *const f64,
            offsets: svint64_t,
        ) -> svfloat64_t;
    }
    _svldff1_gather_s64offset_f64(pg.into(), base, offsets)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1d))]
pub unsafe fn svldff1_gather_s64offset_s64(
    pg: svbool_t,
    base: *const i64,
    offsets: svint64_t,
) -> svint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.nxv2i64"
        )]
        fn _svldff1_gather_s64offset_s64(
            pg: svbool2_t,
            base: *const i64,
            offsets: svint64_t,
        ) -> svint64_t;
    }
    _svldff1_gather_s64offset_s64(pg.into(), base, offsets)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1d))]
pub unsafe fn svldff1_gather_s64offset_u64(
    pg: svbool_t,
    base: *const u64,
    offsets: svint64_t,
) -> svuint64_t {
    svldff1_gather_s64offset_s64(pg, base.as_signed(), offsets).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1_gather_u32offset_f32(
    pg: svbool_t,
    base: *const f32,
    offsets: svuint32_t,
) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.uxtw.nxv4f32"
        )]
        fn _svldff1_gather_u32offset_f32(
            pg: svbool4_t,
            base: *const f32,
            offsets: svint32_t,
        ) -> svfloat32_t;
    }
    _svldff1_gather_u32offset_f32(pg.into(), base, offsets.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1_gather_u32offset_s32(
    pg: svbool_t,
    base: *const i32,
    offsets: svuint32_t,
) -> svint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.uxtw.nxv4i32"
        )]
        fn _svldff1_gather_u32offset_s32(
            pg: svbool4_t,
            base: *const i32,
            offsets: svint32_t,
        ) -> svint32_t;
    }
    _svldff1_gather_u32offset_s32(pg.into(), base, offsets.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1_gather_u32offset_u32(
    pg: svbool_t,
    base: *const u32,
    offsets: svuint32_t,
) -> svuint32_t {
    svldff1_gather_u32offset_s32(pg, base.as_signed(), offsets).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1d))]
pub unsafe fn svldff1_gather_u64offset_f64(
    pg: svbool_t,
    base: *const f64,
    offsets: svuint64_t,
) -> svfloat64_t {
    svldff1_gather_s64offset_f64(pg, base, offsets.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1d))]
pub unsafe fn svldff1_gather_u64offset_s64(
    pg: svbool_t,
    base: *const i64,
    offsets: svuint64_t,
) -> svint64_t {
    svldff1_gather_s64offset_s64(pg, base, offsets.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1d))]
pub unsafe fn svldff1_gather_u64offset_u64(
    pg: svbool_t,
    base: *const u64,
    offsets: svuint64_t,
) -> svuint64_t {
    svldff1_gather_s64offset_s64(pg, base.as_signed(), offsets.as_signed()).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1_gather_u32base_f32(pg: svbool_t, bases: svuint32_t) -> svfloat32_t {
    svldff1_gather_u32base_offset_f32(pg, bases, 0)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1_gather_u32base_s32(pg: svbool_t, bases: svuint32_t) -> svint32_t {
    svldff1_gather_u32base_offset_s32(pg, bases, 0)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1_gather_u32base_u32(pg: svbool_t, bases: svuint32_t) -> svuint32_t {
    svldff1_gather_u32base_offset_u32(pg, bases, 0)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1d))]
pub unsafe fn svldff1_gather_u64base_f64(pg: svbool_t, bases: svuint64_t) -> svfloat64_t {
    svldff1_gather_u64base_offset_f64(pg, bases, 0)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1d))]
pub unsafe fn svldff1_gather_u64base_s64(pg: svbool_t, bases: svuint64_t) -> svint64_t {
    svldff1_gather_u64base_offset_s64(pg, bases, 0)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1d))]
pub unsafe fn svldff1_gather_u64base_u64(pg: svbool_t, bases: svuint64_t) -> svuint64_t {
    svldff1_gather_u64base_offset_u64(pg, bases, 0)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1_gather_u32base_index_f32(
    pg: svbool_t,
    bases: svuint32_t,
    index: i64,
) -> svfloat32_t {
    svldff1_gather_u32base_offset_f32(pg, bases, index.unchecked_shl(2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1_gather_u32base_index_s32(
    pg: svbool_t,
    bases: svuint32_t,
    index: i64,
) -> svint32_t {
    svldff1_gather_u32base_offset_s32(pg, bases, index.unchecked_shl(2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1_gather_u32base_index_u32(
    pg: svbool_t,
    bases: svuint32_t,
    index: i64,
) -> svuint32_t {
    svldff1_gather_u32base_offset_u32(pg, bases, index.unchecked_shl(2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1d))]
pub unsafe fn svldff1_gather_u64base_index_f64(
    pg: svbool_t,
    bases: svuint64_t,
    index: i64,
) -> svfloat64_t {
    svldff1_gather_u64base_offset_f64(pg, bases, index.unchecked_shl(3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1d))]
pub unsafe fn svldff1_gather_u64base_index_s64(
    pg: svbool_t,
    bases: svuint64_t,
    index: i64,
) -> svint64_t {
    svldff1_gather_u64base_offset_s64(pg, bases, index.unchecked_shl(3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1d))]
pub unsafe fn svldff1_gather_u64base_index_u64(
    pg: svbool_t,
    bases: svuint64_t,
    index: i64,
) -> svuint64_t {
    svldff1_gather_u64base_offset_u64(pg, bases, index.unchecked_shl(3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1_gather_u32base_offset_f32(
    pg: svbool_t,
    bases: svuint32_t,
    offset: i64,
) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.scalar.offset.nxv4f32.nxv4i32"
        )]
        fn _svldff1_gather_u32base_offset_f32(
            pg: svbool4_t,
            bases: svint32_t,
            offset: i64,
        ) -> svfloat32_t;
    }
    _svldff1_gather_u32base_offset_f32(pg.into(), bases.as_signed(), offset)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1_gather_u32base_offset_s32(
    pg: svbool_t,
    bases: svuint32_t,
    offset: i64,
) -> svint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.scalar.offset.nxv4i32.nxv4i32"
        )]
        fn _svldff1_gather_u32base_offset_s32(
            pg: svbool4_t,
            bases: svint32_t,
            offset: i64,
        ) -> svint32_t;
    }
    _svldff1_gather_u32base_offset_s32(pg.into(), bases.as_signed(), offset)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1_gather_u32base_offset_u32(
    pg: svbool_t,
    bases: svuint32_t,
    offset: i64,
) -> svuint32_t {
    svldff1_gather_u32base_offset_s32(pg, bases, offset).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1d))]
pub unsafe fn svldff1_gather_u64base_offset_f64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.scalar.offset.nxv2f64.nxv2i64"
        )]
        fn _svldff1_gather_u64base_offset_f64(
            pg: svbool2_t,
            bases: svint64_t,
            offset: i64,
        ) -> svfloat64_t;
    }
    _svldff1_gather_u64base_offset_f64(pg.into(), bases.as_signed(), offset)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1d))]
pub unsafe fn svldff1_gather_u64base_offset_s64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
) -> svint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.scalar.offset.nxv2i64.nxv2i64"
        )]
        fn _svldff1_gather_u64base_offset_s64(
            pg: svbool2_t,
            bases: svint64_t,
            offset: i64,
        ) -> svint64_t;
    }
    _svldff1_gather_u64base_offset_s64(pg.into(), bases.as_signed(), offset)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1d))]
pub unsafe fn svldff1_gather_u64base_offset_u64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
) -> svuint64_t {
    svldff1_gather_u64base_offset_s64(pg, bases, offset).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1_vnum_f32(pg: svbool_t, base: *const f32, vnum: i64) -> svfloat32_t {
    svldff1_f32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1d))]
pub unsafe fn svldff1_vnum_f64(pg: svbool_t, base: *const f64, vnum: i64) -> svfloat64_t {
    svldff1_f64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1b))]
pub unsafe fn svldff1_vnum_s8(pg: svbool_t, base: *const i8, vnum: i64) -> svint8_t {
    svldff1_s8(pg, base.offset(svcntb() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1_vnum_s16(pg: svbool_t, base: *const i16, vnum: i64) -> svint16_t {
    svldff1_s16(pg, base.offset(svcnth() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1_vnum_s32(pg: svbool_t, base: *const i32, vnum: i64) -> svint32_t {
    svldff1_s32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1d))]
pub unsafe fn svldff1_vnum_s64(pg: svbool_t, base: *const i64, vnum: i64) -> svint64_t {
    svldff1_s64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1b))]
pub unsafe fn svldff1_vnum_u8(pg: svbool_t, base: *const u8, vnum: i64) -> svuint8_t {
    svldff1_u8(pg, base.offset(svcntb() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1_vnum_u16(pg: svbool_t, base: *const u16, vnum: i64) -> svuint16_t {
    svldff1_u16(pg, base.offset(svcnth() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1_vnum_u32(pg: svbool_t, base: *const u32, vnum: i64) -> svuint32_t {
    svldff1_u32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1d))]
pub unsafe fn svldff1_vnum_u64(pg: svbool_t, base: *const u64, vnum: i64) -> svuint64_t {
    svldff1_u64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sb))]
pub unsafe fn svldff1sb_gather_s32offset_s32(
    pg: svbool_t,
    base: *const i8,
    offsets: svint32_t,
) -> svint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.sxtw.nxv4i8"
        )]
        fn _svldff1sb_gather_s32offset_s32(
            pg: svbool4_t,
            base: *const i8,
            offsets: svint32_t,
        ) -> nxv4i8;
    }
    simd_cast(_svldff1sb_gather_s32offset_s32(pg.into(), base, offsets))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sh))]
pub unsafe fn svldff1sh_gather_s32offset_s32(
    pg: svbool_t,
    base: *const i16,
    offsets: svint32_t,
) -> svint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.sxtw.nxv4i16"
        )]
        fn _svldff1sh_gather_s32offset_s32(
            pg: svbool4_t,
            base: *const i16,
            offsets: svint32_t,
        ) -> nxv4i16;
    }
    simd_cast(_svldff1sh_gather_s32offset_s32(pg.into(), base, offsets))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sb))]
pub unsafe fn svldff1sb_gather_s32offset_u32(
    pg: svbool_t,
    base: *const i8,
    offsets: svint32_t,
) -> svuint32_t {
    svldff1sb_gather_s32offset_s32(pg, base, offsets).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sh))]
pub unsafe fn svldff1sh_gather_s32offset_u32(
    pg: svbool_t,
    base: *const i16,
    offsets: svint32_t,
) -> svuint32_t {
    svldff1sh_gather_s32offset_s32(pg, base, offsets).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sb))]
pub unsafe fn svldff1sb_gather_s64offset_s64(
    pg: svbool_t,
    base: *const i8,
    offsets: svint64_t,
) -> svint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.nxv2i8"
        )]
        fn _svldff1sb_gather_s64offset_s64(
            pg: svbool2_t,
            base: *const i8,
            offsets: svint64_t,
        ) -> nxv2i8;
    }
    simd_cast(_svldff1sb_gather_s64offset_s64(pg.into(), base, offsets))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sh))]
pub unsafe fn svldff1sh_gather_s64offset_s64(
    pg: svbool_t,
    base: *const i16,
    offsets: svint64_t,
) -> svint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.nxv2i16"
        )]
        fn _svldff1sh_gather_s64offset_s64(
            pg: svbool2_t,
            base: *const i16,
            offsets: svint64_t,
        ) -> nxv2i16;
    }
    simd_cast(_svldff1sh_gather_s64offset_s64(pg.into(), base, offsets))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sw))]
pub unsafe fn svldff1sw_gather_s64offset_s64(
    pg: svbool_t,
    base: *const i32,
    offsets: svint64_t,
) -> svint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.nxv2i32"
        )]
        fn _svldff1sw_gather_s64offset_s64(
            pg: svbool2_t,
            base: *const i32,
            offsets: svint64_t,
        ) -> nxv2i32;
    }
    simd_cast(_svldff1sw_gather_s64offset_s64(pg.into(), base, offsets))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sb))]
pub unsafe fn svldff1sb_gather_s64offset_u64(
    pg: svbool_t,
    base: *const i8,
    offsets: svint64_t,
) -> svuint64_t {
    svldff1sb_gather_s64offset_s64(pg, base, offsets).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sh))]
pub unsafe fn svldff1sh_gather_s64offset_u64(
    pg: svbool_t,
    base: *const i16,
    offsets: svint64_t,
) -> svuint64_t {
    svldff1sh_gather_s64offset_s64(pg, base, offsets).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sw))]
pub unsafe fn svldff1sw_gather_s64offset_u64(
    pg: svbool_t,
    base: *const i32,
    offsets: svint64_t,
) -> svuint64_t {
    svldff1sw_gather_s64offset_s64(pg, base, offsets).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sb))]
pub unsafe fn svldff1sb_gather_u32offset_s32(
    pg: svbool_t,
    base: *const i8,
    offsets: svuint32_t,
) -> svint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.uxtw.nxv4i8"
        )]
        fn _svldff1sb_gather_u32offset_s32(
            pg: svbool4_t,
            base: *const i8,
            offsets: svint32_t,
        ) -> nxv4i8;
    }
    simd_cast(_svldff1sb_gather_u32offset_s32(
        pg.into(),
        base,
        offsets.as_signed(),
    ))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sh))]
pub unsafe fn svldff1sh_gather_u32offset_s32(
    pg: svbool_t,
    base: *const i16,
    offsets: svuint32_t,
) -> svint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.uxtw.nxv4i16"
        )]
        fn _svldff1sh_gather_u32offset_s32(
            pg: svbool4_t,
            base: *const i16,
            offsets: svint32_t,
        ) -> nxv4i16;
    }
    simd_cast(_svldff1sh_gather_u32offset_s32(
        pg.into(),
        base,
        offsets.as_signed(),
    ))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sb))]
pub unsafe fn svldff1sb_gather_u32offset_u32(
    pg: svbool_t,
    base: *const i8,
    offsets: svuint32_t,
) -> svuint32_t {
    svldff1sb_gather_u32offset_s32(pg, base, offsets).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sh))]
pub unsafe fn svldff1sh_gather_u32offset_u32(
    pg: svbool_t,
    base: *const i16,
    offsets: svuint32_t,
) -> svuint32_t {
    svldff1sh_gather_u32offset_s32(pg, base, offsets).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sb))]
pub unsafe fn svldff1sb_gather_u64offset_s64(
    pg: svbool_t,
    base: *const i8,
    offsets: svuint64_t,
) -> svint64_t {
    svldff1sb_gather_s64offset_s64(pg, base, offsets.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sh))]
pub unsafe fn svldff1sh_gather_u64offset_s64(
    pg: svbool_t,
    base: *const i16,
    offsets: svuint64_t,
) -> svint64_t {
    svldff1sh_gather_s64offset_s64(pg, base, offsets.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sw))]
pub unsafe fn svldff1sw_gather_u64offset_s64(
    pg: svbool_t,
    base: *const i32,
    offsets: svuint64_t,
) -> svint64_t {
    svldff1sw_gather_s64offset_s64(pg, base, offsets.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sb))]
pub unsafe fn svldff1sb_gather_u64offset_u64(
    pg: svbool_t,
    base: *const i8,
    offsets: svuint64_t,
) -> svuint64_t {
    svldff1sb_gather_s64offset_s64(pg, base, offsets.as_signed()).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sh))]
pub unsafe fn svldff1sh_gather_u64offset_u64(
    pg: svbool_t,
    base: *const i16,
    offsets: svuint64_t,
) -> svuint64_t {
    svldff1sh_gather_s64offset_s64(pg, base, offsets.as_signed()).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sw))]
pub unsafe fn svldff1sw_gather_u64offset_u64(
    pg: svbool_t,
    base: *const i32,
    offsets: svuint64_t,
) -> svuint64_t {
    svldff1sw_gather_s64offset_s64(pg, base, offsets.as_signed()).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sb))]
pub unsafe fn svldff1sb_gather_u32base_offset_s32(
    pg: svbool_t,
    bases: svuint32_t,
    offset: i64,
) -> svint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.scalar.offset.nxv4i8.nxv4i32"
        )]
        fn _svldff1sb_gather_u32base_offset_s32(
            pg: svbool4_t,
            bases: svint32_t,
            offset: i64,
        ) -> nxv4i8;
    }
    simd_cast(_svldff1sb_gather_u32base_offset_s32(
        pg.into(),
        bases.as_signed(),
        offset,
    ))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sh))]
pub unsafe fn svldff1sh_gather_u32base_offset_s32(
    pg: svbool_t,
    bases: svuint32_t,
    offset: i64,
) -> svint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.scalar.offset.nxv4i16.nxv4i32"
        )]
        fn _svldff1sh_gather_u32base_offset_s32(
            pg: svbool4_t,
            bases: svint32_t,
            offset: i64,
        ) -> nxv4i16;
    }
    simd_cast(_svldff1sh_gather_u32base_offset_s32(
        pg.into(),
        bases.as_signed(),
        offset,
    ))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sb))]
pub unsafe fn svldff1sb_gather_u32base_offset_u32(
    pg: svbool_t,
    bases: svuint32_t,
    offset: i64,
) -> svuint32_t {
    svldff1sb_gather_u32base_offset_s32(pg, bases, offset).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sh))]
pub unsafe fn svldff1sh_gather_u32base_offset_u32(
    pg: svbool_t,
    bases: svuint32_t,
    offset: i64,
) -> svuint32_t {
    svldff1sh_gather_u32base_offset_s32(pg, bases, offset).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sb))]
pub unsafe fn svldff1sb_gather_u64base_offset_s64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
) -> svint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.scalar.offset.nxv2i8.nxv2i64"
        )]
        fn _svldff1sb_gather_u64base_offset_s64(
            pg: svbool2_t,
            bases: svint64_t,
            offset: i64,
        ) -> nxv2i8;
    }
    simd_cast(_svldff1sb_gather_u64base_offset_s64(
        pg.into(),
        bases.as_signed(),
        offset,
    ))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sh))]
pub unsafe fn svldff1sh_gather_u64base_offset_s64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
) -> svint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.scalar.offset.nxv2i16.nxv2i64"
        )]
        fn _svldff1sh_gather_u64base_offset_s64(
            pg: svbool2_t,
            bases: svint64_t,
            offset: i64,
        ) -> nxv2i16;
    }
    simd_cast(_svldff1sh_gather_u64base_offset_s64(
        pg.into(),
        bases.as_signed(),
        offset,
    ))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sw))]
pub unsafe fn svldff1sw_gather_u64base_offset_s64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
) -> svint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.scalar.offset.nxv2i32.nxv2i64"
        )]
        fn _svldff1sw_gather_u64base_offset_s64(
            pg: svbool2_t,
            bases: svint64_t,
            offset: i64,
        ) -> nxv2i32;
    }
    simd_cast(_svldff1sw_gather_u64base_offset_s64(
        pg.into(),
        bases.as_signed(),
        offset,
    ))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sb))]
pub unsafe fn svldff1sb_gather_u64base_offset_u64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
) -> svuint64_t {
    svldff1sb_gather_u64base_offset_s64(pg, bases, offset).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sh))]
pub unsafe fn svldff1sh_gather_u64base_offset_u64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
) -> svuint64_t {
    svldff1sh_gather_u64base_offset_s64(pg, bases, offset).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sw))]
pub unsafe fn svldff1sw_gather_u64base_offset_u64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
) -> svuint64_t {
    svldff1sw_gather_u64base_offset_s64(pg, bases, offset).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sb))]
pub unsafe fn svldff1sb_gather_u32base_s32(pg: svbool_t, bases: svuint32_t) -> svint32_t {
    svldff1sb_gather_u32base_offset_s32(pg, bases, 0)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sh))]
pub unsafe fn svldff1sh_gather_u32base_s32(pg: svbool_t, bases: svuint32_t) -> svint32_t {
    svldff1sh_gather_u32base_offset_s32(pg, bases, 0)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sb))]
pub unsafe fn svldff1sb_gather_u32base_u32(pg: svbool_t, bases: svuint32_t) -> svuint32_t {
    svldff1sb_gather_u32base_offset_u32(pg, bases, 0)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sh))]
pub unsafe fn svldff1sh_gather_u32base_u32(pg: svbool_t, bases: svuint32_t) -> svuint32_t {
    svldff1sh_gather_u32base_offset_u32(pg, bases, 0)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sb))]
pub unsafe fn svldff1sb_gather_u64base_s64(pg: svbool_t, bases: svuint64_t) -> svint64_t {
    svldff1sb_gather_u64base_offset_s64(pg, bases, 0)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sh))]
pub unsafe fn svldff1sh_gather_u64base_s64(pg: svbool_t, bases: svuint64_t) -> svint64_t {
    svldff1sh_gather_u64base_offset_s64(pg, bases, 0)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sw))]
pub unsafe fn svldff1sw_gather_u64base_s64(pg: svbool_t, bases: svuint64_t) -> svint64_t {
    svldff1sw_gather_u64base_offset_s64(pg, bases, 0)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sb))]
pub unsafe fn svldff1sb_gather_u64base_u64(pg: svbool_t, bases: svuint64_t) -> svuint64_t {
    svldff1sb_gather_u64base_offset_u64(pg, bases, 0)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sh))]
pub unsafe fn svldff1sh_gather_u64base_u64(pg: svbool_t, bases: svuint64_t) -> svuint64_t {
    svldff1sh_gather_u64base_offset_u64(pg, bases, 0)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sw))]
pub unsafe fn svldff1sw_gather_u64base_u64(pg: svbool_t, bases: svuint64_t) -> svuint64_t {
    svldff1sw_gather_u64base_offset_u64(pg, bases, 0)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sb))]
pub unsafe fn svldff1sb_s16(pg: svbool_t, base: *const i8) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldff1.nxv8i8")]
        fn _svldff1sb_s16(pg: svbool8_t, base: *const i8) -> nxv8i8;
    }
    simd_cast(_svldff1sb_s16(pg.into(), base))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sb))]
pub unsafe fn svldff1sb_s32(pg: svbool_t, base: *const i8) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldff1.nxv4i8")]
        fn _svldff1sb_s32(pg: svbool4_t, base: *const i8) -> nxv4i8;
    }
    simd_cast(_svldff1sb_s32(pg.into(), base))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sh))]
pub unsafe fn svldff1sh_s32(pg: svbool_t, base: *const i16) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldff1.nxv4i16")]
        fn _svldff1sh_s32(pg: svbool4_t, base: *const i16) -> nxv4i16;
    }
    simd_cast(_svldff1sh_s32(pg.into(), base))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sb))]
pub unsafe fn svldff1sb_s64(pg: svbool_t, base: *const i8) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldff1.nxv2i8")]
        fn _svldff1sb_s64(pg: svbool2_t, base: *const i8) -> nxv2i8;
    }
    simd_cast(_svldff1sb_s64(pg.into(), base))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sh))]
pub unsafe fn svldff1sh_s64(pg: svbool_t, base: *const i16) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldff1.nxv2i16")]
        fn _svldff1sh_s64(pg: svbool2_t, base: *const i16) -> nxv2i16;
    }
    simd_cast(_svldff1sh_s64(pg.into(), base))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sw))]
pub unsafe fn svldff1sw_s64(pg: svbool_t, base: *const i32) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldff1.nxv2i32")]
        fn _svldff1sw_s64(pg: svbool2_t, base: *const i32) -> nxv2i32;
    }
    simd_cast(_svldff1sw_s64(pg.into(), base))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sb))]
pub unsafe fn svldff1sb_u16(pg: svbool_t, base: *const i8) -> svuint16_t {
    svldff1sb_s16(pg, base).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sb))]
pub unsafe fn svldff1sb_u32(pg: svbool_t, base: *const i8) -> svuint32_t {
    svldff1sb_s32(pg, base).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sh))]
pub unsafe fn svldff1sh_u32(pg: svbool_t, base: *const i16) -> svuint32_t {
    svldff1sh_s32(pg, base).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sb))]
pub unsafe fn svldff1sb_u64(pg: svbool_t, base: *const i8) -> svuint64_t {
    svldff1sb_s64(pg, base).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sh))]
pub unsafe fn svldff1sh_u64(pg: svbool_t, base: *const i16) -> svuint64_t {
    svldff1sh_s64(pg, base).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sw))]
pub unsafe fn svldff1sw_u64(pg: svbool_t, base: *const i32) -> svuint64_t {
    svldff1sw_s64(pg, base).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sb))]
pub unsafe fn svldff1sb_vnum_s16(pg: svbool_t, base: *const i8, vnum: i64) -> svint16_t {
    svldff1sb_s16(pg, base.offset(svcnth() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sb))]
pub unsafe fn svldff1sb_vnum_s32(pg: svbool_t, base: *const i8, vnum: i64) -> svint32_t {
    svldff1sb_s32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sh))]
pub unsafe fn svldff1sh_vnum_s32(pg: svbool_t, base: *const i16, vnum: i64) -> svint32_t {
    svldff1sh_s32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sb))]
pub unsafe fn svldff1sb_vnum_s64(pg: svbool_t, base: *const i8, vnum: i64) -> svint64_t {
    svldff1sb_s64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sh))]
pub unsafe fn svldff1sh_vnum_s64(pg: svbool_t, base: *const i16, vnum: i64) -> svint64_t {
    svldff1sh_s64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sw))]
pub unsafe fn svldff1sw_vnum_s64(pg: svbool_t, base: *const i32, vnum: i64) -> svint64_t {
    svldff1sw_s64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sb))]
pub unsafe fn svldff1sb_vnum_u16(pg: svbool_t, base: *const i8, vnum: i64) -> svuint16_t {
    svldff1sb_u16(pg, base.offset(svcnth() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sb))]
pub unsafe fn svldff1sb_vnum_u32(pg: svbool_t, base: *const i8, vnum: i64) -> svuint32_t {
    svldff1sb_u32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sh))]
pub unsafe fn svldff1sh_vnum_u32(pg: svbool_t, base: *const i16, vnum: i64) -> svuint32_t {
    svldff1sh_u32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sb))]
pub unsafe fn svldff1sb_vnum_u64(pg: svbool_t, base: *const i8, vnum: i64) -> svuint64_t {
    svldff1sb_u64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sh))]
pub unsafe fn svldff1sh_vnum_u64(pg: svbool_t, base: *const i16, vnum: i64) -> svuint64_t {
    svldff1sh_u64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sw))]
pub unsafe fn svldff1sw_vnum_u64(pg: svbool_t, base: *const i32, vnum: i64) -> svuint64_t {
    svldff1sw_u64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sh))]
pub unsafe fn svldff1sh_gather_s32index_s32(
    pg: svbool_t,
    base: *const i16,
    indices: svint32_t,
) -> svint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.sxtw.index.nxv4i16"
        )]
        fn _svldff1sh_gather_s32index_s32(
            pg: svbool4_t,
            base: *const i16,
            indices: svint32_t,
        ) -> nxv4i16;
    }
    simd_cast(_svldff1sh_gather_s32index_s32(pg.into(), base, indices))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sh))]
pub unsafe fn svldff1sh_gather_s32index_u32(
    pg: svbool_t,
    base: *const i16,
    indices: svint32_t,
) -> svuint32_t {
    svldff1sh_gather_s32index_s32(pg, base, indices).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sh))]
pub unsafe fn svldff1sh_gather_s64index_s64(
    pg: svbool_t,
    base: *const i16,
    indices: svint64_t,
) -> svint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.index.nxv2i16"
        )]
        fn _svldff1sh_gather_s64index_s64(
            pg: svbool2_t,
            base: *const i16,
            indices: svint64_t,
        ) -> nxv2i16;
    }
    simd_cast(_svldff1sh_gather_s64index_s64(pg.into(), base, indices))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sw))]
pub unsafe fn svldff1sw_gather_s64index_s64(
    pg: svbool_t,
    base: *const i32,
    indices: svint64_t,
) -> svint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.index.nxv2i32"
        )]
        fn _svldff1sw_gather_s64index_s64(
            pg: svbool2_t,
            base: *const i32,
            indices: svint64_t,
        ) -> nxv2i32;
    }
    simd_cast(_svldff1sw_gather_s64index_s64(pg.into(), base, indices))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sh))]
pub unsafe fn svldff1sh_gather_s64index_u64(
    pg: svbool_t,
    base: *const i16,
    indices: svint64_t,
) -> svuint64_t {
    svldff1sh_gather_s64index_s64(pg, base, indices).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sw))]
pub unsafe fn svldff1sw_gather_s64index_u64(
    pg: svbool_t,
    base: *const i32,
    indices: svint64_t,
) -> svuint64_t {
    svldff1sw_gather_s64index_s64(pg, base, indices).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sh))]
pub unsafe fn svldff1sh_gather_u32index_s32(
    pg: svbool_t,
    base: *const i16,
    indices: svuint32_t,
) -> svint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.uxtw.index.nxv4i16"
        )]
        fn _svldff1sh_gather_u32index_s32(
            pg: svbool4_t,
            base: *const i16,
            indices: svint32_t,
        ) -> nxv4i16;
    }
    simd_cast(_svldff1sh_gather_u32index_s32(
        pg.into(),
        base,
        indices.as_signed(),
    ))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sh))]
pub unsafe fn svldff1sh_gather_u32index_u32(
    pg: svbool_t,
    base: *const i16,
    indices: svuint32_t,
) -> svuint32_t {
    svldff1sh_gather_u32index_s32(pg, base, indices).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sh))]
pub unsafe fn svldff1sh_gather_u64index_s64(
    pg: svbool_t,
    base: *const i16,
    indices: svuint64_t,
) -> svint64_t {
    svldff1sh_gather_s64index_s64(pg, base, indices.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sw))]
pub unsafe fn svldff1sw_gather_u64index_s64(
    pg: svbool_t,
    base: *const i32,
    indices: svuint64_t,
) -> svint64_t {
    svldff1sw_gather_s64index_s64(pg, base, indices.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sh))]
pub unsafe fn svldff1sh_gather_u64index_u64(
    pg: svbool_t,
    base: *const i16,
    indices: svuint64_t,
) -> svuint64_t {
    svldff1sh_gather_s64index_s64(pg, base, indices.as_signed()).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sw))]
pub unsafe fn svldff1sw_gather_u64index_u64(
    pg: svbool_t,
    base: *const i32,
    indices: svuint64_t,
) -> svuint64_t {
    svldff1sw_gather_s64index_s64(pg, base, indices.as_signed()).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sh))]
pub unsafe fn svldff1sh_gather_u32base_index_s32(
    pg: svbool_t,
    bases: svuint32_t,
    index: i64,
) -> svint32_t {
    svldff1sh_gather_u32base_offset_s32(pg, bases, index.unchecked_shl(1))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sh))]
pub unsafe fn svldff1sh_gather_u32base_index_u32(
    pg: svbool_t,
    bases: svuint32_t,
    index: i64,
) -> svuint32_t {
    svldff1sh_gather_u32base_offset_u32(pg, bases, index.unchecked_shl(1))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sh))]
pub unsafe fn svldff1sh_gather_u64base_index_s64(
    pg: svbool_t,
    bases: svuint64_t,
    index: i64,
) -> svint64_t {
    svldff1sh_gather_u64base_offset_s64(pg, bases, index.unchecked_shl(1))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sw))]
pub unsafe fn svldff1sw_gather_u64base_index_s64(
    pg: svbool_t,
    bases: svuint64_t,
    index: i64,
) -> svint64_t {
    svldff1sw_gather_u64base_offset_s64(pg, bases, index.unchecked_shl(2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sh))]
pub unsafe fn svldff1sh_gather_u64base_index_u64(
    pg: svbool_t,
    bases: svuint64_t,
    index: i64,
) -> svuint64_t {
    svldff1sh_gather_u64base_offset_u64(pg, bases, index.unchecked_shl(1))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sw))]
pub unsafe fn svldff1sw_gather_u64base_index_u64(
    pg: svbool_t,
    bases: svuint64_t,
    index: i64,
) -> svuint64_t {
    svldff1sw_gather_u64base_offset_u64(pg, bases, index.unchecked_shl(2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1b))]
pub unsafe fn svldff1ub_gather_s32offset_s32(
    pg: svbool_t,
    base: *const u8,
    offsets: svint32_t,
) -> svint32_t {
    svldff1ub_gather_s32offset_u32(pg, base, offsets).as_signed()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1uh_gather_s32offset_s32(
    pg: svbool_t,
    base: *const u16,
    offsets: svint32_t,
) -> svint32_t {
    svldff1uh_gather_s32offset_u32(pg, base, offsets).as_signed()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1b))]
pub unsafe fn svldff1ub_gather_s32offset_u32(
    pg: svbool_t,
    base: *const u8,
    offsets: svint32_t,
) -> svuint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.sxtw.nxv4i8"
        )]
        fn _svldff1ub_gather_s32offset_u32(
            pg: svbool4_t,
            base: *const i8,
            offsets: svint32_t,
        ) -> nxv4i8;
    }
    simd_cast::<nxv4u8, _>(
        _svldff1ub_gather_s32offset_u32(pg.into(), base.as_signed(), offsets).as_unsigned(),
    )
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1uh_gather_s32offset_u32(
    pg: svbool_t,
    base: *const u16,
    offsets: svint32_t,
) -> svuint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.sxtw.nxv4i16"
        )]
        fn _svldff1uh_gather_s32offset_u32(
            pg: svbool4_t,
            base: *const i16,
            offsets: svint32_t,
        ) -> nxv4i16;
    }
    simd_cast::<nxv4u16, _>(
        _svldff1uh_gather_s32offset_u32(pg.into(), base.as_signed(), offsets).as_unsigned(),
    )
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1b))]
pub unsafe fn svldff1ub_gather_s64offset_s64(
    pg: svbool_t,
    base: *const u8,
    offsets: svint64_t,
) -> svint64_t {
    svldff1ub_gather_s64offset_u64(pg, base, offsets).as_signed()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1uh_gather_s64offset_s64(
    pg: svbool_t,
    base: *const u16,
    offsets: svint64_t,
) -> svint64_t {
    svldff1uh_gather_s64offset_u64(pg, base, offsets).as_signed()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1uw_gather_s64offset_s64(
    pg: svbool_t,
    base: *const u32,
    offsets: svint64_t,
) -> svint64_t {
    svldff1uw_gather_s64offset_u64(pg, base, offsets).as_signed()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1b))]
pub unsafe fn svldff1ub_gather_s64offset_u64(
    pg: svbool_t,
    base: *const u8,
    offsets: svint64_t,
) -> svuint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.nxv2i8"
        )]
        fn _svldff1ub_gather_s64offset_u64(
            pg: svbool2_t,
            base: *const i8,
            offsets: svint64_t,
        ) -> nxv2i8;
    }
    simd_cast::<nxv2u8, _>(
        _svldff1ub_gather_s64offset_u64(pg.into(), base.as_signed(), offsets).as_unsigned(),
    )
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1uh_gather_s64offset_u64(
    pg: svbool_t,
    base: *const u16,
    offsets: svint64_t,
) -> svuint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.nxv2i16"
        )]
        fn _svldff1uh_gather_s64offset_u64(
            pg: svbool2_t,
            base: *const i16,
            offsets: svint64_t,
        ) -> nxv2i16;
    }
    simd_cast::<nxv2u16, _>(
        _svldff1uh_gather_s64offset_u64(pg.into(), base.as_signed(), offsets).as_unsigned(),
    )
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1uw_gather_s64offset_u64(
    pg: svbool_t,
    base: *const u32,
    offsets: svint64_t,
) -> svuint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.nxv2i32"
        )]
        fn _svldff1uw_gather_s64offset_u64(
            pg: svbool2_t,
            base: *const i32,
            offsets: svint64_t,
        ) -> nxv2i32;
    }
    simd_cast::<nxv2u32, _>(
        _svldff1uw_gather_s64offset_u64(pg.into(), base.as_signed(), offsets).as_unsigned(),
    )
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1b))]
pub unsafe fn svldff1ub_gather_u32offset_s32(
    pg: svbool_t,
    base: *const u8,
    offsets: svuint32_t,
) -> svint32_t {
    svldff1ub_gather_u32offset_u32(pg, base, offsets).as_signed()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1uh_gather_u32offset_s32(
    pg: svbool_t,
    base: *const u16,
    offsets: svuint32_t,
) -> svint32_t {
    svldff1uh_gather_u32offset_u32(pg, base, offsets).as_signed()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1b))]
pub unsafe fn svldff1ub_gather_u32offset_u32(
    pg: svbool_t,
    base: *const u8,
    offsets: svuint32_t,
) -> svuint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.uxtw.nxv4i8"
        )]
        fn _svldff1ub_gather_u32offset_u32(
            pg: svbool4_t,
            base: *const i8,
            offsets: svint32_t,
        ) -> nxv4i8;
    }
    simd_cast::<nxv4u8, _>(
        _svldff1ub_gather_u32offset_u32(pg.into(), base.as_signed(), offsets.as_signed())
            .as_unsigned(),
    )
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1uh_gather_u32offset_u32(
    pg: svbool_t,
    base: *const u16,
    offsets: svuint32_t,
) -> svuint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.uxtw.nxv4i16"
        )]
        fn _svldff1uh_gather_u32offset_u32(
            pg: svbool4_t,
            base: *const i16,
            offsets: svint32_t,
        ) -> nxv4i16;
    }
    simd_cast::<nxv4u16, _>(
        _svldff1uh_gather_u32offset_u32(pg.into(), base.as_signed(), offsets.as_signed())
            .as_unsigned(),
    )
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1b))]
pub unsafe fn svldff1ub_gather_u64offset_s64(
    pg: svbool_t,
    base: *const u8,
    offsets: svuint64_t,
) -> svint64_t {
    svldff1ub_gather_s64offset_u64(pg, base, offsets.as_signed()).as_signed()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1uh_gather_u64offset_s64(
    pg: svbool_t,
    base: *const u16,
    offsets: svuint64_t,
) -> svint64_t {
    svldff1uh_gather_s64offset_u64(pg, base, offsets.as_signed()).as_signed()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1uw_gather_u64offset_s64(
    pg: svbool_t,
    base: *const u32,
    offsets: svuint64_t,
) -> svint64_t {
    svldff1uw_gather_s64offset_u64(pg, base, offsets.as_signed()).as_signed()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1b))]
pub unsafe fn svldff1ub_gather_u64offset_u64(
    pg: svbool_t,
    base: *const u8,
    offsets: svuint64_t,
) -> svuint64_t {
    svldff1ub_gather_s64offset_u64(pg, base, offsets.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1uh_gather_u64offset_u64(
    pg: svbool_t,
    base: *const u16,
    offsets: svuint64_t,
) -> svuint64_t {
    svldff1uh_gather_s64offset_u64(pg, base, offsets.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1uw_gather_u64offset_u64(
    pg: svbool_t,
    base: *const u32,
    offsets: svuint64_t,
) -> svuint64_t {
    svldff1uw_gather_s64offset_u64(pg, base, offsets.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1b))]
pub unsafe fn svldff1ub_gather_u32base_offset_s32(
    pg: svbool_t,
    bases: svuint32_t,
    offset: i64,
) -> svint32_t {
    svldff1ub_gather_u32base_offset_u32(pg, bases, offset).as_signed()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1uh_gather_u32base_offset_s32(
    pg: svbool_t,
    bases: svuint32_t,
    offset: i64,
) -> svint32_t {
    svldff1uh_gather_u32base_offset_u32(pg, bases, offset).as_signed()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1b))]
pub unsafe fn svldff1ub_gather_u32base_offset_u32(
    pg: svbool_t,
    bases: svuint32_t,
    offset: i64,
) -> svuint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.scalar.offset.nxv4i8.nxv4i32"
        )]
        fn _svldff1ub_gather_u32base_offset_u32(
            pg: svbool4_t,
            bases: svint32_t,
            offset: i64,
        ) -> nxv4i8;
    }
    simd_cast::<nxv4u8, _>(
        _svldff1ub_gather_u32base_offset_u32(pg.into(), bases.as_signed(), offset).as_unsigned(),
    )
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1uh_gather_u32base_offset_u32(
    pg: svbool_t,
    bases: svuint32_t,
    offset: i64,
) -> svuint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.scalar.offset.nxv4i16.nxv4i32"
        )]
        fn _svldff1uh_gather_u32base_offset_u32(
            pg: svbool4_t,
            bases: svint32_t,
            offset: i64,
        ) -> nxv4i16;
    }
    simd_cast::<nxv4u16, _>(
        _svldff1uh_gather_u32base_offset_u32(pg.into(), bases.as_signed(), offset).as_unsigned(),
    )
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1b))]
pub unsafe fn svldff1ub_gather_u64base_offset_s64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
) -> svint64_t {
    svldff1ub_gather_u64base_offset_u64(pg, bases, offset).as_signed()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1uh_gather_u64base_offset_s64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
) -> svint64_t {
    svldff1uh_gather_u64base_offset_u64(pg, bases, offset).as_signed()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1uw_gather_u64base_offset_s64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
) -> svint64_t {
    svldff1uw_gather_u64base_offset_u64(pg, bases, offset).as_signed()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1b))]
pub unsafe fn svldff1ub_gather_u64base_offset_u64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
) -> svuint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.scalar.offset.nxv2i8.nxv2i64"
        )]
        fn _svldff1ub_gather_u64base_offset_u64(
            pg: svbool2_t,
            bases: svint64_t,
            offset: i64,
        ) -> nxv2i8;
    }
    simd_cast::<nxv2u8, _>(
        _svldff1ub_gather_u64base_offset_u64(pg.into(), bases.as_signed(), offset).as_unsigned(),
    )
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1uh_gather_u64base_offset_u64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
) -> svuint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.scalar.offset.nxv2i16.nxv2i64"
        )]
        fn _svldff1uh_gather_u64base_offset_u64(
            pg: svbool2_t,
            bases: svint64_t,
            offset: i64,
        ) -> nxv2i16;
    }
    simd_cast::<nxv2u16, _>(
        _svldff1uh_gather_u64base_offset_u64(pg.into(), bases.as_signed(), offset).as_unsigned(),
    )
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1uw_gather_u64base_offset_u64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
) -> svuint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.scalar.offset.nxv2i32.nxv2i64"
        )]
        fn _svldff1uw_gather_u64base_offset_u64(
            pg: svbool2_t,
            bases: svint64_t,
            offset: i64,
        ) -> nxv2i32;
    }
    simd_cast::<nxv2u32, _>(
        _svldff1uw_gather_u64base_offset_u64(pg.into(), bases.as_signed(), offset).as_unsigned(),
    )
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1b))]
pub unsafe fn svldff1ub_gather_u32base_s32(pg: svbool_t, bases: svuint32_t) -> svint32_t {
    svldff1ub_gather_u32base_offset_s32(pg, bases, 0)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1uh_gather_u32base_s32(pg: svbool_t, bases: svuint32_t) -> svint32_t {
    svldff1uh_gather_u32base_offset_s32(pg, bases, 0)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1b))]
pub unsafe fn svldff1ub_gather_u32base_u32(pg: svbool_t, bases: svuint32_t) -> svuint32_t {
    svldff1ub_gather_u32base_offset_u32(pg, bases, 0)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1uh_gather_u32base_u32(pg: svbool_t, bases: svuint32_t) -> svuint32_t {
    svldff1uh_gather_u32base_offset_u32(pg, bases, 0)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1b))]
pub unsafe fn svldff1ub_gather_u64base_s64(pg: svbool_t, bases: svuint64_t) -> svint64_t {
    svldff1ub_gather_u64base_offset_s64(pg, bases, 0)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1uh_gather_u64base_s64(pg: svbool_t, bases: svuint64_t) -> svint64_t {
    svldff1uh_gather_u64base_offset_s64(pg, bases, 0)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1uw_gather_u64base_s64(pg: svbool_t, bases: svuint64_t) -> svint64_t {
    svldff1uw_gather_u64base_offset_s64(pg, bases, 0)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1b))]
pub unsafe fn svldff1ub_gather_u64base_u64(pg: svbool_t, bases: svuint64_t) -> svuint64_t {
    svldff1ub_gather_u64base_offset_u64(pg, bases, 0)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1uh_gather_u64base_u64(pg: svbool_t, bases: svuint64_t) -> svuint64_t {
    svldff1uh_gather_u64base_offset_u64(pg, bases, 0)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1uw_gather_u64base_u64(pg: svbool_t, bases: svuint64_t) -> svuint64_t {
    svldff1uw_gather_u64base_offset_u64(pg, bases, 0)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1b))]
pub unsafe fn svldff1ub_s16(pg: svbool_t, base: *const u8) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldff1.nxv8i8")]
        fn _svldff1ub_s16(pg: svbool8_t, base: *const i8) -> nxv8i8;
    }
    simd_cast::<nxv8u8, _>(_svldff1ub_s16(pg.into(), base.as_signed()).as_unsigned())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1b))]
pub unsafe fn svldff1ub_s32(pg: svbool_t, base: *const u8) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldff1.nxv4i8")]
        fn _svldff1ub_s32(pg: svbool4_t, base: *const i8) -> nxv4i8;
    }
    simd_cast::<nxv4u8, _>(_svldff1ub_s32(pg.into(), base.as_signed()).as_unsigned())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1uh_s32(pg: svbool_t, base: *const u16) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldff1.nxv4i16")]
        fn _svldff1uh_s32(pg: svbool4_t, base: *const i16) -> nxv4i16;
    }
    simd_cast::<nxv4u16, _>(_svldff1uh_s32(pg.into(), base.as_signed()).as_unsigned())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1b))]
pub unsafe fn svldff1ub_s64(pg: svbool_t, base: *const u8) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldff1.nxv2i8")]
        fn _svldff1ub_s64(pg: svbool2_t, base: *const i8) -> nxv2i8;
    }
    simd_cast::<nxv2u8, _>(_svldff1ub_s64(pg.into(), base.as_signed()).as_unsigned())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1uh_s64(pg: svbool_t, base: *const u16) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldff1.nxv2i16")]
        fn _svldff1uh_s64(pg: svbool2_t, base: *const i16) -> nxv2i16;
    }
    simd_cast::<nxv2u16, _>(_svldff1uh_s64(pg.into(), base.as_signed()).as_unsigned())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1uw_s64(pg: svbool_t, base: *const u32) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldff1.nxv2i32")]
        fn _svldff1uw_s64(pg: svbool2_t, base: *const i32) -> nxv2i32;
    }
    simd_cast::<nxv2u32, _>(_svldff1uw_s64(pg.into(), base.as_signed()).as_unsigned())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1b))]
pub unsafe fn svldff1ub_u16(pg: svbool_t, base: *const u8) -> svuint16_t {
    svldff1ub_s16(pg, base).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1b))]
pub unsafe fn svldff1ub_u32(pg: svbool_t, base: *const u8) -> svuint32_t {
    svldff1ub_s32(pg, base).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1uh_u32(pg: svbool_t, base: *const u16) -> svuint32_t {
    svldff1uh_s32(pg, base).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1b))]
pub unsafe fn svldff1ub_u64(pg: svbool_t, base: *const u8) -> svuint64_t {
    svldff1ub_s64(pg, base).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1uh_u64(pg: svbool_t, base: *const u16) -> svuint64_t {
    svldff1uh_s64(pg, base).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1uw_u64(pg: svbool_t, base: *const u32) -> svuint64_t {
    svldff1uw_s64(pg, base).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1b))]
pub unsafe fn svldff1ub_vnum_s16(pg: svbool_t, base: *const u8, vnum: i64) -> svint16_t {
    svldff1ub_s16(pg, base.offset(svcnth() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1b))]
pub unsafe fn svldff1ub_vnum_s32(pg: svbool_t, base: *const u8, vnum: i64) -> svint32_t {
    svldff1ub_s32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1uh_vnum_s32(pg: svbool_t, base: *const u16, vnum: i64) -> svint32_t {
    svldff1uh_s32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1b))]
pub unsafe fn svldff1ub_vnum_s64(pg: svbool_t, base: *const u8, vnum: i64) -> svint64_t {
    svldff1ub_s64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1uh_vnum_s64(pg: svbool_t, base: *const u16, vnum: i64) -> svint64_t {
    svldff1uh_s64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1uw_vnum_s64(pg: svbool_t, base: *const u32, vnum: i64) -> svint64_t {
    svldff1uw_s64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1b))]
pub unsafe fn svldff1ub_vnum_u16(pg: svbool_t, base: *const u8, vnum: i64) -> svuint16_t {
    svldff1ub_u16(pg, base.offset(svcnth() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1b))]
pub unsafe fn svldff1ub_vnum_u32(pg: svbool_t, base: *const u8, vnum: i64) -> svuint32_t {
    svldff1ub_u32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1uh_vnum_u32(pg: svbool_t, base: *const u16, vnum: i64) -> svuint32_t {
    svldff1uh_u32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1b))]
pub unsafe fn svldff1ub_vnum_u64(pg: svbool_t, base: *const u8, vnum: i64) -> svuint64_t {
    svldff1ub_u64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1uh_vnum_u64(pg: svbool_t, base: *const u16, vnum: i64) -> svuint64_t {
    svldff1uh_u64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1uw_vnum_u64(pg: svbool_t, base: *const u32, vnum: i64) -> svuint64_t {
    svldff1uw_u64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1uh_gather_s32index_s32(
    pg: svbool_t,
    base: *const u16,
    indices: svint32_t,
) -> svint32_t {
    svldff1uh_gather_s32index_u32(pg, base, indices).as_signed()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1uh_gather_s32index_u32(
    pg: svbool_t,
    base: *const u16,
    indices: svint32_t,
) -> svuint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.sxtw.index.nxv4i16"
        )]
        fn _svldff1uh_gather_s32index_u32(
            pg: svbool4_t,
            base: *const i16,
            indices: svint32_t,
        ) -> nxv4i16;
    }
    simd_cast::<nxv4u16, _>(
        _svldff1uh_gather_s32index_u32(pg.into(), base.as_signed(), indices).as_unsigned(),
    )
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1uh_gather_s64index_s64(
    pg: svbool_t,
    base: *const u16,
    indices: svint64_t,
) -> svint64_t {
    svldff1uh_gather_s64index_u64(pg, base, indices).as_signed()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1uw_gather_s64index_s64(
    pg: svbool_t,
    base: *const u32,
    indices: svint64_t,
) -> svint64_t {
    svldff1uw_gather_s64index_u64(pg, base, indices).as_signed()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1uh_gather_s64index_u64(
    pg: svbool_t,
    base: *const u16,
    indices: svint64_t,
) -> svuint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.index.nxv2i16"
        )]
        fn _svldff1uh_gather_s64index_u64(
            pg: svbool2_t,
            base: *const i16,
            indices: svint64_t,
        ) -> nxv2i16;
    }
    simd_cast::<nxv2u16, _>(
        _svldff1uh_gather_s64index_u64(pg.into(), base.as_signed(), indices).as_unsigned(),
    )
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1uw_gather_s64index_u64(
    pg: svbool_t,
    base: *const u32,
    indices: svint64_t,
) -> svuint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.index.nxv2i32"
        )]
        fn _svldff1uw_gather_s64index_u64(
            pg: svbool2_t,
            base: *const i32,
            indices: svint64_t,
        ) -> nxv2i32;
    }
    simd_cast::<nxv2u32, _>(
        _svldff1uw_gather_s64index_u64(pg.into(), base.as_signed(), indices).as_unsigned(),
    )
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1uh_gather_u32index_s32(
    pg: svbool_t,
    base: *const u16,
    indices: svuint32_t,
) -> svint32_t {
    svldff1uh_gather_u32index_u32(pg, base, indices).as_signed()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1uh_gather_u32index_u32(
    pg: svbool_t,
    base: *const u16,
    indices: svuint32_t,
) -> svuint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.uxtw.index.nxv4i16"
        )]
        fn _svldff1uh_gather_u32index_u32(
            pg: svbool4_t,
            base: *const i16,
            indices: svint32_t,
        ) -> nxv4i16;
    }
    simd_cast::<nxv4u16, _>(
        _svldff1uh_gather_u32index_u32(pg.into(), base.as_signed(), indices.as_signed())
            .as_unsigned(),
    )
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1uh_gather_u64index_s64(
    pg: svbool_t,
    base: *const u16,
    indices: svuint64_t,
) -> svint64_t {
    svldff1uh_gather_s64index_u64(pg, base, indices.as_signed()).as_signed()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1uw_gather_u64index_s64(
    pg: svbool_t,
    base: *const u32,
    indices: svuint64_t,
) -> svint64_t {
    svldff1uw_gather_s64index_u64(pg, base, indices.as_signed()).as_signed()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1uh_gather_u64index_u64(
    pg: svbool_t,
    base: *const u16,
    indices: svuint64_t,
) -> svuint64_t {
    svldff1uh_gather_s64index_u64(pg, base, indices.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1uw_gather_u64index_u64(
    pg: svbool_t,
    base: *const u32,
    indices: svuint64_t,
) -> svuint64_t {
    svldff1uw_gather_s64index_u64(pg, base, indices.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1uh_gather_u32base_index_s32(
    pg: svbool_t,
    bases: svuint32_t,
    index: i64,
) -> svint32_t {
    svldff1uh_gather_u32base_offset_s32(pg, bases, index.unchecked_shl(1))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1uh_gather_u32base_index_u32(
    pg: svbool_t,
    bases: svuint32_t,
    index: i64,
) -> svuint32_t {
    svldff1uh_gather_u32base_offset_u32(pg, bases, index.unchecked_shl(1))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1uh_gather_u64base_index_s64(
    pg: svbool_t,
    bases: svuint64_t,
    index: i64,
) -> svint64_t {
    svldff1uh_gather_u64base_offset_s64(pg, bases, index.unchecked_shl(1))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1uw_gather_u64base_index_s64(
    pg: svbool_t,
    bases: svuint64_t,
    index: i64,
) -> svint64_t {
    svldff1uw_gather_u64base_offset_s64(pg, bases, index.unchecked_shl(2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1uh_gather_u64base_index_u64(
    pg: svbool_t,
    bases: svuint64_t,
    index: i64,
) -> svuint64_t {
    svldff1uh_gather_u64base_offset_u64(pg, bases, index.unchecked_shl(1))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1uw_gather_u64base_index_u64(
    pg: svbool_t,
    bases: svuint64_t,
    index: i64,
) -> svuint64_t {
    svldff1uw_gather_u64base_offset_u64(pg, bases, index.unchecked_shl(2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1w))]
pub unsafe fn svldnf1_f32(pg: svbool_t, base: *const f32) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldnf1.nxv4f32")]
        fn _svldnf1_f32(pg: svbool4_t, base: *const f32) -> svfloat32_t;
    }
    _svldnf1_f32(pg.into(), base)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1d))]
pub unsafe fn svldnf1_f64(pg: svbool_t, base: *const f64) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldnf1.nxv2f64")]
        fn _svldnf1_f64(pg: svbool2_t, base: *const f64) -> svfloat64_t;
    }
    _svldnf1_f64(pg.into(), base)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1b))]
pub unsafe fn svldnf1_s8(pg: svbool_t, base: *const i8) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldnf1.nxv16i8")]
        fn _svldnf1_s8(pg: svbool_t, base: *const i8) -> svint8_t;
    }
    _svldnf1_s8(pg, base)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1h))]
pub unsafe fn svldnf1_s16(pg: svbool_t, base: *const i16) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldnf1.nxv8i16")]
        fn _svldnf1_s16(pg: svbool8_t, base: *const i16) -> svint16_t;
    }
    _svldnf1_s16(pg.into(), base)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1w))]
pub unsafe fn svldnf1_s32(pg: svbool_t, base: *const i32) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldnf1.nxv4i32")]
        fn _svldnf1_s32(pg: svbool4_t, base: *const i32) -> svint32_t;
    }
    _svldnf1_s32(pg.into(), base)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1d))]
pub unsafe fn svldnf1_s64(pg: svbool_t, base: *const i64) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldnf1.nxv2i64")]
        fn _svldnf1_s64(pg: svbool2_t, base: *const i64) -> svint64_t;
    }
    _svldnf1_s64(pg.into(), base)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1b))]
pub unsafe fn svldnf1_u8(pg: svbool_t, base: *const u8) -> svuint8_t {
    svldnf1_s8(pg, base.as_signed()).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1h))]
pub unsafe fn svldnf1_u16(pg: svbool_t, base: *const u16) -> svuint16_t {
    svldnf1_s16(pg, base.as_signed()).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1w))]
pub unsafe fn svldnf1_u32(pg: svbool_t, base: *const u32) -> svuint32_t {
    svldnf1_s32(pg, base.as_signed()).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1d))]
pub unsafe fn svldnf1_u64(pg: svbool_t, base: *const u64) -> svuint64_t {
    svldnf1_s64(pg, base.as_signed()).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1w))]
pub unsafe fn svldnf1_vnum_f32(pg: svbool_t, base: *const f32, vnum: i64) -> svfloat32_t {
    svldnf1_f32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1d))]
pub unsafe fn svldnf1_vnum_f64(pg: svbool_t, base: *const f64, vnum: i64) -> svfloat64_t {
    svldnf1_f64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1b))]
pub unsafe fn svldnf1_vnum_s8(pg: svbool_t, base: *const i8, vnum: i64) -> svint8_t {
    svldnf1_s8(pg, base.offset(svcntb() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1h))]
pub unsafe fn svldnf1_vnum_s16(pg: svbool_t, base: *const i16, vnum: i64) -> svint16_t {
    svldnf1_s16(pg, base.offset(svcnth() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1w))]
pub unsafe fn svldnf1_vnum_s32(pg: svbool_t, base: *const i32, vnum: i64) -> svint32_t {
    svldnf1_s32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1d))]
pub unsafe fn svldnf1_vnum_s64(pg: svbool_t, base: *const i64, vnum: i64) -> svint64_t {
    svldnf1_s64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1b))]
pub unsafe fn svldnf1_vnum_u8(pg: svbool_t, base: *const u8, vnum: i64) -> svuint8_t {
    svldnf1_u8(pg, base.offset(svcntb() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1h))]
pub unsafe fn svldnf1_vnum_u16(pg: svbool_t, base: *const u16, vnum: i64) -> svuint16_t {
    svldnf1_u16(pg, base.offset(svcnth() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1w))]
pub unsafe fn svldnf1_vnum_u32(pg: svbool_t, base: *const u32, vnum: i64) -> svuint32_t {
    svldnf1_u32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1d))]
pub unsafe fn svldnf1_vnum_u64(pg: svbool_t, base: *const u64, vnum: i64) -> svuint64_t {
    svldnf1_u64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1sb))]
pub unsafe fn svldnf1sb_s16(pg: svbool_t, base: *const i8) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldnf1.nxv8i8")]
        fn _svldnf1sb_s16(pg: svbool8_t, base: *const i8) -> nxv8i8;
    }
    simd_cast(_svldnf1sb_s16(pg.into(), base))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1sb))]
pub unsafe fn svldnf1sb_s32(pg: svbool_t, base: *const i8) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldnf1.nxv4i8")]
        fn _svldnf1sb_s32(pg: svbool4_t, base: *const i8) -> nxv4i8;
    }
    simd_cast(_svldnf1sb_s32(pg.into(), base))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1sh))]
pub unsafe fn svldnf1sh_s32(pg: svbool_t, base: *const i16) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldnf1.nxv4i16")]
        fn _svldnf1sh_s32(pg: svbool4_t, base: *const i16) -> nxv4i16;
    }
    simd_cast(_svldnf1sh_s32(pg.into(), base))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1sb))]
pub unsafe fn svldnf1sb_s64(pg: svbool_t, base: *const i8) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldnf1.nxv2i8")]
        fn _svldnf1sb_s64(pg: svbool2_t, base: *const i8) -> nxv2i8;
    }
    simd_cast(_svldnf1sb_s64(pg.into(), base))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1sh))]
pub unsafe fn svldnf1sh_s64(pg: svbool_t, base: *const i16) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldnf1.nxv2i16")]
        fn _svldnf1sh_s64(pg: svbool2_t, base: *const i16) -> nxv2i16;
    }
    simd_cast(_svldnf1sh_s64(pg.into(), base))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1sw))]
pub unsafe fn svldnf1sw_s64(pg: svbool_t, base: *const i32) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldnf1.nxv2i32")]
        fn _svldnf1sw_s64(pg: svbool2_t, base: *const i32) -> nxv2i32;
    }
    simd_cast(_svldnf1sw_s64(pg.into(), base))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1sb))]
pub unsafe fn svldnf1sb_u16(pg: svbool_t, base: *const i8) -> svuint16_t {
    svldnf1sb_s16(pg, base).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1sb))]
pub unsafe fn svldnf1sb_u32(pg: svbool_t, base: *const i8) -> svuint32_t {
    svldnf1sb_s32(pg, base).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1sh))]
pub unsafe fn svldnf1sh_u32(pg: svbool_t, base: *const i16) -> svuint32_t {
    svldnf1sh_s32(pg, base).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1sb))]
pub unsafe fn svldnf1sb_u64(pg: svbool_t, base: *const i8) -> svuint64_t {
    svldnf1sb_s64(pg, base).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1sh))]
pub unsafe fn svldnf1sh_u64(pg: svbool_t, base: *const i16) -> svuint64_t {
    svldnf1sh_s64(pg, base).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1sw))]
pub unsafe fn svldnf1sw_u64(pg: svbool_t, base: *const i32) -> svuint64_t {
    svldnf1sw_s64(pg, base).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1sb))]
pub unsafe fn svldnf1sb_vnum_s16(pg: svbool_t, base: *const i8, vnum: i64) -> svint16_t {
    svldnf1sb_s16(pg, base.offset(svcnth() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1sb))]
pub unsafe fn svldnf1sb_vnum_s32(pg: svbool_t, base: *const i8, vnum: i64) -> svint32_t {
    svldnf1sb_s32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1sh))]
pub unsafe fn svldnf1sh_vnum_s32(pg: svbool_t, base: *const i16, vnum: i64) -> svint32_t {
    svldnf1sh_s32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1sb))]
pub unsafe fn svldnf1sb_vnum_s64(pg: svbool_t, base: *const i8, vnum: i64) -> svint64_t {
    svldnf1sb_s64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1sh))]
pub unsafe fn svldnf1sh_vnum_s64(pg: svbool_t, base: *const i16, vnum: i64) -> svint64_t {
    svldnf1sh_s64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1sw))]
pub unsafe fn svldnf1sw_vnum_s64(pg: svbool_t, base: *const i32, vnum: i64) -> svint64_t {
    svldnf1sw_s64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1sb))]
pub unsafe fn svldnf1sb_vnum_u16(pg: svbool_t, base: *const i8, vnum: i64) -> svuint16_t {
    svldnf1sb_u16(pg, base.offset(svcnth() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1sb))]
pub unsafe fn svldnf1sb_vnum_u32(pg: svbool_t, base: *const i8, vnum: i64) -> svuint32_t {
    svldnf1sb_u32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1sh))]
pub unsafe fn svldnf1sh_vnum_u32(pg: svbool_t, base: *const i16, vnum: i64) -> svuint32_t {
    svldnf1sh_u32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1sb))]
pub unsafe fn svldnf1sb_vnum_u64(pg: svbool_t, base: *const i8, vnum: i64) -> svuint64_t {
    svldnf1sb_u64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1sh))]
pub unsafe fn svldnf1sh_vnum_u64(pg: svbool_t, base: *const i16, vnum: i64) -> svuint64_t {
    svldnf1sh_u64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1sw))]
pub unsafe fn svldnf1sw_vnum_u64(pg: svbool_t, base: *const i32, vnum: i64) -> svuint64_t {
    svldnf1sw_u64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1b))]
pub unsafe fn svldnf1ub_s16(pg: svbool_t, base: *const u8) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldnf1.nxv8i8")]
        fn _svldnf1ub_s16(pg: svbool8_t, base: *const i8) -> nxv8i8;
    }
    simd_cast::<nxv8u8, _>(_svldnf1ub_s16(pg.into(), base.as_signed()).as_unsigned())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1b))]
pub unsafe fn svldnf1ub_s32(pg: svbool_t, base: *const u8) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldnf1.nxv4i8")]
        fn _svldnf1ub_s32(pg: svbool4_t, base: *const i8) -> nxv4i8;
    }
    simd_cast::<nxv4u8, _>(_svldnf1ub_s32(pg.into(), base.as_signed()).as_unsigned())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1h))]
pub unsafe fn svldnf1uh_s32(pg: svbool_t, base: *const u16) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldnf1.nxv4i16")]
        fn _svldnf1uh_s32(pg: svbool4_t, base: *const i16) -> nxv4i16;
    }
    simd_cast::<nxv4u16, _>(_svldnf1uh_s32(pg.into(), base.as_signed()).as_unsigned())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1b))]
pub unsafe fn svldnf1ub_s64(pg: svbool_t, base: *const u8) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldnf1.nxv2i8")]
        fn _svldnf1ub_s64(pg: svbool2_t, base: *const i8) -> nxv2i8;
    }
    simd_cast::<nxv2u8, _>(_svldnf1ub_s64(pg.into(), base.as_signed()).as_unsigned())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1h))]
pub unsafe fn svldnf1uh_s64(pg: svbool_t, base: *const u16) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldnf1.nxv2i16")]
        fn _svldnf1uh_s64(pg: svbool2_t, base: *const i16) -> nxv2i16;
    }
    simd_cast::<nxv2u16, _>(_svldnf1uh_s64(pg.into(), base.as_signed()).as_unsigned())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1w))]
pub unsafe fn svldnf1uw_s64(pg: svbool_t, base: *const u32) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldnf1.nxv2i32")]
        fn _svldnf1uw_s64(pg: svbool2_t, base: *const i32) -> nxv2i32;
    }
    simd_cast::<nxv2u32, _>(_svldnf1uw_s64(pg.into(), base.as_signed()).as_unsigned())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1b))]
pub unsafe fn svldnf1ub_u16(pg: svbool_t, base: *const u8) -> svuint16_t {
    svldnf1ub_s16(pg, base).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1b))]
pub unsafe fn svldnf1ub_u32(pg: svbool_t, base: *const u8) -> svuint32_t {
    svldnf1ub_s32(pg, base).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1h))]
pub unsafe fn svldnf1uh_u32(pg: svbool_t, base: *const u16) -> svuint32_t {
    svldnf1uh_s32(pg, base).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1b))]
pub unsafe fn svldnf1ub_u64(pg: svbool_t, base: *const u8) -> svuint64_t {
    svldnf1ub_s64(pg, base).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1h))]
pub unsafe fn svldnf1uh_u64(pg: svbool_t, base: *const u16) -> svuint64_t {
    svldnf1uh_s64(pg, base).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1w))]
pub unsafe fn svldnf1uw_u64(pg: svbool_t, base: *const u32) -> svuint64_t {
    svldnf1uw_s64(pg, base).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1b))]
pub unsafe fn svldnf1ub_vnum_s16(pg: svbool_t, base: *const u8, vnum: i64) -> svint16_t {
    svldnf1ub_s16(pg, base.offset(svcnth() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1b))]
pub unsafe fn svldnf1ub_vnum_s32(pg: svbool_t, base: *const u8, vnum: i64) -> svint32_t {
    svldnf1ub_s32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1h))]
pub unsafe fn svldnf1uh_vnum_s32(pg: svbool_t, base: *const u16, vnum: i64) -> svint32_t {
    svldnf1uh_s32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1b))]
pub unsafe fn svldnf1ub_vnum_s64(pg: svbool_t, base: *const u8, vnum: i64) -> svint64_t {
    svldnf1ub_s64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1h))]
pub unsafe fn svldnf1uh_vnum_s64(pg: svbool_t, base: *const u16, vnum: i64) -> svint64_t {
    svldnf1uh_s64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1w))]
pub unsafe fn svldnf1uw_vnum_s64(pg: svbool_t, base: *const u32, vnum: i64) -> svint64_t {
    svldnf1uw_s64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1b))]
pub unsafe fn svldnf1ub_vnum_u16(pg: svbool_t, base: *const u8, vnum: i64) -> svuint16_t {
    svldnf1ub_u16(pg, base.offset(svcnth() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1b))]
pub unsafe fn svldnf1ub_vnum_u32(pg: svbool_t, base: *const u8, vnum: i64) -> svuint32_t {
    svldnf1ub_u32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1h))]
pub unsafe fn svldnf1uh_vnum_u32(pg: svbool_t, base: *const u16, vnum: i64) -> svuint32_t {
    svldnf1uh_u32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1b))]
pub unsafe fn svldnf1ub_vnum_u64(pg: svbool_t, base: *const u8, vnum: i64) -> svuint64_t {
    svldnf1ub_u64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1h))]
pub unsafe fn svldnf1uh_vnum_u64(pg: svbool_t, base: *const u16, vnum: i64) -> svuint64_t {
    svldnf1uh_u64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1w))]
pub unsafe fn svldnf1uw_vnum_u64(pg: svbool_t, base: *const u32, vnum: i64) -> svuint64_t {
    svldnf1uw_u64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnt1w))]
pub unsafe fn svldnt1_f32(pg: svbool_t, base: *const f32) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldnt1.nxv4f32")]
        fn _svldnt1_f32(pg: svbool4_t, base: *const f32) -> svfloat32_t;
    }
    _svldnt1_f32(pg.into(), base)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnt1d))]
pub unsafe fn svldnt1_f64(pg: svbool_t, base: *const f64) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldnt1.nxv2f64")]
        fn _svldnt1_f64(pg: svbool2_t, base: *const f64) -> svfloat64_t;
    }
    _svldnt1_f64(pg.into(), base)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnt1b))]
pub unsafe fn svldnt1_s8(pg: svbool_t, base: *const i8) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldnt1.nxv16i8")]
        fn _svldnt1_s8(pg: svbool_t, base: *const i8) -> svint8_t;
    }
    _svldnt1_s8(pg, base)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnt1h))]
pub unsafe fn svldnt1_s16(pg: svbool_t, base: *const i16) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldnt1.nxv8i16")]
        fn _svldnt1_s16(pg: svbool8_t, base: *const i16) -> svint16_t;
    }
    _svldnt1_s16(pg.into(), base)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnt1w))]
pub unsafe fn svldnt1_s32(pg: svbool_t, base: *const i32) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldnt1.nxv4i32")]
        fn _svldnt1_s32(pg: svbool4_t, base: *const i32) -> svint32_t;
    }
    _svldnt1_s32(pg.into(), base)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnt1d))]
pub unsafe fn svldnt1_s64(pg: svbool_t, base: *const i64) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldnt1.nxv2i64")]
        fn _svldnt1_s64(pg: svbool2_t, base: *const i64) -> svint64_t;
    }
    _svldnt1_s64(pg.into(), base)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnt1b))]
pub unsafe fn svldnt1_u8(pg: svbool_t, base: *const u8) -> svuint8_t {
    svldnt1_s8(pg, base.as_signed()).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnt1h))]
pub unsafe fn svldnt1_u16(pg: svbool_t, base: *const u16) -> svuint16_t {
    svldnt1_s16(pg, base.as_signed()).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnt1w))]
pub unsafe fn svldnt1_u32(pg: svbool_t, base: *const u32) -> svuint32_t {
    svldnt1_s32(pg, base.as_signed()).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnt1d))]
pub unsafe fn svldnt1_u64(pg: svbool_t, base: *const u64) -> svuint64_t {
    svldnt1_s64(pg, base.as_signed()).as_unsigned()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnt1w))]
pub unsafe fn svldnt1_vnum_f32(pg: svbool_t, base: *const f32, vnum: i64) -> svfloat32_t {
    svldnt1_f32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnt1d))]
pub unsafe fn svldnt1_vnum_f64(pg: svbool_t, base: *const f64, vnum: i64) -> svfloat64_t {
    svldnt1_f64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnt1b))]
pub unsafe fn svldnt1_vnum_s8(pg: svbool_t, base: *const i8, vnum: i64) -> svint8_t {
    svldnt1_s8(pg, base.offset(svcntb() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnt1h))]
pub unsafe fn svldnt1_vnum_s16(pg: svbool_t, base: *const i16, vnum: i64) -> svint16_t {
    svldnt1_s16(pg, base.offset(svcnth() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnt1w))]
pub unsafe fn svldnt1_vnum_s32(pg: svbool_t, base: *const i32, vnum: i64) -> svint32_t {
    svldnt1_s32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnt1d))]
pub unsafe fn svldnt1_vnum_s64(pg: svbool_t, base: *const i64, vnum: i64) -> svint64_t {
    svldnt1_s64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnt1b))]
pub unsafe fn svldnt1_vnum_u8(pg: svbool_t, base: *const u8, vnum: i64) -> svuint8_t {
    svldnt1_u8(pg, base.offset(svcntb() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnt1h))]
pub unsafe fn svldnt1_vnum_u16(pg: svbool_t, base: *const u16, vnum: i64) -> svuint16_t {
    svldnt1_u16(pg, base.offset(svcnth() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnt1w))]
pub unsafe fn svldnt1_vnum_u32(pg: svbool_t, base: *const u32, vnum: i64) -> svuint32_t {
    svldnt1_u32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnt1d))]
pub unsafe fn svldnt1_vnum_u64(pg: svbool_t, base: *const u64, vnum: i64) -> svuint64_t {
    svldnt1_u64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cntw))]
pub unsafe fn svlen_f32(_op: svfloat32_t) -> u64 {
    svcntw()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cntd))]
pub unsafe fn svlen_f64(_op: svfloat64_t) -> u64 {
    svcntd()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rdvl))]
pub unsafe fn svlen_s8(_op: svint8_t) -> u64 {
    svcntb()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnth))]
pub unsafe fn svlen_s16(_op: svint16_t) -> u64 {
    svcnth()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cntw))]
pub unsafe fn svlen_s32(_op: svint32_t) -> u64 {
    svcntw()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cntd))]
pub unsafe fn svlen_s64(_op: svint64_t) -> u64 {
    svcntd()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rdvl))]
pub unsafe fn svlen_u8(_op: svuint8_t) -> u64 {
    svcntb()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnth))]
pub unsafe fn svlen_u16(_op: svuint16_t) -> u64 {
    svcnth()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cntw))]
pub unsafe fn svlen_u32(_op: svuint32_t) -> u64 {
    svcntw()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cntd))]
pub unsafe fn svlen_u64(_op: svuint64_t) -> u64 {
    svcntd()
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_s8_m(pg: svbool_t, op1: svint8_t, op2: svuint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.lsl.nxv16i8")]
        fn _svlsl_s8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t;
    }
    unsafe { _svlsl_s8_m(pg, op1, op2.as_signed()) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_n_s8_m(pg: svbool_t, op1: svint8_t, op2: u8) -> svint8_t {
    svlsl_s8_m(pg, op1, svdup_n_u8(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_s8_x(pg: svbool_t, op1: svint8_t, op2: svuint8_t) -> svint8_t {
    svlsl_s8_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_n_s8_x(pg: svbool_t, op1: svint8_t, op2: u8) -> svint8_t {
    svlsl_s8_x(pg, op1, svdup_n_u8(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_s8_z(pg: svbool_t, op1: svint8_t, op2: svuint8_t) -> svint8_t {
    svlsl_s8_m(pg.clone(), svsel_s8(pg, op1, svdup_n_s8(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_n_s8_z(pg: svbool_t, op1: svint8_t, op2: u8) -> svint8_t {
    svlsl_s8_z(pg, op1, svdup_n_u8(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_s16_m(pg: svbool_t, op1: svint16_t, op2: svuint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.lsl.nxv8i16")]
        fn _svlsl_s16_m(pg: svbool8_t, op1: svint16_t, op2: svint16_t) -> svint16_t;
    }
    unsafe { _svlsl_s16_m(pg.into(), op1, op2.as_signed()) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_n_s16_m(pg: svbool_t, op1: svint16_t, op2: u16) -> svint16_t {
    svlsl_s16_m(pg, op1, svdup_n_u16(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_s16_x(pg: svbool_t, op1: svint16_t, op2: svuint16_t) -> svint16_t {
    svlsl_s16_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_n_s16_x(pg: svbool_t, op1: svint16_t, op2: u16) -> svint16_t {
    svlsl_s16_x(pg, op1, svdup_n_u16(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_s16_z(pg: svbool_t, op1: svint16_t, op2: svuint16_t) -> svint16_t {
    svlsl_s16_m(pg.clone(), svsel_s16(pg, op1, svdup_n_s16(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_n_s16_z(pg: svbool_t, op1: svint16_t, op2: u16) -> svint16_t {
    svlsl_s16_z(pg, op1, svdup_n_u16(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_s32_m(pg: svbool_t, op1: svint32_t, op2: svuint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.lsl.nxv4i32")]
        fn _svlsl_s32_m(pg: svbool4_t, op1: svint32_t, op2: svint32_t) -> svint32_t;
    }
    unsafe { _svlsl_s32_m(pg.into(), op1, op2.as_signed()) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_n_s32_m(pg: svbool_t, op1: svint32_t, op2: u32) -> svint32_t {
    svlsl_s32_m(pg, op1, svdup_n_u32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_s32_x(pg: svbool_t, op1: svint32_t, op2: svuint32_t) -> svint32_t {
    svlsl_s32_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_n_s32_x(pg: svbool_t, op1: svint32_t, op2: u32) -> svint32_t {
    svlsl_s32_x(pg, op1, svdup_n_u32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_s32_z(pg: svbool_t, op1: svint32_t, op2: svuint32_t) -> svint32_t {
    svlsl_s32_m(pg.clone(), svsel_s32(pg, op1, svdup_n_s32(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_n_s32_z(pg: svbool_t, op1: svint32_t, op2: u32) -> svint32_t {
    svlsl_s32_z(pg, op1, svdup_n_u32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_s64_m(pg: svbool_t, op1: svint64_t, op2: svuint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.lsl.nxv2i64")]
        fn _svlsl_s64_m(pg: svbool2_t, op1: svint64_t, op2: svint64_t) -> svint64_t;
    }
    unsafe { _svlsl_s64_m(pg.into(), op1, op2.as_signed()) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_n_s64_m(pg: svbool_t, op1: svint64_t, op2: u64) -> svint64_t {
    svlsl_s64_m(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_s64_x(pg: svbool_t, op1: svint64_t, op2: svuint64_t) -> svint64_t {
    svlsl_s64_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_n_s64_x(pg: svbool_t, op1: svint64_t, op2: u64) -> svint64_t {
    svlsl_s64_x(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_s64_z(pg: svbool_t, op1: svint64_t, op2: svuint64_t) -> svint64_t {
    svlsl_s64_m(pg.clone(), svsel_s64(pg, op1, svdup_n_s64(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_n_s64_z(pg: svbool_t, op1: svint64_t, op2: u64) -> svint64_t {
    svlsl_s64_z(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_u8_m(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    unsafe { svlsl_s8_m(pg, op1.as_signed(), op2).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_n_u8_m(pg: svbool_t, op1: svuint8_t, op2: u8) -> svuint8_t {
    svlsl_u8_m(pg, op1, svdup_n_u8(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_u8_x(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    svlsl_u8_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_n_u8_x(pg: svbool_t, op1: svuint8_t, op2: u8) -> svuint8_t {
    svlsl_u8_x(pg, op1, svdup_n_u8(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_u8_z(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    svlsl_u8_m(pg.clone(), svsel_u8(pg, op1, svdup_n_u8(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_n_u8_z(pg: svbool_t, op1: svuint8_t, op2: u8) -> svuint8_t {
    svlsl_u8_z(pg, op1, svdup_n_u8(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_u16_m(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    unsafe { svlsl_s16_m(pg, op1.as_signed(), op2).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_n_u16_m(pg: svbool_t, op1: svuint16_t, op2: u16) -> svuint16_t {
    svlsl_u16_m(pg, op1, svdup_n_u16(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_u16_x(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    svlsl_u16_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_n_u16_x(pg: svbool_t, op1: svuint16_t, op2: u16) -> svuint16_t {
    svlsl_u16_x(pg, op1, svdup_n_u16(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_u16_z(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    svlsl_u16_m(pg.clone(), svsel_u16(pg, op1, svdup_n_u16(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_n_u16_z(pg: svbool_t, op1: svuint16_t, op2: u16) -> svuint16_t {
    svlsl_u16_z(pg, op1, svdup_n_u16(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_u32_m(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    unsafe { svlsl_s32_m(pg, op1.as_signed(), op2).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_n_u32_m(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svlsl_u32_m(pg, op1, svdup_n_u32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_u32_x(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    svlsl_u32_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_n_u32_x(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svlsl_u32_x(pg, op1, svdup_n_u32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_u32_z(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    svlsl_u32_m(pg.clone(), svsel_u32(pg, op1, svdup_n_u32(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_n_u32_z(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svlsl_u32_z(pg, op1, svdup_n_u32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_u64_m(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    unsafe { svlsl_s64_m(pg, op1.as_signed(), op2).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_n_u64_m(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svlsl_u64_m(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_u64_x(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    svlsl_u64_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_n_u64_x(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svlsl_u64_x(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_u64_z(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    svlsl_u64_m(pg.clone(), svsel_u64(pg, op1, svdup_n_u64(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_n_u64_z(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svlsl_u64_z(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_wide_s8_m(pg: svbool_t, op1: svint8_t, op2: svuint64_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.lsl.wide.nxv16i8"
        )]
        fn _svlsl_wide_s8_m(pg: svbool_t, op1: svint8_t, op2: svint64_t) -> svint8_t;
    }
    unsafe { _svlsl_wide_s8_m(pg, op1, op2.as_signed()) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_wide_n_s8_m(pg: svbool_t, op1: svint8_t, op2: u64) -> svint8_t {
    svlsl_wide_s8_m(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_wide_s8_x(pg: svbool_t, op1: svint8_t, op2: svuint64_t) -> svint8_t {
    svlsl_wide_s8_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_wide_n_s8_x(pg: svbool_t, op1: svint8_t, op2: u64) -> svint8_t {
    svlsl_wide_s8_x(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_wide_s8_z(pg: svbool_t, op1: svint8_t, op2: svuint64_t) -> svint8_t {
    svlsl_wide_s8_m(pg.clone(), svsel_s8(pg, op1, svdup_n_s8(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_wide_n_s8_z(pg: svbool_t, op1: svint8_t, op2: u64) -> svint8_t {
    svlsl_wide_s8_z(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_wide_s16_m(pg: svbool_t, op1: svint16_t, op2: svuint64_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.lsl.wide.nxv8i16"
        )]
        fn _svlsl_wide_s16_m(pg: svbool8_t, op1: svint16_t, op2: svint64_t) -> svint16_t;
    }
    unsafe { _svlsl_wide_s16_m(pg.into(), op1, op2.as_signed()) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_wide_n_s16_m(pg: svbool_t, op1: svint16_t, op2: u64) -> svint16_t {
    svlsl_wide_s16_m(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_wide_s16_x(pg: svbool_t, op1: svint16_t, op2: svuint64_t) -> svint16_t {
    svlsl_wide_s16_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_wide_n_s16_x(pg: svbool_t, op1: svint16_t, op2: u64) -> svint16_t {
    svlsl_wide_s16_x(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_wide_s16_z(pg: svbool_t, op1: svint16_t, op2: svuint64_t) -> svint16_t {
    svlsl_wide_s16_m(pg.clone(), svsel_s16(pg, op1, svdup_n_s16(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_wide_n_s16_z(pg: svbool_t, op1: svint16_t, op2: u64) -> svint16_t {
    svlsl_wide_s16_z(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_wide_s32_m(pg: svbool_t, op1: svint32_t, op2: svuint64_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.lsl.wide.nxv4i32"
        )]
        fn _svlsl_wide_s32_m(pg: svbool4_t, op1: svint32_t, op2: svint64_t) -> svint32_t;
    }
    unsafe { _svlsl_wide_s32_m(pg.into(), op1, op2.as_signed()) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_wide_n_s32_m(pg: svbool_t, op1: svint32_t, op2: u64) -> svint32_t {
    svlsl_wide_s32_m(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_wide_s32_x(pg: svbool_t, op1: svint32_t, op2: svuint64_t) -> svint32_t {
    svlsl_wide_s32_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_wide_n_s32_x(pg: svbool_t, op1: svint32_t, op2: u64) -> svint32_t {
    svlsl_wide_s32_x(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_wide_s32_z(pg: svbool_t, op1: svint32_t, op2: svuint64_t) -> svint32_t {
    svlsl_wide_s32_m(pg.clone(), svsel_s32(pg, op1, svdup_n_s32(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_wide_n_s32_z(pg: svbool_t, op1: svint32_t, op2: u64) -> svint32_t {
    svlsl_wide_s32_z(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_wide_u8_m(pg: svbool_t, op1: svuint8_t, op2: svuint64_t) -> svuint8_t {
    unsafe { svlsl_wide_s8_m(pg, op1.as_signed(), op2).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_wide_n_u8_m(pg: svbool_t, op1: svuint8_t, op2: u64) -> svuint8_t {
    svlsl_wide_u8_m(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_wide_u8_x(pg: svbool_t, op1: svuint8_t, op2: svuint64_t) -> svuint8_t {
    svlsl_wide_u8_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_wide_n_u8_x(pg: svbool_t, op1: svuint8_t, op2: u64) -> svuint8_t {
    svlsl_wide_u8_x(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_wide_u8_z(pg: svbool_t, op1: svuint8_t, op2: svuint64_t) -> svuint8_t {
    svlsl_wide_u8_m(pg.clone(), svsel_u8(pg, op1, svdup_n_u8(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_wide_n_u8_z(pg: svbool_t, op1: svuint8_t, op2: u64) -> svuint8_t {
    svlsl_wide_u8_z(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_wide_u16_m(pg: svbool_t, op1: svuint16_t, op2: svuint64_t) -> svuint16_t {
    unsafe { svlsl_wide_s16_m(pg, op1.as_signed(), op2).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_wide_n_u16_m(pg: svbool_t, op1: svuint16_t, op2: u64) -> svuint16_t {
    svlsl_wide_u16_m(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_wide_u16_x(pg: svbool_t, op1: svuint16_t, op2: svuint64_t) -> svuint16_t {
    svlsl_wide_u16_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_wide_n_u16_x(pg: svbool_t, op1: svuint16_t, op2: u64) -> svuint16_t {
    svlsl_wide_u16_x(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_wide_u16_z(pg: svbool_t, op1: svuint16_t, op2: svuint64_t) -> svuint16_t {
    svlsl_wide_u16_m(pg.clone(), svsel_u16(pg, op1, svdup_n_u16(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_wide_n_u16_z(pg: svbool_t, op1: svuint16_t, op2: u64) -> svuint16_t {
    svlsl_wide_u16_z(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_wide_u32_m(pg: svbool_t, op1: svuint32_t, op2: svuint64_t) -> svuint32_t {
    unsafe { svlsl_wide_s32_m(pg, op1.as_signed(), op2).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_wide_n_u32_m(pg: svbool_t, op1: svuint32_t, op2: u64) -> svuint32_t {
    svlsl_wide_u32_m(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_wide_u32_x(pg: svbool_t, op1: svuint32_t, op2: svuint64_t) -> svuint32_t {
    svlsl_wide_u32_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_wide_n_u32_x(pg: svbool_t, op1: svuint32_t, op2: u64) -> svuint32_t {
    svlsl_wide_u32_x(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_wide_u32_z(pg: svbool_t, op1: svuint32_t, op2: svuint64_t) -> svuint32_t {
    svlsl_wide_u32_m(pg.clone(), svsel_u32(pg, op1, svdup_n_u32(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub unsafe fn svlsl_wide_n_u32_z(pg: svbool_t, op1: svuint32_t, op2: u64) -> svuint32_t {
    svlsl_wide_u32_z(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub unsafe fn svlsr_u8_m(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.lsr.nxv16i8")]
        fn _svlsr_u8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t;
    }
    unsafe { _svlsr_u8_m(pg, op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub unsafe fn svlsr_n_u8_m(pg: svbool_t, op1: svuint8_t, op2: u8) -> svuint8_t {
    svlsr_u8_m(pg, op1, svdup_n_u8(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub unsafe fn svlsr_u8_x(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    svlsr_u8_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub unsafe fn svlsr_n_u8_x(pg: svbool_t, op1: svuint8_t, op2: u8) -> svuint8_t {
    svlsr_u8_x(pg, op1, svdup_n_u8(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub unsafe fn svlsr_u8_z(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    svlsr_u8_m(pg.clone(), svsel_u8(pg, op1, svdup_n_u8(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub unsafe fn svlsr_n_u8_z(pg: svbool_t, op1: svuint8_t, op2: u8) -> svuint8_t {
    svlsr_u8_z(pg, op1, svdup_n_u8(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub unsafe fn svlsr_u16_m(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.lsr.nxv8i16")]
        fn _svlsr_u16_m(pg: svbool8_t, op1: svint16_t, op2: svint16_t) -> svint16_t;
    }
    unsafe { _svlsr_u16_m(pg.into(), op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub unsafe fn svlsr_n_u16_m(pg: svbool_t, op1: svuint16_t, op2: u16) -> svuint16_t {
    svlsr_u16_m(pg, op1, svdup_n_u16(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub unsafe fn svlsr_u16_x(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    svlsr_u16_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub unsafe fn svlsr_n_u16_x(pg: svbool_t, op1: svuint16_t, op2: u16) -> svuint16_t {
    svlsr_u16_x(pg, op1, svdup_n_u16(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub unsafe fn svlsr_u16_z(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    svlsr_u16_m(pg.clone(), svsel_u16(pg, op1, svdup_n_u16(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub unsafe fn svlsr_n_u16_z(pg: svbool_t, op1: svuint16_t, op2: u16) -> svuint16_t {
    svlsr_u16_z(pg, op1, svdup_n_u16(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub unsafe fn svlsr_u32_m(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.lsr.nxv4i32")]
        fn _svlsr_u32_m(pg: svbool4_t, op1: svint32_t, op2: svint32_t) -> svint32_t;
    }
    unsafe { _svlsr_u32_m(pg.into(), op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub unsafe fn svlsr_n_u32_m(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svlsr_u32_m(pg, op1, svdup_n_u32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub unsafe fn svlsr_u32_x(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    svlsr_u32_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub unsafe fn svlsr_n_u32_x(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svlsr_u32_x(pg, op1, svdup_n_u32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub unsafe fn svlsr_u32_z(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    svlsr_u32_m(pg.clone(), svsel_u32(pg, op1, svdup_n_u32(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub unsafe fn svlsr_n_u32_z(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svlsr_u32_z(pg, op1, svdup_n_u32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub unsafe fn svlsr_u64_m(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.lsr.nxv2i64")]
        fn _svlsr_u64_m(pg: svbool2_t, op1: svint64_t, op2: svint64_t) -> svint64_t;
    }
    unsafe { _svlsr_u64_m(pg.into(), op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub unsafe fn svlsr_n_u64_m(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svlsr_u64_m(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub unsafe fn svlsr_u64_x(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    svlsr_u64_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub unsafe fn svlsr_n_u64_x(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svlsr_u64_x(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub unsafe fn svlsr_u64_z(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    svlsr_u64_m(pg.clone(), svsel_u64(pg, op1, svdup_n_u64(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub unsafe fn svlsr_n_u64_z(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svlsr_u64_z(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub unsafe fn svlsr_wide_u8_m(pg: svbool_t, op1: svuint8_t, op2: svuint64_t) -> svuint8_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.lsr.wide.nxv16i8"
        )]
        fn _svlsr_wide_u8_m(pg: svbool_t, op1: svint8_t, op2: svint64_t) -> svint8_t;
    }
    unsafe { _svlsr_wide_u8_m(pg, op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub unsafe fn svlsr_wide_n_u8_m(pg: svbool_t, op1: svuint8_t, op2: u64) -> svuint8_t {
    svlsr_wide_u8_m(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub unsafe fn svlsr_wide_u8_x(pg: svbool_t, op1: svuint8_t, op2: svuint64_t) -> svuint8_t {
    svlsr_wide_u8_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub unsafe fn svlsr_wide_n_u8_x(pg: svbool_t, op1: svuint8_t, op2: u64) -> svuint8_t {
    svlsr_wide_u8_x(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub unsafe fn svlsr_wide_u8_z(pg: svbool_t, op1: svuint8_t, op2: svuint64_t) -> svuint8_t {
    svlsr_wide_u8_m(pg.clone(), svsel_u8(pg, op1, svdup_n_u8(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub unsafe fn svlsr_wide_n_u8_z(pg: svbool_t, op1: svuint8_t, op2: u64) -> svuint8_t {
    svlsr_wide_u8_z(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub unsafe fn svlsr_wide_u16_m(pg: svbool_t, op1: svuint16_t, op2: svuint64_t) -> svuint16_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.lsr.wide.nxv8i16"
        )]
        fn _svlsr_wide_u16_m(pg: svbool8_t, op1: svint16_t, op2: svint64_t) -> svint16_t;
    }
    unsafe { _svlsr_wide_u16_m(pg.into(), op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub unsafe fn svlsr_wide_n_u16_m(pg: svbool_t, op1: svuint16_t, op2: u64) -> svuint16_t {
    svlsr_wide_u16_m(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub unsafe fn svlsr_wide_u16_x(pg: svbool_t, op1: svuint16_t, op2: svuint64_t) -> svuint16_t {
    svlsr_wide_u16_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub unsafe fn svlsr_wide_n_u16_x(pg: svbool_t, op1: svuint16_t, op2: u64) -> svuint16_t {
    svlsr_wide_u16_x(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub unsafe fn svlsr_wide_u16_z(pg: svbool_t, op1: svuint16_t, op2: svuint64_t) -> svuint16_t {
    svlsr_wide_u16_m(pg.clone(), svsel_u16(pg, op1, svdup_n_u16(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub unsafe fn svlsr_wide_n_u16_z(pg: svbool_t, op1: svuint16_t, op2: u64) -> svuint16_t {
    svlsr_wide_u16_z(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub unsafe fn svlsr_wide_u32_m(pg: svbool_t, op1: svuint32_t, op2: svuint64_t) -> svuint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.lsr.wide.nxv4i32"
        )]
        fn _svlsr_wide_u32_m(pg: svbool4_t, op1: svint32_t, op2: svint64_t) -> svint32_t;
    }
    unsafe { _svlsr_wide_u32_m(pg.into(), op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub unsafe fn svlsr_wide_n_u32_m(pg: svbool_t, op1: svuint32_t, op2: u64) -> svuint32_t {
    svlsr_wide_u32_m(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub unsafe fn svlsr_wide_u32_x(pg: svbool_t, op1: svuint32_t, op2: svuint64_t) -> svuint32_t {
    svlsr_wide_u32_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub unsafe fn svlsr_wide_n_u32_x(pg: svbool_t, op1: svuint32_t, op2: u64) -> svuint32_t {
    svlsr_wide_u32_x(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub unsafe fn svlsr_wide_u32_z(pg: svbool_t, op1: svuint32_t, op2: svuint64_t) -> svuint32_t {
    svlsr_wide_u32_m(pg.clone(), svsel_u32(pg, op1, svdup_n_u32(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub unsafe fn svlsr_wide_n_u32_z(pg: svbool_t, op1: svuint32_t, op2: u64) -> svuint32_t {
    svlsr_wide_u32_z(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmad))]
pub unsafe fn svmad_f32_m(
    pg: svbool_t,
    op1: svfloat32_t,
    op2: svfloat32_t,
    op3: svfloat32_t,
) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fmad.nxv4f32")]
        fn _svmad_f32_m(
            pg: svbool4_t,
            op1: svfloat32_t,
            op2: svfloat32_t,
            op3: svfloat32_t,
        ) -> svfloat32_t;
    }
    unsafe { _svmad_f32_m(pg.into(), op1, op2, op3) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmad))]
pub unsafe fn svmad_n_f32_m(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t, op3: f32) -> svfloat32_t {
    svmad_f32_m(pg, op1, op2, svdup_n_f32(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmad))]
pub unsafe fn svmad_f32_x(
    pg: svbool_t,
    op1: svfloat32_t,
    op2: svfloat32_t,
    op3: svfloat32_t,
) -> svfloat32_t {
    svmad_f32_m(pg, op1, op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmad))]
pub unsafe fn svmad_n_f32_x(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t, op3: f32) -> svfloat32_t {
    svmad_f32_x(pg, op1, op2, svdup_n_f32(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmad))]
pub unsafe fn svmad_f32_z(
    pg: svbool_t,
    op1: svfloat32_t,
    op2: svfloat32_t,
    op3: svfloat32_t,
) -> svfloat32_t {
    svmad_f32_m(pg.clone(), svsel_f32(pg, op1, svdup_n_f32(0.0)), op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmad))]
pub unsafe fn svmad_n_f32_z(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t, op3: f32) -> svfloat32_t {
    svmad_f32_z(pg, op1, op2, svdup_n_f32(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmad))]
pub unsafe fn svmad_f64_m(
    pg: svbool_t,
    op1: svfloat64_t,
    op2: svfloat64_t,
    op3: svfloat64_t,
) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fmad.nxv2f64")]
        fn _svmad_f64_m(
            pg: svbool2_t,
            op1: svfloat64_t,
            op2: svfloat64_t,
            op3: svfloat64_t,
        ) -> svfloat64_t;
    }
    unsafe { _svmad_f64_m(pg.into(), op1, op2, op3) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmad))]
pub unsafe fn svmad_n_f64_m(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t, op3: f64) -> svfloat64_t {
    svmad_f64_m(pg, op1, op2, svdup_n_f64(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmad))]
pub unsafe fn svmad_f64_x(
    pg: svbool_t,
    op1: svfloat64_t,
    op2: svfloat64_t,
    op3: svfloat64_t,
) -> svfloat64_t {
    svmad_f64_m(pg, op1, op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmad))]
pub unsafe fn svmad_n_f64_x(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t, op3: f64) -> svfloat64_t {
    svmad_f64_x(pg, op1, op2, svdup_n_f64(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmad))]
pub unsafe fn svmad_f64_z(
    pg: svbool_t,
    op1: svfloat64_t,
    op2: svfloat64_t,
    op3: svfloat64_t,
) -> svfloat64_t {
    svmad_f64_m(pg.clone(), svsel_f64(pg, op1, svdup_n_f64(0.0)), op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmad))]
pub unsafe fn svmad_n_f64_z(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t, op3: f64) -> svfloat64_t {
    svmad_f64_z(pg, op1, op2, svdup_n_f64(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub unsafe fn svmad_s8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t, op3: svint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.mad.nxv16i8")]
        fn _svmad_s8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t, op3: svint8_t) -> svint8_t;
    }
    unsafe { _svmad_s8_m(pg, op1, op2, op3) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub unsafe fn svmad_n_s8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t, op3: i8) -> svint8_t {
    svmad_s8_m(pg, op1, op2, svdup_n_s8(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub unsafe fn svmad_s8_x(pg: svbool_t, op1: svint8_t, op2: svint8_t, op3: svint8_t) -> svint8_t {
    svmad_s8_m(pg, op1, op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub unsafe fn svmad_n_s8_x(pg: svbool_t, op1: svint8_t, op2: svint8_t, op3: i8) -> svint8_t {
    svmad_s8_x(pg, op1, op2, svdup_n_s8(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub unsafe fn svmad_s8_z(pg: svbool_t, op1: svint8_t, op2: svint8_t, op3: svint8_t) -> svint8_t {
    svmad_s8_m(pg.clone(), svsel_s8(pg, op1, svdup_n_s8(0)), op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub unsafe fn svmad_n_s8_z(pg: svbool_t, op1: svint8_t, op2: svint8_t, op3: i8) -> svint8_t {
    svmad_s8_z(pg, op1, op2, svdup_n_s8(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub unsafe fn svmad_s16_m(pg: svbool_t, op1: svint16_t, op2: svint16_t, op3: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.mad.nxv8i16")]
        fn _svmad_s16_m(pg: svbool8_t, op1: svint16_t, op2: svint16_t, op3: svint16_t)
            -> svint16_t;
    }
    unsafe { _svmad_s16_m(pg.into(), op1, op2, op3) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub unsafe fn svmad_n_s16_m(pg: svbool_t, op1: svint16_t, op2: svint16_t, op3: i16) -> svint16_t {
    svmad_s16_m(pg, op1, op2, svdup_n_s16(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub unsafe fn svmad_s16_x(pg: svbool_t, op1: svint16_t, op2: svint16_t, op3: svint16_t) -> svint16_t {
    svmad_s16_m(pg, op1, op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub unsafe fn svmad_n_s16_x(pg: svbool_t, op1: svint16_t, op2: svint16_t, op3: i16) -> svint16_t {
    svmad_s16_x(pg, op1, op2, svdup_n_s16(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub unsafe fn svmad_s16_z(pg: svbool_t, op1: svint16_t, op2: svint16_t, op3: svint16_t) -> svint16_t {
    svmad_s16_m(pg.clone(), svsel_s16(pg, op1, svdup_n_s16(0)), op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub unsafe fn svmad_n_s16_z(pg: svbool_t, op1: svint16_t, op2: svint16_t, op3: i16) -> svint16_t {
    svmad_s16_z(pg, op1, op2, svdup_n_s16(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub unsafe fn svmad_s32_m(pg: svbool_t, op1: svint32_t, op2: svint32_t, op3: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.mad.nxv4i32")]
        fn _svmad_s32_m(pg: svbool4_t, op1: svint32_t, op2: svint32_t, op3: svint32_t)
            -> svint32_t;
    }
    unsafe { _svmad_s32_m(pg.into(), op1, op2, op3) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub unsafe fn svmad_n_s32_m(pg: svbool_t, op1: svint32_t, op2: svint32_t, op3: i32) -> svint32_t {
    svmad_s32_m(pg, op1, op2, svdup_n_s32(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub unsafe fn svmad_s32_x(pg: svbool_t, op1: svint32_t, op2: svint32_t, op3: svint32_t) -> svint32_t {
    svmad_s32_m(pg, op1, op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub unsafe fn svmad_n_s32_x(pg: svbool_t, op1: svint32_t, op2: svint32_t, op3: i32) -> svint32_t {
    svmad_s32_x(pg, op1, op2, svdup_n_s32(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub unsafe fn svmad_s32_z(pg: svbool_t, op1: svint32_t, op2: svint32_t, op3: svint32_t) -> svint32_t {
    svmad_s32_m(pg.clone(), svsel_s32(pg, op1, svdup_n_s32(0)), op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub unsafe fn svmad_n_s32_z(pg: svbool_t, op1: svint32_t, op2: svint32_t, op3: i32) -> svint32_t {
    svmad_s32_z(pg, op1, op2, svdup_n_s32(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub unsafe fn svmad_s64_m(pg: svbool_t, op1: svint64_t, op2: svint64_t, op3: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.mad.nxv2i64")]
        fn _svmad_s64_m(pg: svbool2_t, op1: svint64_t, op2: svint64_t, op3: svint64_t)
            -> svint64_t;
    }
    unsafe { _svmad_s64_m(pg.into(), op1, op2, op3) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub unsafe fn svmad_n_s64_m(pg: svbool_t, op1: svint64_t, op2: svint64_t, op3: i64) -> svint64_t {
    svmad_s64_m(pg, op1, op2, svdup_n_s64(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub unsafe fn svmad_s64_x(pg: svbool_t, op1: svint64_t, op2: svint64_t, op3: svint64_t) -> svint64_t {
    svmad_s64_m(pg, op1, op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub unsafe fn svmad_n_s64_x(pg: svbool_t, op1: svint64_t, op2: svint64_t, op3: i64) -> svint64_t {
    svmad_s64_x(pg, op1, op2, svdup_n_s64(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub unsafe fn svmad_s64_z(pg: svbool_t, op1: svint64_t, op2: svint64_t, op3: svint64_t) -> svint64_t {
    svmad_s64_m(pg.clone(), svsel_s64(pg, op1, svdup_n_s64(0)), op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub unsafe fn svmad_n_s64_z(pg: svbool_t, op1: svint64_t, op2: svint64_t, op3: i64) -> svint64_t {
    svmad_s64_z(pg, op1, op2, svdup_n_s64(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub unsafe fn svmad_u8_m(pg: svbool_t, op1: svuint8_t, op2: svuint8_t, op3: svuint8_t) -> svuint8_t {
    unsafe { svmad_s8_m(pg, op1.as_signed(), op2.as_signed(), op3.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub unsafe fn svmad_n_u8_m(pg: svbool_t, op1: svuint8_t, op2: svuint8_t, op3: u8) -> svuint8_t {
    svmad_u8_m(pg, op1, op2, svdup_n_u8(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub unsafe fn svmad_u8_x(pg: svbool_t, op1: svuint8_t, op2: svuint8_t, op3: svuint8_t) -> svuint8_t {
    svmad_u8_m(pg, op1, op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub unsafe fn svmad_n_u8_x(pg: svbool_t, op1: svuint8_t, op2: svuint8_t, op3: u8) -> svuint8_t {
    svmad_u8_x(pg, op1, op2, svdup_n_u8(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub unsafe fn svmad_u8_z(pg: svbool_t, op1: svuint8_t, op2: svuint8_t, op3: svuint8_t) -> svuint8_t {
    svmad_u8_m(pg.clone(), svsel_u8(pg, op1, svdup_n_u8(0)), op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub unsafe fn svmad_n_u8_z(pg: svbool_t, op1: svuint8_t, op2: svuint8_t, op3: u8) -> svuint8_t {
    svmad_u8_z(pg, op1, op2, svdup_n_u8(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub unsafe fn svmad_u16_m(pg: svbool_t, op1: svuint16_t, op2: svuint16_t, op3: svuint16_t) -> svuint16_t {
    unsafe { svmad_s16_m(pg, op1.as_signed(), op2.as_signed(), op3.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub unsafe fn svmad_n_u16_m(pg: svbool_t, op1: svuint16_t, op2: svuint16_t, op3: u16) -> svuint16_t {
    svmad_u16_m(pg, op1, op2, svdup_n_u16(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub unsafe fn svmad_u16_x(pg: svbool_t, op1: svuint16_t, op2: svuint16_t, op3: svuint16_t) -> svuint16_t {
    svmad_u16_m(pg, op1, op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub unsafe fn svmad_n_u16_x(pg: svbool_t, op1: svuint16_t, op2: svuint16_t, op3: u16) -> svuint16_t {
    svmad_u16_x(pg, op1, op2, svdup_n_u16(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub unsafe fn svmad_u16_z(pg: svbool_t, op1: svuint16_t, op2: svuint16_t, op3: svuint16_t) -> svuint16_t {
    svmad_u16_m(pg.clone(), svsel_u16(pg, op1, svdup_n_u16(0)), op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub unsafe fn svmad_n_u16_z(pg: svbool_t, op1: svuint16_t, op2: svuint16_t, op3: u16) -> svuint16_t {
    svmad_u16_z(pg, op1, op2, svdup_n_u16(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub unsafe fn svmad_u32_m(pg: svbool_t, op1: svuint32_t, op2: svuint32_t, op3: svuint32_t) -> svuint32_t {
    unsafe { svmad_s32_m(pg, op1.as_signed(), op2.as_signed(), op3.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub unsafe fn svmad_n_u32_m(pg: svbool_t, op1: svuint32_t, op2: svuint32_t, op3: u32) -> svuint32_t {
    svmad_u32_m(pg, op1, op2, svdup_n_u32(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub unsafe fn svmad_u32_x(pg: svbool_t, op1: svuint32_t, op2: svuint32_t, op3: svuint32_t) -> svuint32_t {
    svmad_u32_m(pg, op1, op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub unsafe fn svmad_n_u32_x(pg: svbool_t, op1: svuint32_t, op2: svuint32_t, op3: u32) -> svuint32_t {
    svmad_u32_x(pg, op1, op2, svdup_n_u32(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub unsafe fn svmad_u32_z(pg: svbool_t, op1: svuint32_t, op2: svuint32_t, op3: svuint32_t) -> svuint32_t {
    svmad_u32_m(pg.clone(), svsel_u32(pg, op1, svdup_n_u32(0)), op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub unsafe fn svmad_n_u32_z(pg: svbool_t, op1: svuint32_t, op2: svuint32_t, op3: u32) -> svuint32_t {
    svmad_u32_z(pg, op1, op2, svdup_n_u32(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub unsafe fn svmad_u64_m(pg: svbool_t, op1: svuint64_t, op2: svuint64_t, op3: svuint64_t) -> svuint64_t {
    unsafe { svmad_s64_m(pg, op1.as_signed(), op2.as_signed(), op3.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub unsafe fn svmad_n_u64_m(pg: svbool_t, op1: svuint64_t, op2: svuint64_t, op3: u64) -> svuint64_t {
    svmad_u64_m(pg, op1, op2, svdup_n_u64(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub unsafe fn svmad_u64_x(pg: svbool_t, op1: svuint64_t, op2: svuint64_t, op3: svuint64_t) -> svuint64_t {
    svmad_u64_m(pg, op1, op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub unsafe fn svmad_n_u64_x(pg: svbool_t, op1: svuint64_t, op2: svuint64_t, op3: u64) -> svuint64_t {
    svmad_u64_x(pg, op1, op2, svdup_n_u64(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub unsafe fn svmad_u64_z(pg: svbool_t, op1: svuint64_t, op2: svuint64_t, op3: svuint64_t) -> svuint64_t {
    svmad_u64_m(pg.clone(), svsel_u64(pg, op1, svdup_n_u64(0)), op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub unsafe fn svmad_n_u64_z(pg: svbool_t, op1: svuint64_t, op2: svuint64_t, op3: u64) -> svuint64_t {
    svmad_u64_z(pg, op1, op2, svdup_n_u64(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmax))]
pub unsafe fn svmax_f32_m(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fmax.nxv4f32")]
        fn _svmax_f32_m(pg: svbool4_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svmax_f32_m(pg.into(), op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmax))]
pub unsafe fn svmax_n_f32_m(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svfloat32_t {
    svmax_f32_m(pg, op1, svdup_n_f32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmax))]
pub unsafe fn svmax_f32_x(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    svmax_f32_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmax))]
pub unsafe fn svmax_n_f32_x(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svfloat32_t {
    svmax_f32_x(pg, op1, svdup_n_f32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmax))]
pub unsafe fn svmax_f32_z(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    svmax_f32_m(pg.clone(), svsel_f32(pg, op1, svdup_n_f32(0.0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmax))]
pub unsafe fn svmax_n_f32_z(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svfloat32_t {
    svmax_f32_z(pg, op1, svdup_n_f32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmax))]
pub unsafe fn svmax_f64_m(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fmax.nxv2f64")]
        fn _svmax_f64_m(pg: svbool2_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svmax_f64_m(pg.into(), op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmax))]
pub unsafe fn svmax_n_f64_m(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svfloat64_t {
    svmax_f64_m(pg, op1, svdup_n_f64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmax))]
pub unsafe fn svmax_f64_x(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    svmax_f64_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmax))]
pub unsafe fn svmax_n_f64_x(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svfloat64_t {
    svmax_f64_x(pg, op1, svdup_n_f64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmax))]
pub unsafe fn svmax_f64_z(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    svmax_f64_m(pg.clone(), svsel_f64(pg, op1, svdup_n_f64(0.0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmax))]
pub unsafe fn svmax_n_f64_z(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svfloat64_t {
    svmax_f64_z(pg, op1, svdup_n_f64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smax))]
pub unsafe fn svmax_s8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.smax.nxv16i8")]
        fn _svmax_s8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t;
    }
    unsafe { _svmax_s8_m(pg, op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smax))]
pub unsafe fn svmax_n_s8_m(pg: svbool_t, op1: svint8_t, op2: i8) -> svint8_t {
    svmax_s8_m(pg, op1, svdup_n_s8(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smax))]
pub unsafe fn svmax_s8_x(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t {
    svmax_s8_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smax))]
pub unsafe fn svmax_n_s8_x(pg: svbool_t, op1: svint8_t, op2: i8) -> svint8_t {
    svmax_s8_x(pg, op1, svdup_n_s8(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smax))]
pub unsafe fn svmax_s8_z(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t {
    svmax_s8_m(pg.clone(), svsel_s8(pg, op1, svdup_n_s8(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smax))]
pub unsafe fn svmax_n_s8_z(pg: svbool_t, op1: svint8_t, op2: i8) -> svint8_t {
    svmax_s8_z(pg, op1, svdup_n_s8(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smax))]
pub unsafe fn svmax_s16_m(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.smax.nxv8i16")]
        fn _svmax_s16_m(pg: svbool8_t, op1: svint16_t, op2: svint16_t) -> svint16_t;
    }
    unsafe { _svmax_s16_m(pg.into(), op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smax))]
pub unsafe fn svmax_n_s16_m(pg: svbool_t, op1: svint16_t, op2: i16) -> svint16_t {
    svmax_s16_m(pg, op1, svdup_n_s16(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smax))]
pub unsafe fn svmax_s16_x(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svint16_t {
    svmax_s16_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smax))]
pub unsafe fn svmax_n_s16_x(pg: svbool_t, op1: svint16_t, op2: i16) -> svint16_t {
    svmax_s16_x(pg, op1, svdup_n_s16(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smax))]
pub unsafe fn svmax_s16_z(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svint16_t {
    svmax_s16_m(pg.clone(), svsel_s16(pg, op1, svdup_n_s16(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smax))]
pub unsafe fn svmax_n_s16_z(pg: svbool_t, op1: svint16_t, op2: i16) -> svint16_t {
    svmax_s16_z(pg, op1, svdup_n_s16(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smax))]
pub unsafe fn svmax_s32_m(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.smax.nxv4i32")]
        fn _svmax_s32_m(pg: svbool4_t, op1: svint32_t, op2: svint32_t) -> svint32_t;
    }
    unsafe { _svmax_s32_m(pg.into(), op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smax))]
pub unsafe fn svmax_n_s32_m(pg: svbool_t, op1: svint32_t, op2: i32) -> svint32_t {
    svmax_s32_m(pg, op1, svdup_n_s32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smax))]
pub unsafe fn svmax_s32_x(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    svmax_s32_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smax))]
pub unsafe fn svmax_n_s32_x(pg: svbool_t, op1: svint32_t, op2: i32) -> svint32_t {
    svmax_s32_x(pg, op1, svdup_n_s32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smax))]
pub unsafe fn svmax_s32_z(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    svmax_s32_m(pg.clone(), svsel_s32(pg, op1, svdup_n_s32(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smax))]
pub unsafe fn svmax_n_s32_z(pg: svbool_t, op1: svint32_t, op2: i32) -> svint32_t {
    svmax_s32_z(pg, op1, svdup_n_s32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smax))]
pub unsafe fn svmax_s64_m(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.smax.nxv2i64")]
        fn _svmax_s64_m(pg: svbool2_t, op1: svint64_t, op2: svint64_t) -> svint64_t;
    }
    unsafe { _svmax_s64_m(pg.into(), op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smax))]
pub unsafe fn svmax_n_s64_m(pg: svbool_t, op1: svint64_t, op2: i64) -> svint64_t {
    svmax_s64_m(pg, op1, svdup_n_s64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smax))]
pub unsafe fn svmax_s64_x(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    svmax_s64_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smax))]
pub unsafe fn svmax_n_s64_x(pg: svbool_t, op1: svint64_t, op2: i64) -> svint64_t {
    svmax_s64_x(pg, op1, svdup_n_s64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smax))]
pub unsafe fn svmax_s64_z(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    svmax_s64_m(pg.clone(), svsel_s64(pg, op1, svdup_n_s64(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smax))]
pub unsafe fn svmax_n_s64_z(pg: svbool_t, op1: svint64_t, op2: i64) -> svint64_t {
    svmax_s64_z(pg, op1, svdup_n_s64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umax))]
pub unsafe fn svmax_u8_m(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.umax.nxv16i8")]
        fn _svmax_u8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t;
    }
    unsafe { _svmax_u8_m(pg, op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umax))]
pub unsafe fn svmax_n_u8_m(pg: svbool_t, op1: svuint8_t, op2: u8) -> svuint8_t {
    svmax_u8_m(pg, op1, svdup_n_u8(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umax))]
pub unsafe fn svmax_u8_x(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    svmax_u8_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umax))]
pub unsafe fn svmax_n_u8_x(pg: svbool_t, op1: svuint8_t, op2: u8) -> svuint8_t {
    svmax_u8_x(pg, op1, svdup_n_u8(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umax))]
pub unsafe fn svmax_u8_z(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    svmax_u8_m(pg.clone(), svsel_u8(pg, op1, svdup_n_u8(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umax))]
pub unsafe fn svmax_n_u8_z(pg: svbool_t, op1: svuint8_t, op2: u8) -> svuint8_t {
    svmax_u8_z(pg, op1, svdup_n_u8(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umax))]
pub unsafe fn svmax_u16_m(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.umax.nxv8i16")]
        fn _svmax_u16_m(pg: svbool8_t, op1: svint16_t, op2: svint16_t) -> svint16_t;
    }
    unsafe { _svmax_u16_m(pg.into(), op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umax))]
pub unsafe fn svmax_n_u16_m(pg: svbool_t, op1: svuint16_t, op2: u16) -> svuint16_t {
    svmax_u16_m(pg, op1, svdup_n_u16(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umax))]
pub unsafe fn svmax_u16_x(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    svmax_u16_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umax))]
pub unsafe fn svmax_n_u16_x(pg: svbool_t, op1: svuint16_t, op2: u16) -> svuint16_t {
    svmax_u16_x(pg, op1, svdup_n_u16(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umax))]
pub unsafe fn svmax_u16_z(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    svmax_u16_m(pg.clone(), svsel_u16(pg, op1, svdup_n_u16(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umax))]
pub unsafe fn svmax_n_u16_z(pg: svbool_t, op1: svuint16_t, op2: u16) -> svuint16_t {
    svmax_u16_z(pg, op1, svdup_n_u16(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umax))]
pub unsafe fn svmax_u32_m(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.umax.nxv4i32")]
        fn _svmax_u32_m(pg: svbool4_t, op1: svint32_t, op2: svint32_t) -> svint32_t;
    }
    unsafe { _svmax_u32_m(pg.into(), op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umax))]
pub unsafe fn svmax_n_u32_m(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svmax_u32_m(pg, op1, svdup_n_u32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umax))]
pub unsafe fn svmax_u32_x(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    svmax_u32_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umax))]
pub unsafe fn svmax_n_u32_x(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svmax_u32_x(pg, op1, svdup_n_u32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umax))]
pub unsafe fn svmax_u32_z(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    svmax_u32_m(pg.clone(), svsel_u32(pg, op1, svdup_n_u32(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umax))]
pub unsafe fn svmax_n_u32_z(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svmax_u32_z(pg, op1, svdup_n_u32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umax))]
pub unsafe fn svmax_u64_m(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.umax.nxv2i64")]
        fn _svmax_u64_m(pg: svbool2_t, op1: svint64_t, op2: svint64_t) -> svint64_t;
    }
    unsafe { _svmax_u64_m(pg.into(), op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umax))]
pub unsafe fn svmax_n_u64_m(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svmax_u64_m(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umax))]
pub unsafe fn svmax_u64_x(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    svmax_u64_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umax))]
pub unsafe fn svmax_n_u64_x(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svmax_u64_x(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umax))]
pub unsafe fn svmax_u64_z(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    svmax_u64_m(pg.clone(), svsel_u64(pg, op1, svdup_n_u64(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umax))]
pub unsafe fn svmax_n_u64_z(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svmax_u64_z(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmaxnm))]
pub unsafe fn svmaxnm_f32_m(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fmaxnm.nxv4f32")]
        fn _svmaxnm_f32_m(pg: svbool4_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svmaxnm_f32_m(pg.into(), op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmaxnm))]
pub unsafe fn svmaxnm_n_f32_m(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svfloat32_t {
    svmaxnm_f32_m(pg, op1, svdup_n_f32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmaxnm))]
pub unsafe fn svmaxnm_f32_x(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    svmaxnm_f32_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmaxnm))]
pub unsafe fn svmaxnm_n_f32_x(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svfloat32_t {
    svmaxnm_f32_x(pg, op1, svdup_n_f32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmaxnm))]
pub unsafe fn svmaxnm_f32_z(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    svmaxnm_f32_m(pg.clone(), svsel_f32(pg, op1, svdup_n_f32(0.0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmaxnm))]
pub unsafe fn svmaxnm_n_f32_z(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svfloat32_t {
    svmaxnm_f32_z(pg, op1, svdup_n_f32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmaxnm))]
pub unsafe fn svmaxnm_f64_m(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fmaxnm.nxv2f64")]
        fn _svmaxnm_f64_m(pg: svbool2_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svmaxnm_f64_m(pg.into(), op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmaxnm))]
pub unsafe fn svmaxnm_n_f64_m(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svfloat64_t {
    svmaxnm_f64_m(pg, op1, svdup_n_f64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmaxnm))]
pub unsafe fn svmaxnm_f64_x(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    svmaxnm_f64_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmaxnm))]
pub unsafe fn svmaxnm_n_f64_x(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svfloat64_t {
    svmaxnm_f64_x(pg, op1, svdup_n_f64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmaxnm))]
pub unsafe fn svmaxnm_f64_z(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    svmaxnm_f64_m(pg.clone(), svsel_f64(pg, op1, svdup_n_f64(0.0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmaxnm))]
pub unsafe fn svmaxnm_n_f64_z(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svfloat64_t {
    svmaxnm_f64_z(pg, op1, svdup_n_f64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmaxnmv))]
pub unsafe fn svmaxnmv_f32(pg: svbool_t, op: svfloat32_t) -> f32 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.fmaxnmv.nxv4f32"
        )]
        fn _svmaxnmv_f32(pg: svbool4_t, op: svfloat32_t) -> f32;
    }
    unsafe { _svmaxnmv_f32(pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmaxnmv))]
pub unsafe fn svmaxnmv_f64(pg: svbool_t, op: svfloat64_t) -> f64 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.fmaxnmv.nxv2f64"
        )]
        fn _svmaxnmv_f64(pg: svbool2_t, op: svfloat64_t) -> f64;
    }
    unsafe { _svmaxnmv_f64(pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmaxv))]
pub unsafe fn svmaxv_f32(pg: svbool_t, op: svfloat32_t) -> f32 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fmaxv.nxv4f32")]
        fn _svmaxv_f32(pg: svbool4_t, op: svfloat32_t) -> f32;
    }
    unsafe { _svmaxv_f32(pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmaxv))]
pub unsafe fn svmaxv_f64(pg: svbool_t, op: svfloat64_t) -> f64 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fmaxv.nxv2f64")]
        fn _svmaxv_f64(pg: svbool2_t, op: svfloat64_t) -> f64;
    }
    unsafe { _svmaxv_f64(pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smaxv))]
pub unsafe fn svmaxv_s8(pg: svbool_t, op: svint8_t) -> i8 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.smaxv.nxv16i8")]
        fn _svmaxv_s8(pg: svbool_t, op: svint8_t) -> i8;
    }
    unsafe { _svmaxv_s8(pg, op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smaxv))]
pub unsafe fn svmaxv_s16(pg: svbool_t, op: svint16_t) -> i16 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.smaxv.nxv8i16")]
        fn _svmaxv_s16(pg: svbool8_t, op: svint16_t) -> i16;
    }
    unsafe { _svmaxv_s16(pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smaxv))]
pub unsafe fn svmaxv_s32(pg: svbool_t, op: svint32_t) -> i32 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.smaxv.nxv4i32")]
        fn _svmaxv_s32(pg: svbool4_t, op: svint32_t) -> i32;
    }
    unsafe { _svmaxv_s32(pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smaxv))]
pub unsafe fn svmaxv_s64(pg: svbool_t, op: svint64_t) -> i64 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.smaxv.nxv2i64")]
        fn _svmaxv_s64(pg: svbool2_t, op: svint64_t) -> i64;
    }
    unsafe { _svmaxv_s64(pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umaxv))]
pub unsafe fn svmaxv_u8(pg: svbool_t, op: svuint8_t) -> u8 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.umaxv.nxv16i8")]
        fn _svmaxv_u8(pg: svbool_t, op: svint8_t) -> i8;
    }
    unsafe { _svmaxv_u8(pg, op.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umaxv))]
pub unsafe fn svmaxv_u16(pg: svbool_t, op: svuint16_t) -> u16 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.umaxv.nxv8i16")]
        fn _svmaxv_u16(pg: svbool8_t, op: svint16_t) -> i16;
    }
    unsafe { _svmaxv_u16(pg.into(), op.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umaxv))]
pub unsafe fn svmaxv_u32(pg: svbool_t, op: svuint32_t) -> u32 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.umaxv.nxv4i32")]
        fn _svmaxv_u32(pg: svbool4_t, op: svint32_t) -> i32;
    }
    unsafe { _svmaxv_u32(pg.into(), op.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umaxv))]
pub unsafe fn svmaxv_u64(pg: svbool_t, op: svuint64_t) -> u64 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.umaxv.nxv2i64")]
        fn _svmaxv_u64(pg: svbool2_t, op: svint64_t) -> i64;
    }
    unsafe { _svmaxv_u64(pg.into(), op.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmin))]
pub unsafe fn svmin_f32_m(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fmin.nxv4f32")]
        fn _svmin_f32_m(pg: svbool4_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svmin_f32_m(pg.into(), op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmin))]
pub unsafe fn svmin_n_f32_m(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svfloat32_t {
    svmin_f32_m(pg, op1, svdup_n_f32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmin))]
pub unsafe fn svmin_f32_x(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    svmin_f32_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmin))]
pub unsafe fn svmin_n_f32_x(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svfloat32_t {
    svmin_f32_x(pg, op1, svdup_n_f32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmin))]
pub unsafe fn svmin_f32_z(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    svmin_f32_m(pg.clone(), svsel_f32(pg, op1, svdup_n_f32(0.0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmin))]
pub unsafe fn svmin_n_f32_z(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svfloat32_t {
    svmin_f32_z(pg, op1, svdup_n_f32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmin))]
pub unsafe fn svmin_f64_m(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fmin.nxv2f64")]
        fn _svmin_f64_m(pg: svbool2_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svmin_f64_m(pg.into(), op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmin))]
pub unsafe fn svmin_n_f64_m(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svfloat64_t {
    svmin_f64_m(pg, op1, svdup_n_f64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmin))]
pub unsafe fn svmin_f64_x(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    svmin_f64_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmin))]
pub unsafe fn svmin_n_f64_x(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svfloat64_t {
    svmin_f64_x(pg, op1, svdup_n_f64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmin))]
pub unsafe fn svmin_f64_z(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    svmin_f64_m(pg.clone(), svsel_f64(pg, op1, svdup_n_f64(0.0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmin))]
pub unsafe fn svmin_n_f64_z(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svfloat64_t {
    svmin_f64_z(pg, op1, svdup_n_f64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smin))]
pub unsafe fn svmin_s8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.smin.nxv16i8")]
        fn _svmin_s8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t;
    }
    unsafe { _svmin_s8_m(pg, op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smin))]
pub unsafe fn svmin_n_s8_m(pg: svbool_t, op1: svint8_t, op2: i8) -> svint8_t {
    svmin_s8_m(pg, op1, svdup_n_s8(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smin))]
pub unsafe fn svmin_s8_x(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t {
    svmin_s8_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smin))]
pub unsafe fn svmin_n_s8_x(pg: svbool_t, op1: svint8_t, op2: i8) -> svint8_t {
    svmin_s8_x(pg, op1, svdup_n_s8(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smin))]
pub unsafe fn svmin_s8_z(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t {
    svmin_s8_m(pg.clone(), svsel_s8(pg, op1, svdup_n_s8(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smin))]
pub unsafe fn svmin_n_s8_z(pg: svbool_t, op1: svint8_t, op2: i8) -> svint8_t {
    svmin_s8_z(pg, op1, svdup_n_s8(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smin))]
pub unsafe fn svmin_s16_m(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.smin.nxv8i16")]
        fn _svmin_s16_m(pg: svbool8_t, op1: svint16_t, op2: svint16_t) -> svint16_t;
    }
    unsafe { _svmin_s16_m(pg.into(), op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smin))]
pub unsafe fn svmin_n_s16_m(pg: svbool_t, op1: svint16_t, op2: i16) -> svint16_t {
    svmin_s16_m(pg, op1, svdup_n_s16(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smin))]
pub unsafe fn svmin_s16_x(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svint16_t {
    svmin_s16_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smin))]
pub unsafe fn svmin_n_s16_x(pg: svbool_t, op1: svint16_t, op2: i16) -> svint16_t {
    svmin_s16_x(pg, op1, svdup_n_s16(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smin))]
pub unsafe fn svmin_s16_z(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svint16_t {
    svmin_s16_m(pg.clone(), svsel_s16(pg, op1, svdup_n_s16(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smin))]
pub unsafe fn svmin_n_s16_z(pg: svbool_t, op1: svint16_t, op2: i16) -> svint16_t {
    svmin_s16_z(pg, op1, svdup_n_s16(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smin))]
pub unsafe fn svmin_s32_m(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.smin.nxv4i32")]
        fn _svmin_s32_m(pg: svbool4_t, op1: svint32_t, op2: svint32_t) -> svint32_t;
    }
    unsafe { _svmin_s32_m(pg.into(), op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smin))]
pub unsafe fn svmin_n_s32_m(pg: svbool_t, op1: svint32_t, op2: i32) -> svint32_t {
    svmin_s32_m(pg, op1, svdup_n_s32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smin))]
pub unsafe fn svmin_s32_x(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    svmin_s32_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smin))]
pub unsafe fn svmin_n_s32_x(pg: svbool_t, op1: svint32_t, op2: i32) -> svint32_t {
    svmin_s32_x(pg, op1, svdup_n_s32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smin))]
pub unsafe fn svmin_s32_z(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    svmin_s32_m(pg.clone(), svsel_s32(pg, op1, svdup_n_s32(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smin))]
pub unsafe fn svmin_n_s32_z(pg: svbool_t, op1: svint32_t, op2: i32) -> svint32_t {
    svmin_s32_z(pg, op1, svdup_n_s32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smin))]
pub unsafe fn svmin_s64_m(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.smin.nxv2i64")]
        fn _svmin_s64_m(pg: svbool2_t, op1: svint64_t, op2: svint64_t) -> svint64_t;
    }
    unsafe { _svmin_s64_m(pg.into(), op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smin))]
pub unsafe fn svmin_n_s64_m(pg: svbool_t, op1: svint64_t, op2: i64) -> svint64_t {
    svmin_s64_m(pg, op1, svdup_n_s64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smin))]
pub unsafe fn svmin_s64_x(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    svmin_s64_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smin))]
pub unsafe fn svmin_n_s64_x(pg: svbool_t, op1: svint64_t, op2: i64) -> svint64_t {
    svmin_s64_x(pg, op1, svdup_n_s64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smin))]
pub unsafe fn svmin_s64_z(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    svmin_s64_m(pg.clone(), svsel_s64(pg, op1, svdup_n_s64(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smin))]
pub unsafe fn svmin_n_s64_z(pg: svbool_t, op1: svint64_t, op2: i64) -> svint64_t {
    svmin_s64_z(pg, op1, svdup_n_s64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umin))]
pub unsafe fn svmin_u8_m(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.umin.nxv16i8")]
        fn _svmin_u8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t;
    }
    unsafe { _svmin_u8_m(pg, op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umin))]
pub unsafe fn svmin_n_u8_m(pg: svbool_t, op1: svuint8_t, op2: u8) -> svuint8_t {
    svmin_u8_m(pg, op1, svdup_n_u8(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umin))]
pub unsafe fn svmin_u8_x(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    svmin_u8_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umin))]
pub unsafe fn svmin_n_u8_x(pg: svbool_t, op1: svuint8_t, op2: u8) -> svuint8_t {
    svmin_u8_x(pg, op1, svdup_n_u8(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umin))]
pub unsafe fn svmin_u8_z(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    svmin_u8_m(pg.clone(), svsel_u8(pg, op1, svdup_n_u8(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umin))]
pub unsafe fn svmin_n_u8_z(pg: svbool_t, op1: svuint8_t, op2: u8) -> svuint8_t {
    svmin_u8_z(pg, op1, svdup_n_u8(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umin))]
pub unsafe fn svmin_u16_m(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.umin.nxv8i16")]
        fn _svmin_u16_m(pg: svbool8_t, op1: svint16_t, op2: svint16_t) -> svint16_t;
    }
    unsafe { _svmin_u16_m(pg.into(), op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umin))]
pub unsafe fn svmin_n_u16_m(pg: svbool_t, op1: svuint16_t, op2: u16) -> svuint16_t {
    svmin_u16_m(pg, op1, svdup_n_u16(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umin))]
pub unsafe fn svmin_u16_x(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    svmin_u16_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umin))]
pub unsafe fn svmin_n_u16_x(pg: svbool_t, op1: svuint16_t, op2: u16) -> svuint16_t {
    svmin_u16_x(pg, op1, svdup_n_u16(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umin))]
pub unsafe fn svmin_u16_z(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    svmin_u16_m(pg.clone(), svsel_u16(pg, op1, svdup_n_u16(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umin))]
pub unsafe fn svmin_n_u16_z(pg: svbool_t, op1: svuint16_t, op2: u16) -> svuint16_t {
    svmin_u16_z(pg, op1, svdup_n_u16(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umin))]
pub unsafe fn svmin_u32_m(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.umin.nxv4i32")]
        fn _svmin_u32_m(pg: svbool4_t, op1: svint32_t, op2: svint32_t) -> svint32_t;
    }
    unsafe { _svmin_u32_m(pg.into(), op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umin))]
pub unsafe fn svmin_n_u32_m(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svmin_u32_m(pg, op1, svdup_n_u32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umin))]
pub unsafe fn svmin_u32_x(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    svmin_u32_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umin))]
pub unsafe fn svmin_n_u32_x(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svmin_u32_x(pg, op1, svdup_n_u32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umin))]
pub unsafe fn svmin_u32_z(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    svmin_u32_m(pg.clone(), svsel_u32(pg, op1, svdup_n_u32(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umin))]
pub unsafe fn svmin_n_u32_z(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svmin_u32_z(pg, op1, svdup_n_u32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umin))]
pub unsafe fn svmin_u64_m(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.umin.nxv2i64")]
        fn _svmin_u64_m(pg: svbool2_t, op1: svint64_t, op2: svint64_t) -> svint64_t;
    }
    unsafe { _svmin_u64_m(pg.into(), op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umin))]
pub unsafe fn svmin_n_u64_m(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svmin_u64_m(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umin))]
pub unsafe fn svmin_u64_x(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    svmin_u64_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umin))]
pub unsafe fn svmin_n_u64_x(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svmin_u64_x(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umin))]
pub unsafe fn svmin_u64_z(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    svmin_u64_m(pg.clone(), svsel_u64(pg, op1, svdup_n_u64(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umin))]
pub unsafe fn svmin_n_u64_z(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svmin_u64_z(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fminnm))]
pub unsafe fn svminnm_f32_m(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fminnm.nxv4f32")]
        fn _svminnm_f32_m(pg: svbool4_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svminnm_f32_m(pg.into(), op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fminnm))]
pub unsafe fn svminnm_n_f32_m(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svfloat32_t {
    svminnm_f32_m(pg, op1, svdup_n_f32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fminnm))]
pub unsafe fn svminnm_f32_x(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    svminnm_f32_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fminnm))]
pub unsafe fn svminnm_n_f32_x(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svfloat32_t {
    svminnm_f32_x(pg, op1, svdup_n_f32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fminnm))]
pub unsafe fn svminnm_f32_z(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    svminnm_f32_m(pg.clone(), svsel_f32(pg, op1, svdup_n_f32(0.0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fminnm))]
pub unsafe fn svminnm_n_f32_z(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svfloat32_t {
    svminnm_f32_z(pg, op1, svdup_n_f32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fminnm))]
pub unsafe fn svminnm_f64_m(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fminnm.nxv2f64")]
        fn _svminnm_f64_m(pg: svbool2_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svminnm_f64_m(pg.into(), op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fminnm))]
pub unsafe fn svminnm_n_f64_m(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svfloat64_t {
    svminnm_f64_m(pg, op1, svdup_n_f64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fminnm))]
pub unsafe fn svminnm_f64_x(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    svminnm_f64_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fminnm))]
pub unsafe fn svminnm_n_f64_x(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svfloat64_t {
    svminnm_f64_x(pg, op1, svdup_n_f64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fminnm))]
pub unsafe fn svminnm_f64_z(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    svminnm_f64_m(pg.clone(), svsel_f64(pg, op1, svdup_n_f64(0.0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fminnm))]
pub unsafe fn svminnm_n_f64_z(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svfloat64_t {
    svminnm_f64_z(pg, op1, svdup_n_f64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fminnmv))]
pub unsafe fn svminnmv_f32(pg: svbool_t, op: svfloat32_t) -> f32 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.fminnmv.nxv4f32"
        )]
        fn _svminnmv_f32(pg: svbool4_t, op: svfloat32_t) -> f32;
    }
    unsafe { _svminnmv_f32(pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fminnmv))]
pub unsafe fn svminnmv_f64(pg: svbool_t, op: svfloat64_t) -> f64 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.fminnmv.nxv2f64"
        )]
        fn _svminnmv_f64(pg: svbool2_t, op: svfloat64_t) -> f64;
    }
    unsafe { _svminnmv_f64(pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fminv))]
pub unsafe fn svminv_f32(pg: svbool_t, op: svfloat32_t) -> f32 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fminv.nxv4f32")]
        fn _svminv_f32(pg: svbool4_t, op: svfloat32_t) -> f32;
    }
    unsafe { _svminv_f32(pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fminv))]
pub unsafe fn svminv_f64(pg: svbool_t, op: svfloat64_t) -> f64 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fminv.nxv2f64")]
        fn _svminv_f64(pg: svbool2_t, op: svfloat64_t) -> f64;
    }
    unsafe { _svminv_f64(pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sminv))]
pub unsafe fn svminv_s8(pg: svbool_t, op: svint8_t) -> i8 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sminv.nxv16i8")]
        fn _svminv_s8(pg: svbool_t, op: svint8_t) -> i8;
    }
    unsafe { _svminv_s8(pg, op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sminv))]
pub unsafe fn svminv_s16(pg: svbool_t, op: svint16_t) -> i16 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sminv.nxv8i16")]
        fn _svminv_s16(pg: svbool8_t, op: svint16_t) -> i16;
    }
    unsafe { _svminv_s16(pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sminv))]
pub unsafe fn svminv_s32(pg: svbool_t, op: svint32_t) -> i32 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sminv.nxv4i32")]
        fn _svminv_s32(pg: svbool4_t, op: svint32_t) -> i32;
    }
    unsafe { _svminv_s32(pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sminv))]
pub unsafe fn svminv_s64(pg: svbool_t, op: svint64_t) -> i64 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sminv.nxv2i64")]
        fn _svminv_s64(pg: svbool2_t, op: svint64_t) -> i64;
    }
    unsafe { _svminv_s64(pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uminv))]
pub unsafe fn svminv_u8(pg: svbool_t, op: svuint8_t) -> u8 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uminv.nxv16i8")]
        fn _svminv_u8(pg: svbool_t, op: svint8_t) -> i8;
    }
    unsafe { _svminv_u8(pg, op.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uminv))]
pub unsafe fn svminv_u16(pg: svbool_t, op: svuint16_t) -> u16 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uminv.nxv8i16")]
        fn _svminv_u16(pg: svbool8_t, op: svint16_t) -> i16;
    }
    unsafe { _svminv_u16(pg.into(), op.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uminv))]
pub unsafe fn svminv_u32(pg: svbool_t, op: svuint32_t) -> u32 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uminv.nxv4i32")]
        fn _svminv_u32(pg: svbool4_t, op: svint32_t) -> i32;
    }
    unsafe { _svminv_u32(pg.into(), op.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uminv))]
pub unsafe fn svminv_u64(pg: svbool_t, op: svuint64_t) -> u64 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uminv.nxv2i64")]
        fn _svminv_u64(pg: svbool2_t, op: svint64_t) -> i64;
    }
    unsafe { _svminv_u64(pg.into(), op.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmla))]
pub unsafe fn svmla_f32_m(
    pg: svbool_t,
    op1: svfloat32_t,
    op2: svfloat32_t,
    op3: svfloat32_t,
) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fmla.nxv4f32")]
        fn _svmla_f32_m(
            pg: svbool4_t,
            op1: svfloat32_t,
            op2: svfloat32_t,
            op3: svfloat32_t,
        ) -> svfloat32_t;
    }
    unsafe { _svmla_f32_m(pg.into(), op1, op2, op3) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmla))]
pub unsafe fn svmla_n_f32_m(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t, op3: f32) -> svfloat32_t {
    svmla_f32_m(pg, op1, op2, svdup_n_f32(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmla))]
pub unsafe fn svmla_f32_x(
    pg: svbool_t,
    op1: svfloat32_t,
    op2: svfloat32_t,
    op3: svfloat32_t,
) -> svfloat32_t {
    svmla_f32_m(pg, op1, op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmla))]
pub unsafe fn svmla_n_f32_x(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t, op3: f32) -> svfloat32_t {
    svmla_f32_x(pg, op1, op2, svdup_n_f32(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmla))]
pub unsafe fn svmla_f32_z(
    pg: svbool_t,
    op1: svfloat32_t,
    op2: svfloat32_t,
    op3: svfloat32_t,
) -> svfloat32_t {
    svmla_f32_m(pg.clone(), svsel_f32(pg, op1, svdup_n_f32(0.0)), op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmla))]
pub unsafe fn svmla_n_f32_z(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t, op3: f32) -> svfloat32_t {
    svmla_f32_z(pg, op1, op2, svdup_n_f32(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmla))]
pub unsafe fn svmla_f64_m(
    pg: svbool_t,
    op1: svfloat64_t,
    op2: svfloat64_t,
    op3: svfloat64_t,
) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fmla.nxv2f64")]
        fn _svmla_f64_m(
            pg: svbool2_t,
            op1: svfloat64_t,
            op2: svfloat64_t,
            op3: svfloat64_t,
        ) -> svfloat64_t;
    }
    unsafe { _svmla_f64_m(pg.into(), op1, op2, op3) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmla))]
pub unsafe fn svmla_n_f64_m(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t, op3: f64) -> svfloat64_t {
    svmla_f64_m(pg, op1, op2, svdup_n_f64(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmla))]
pub unsafe fn svmla_f64_x(
    pg: svbool_t,
    op1: svfloat64_t,
    op2: svfloat64_t,
    op3: svfloat64_t,
) -> svfloat64_t {
    svmla_f64_m(pg, op1, op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmla))]
pub unsafe fn svmla_n_f64_x(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t, op3: f64) -> svfloat64_t {
    svmla_f64_x(pg, op1, op2, svdup_n_f64(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmla))]
pub unsafe fn svmla_f64_z(
    pg: svbool_t,
    op1: svfloat64_t,
    op2: svfloat64_t,
    op3: svfloat64_t,
) -> svfloat64_t {
    svmla_f64_m(pg.clone(), svsel_f64(pg, op1, svdup_n_f64(0.0)), op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmla))]
pub unsafe fn svmla_n_f64_z(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t, op3: f64) -> svfloat64_t {
    svmla_f64_z(pg, op1, op2, svdup_n_f64(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub unsafe fn svmla_s8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t, op3: svint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.mla.nxv16i8")]
        fn _svmla_s8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t, op3: svint8_t) -> svint8_t;
    }
    unsafe { _svmla_s8_m(pg, op1, op2, op3) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub unsafe fn svmla_n_s8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t, op3: i8) -> svint8_t {
    svmla_s8_m(pg, op1, op2, svdup_n_s8(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub unsafe fn svmla_s8_x(pg: svbool_t, op1: svint8_t, op2: svint8_t, op3: svint8_t) -> svint8_t {
    svmla_s8_m(pg, op1, op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub unsafe fn svmla_n_s8_x(pg: svbool_t, op1: svint8_t, op2: svint8_t, op3: i8) -> svint8_t {
    svmla_s8_x(pg, op1, op2, svdup_n_s8(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub unsafe fn svmla_s8_z(pg: svbool_t, op1: svint8_t, op2: svint8_t, op3: svint8_t) -> svint8_t {
    svmla_s8_m(pg.clone(), svsel_s8(pg, op1, svdup_n_s8(0)), op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub unsafe fn svmla_n_s8_z(pg: svbool_t, op1: svint8_t, op2: svint8_t, op3: i8) -> svint8_t {
    svmla_s8_z(pg, op1, op2, svdup_n_s8(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub unsafe fn svmla_s16_m(pg: svbool_t, op1: svint16_t, op2: svint16_t, op3: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.mla.nxv8i16")]
        fn _svmla_s16_m(pg: svbool8_t, op1: svint16_t, op2: svint16_t, op3: svint16_t)
            -> svint16_t;
    }
    unsafe { _svmla_s16_m(pg.into(), op1, op2, op3) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub unsafe fn svmla_n_s16_m(pg: svbool_t, op1: svint16_t, op2: svint16_t, op3: i16) -> svint16_t {
    svmla_s16_m(pg, op1, op2, svdup_n_s16(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub unsafe fn svmla_s16_x(pg: svbool_t, op1: svint16_t, op2: svint16_t, op3: svint16_t) -> svint16_t {
    svmla_s16_m(pg, op1, op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub unsafe fn svmla_n_s16_x(pg: svbool_t, op1: svint16_t, op2: svint16_t, op3: i16) -> svint16_t {
    svmla_s16_x(pg, op1, op2, svdup_n_s16(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub unsafe fn svmla_s16_z(pg: svbool_t, op1: svint16_t, op2: svint16_t, op3: svint16_t) -> svint16_t {
    svmla_s16_m(pg.clone(), svsel_s16(pg, op1, svdup_n_s16(0)), op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub unsafe fn svmla_n_s16_z(pg: svbool_t, op1: svint16_t, op2: svint16_t, op3: i16) -> svint16_t {
    svmla_s16_z(pg, op1, op2, svdup_n_s16(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub unsafe fn svmla_s32_m(pg: svbool_t, op1: svint32_t, op2: svint32_t, op3: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.mla.nxv4i32")]
        fn _svmla_s32_m(pg: svbool4_t, op1: svint32_t, op2: svint32_t, op3: svint32_t)
            -> svint32_t;
    }
    unsafe { _svmla_s32_m(pg.into(), op1, op2, op3) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub unsafe fn svmla_n_s32_m(pg: svbool_t, op1: svint32_t, op2: svint32_t, op3: i32) -> svint32_t {
    svmla_s32_m(pg, op1, op2, svdup_n_s32(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub unsafe fn svmla_s32_x(pg: svbool_t, op1: svint32_t, op2: svint32_t, op3: svint32_t) -> svint32_t {
    svmla_s32_m(pg, op1, op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub unsafe fn svmla_n_s32_x(pg: svbool_t, op1: svint32_t, op2: svint32_t, op3: i32) -> svint32_t {
    svmla_s32_x(pg, op1, op2, svdup_n_s32(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub unsafe fn svmla_s32_z(pg: svbool_t, op1: svint32_t, op2: svint32_t, op3: svint32_t) -> svint32_t {
    svmla_s32_m(pg.clone(), svsel_s32(pg, op1, svdup_n_s32(0)), op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub unsafe fn svmla_n_s32_z(pg: svbool_t, op1: svint32_t, op2: svint32_t, op3: i32) -> svint32_t {
    svmla_s32_z(pg, op1, op2, svdup_n_s32(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub unsafe fn svmla_s64_m(pg: svbool_t, op1: svint64_t, op2: svint64_t, op3: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.mla.nxv2i64")]
        fn _svmla_s64_m(pg: svbool2_t, op1: svint64_t, op2: svint64_t, op3: svint64_t)
            -> svint64_t;
    }
    unsafe { _svmla_s64_m(pg.into(), op1, op2, op3) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub unsafe fn svmla_n_s64_m(pg: svbool_t, op1: svint64_t, op2: svint64_t, op3: i64) -> svint64_t {
    svmla_s64_m(pg, op1, op2, svdup_n_s64(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub unsafe fn svmla_s64_x(pg: svbool_t, op1: svint64_t, op2: svint64_t, op3: svint64_t) -> svint64_t {
    svmla_s64_m(pg, op1, op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub unsafe fn svmla_n_s64_x(pg: svbool_t, op1: svint64_t, op2: svint64_t, op3: i64) -> svint64_t {
    svmla_s64_x(pg, op1, op2, svdup_n_s64(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub unsafe fn svmla_s64_z(pg: svbool_t, op1: svint64_t, op2: svint64_t, op3: svint64_t) -> svint64_t {
    svmla_s64_m(pg.clone(), svsel_s64(pg, op1, svdup_n_s64(0)), op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub unsafe fn svmla_n_s64_z(pg: svbool_t, op1: svint64_t, op2: svint64_t, op3: i64) -> svint64_t {
    svmla_s64_z(pg, op1, op2, svdup_n_s64(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub unsafe fn svmla_u8_m(pg: svbool_t, op1: svuint8_t, op2: svuint8_t, op3: svuint8_t) -> svuint8_t {
    unsafe { svmla_s8_m(pg, op1.as_signed(), op2.as_signed(), op3.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub unsafe fn svmla_n_u8_m(pg: svbool_t, op1: svuint8_t, op2: svuint8_t, op3: u8) -> svuint8_t {
    svmla_u8_m(pg, op1, op2, svdup_n_u8(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub unsafe fn svmla_u8_x(pg: svbool_t, op1: svuint8_t, op2: svuint8_t, op3: svuint8_t) -> svuint8_t {
    svmla_u8_m(pg, op1, op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub unsafe fn svmla_n_u8_x(pg: svbool_t, op1: svuint8_t, op2: svuint8_t, op3: u8) -> svuint8_t {
    svmla_u8_x(pg, op1, op2, svdup_n_u8(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub unsafe fn svmla_u8_z(pg: svbool_t, op1: svuint8_t, op2: svuint8_t, op3: svuint8_t) -> svuint8_t {
    svmla_u8_m(pg.clone(), svsel_u8(pg, op1, svdup_n_u8(0)), op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub unsafe fn svmla_n_u8_z(pg: svbool_t, op1: svuint8_t, op2: svuint8_t, op3: u8) -> svuint8_t {
    svmla_u8_z(pg, op1, op2, svdup_n_u8(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub unsafe fn svmla_u16_m(pg: svbool_t, op1: svuint16_t, op2: svuint16_t, op3: svuint16_t) -> svuint16_t {
    unsafe { svmla_s16_m(pg, op1.as_signed(), op2.as_signed(), op3.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub unsafe fn svmla_n_u16_m(pg: svbool_t, op1: svuint16_t, op2: svuint16_t, op3: u16) -> svuint16_t {
    svmla_u16_m(pg, op1, op2, svdup_n_u16(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub unsafe fn svmla_u16_x(pg: svbool_t, op1: svuint16_t, op2: svuint16_t, op3: svuint16_t) -> svuint16_t {
    svmla_u16_m(pg, op1, op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub unsafe fn svmla_n_u16_x(pg: svbool_t, op1: svuint16_t, op2: svuint16_t, op3: u16) -> svuint16_t {
    svmla_u16_x(pg, op1, op2, svdup_n_u16(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub unsafe fn svmla_u16_z(pg: svbool_t, op1: svuint16_t, op2: svuint16_t, op3: svuint16_t) -> svuint16_t {
    svmla_u16_m(pg.clone(), svsel_u16(pg, op1, svdup_n_u16(0)), op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub unsafe fn svmla_n_u16_z(pg: svbool_t, op1: svuint16_t, op2: svuint16_t, op3: u16) -> svuint16_t {
    svmla_u16_z(pg, op1, op2, svdup_n_u16(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub unsafe fn svmla_u32_m(pg: svbool_t, op1: svuint32_t, op2: svuint32_t, op3: svuint32_t) -> svuint32_t {
    unsafe { svmla_s32_m(pg, op1.as_signed(), op2.as_signed(), op3.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub unsafe fn svmla_n_u32_m(pg: svbool_t, op1: svuint32_t, op2: svuint32_t, op3: u32) -> svuint32_t {
    svmla_u32_m(pg, op1, op2, svdup_n_u32(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub unsafe fn svmla_u32_x(pg: svbool_t, op1: svuint32_t, op2: svuint32_t, op3: svuint32_t) -> svuint32_t {
    svmla_u32_m(pg, op1, op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub unsafe fn svmla_n_u32_x(pg: svbool_t, op1: svuint32_t, op2: svuint32_t, op3: u32) -> svuint32_t {
    svmla_u32_x(pg, op1, op2, svdup_n_u32(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub unsafe fn svmla_u32_z(pg: svbool_t, op1: svuint32_t, op2: svuint32_t, op3: svuint32_t) -> svuint32_t {
    svmla_u32_m(pg.clone(), svsel_u32(pg, op1, svdup_n_u32(0)), op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub unsafe fn svmla_n_u32_z(pg: svbool_t, op1: svuint32_t, op2: svuint32_t, op3: u32) -> svuint32_t {
    svmla_u32_z(pg, op1, op2, svdup_n_u32(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub unsafe fn svmla_u64_m(pg: svbool_t, op1: svuint64_t, op2: svuint64_t, op3: svuint64_t) -> svuint64_t {
    unsafe { svmla_s64_m(pg, op1.as_signed(), op2.as_signed(), op3.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub unsafe fn svmla_n_u64_m(pg: svbool_t, op1: svuint64_t, op2: svuint64_t, op3: u64) -> svuint64_t {
    svmla_u64_m(pg, op1, op2, svdup_n_u64(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub unsafe fn svmla_u64_x(pg: svbool_t, op1: svuint64_t, op2: svuint64_t, op3: svuint64_t) -> svuint64_t {
    svmla_u64_m(pg, op1, op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub unsafe fn svmla_n_u64_x(pg: svbool_t, op1: svuint64_t, op2: svuint64_t, op3: u64) -> svuint64_t {
    svmla_u64_x(pg, op1, op2, svdup_n_u64(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub unsafe fn svmla_u64_z(pg: svbool_t, op1: svuint64_t, op2: svuint64_t, op3: svuint64_t) -> svuint64_t {
    svmla_u64_m(pg.clone(), svsel_u64(pg, op1, svdup_n_u64(0)), op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub unsafe fn svmla_n_u64_z(pg: svbool_t, op1: svuint64_t, op2: svuint64_t, op3: u64) -> svuint64_t {
    svmla_u64_z(pg, op1, op2, svdup_n_u64(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmla, IMM_INDEX = 0))]
pub unsafe fn svmla_lane_f32<const IMM_INDEX: i32>(
    op1: svfloat32_t,
    op2: svfloat32_t,
    op3: svfloat32_t,
) -> svfloat32_t {
    static_assert_range!(IMM_INDEX, 0, 3);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.fmla.lane.nxv4f32"
        )]
        fn _svmla_lane_f32(
            op1: svfloat32_t,
            op2: svfloat32_t,
            op3: svfloat32_t,
            IMM_INDEX: i32,
        ) -> svfloat32_t;
    }
    unsafe { _svmla_lane_f32(op1, op2, op3, IMM_INDEX) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmla, IMM_INDEX = 0))]
pub unsafe fn svmla_lane_f64<const IMM_INDEX: i32>(
    op1: svfloat64_t,
    op2: svfloat64_t,
    op3: svfloat64_t,
) -> svfloat64_t {
    static_assert_range!(IMM_INDEX, 0, 1);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.fmla.lane.nxv2f64"
        )]
        fn _svmla_lane_f64(
            op1: svfloat64_t,
            op2: svfloat64_t,
            op3: svfloat64_t,
            IMM_INDEX: i32,
        ) -> svfloat64_t;
    }
    unsafe { _svmla_lane_f64(op1, op2, op3, IMM_INDEX) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmls))]
pub unsafe fn svmls_f32_m(
    pg: svbool_t,
    op1: svfloat32_t,
    op2: svfloat32_t,
    op3: svfloat32_t,
) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fmls.nxv4f32")]
        fn _svmls_f32_m(
            pg: svbool4_t,
            op1: svfloat32_t,
            op2: svfloat32_t,
            op3: svfloat32_t,
        ) -> svfloat32_t;
    }
    unsafe { _svmls_f32_m(pg.into(), op1, op2, op3) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmls))]
pub unsafe fn svmls_n_f32_m(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t, op3: f32) -> svfloat32_t {
    svmls_f32_m(pg, op1, op2, svdup_n_f32(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmls))]
pub unsafe fn svmls_f32_x(
    pg: svbool_t,
    op1: svfloat32_t,
    op2: svfloat32_t,
    op3: svfloat32_t,
) -> svfloat32_t {
    svmls_f32_m(pg, op1, op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmls))]
pub unsafe fn svmls_n_f32_x(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t, op3: f32) -> svfloat32_t {
    svmls_f32_x(pg, op1, op2, svdup_n_f32(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmls))]
pub unsafe fn svmls_f32_z(
    pg: svbool_t,
    op1: svfloat32_t,
    op2: svfloat32_t,
    op3: svfloat32_t,
) -> svfloat32_t {
    svmls_f32_m(pg.clone(), svsel_f32(pg, op1, svdup_n_f32(0.0)), op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmls))]
pub unsafe fn svmls_n_f32_z(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t, op3: f32) -> svfloat32_t {
    svmls_f32_z(pg, op1, op2, svdup_n_f32(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmls))]
pub unsafe fn svmls_f64_m(
    pg: svbool_t,
    op1: svfloat64_t,
    op2: svfloat64_t,
    op3: svfloat64_t,
) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fmls.nxv2f64")]
        fn _svmls_f64_m(
            pg: svbool2_t,
            op1: svfloat64_t,
            op2: svfloat64_t,
            op3: svfloat64_t,
        ) -> svfloat64_t;
    }
    unsafe { _svmls_f64_m(pg.into(), op1, op2, op3) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmls))]
pub unsafe fn svmls_n_f64_m(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t, op3: f64) -> svfloat64_t {
    svmls_f64_m(pg, op1, op2, svdup_n_f64(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmls))]
pub unsafe fn svmls_f64_x(
    pg: svbool_t,
    op1: svfloat64_t,
    op2: svfloat64_t,
    op3: svfloat64_t,
) -> svfloat64_t {
    svmls_f64_m(pg, op1, op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmls))]
pub unsafe fn svmls_n_f64_x(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t, op3: f64) -> svfloat64_t {
    svmls_f64_x(pg, op1, op2, svdup_n_f64(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmls))]
pub unsafe fn svmls_f64_z(
    pg: svbool_t,
    op1: svfloat64_t,
    op2: svfloat64_t,
    op3: svfloat64_t,
) -> svfloat64_t {
    svmls_f64_m(pg.clone(), svsel_f64(pg, op1, svdup_n_f64(0.0)), op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmls))]
pub unsafe fn svmls_n_f64_z(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t, op3: f64) -> svfloat64_t {
    svmls_f64_z(pg, op1, op2, svdup_n_f64(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub unsafe fn svmls_s8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t, op3: svint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.mls.nxv16i8")]
        fn _svmls_s8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t, op3: svint8_t) -> svint8_t;
    }
    unsafe { _svmls_s8_m(pg, op1, op2, op3) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub unsafe fn svmls_n_s8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t, op3: i8) -> svint8_t {
    svmls_s8_m(pg, op1, op2, svdup_n_s8(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub unsafe fn svmls_s8_x(pg: svbool_t, op1: svint8_t, op2: svint8_t, op3: svint8_t) -> svint8_t {
    svmls_s8_m(pg, op1, op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub unsafe fn svmls_n_s8_x(pg: svbool_t, op1: svint8_t, op2: svint8_t, op3: i8) -> svint8_t {
    svmls_s8_x(pg, op1, op2, svdup_n_s8(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub unsafe fn svmls_s8_z(pg: svbool_t, op1: svint8_t, op2: svint8_t, op3: svint8_t) -> svint8_t {
    svmls_s8_m(pg.clone(), svsel_s8(pg, op1, svdup_n_s8(0)), op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub unsafe fn svmls_n_s8_z(pg: svbool_t, op1: svint8_t, op2: svint8_t, op3: i8) -> svint8_t {
    svmls_s8_z(pg, op1, op2, svdup_n_s8(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub unsafe fn svmls_s16_m(pg: svbool_t, op1: svint16_t, op2: svint16_t, op3: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.mls.nxv8i16")]
        fn _svmls_s16_m(pg: svbool8_t, op1: svint16_t, op2: svint16_t, op3: svint16_t)
            -> svint16_t;
    }
    unsafe { _svmls_s16_m(pg.into(), op1, op2, op3) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub unsafe fn svmls_n_s16_m(pg: svbool_t, op1: svint16_t, op2: svint16_t, op3: i16) -> svint16_t {
    svmls_s16_m(pg, op1, op2, svdup_n_s16(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub unsafe fn svmls_s16_x(pg: svbool_t, op1: svint16_t, op2: svint16_t, op3: svint16_t) -> svint16_t {
    svmls_s16_m(pg, op1, op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub unsafe fn svmls_n_s16_x(pg: svbool_t, op1: svint16_t, op2: svint16_t, op3: i16) -> svint16_t {
    svmls_s16_x(pg, op1, op2, svdup_n_s16(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub unsafe fn svmls_s16_z(pg: svbool_t, op1: svint16_t, op2: svint16_t, op3: svint16_t) -> svint16_t {
    svmls_s16_m(pg.clone(), svsel_s16(pg, op1, svdup_n_s16(0)), op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub unsafe fn svmls_n_s16_z(pg: svbool_t, op1: svint16_t, op2: svint16_t, op3: i16) -> svint16_t {
    svmls_s16_z(pg, op1, op2, svdup_n_s16(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub unsafe fn svmls_s32_m(pg: svbool_t, op1: svint32_t, op2: svint32_t, op3: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.mls.nxv4i32")]
        fn _svmls_s32_m(pg: svbool4_t, op1: svint32_t, op2: svint32_t, op3: svint32_t)
            -> svint32_t;
    }
    unsafe { _svmls_s32_m(pg.into(), op1, op2, op3) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub unsafe fn svmls_n_s32_m(pg: svbool_t, op1: svint32_t, op2: svint32_t, op3: i32) -> svint32_t {
    svmls_s32_m(pg, op1, op2, svdup_n_s32(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub unsafe fn svmls_s32_x(pg: svbool_t, op1: svint32_t, op2: svint32_t, op3: svint32_t) -> svint32_t {
    svmls_s32_m(pg, op1, op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub unsafe fn svmls_n_s32_x(pg: svbool_t, op1: svint32_t, op2: svint32_t, op3: i32) -> svint32_t {
    svmls_s32_x(pg, op1, op2, svdup_n_s32(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub unsafe fn svmls_s32_z(pg: svbool_t, op1: svint32_t, op2: svint32_t, op3: svint32_t) -> svint32_t {
    svmls_s32_m(pg.clone(), svsel_s32(pg, op1, svdup_n_s32(0)), op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub unsafe fn svmls_n_s32_z(pg: svbool_t, op1: svint32_t, op2: svint32_t, op3: i32) -> svint32_t {
    svmls_s32_z(pg, op1, op2, svdup_n_s32(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub unsafe fn svmls_s64_m(pg: svbool_t, op1: svint64_t, op2: svint64_t, op3: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.mls.nxv2i64")]
        fn _svmls_s64_m(pg: svbool2_t, op1: svint64_t, op2: svint64_t, op3: svint64_t)
            -> svint64_t;
    }
    unsafe { _svmls_s64_m(pg.into(), op1, op2, op3) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub unsafe fn svmls_n_s64_m(pg: svbool_t, op1: svint64_t, op2: svint64_t, op3: i64) -> svint64_t {
    svmls_s64_m(pg, op1, op2, svdup_n_s64(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub unsafe fn svmls_s64_x(pg: svbool_t, op1: svint64_t, op2: svint64_t, op3: svint64_t) -> svint64_t {
    svmls_s64_m(pg, op1, op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub unsafe fn svmls_n_s64_x(pg: svbool_t, op1: svint64_t, op2: svint64_t, op3: i64) -> svint64_t {
    svmls_s64_x(pg, op1, op2, svdup_n_s64(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub unsafe fn svmls_s64_z(pg: svbool_t, op1: svint64_t, op2: svint64_t, op3: svint64_t) -> svint64_t {
    svmls_s64_m(pg.clone(), svsel_s64(pg, op1, svdup_n_s64(0)), op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub unsafe fn svmls_n_s64_z(pg: svbool_t, op1: svint64_t, op2: svint64_t, op3: i64) -> svint64_t {
    svmls_s64_z(pg, op1, op2, svdup_n_s64(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub unsafe fn svmls_u8_m(pg: svbool_t, op1: svuint8_t, op2: svuint8_t, op3: svuint8_t) -> svuint8_t {
    unsafe { svmls_s8_m(pg, op1.as_signed(), op2.as_signed(), op3.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub unsafe fn svmls_n_u8_m(pg: svbool_t, op1: svuint8_t, op2: svuint8_t, op3: u8) -> svuint8_t {
    svmls_u8_m(pg, op1, op2, svdup_n_u8(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub unsafe fn svmls_u8_x(pg: svbool_t, op1: svuint8_t, op2: svuint8_t, op3: svuint8_t) -> svuint8_t {
    svmls_u8_m(pg, op1, op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub unsafe fn svmls_n_u8_x(pg: svbool_t, op1: svuint8_t, op2: svuint8_t, op3: u8) -> svuint8_t {
    svmls_u8_x(pg, op1, op2, svdup_n_u8(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub unsafe fn svmls_u8_z(pg: svbool_t, op1: svuint8_t, op2: svuint8_t, op3: svuint8_t) -> svuint8_t {
    svmls_u8_m(pg.clone(), svsel_u8(pg, op1, svdup_n_u8(0)), op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub unsafe fn svmls_n_u8_z(pg: svbool_t, op1: svuint8_t, op2: svuint8_t, op3: u8) -> svuint8_t {
    svmls_u8_z(pg, op1, op2, svdup_n_u8(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub unsafe fn svmls_u16_m(pg: svbool_t, op1: svuint16_t, op2: svuint16_t, op3: svuint16_t) -> svuint16_t {
    unsafe { svmls_s16_m(pg, op1.as_signed(), op2.as_signed(), op3.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub unsafe fn svmls_n_u16_m(pg: svbool_t, op1: svuint16_t, op2: svuint16_t, op3: u16) -> svuint16_t {
    svmls_u16_m(pg, op1, op2, svdup_n_u16(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub unsafe fn svmls_u16_x(pg: svbool_t, op1: svuint16_t, op2: svuint16_t, op3: svuint16_t) -> svuint16_t {
    svmls_u16_m(pg, op1, op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub unsafe fn svmls_n_u16_x(pg: svbool_t, op1: svuint16_t, op2: svuint16_t, op3: u16) -> svuint16_t {
    svmls_u16_x(pg, op1, op2, svdup_n_u16(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub unsafe fn svmls_u16_z(pg: svbool_t, op1: svuint16_t, op2: svuint16_t, op3: svuint16_t) -> svuint16_t {
    svmls_u16_m(pg.clone(), svsel_u16(pg, op1, svdup_n_u16(0)), op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub unsafe fn svmls_n_u16_z(pg: svbool_t, op1: svuint16_t, op2: svuint16_t, op3: u16) -> svuint16_t {
    svmls_u16_z(pg, op1, op2, svdup_n_u16(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub unsafe fn svmls_u32_m(pg: svbool_t, op1: svuint32_t, op2: svuint32_t, op3: svuint32_t) -> svuint32_t {
    unsafe { svmls_s32_m(pg, op1.as_signed(), op2.as_signed(), op3.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub unsafe fn svmls_n_u32_m(pg: svbool_t, op1: svuint32_t, op2: svuint32_t, op3: u32) -> svuint32_t {
    svmls_u32_m(pg, op1, op2, svdup_n_u32(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub unsafe fn svmls_u32_x(pg: svbool_t, op1: svuint32_t, op2: svuint32_t, op3: svuint32_t) -> svuint32_t {
    svmls_u32_m(pg, op1, op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub unsafe fn svmls_n_u32_x(pg: svbool_t, op1: svuint32_t, op2: svuint32_t, op3: u32) -> svuint32_t {
    svmls_u32_x(pg, op1, op2, svdup_n_u32(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub unsafe fn svmls_u32_z(pg: svbool_t, op1: svuint32_t, op2: svuint32_t, op3: svuint32_t) -> svuint32_t {
    svmls_u32_m(pg.clone(), svsel_u32(pg, op1, svdup_n_u32(0)), op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub unsafe fn svmls_n_u32_z(pg: svbool_t, op1: svuint32_t, op2: svuint32_t, op3: u32) -> svuint32_t {
    svmls_u32_z(pg, op1, op2, svdup_n_u32(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub unsafe fn svmls_u64_m(pg: svbool_t, op1: svuint64_t, op2: svuint64_t, op3: svuint64_t) -> svuint64_t {
    unsafe { svmls_s64_m(pg, op1.as_signed(), op2.as_signed(), op3.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub unsafe fn svmls_n_u64_m(pg: svbool_t, op1: svuint64_t, op2: svuint64_t, op3: u64) -> svuint64_t {
    svmls_u64_m(pg, op1, op2, svdup_n_u64(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub unsafe fn svmls_u64_x(pg: svbool_t, op1: svuint64_t, op2: svuint64_t, op3: svuint64_t) -> svuint64_t {
    svmls_u64_m(pg, op1, op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub unsafe fn svmls_n_u64_x(pg: svbool_t, op1: svuint64_t, op2: svuint64_t, op3: u64) -> svuint64_t {
    svmls_u64_x(pg, op1, op2, svdup_n_u64(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub unsafe fn svmls_u64_z(pg: svbool_t, op1: svuint64_t, op2: svuint64_t, op3: svuint64_t) -> svuint64_t {
    svmls_u64_m(pg.clone(), svsel_u64(pg, op1, svdup_n_u64(0)), op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub unsafe fn svmls_n_u64_z(pg: svbool_t, op1: svuint64_t, op2: svuint64_t, op3: u64) -> svuint64_t {
    svmls_u64_z(pg, op1, op2, svdup_n_u64(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmls, IMM_INDEX = 0))]
pub unsafe fn svmls_lane_f32<const IMM_INDEX: i32>(
    op1: svfloat32_t,
    op2: svfloat32_t,
    op3: svfloat32_t,
) -> svfloat32_t {
    static_assert_range!(IMM_INDEX, 0, 3);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.fmls.lane.nxv4f32"
        )]
        fn _svmls_lane_f32(
            op1: svfloat32_t,
            op2: svfloat32_t,
            op3: svfloat32_t,
            IMM_INDEX: i32,
        ) -> svfloat32_t;
    }
    unsafe { _svmls_lane_f32(op1, op2, op3, IMM_INDEX) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmls, IMM_INDEX = 0))]
pub unsafe fn svmls_lane_f64<const IMM_INDEX: i32>(
    op1: svfloat64_t,
    op2: svfloat64_t,
    op3: svfloat64_t,
) -> svfloat64_t {
    static_assert_range!(IMM_INDEX, 0, 1);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.fmls.lane.nxv2f64"
        )]
        fn _svmls_lane_f64(
            op1: svfloat64_t,
            op2: svfloat64_t,
            op3: svfloat64_t,
            IMM_INDEX: i32,
        ) -> svfloat64_t;
    }
    unsafe { _svmls_lane_f64(op1, op2, op3, IMM_INDEX) }
}
#[inline]
#[target_feature(enable = "sve,f32mm")]
#[cfg_attr(test, assert_instr(fmmla))]
pub unsafe fn svmmla_f32(op1: svfloat32_t, op2: svfloat32_t, op3: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fmmla.nxv4f32")]
        fn _svmmla_f32(op1: svfloat32_t, op2: svfloat32_t, op3: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svmmla_f32(op1, op2, op3) }
}
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(fmmla))]
pub unsafe fn svmmla_f64(op1: svfloat64_t, op2: svfloat64_t, op3: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fmmla.nxv2f64")]
        fn _svmmla_f64(op1: svfloat64_t, op2: svfloat64_t, op3: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svmmla_f64(op1, op2, op3) }
}
#[inline]
#[target_feature(enable = "sve,i8mm")]
#[cfg_attr(test, assert_instr(smmla))]
pub unsafe fn svmmla_s32(op1: svint32_t, op2: svint8_t, op3: svint8_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.smmla.nxv4i32")]
        fn _svmmla_s32(op1: svint32_t, op2: svint8_t, op3: svint8_t) -> svint32_t;
    }
    unsafe { _svmmla_s32(op1, op2, op3) }
}
#[inline]
#[target_feature(enable = "sve,i8mm")]
#[cfg_attr(test, assert_instr(ummla))]
pub unsafe fn svmmla_u32(op1: svuint32_t, op2: svuint8_t, op3: svuint8_t) -> svuint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ummla.nxv4i32")]
        fn _svmmla_u32(op1: svint32_t, op2: svint8_t, op3: svint8_t) -> svint32_t;
    }
    unsafe { _svmmla_u32(op1.as_signed(), op2.as_signed(), op3.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub unsafe fn svmov_b_z(pg: svbool_t, op: svbool_t) -> svbool_t {
    svand_b_z(pg, op.clone(), op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmsb))]
pub unsafe fn svmsb_f32_m(
    pg: svbool_t,
    op1: svfloat32_t,
    op2: svfloat32_t,
    op3: svfloat32_t,
) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fmsb.nxv4f32")]
        fn _svmsb_f32_m(
            pg: svbool4_t,
            op1: svfloat32_t,
            op2: svfloat32_t,
            op3: svfloat32_t,
        ) -> svfloat32_t;
    }
    unsafe { _svmsb_f32_m(pg.into(), op1, op2, op3) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmsb))]
pub unsafe fn svmsb_n_f32_m(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t, op3: f32) -> svfloat32_t {
    svmsb_f32_m(pg, op1, op2, svdup_n_f32(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmsb))]
pub unsafe fn svmsb_f32_x(
    pg: svbool_t,
    op1: svfloat32_t,
    op2: svfloat32_t,
    op3: svfloat32_t,
) -> svfloat32_t {
    svmsb_f32_m(pg, op1, op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmsb))]
pub unsafe fn svmsb_n_f32_x(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t, op3: f32) -> svfloat32_t {
    svmsb_f32_x(pg, op1, op2, svdup_n_f32(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmsb))]
pub unsafe fn svmsb_f32_z(
    pg: svbool_t,
    op1: svfloat32_t,
    op2: svfloat32_t,
    op3: svfloat32_t,
) -> svfloat32_t {
    svmsb_f32_m(pg.clone(), svsel_f32(pg, op1, svdup_n_f32(0.0)), op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmsb))]
pub unsafe fn svmsb_n_f32_z(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t, op3: f32) -> svfloat32_t {
    svmsb_f32_z(pg, op1, op2, svdup_n_f32(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmsb))]
pub unsafe fn svmsb_f64_m(
    pg: svbool_t,
    op1: svfloat64_t,
    op2: svfloat64_t,
    op3: svfloat64_t,
) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fmsb.nxv2f64")]
        fn _svmsb_f64_m(
            pg: svbool2_t,
            op1: svfloat64_t,
            op2: svfloat64_t,
            op3: svfloat64_t,
        ) -> svfloat64_t;
    }
    unsafe { _svmsb_f64_m(pg.into(), op1, op2, op3) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmsb))]
pub unsafe fn svmsb_n_f64_m(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t, op3: f64) -> svfloat64_t {
    svmsb_f64_m(pg, op1, op2, svdup_n_f64(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmsb))]
pub unsafe fn svmsb_f64_x(
    pg: svbool_t,
    op1: svfloat64_t,
    op2: svfloat64_t,
    op3: svfloat64_t,
) -> svfloat64_t {
    svmsb_f64_m(pg, op1, op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmsb))]
pub unsafe fn svmsb_n_f64_x(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t, op3: f64) -> svfloat64_t {
    svmsb_f64_x(pg, op1, op2, svdup_n_f64(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmsb))]
pub unsafe fn svmsb_f64_z(
    pg: svbool_t,
    op1: svfloat64_t,
    op2: svfloat64_t,
    op3: svfloat64_t,
) -> svfloat64_t {
    svmsb_f64_m(pg.clone(), svsel_f64(pg, op1, svdup_n_f64(0.0)), op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmsb))]
pub unsafe fn svmsb_n_f64_z(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t, op3: f64) -> svfloat64_t {
    svmsb_f64_z(pg, op1, op2, svdup_n_f64(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub unsafe fn svmsb_s8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t, op3: svint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.msb.nxv16i8")]
        fn _svmsb_s8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t, op3: svint8_t) -> svint8_t;
    }
    unsafe { _svmsb_s8_m(pg, op1, op2, op3) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub unsafe fn svmsb_n_s8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t, op3: i8) -> svint8_t {
    svmsb_s8_m(pg, op1, op2, svdup_n_s8(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub unsafe fn svmsb_s8_x(pg: svbool_t, op1: svint8_t, op2: svint8_t, op3: svint8_t) -> svint8_t {
    svmsb_s8_m(pg, op1, op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub unsafe fn svmsb_n_s8_x(pg: svbool_t, op1: svint8_t, op2: svint8_t, op3: i8) -> svint8_t {
    svmsb_s8_x(pg, op1, op2, svdup_n_s8(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub unsafe fn svmsb_s8_z(pg: svbool_t, op1: svint8_t, op2: svint8_t, op3: svint8_t) -> svint8_t {
    svmsb_s8_m(pg.clone(), svsel_s8(pg, op1, svdup_n_s8(0)), op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub unsafe fn svmsb_n_s8_z(pg: svbool_t, op1: svint8_t, op2: svint8_t, op3: i8) -> svint8_t {
    svmsb_s8_z(pg, op1, op2, svdup_n_s8(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub unsafe fn svmsb_s16_m(pg: svbool_t, op1: svint16_t, op2: svint16_t, op3: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.msb.nxv8i16")]
        fn _svmsb_s16_m(pg: svbool8_t, op1: svint16_t, op2: svint16_t, op3: svint16_t)
            -> svint16_t;
    }
    unsafe { _svmsb_s16_m(pg.into(), op1, op2, op3) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub unsafe fn svmsb_n_s16_m(pg: svbool_t, op1: svint16_t, op2: svint16_t, op3: i16) -> svint16_t {
    svmsb_s16_m(pg, op1, op2, svdup_n_s16(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub unsafe fn svmsb_s16_x(pg: svbool_t, op1: svint16_t, op2: svint16_t, op3: svint16_t) -> svint16_t {
    svmsb_s16_m(pg, op1, op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub unsafe fn svmsb_n_s16_x(pg: svbool_t, op1: svint16_t, op2: svint16_t, op3: i16) -> svint16_t {
    svmsb_s16_x(pg, op1, op2, svdup_n_s16(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub unsafe fn svmsb_s16_z(pg: svbool_t, op1: svint16_t, op2: svint16_t, op3: svint16_t) -> svint16_t {
    svmsb_s16_m(pg.clone(), svsel_s16(pg, op1, svdup_n_s16(0)), op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub unsafe fn svmsb_n_s16_z(pg: svbool_t, op1: svint16_t, op2: svint16_t, op3: i16) -> svint16_t {
    svmsb_s16_z(pg, op1, op2, svdup_n_s16(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub unsafe fn svmsb_s32_m(pg: svbool_t, op1: svint32_t, op2: svint32_t, op3: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.msb.nxv4i32")]
        fn _svmsb_s32_m(pg: svbool4_t, op1: svint32_t, op2: svint32_t, op3: svint32_t)
            -> svint32_t;
    }
    unsafe { _svmsb_s32_m(pg.into(), op1, op2, op3) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub unsafe fn svmsb_n_s32_m(pg: svbool_t, op1: svint32_t, op2: svint32_t, op3: i32) -> svint32_t {
    svmsb_s32_m(pg, op1, op2, svdup_n_s32(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub unsafe fn svmsb_s32_x(pg: svbool_t, op1: svint32_t, op2: svint32_t, op3: svint32_t) -> svint32_t {
    svmsb_s32_m(pg, op1, op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub unsafe fn svmsb_n_s32_x(pg: svbool_t, op1: svint32_t, op2: svint32_t, op3: i32) -> svint32_t {
    svmsb_s32_x(pg, op1, op2, svdup_n_s32(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub unsafe fn svmsb_s32_z(pg: svbool_t, op1: svint32_t, op2: svint32_t, op3: svint32_t) -> svint32_t {
    svmsb_s32_m(pg.clone(), svsel_s32(pg, op1, svdup_n_s32(0)), op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub unsafe fn svmsb_n_s32_z(pg: svbool_t, op1: svint32_t, op2: svint32_t, op3: i32) -> svint32_t {
    svmsb_s32_z(pg, op1, op2, svdup_n_s32(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub unsafe fn svmsb_s64_m(pg: svbool_t, op1: svint64_t, op2: svint64_t, op3: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.msb.nxv2i64")]
        fn _svmsb_s64_m(pg: svbool2_t, op1: svint64_t, op2: svint64_t, op3: svint64_t)
            -> svint64_t;
    }
    unsafe { _svmsb_s64_m(pg.into(), op1, op2, op3) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub unsafe fn svmsb_n_s64_m(pg: svbool_t, op1: svint64_t, op2: svint64_t, op3: i64) -> svint64_t {
    svmsb_s64_m(pg, op1, op2, svdup_n_s64(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub unsafe fn svmsb_s64_x(pg: svbool_t, op1: svint64_t, op2: svint64_t, op3: svint64_t) -> svint64_t {
    svmsb_s64_m(pg, op1, op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub unsafe fn svmsb_n_s64_x(pg: svbool_t, op1: svint64_t, op2: svint64_t, op3: i64) -> svint64_t {
    svmsb_s64_x(pg, op1, op2, svdup_n_s64(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub unsafe fn svmsb_s64_z(pg: svbool_t, op1: svint64_t, op2: svint64_t, op3: svint64_t) -> svint64_t {
    svmsb_s64_m(pg.clone(), svsel_s64(pg, op1, svdup_n_s64(0)), op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub unsafe fn svmsb_n_s64_z(pg: svbool_t, op1: svint64_t, op2: svint64_t, op3: i64) -> svint64_t {
    svmsb_s64_z(pg, op1, op2, svdup_n_s64(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub unsafe fn svmsb_u8_m(pg: svbool_t, op1: svuint8_t, op2: svuint8_t, op3: svuint8_t) -> svuint8_t {
    unsafe { svmsb_s8_m(pg, op1.as_signed(), op2.as_signed(), op3.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub unsafe fn svmsb_n_u8_m(pg: svbool_t, op1: svuint8_t, op2: svuint8_t, op3: u8) -> svuint8_t {
    svmsb_u8_m(pg, op1, op2, svdup_n_u8(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub unsafe fn svmsb_u8_x(pg: svbool_t, op1: svuint8_t, op2: svuint8_t, op3: svuint8_t) -> svuint8_t {
    svmsb_u8_m(pg, op1, op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub unsafe fn svmsb_n_u8_x(pg: svbool_t, op1: svuint8_t, op2: svuint8_t, op3: u8) -> svuint8_t {
    svmsb_u8_x(pg, op1, op2, svdup_n_u8(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub unsafe fn svmsb_u8_z(pg: svbool_t, op1: svuint8_t, op2: svuint8_t, op3: svuint8_t) -> svuint8_t {
    svmsb_u8_m(pg.clone(), svsel_u8(pg, op1, svdup_n_u8(0)), op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub unsafe fn svmsb_n_u8_z(pg: svbool_t, op1: svuint8_t, op2: svuint8_t, op3: u8) -> svuint8_t {
    svmsb_u8_z(pg, op1, op2, svdup_n_u8(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub unsafe fn svmsb_u16_m(pg: svbool_t, op1: svuint16_t, op2: svuint16_t, op3: svuint16_t) -> svuint16_t {
    unsafe { svmsb_s16_m(pg, op1.as_signed(), op2.as_signed(), op3.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub unsafe fn svmsb_n_u16_m(pg: svbool_t, op1: svuint16_t, op2: svuint16_t, op3: u16) -> svuint16_t {
    svmsb_u16_m(pg, op1, op2, svdup_n_u16(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub unsafe fn svmsb_u16_x(pg: svbool_t, op1: svuint16_t, op2: svuint16_t, op3: svuint16_t) -> svuint16_t {
    svmsb_u16_m(pg, op1, op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub unsafe fn svmsb_n_u16_x(pg: svbool_t, op1: svuint16_t, op2: svuint16_t, op3: u16) -> svuint16_t {
    svmsb_u16_x(pg, op1, op2, svdup_n_u16(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub unsafe fn svmsb_u16_z(pg: svbool_t, op1: svuint16_t, op2: svuint16_t, op3: svuint16_t) -> svuint16_t {
    svmsb_u16_m(pg.clone(), svsel_u16(pg, op1, svdup_n_u16(0)), op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub unsafe fn svmsb_n_u16_z(pg: svbool_t, op1: svuint16_t, op2: svuint16_t, op3: u16) -> svuint16_t {
    svmsb_u16_z(pg, op1, op2, svdup_n_u16(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub unsafe fn svmsb_u32_m(pg: svbool_t, op1: svuint32_t, op2: svuint32_t, op3: svuint32_t) -> svuint32_t {
    unsafe { svmsb_s32_m(pg, op1.as_signed(), op2.as_signed(), op3.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub unsafe fn svmsb_n_u32_m(pg: svbool_t, op1: svuint32_t, op2: svuint32_t, op3: u32) -> svuint32_t {
    svmsb_u32_m(pg, op1, op2, svdup_n_u32(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub unsafe fn svmsb_u32_x(pg: svbool_t, op1: svuint32_t, op2: svuint32_t, op3: svuint32_t) -> svuint32_t {
    svmsb_u32_m(pg, op1, op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub unsafe fn svmsb_n_u32_x(pg: svbool_t, op1: svuint32_t, op2: svuint32_t, op3: u32) -> svuint32_t {
    svmsb_u32_x(pg, op1, op2, svdup_n_u32(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub unsafe fn svmsb_u32_z(pg: svbool_t, op1: svuint32_t, op2: svuint32_t, op3: svuint32_t) -> svuint32_t {
    svmsb_u32_m(pg.clone(), svsel_u32(pg, op1, svdup_n_u32(0)), op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub unsafe fn svmsb_n_u32_z(pg: svbool_t, op1: svuint32_t, op2: svuint32_t, op3: u32) -> svuint32_t {
    svmsb_u32_z(pg, op1, op2, svdup_n_u32(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub unsafe fn svmsb_u64_m(pg: svbool_t, op1: svuint64_t, op2: svuint64_t, op3: svuint64_t) -> svuint64_t {
    unsafe { svmsb_s64_m(pg, op1.as_signed(), op2.as_signed(), op3.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub unsafe fn svmsb_n_u64_m(pg: svbool_t, op1: svuint64_t, op2: svuint64_t, op3: u64) -> svuint64_t {
    svmsb_u64_m(pg, op1, op2, svdup_n_u64(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub unsafe fn svmsb_u64_x(pg: svbool_t, op1: svuint64_t, op2: svuint64_t, op3: svuint64_t) -> svuint64_t {
    svmsb_u64_m(pg, op1, op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub unsafe fn svmsb_n_u64_x(pg: svbool_t, op1: svuint64_t, op2: svuint64_t, op3: u64) -> svuint64_t {
    svmsb_u64_x(pg, op1, op2, svdup_n_u64(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub unsafe fn svmsb_u64_z(pg: svbool_t, op1: svuint64_t, op2: svuint64_t, op3: svuint64_t) -> svuint64_t {
    svmsb_u64_m(pg.clone(), svsel_u64(pg, op1, svdup_n_u64(0)), op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub unsafe fn svmsb_n_u64_z(pg: svbool_t, op1: svuint64_t, op2: svuint64_t, op3: u64) -> svuint64_t {
    svmsb_u64_z(pg, op1, op2, svdup_n_u64(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmul))]
pub unsafe fn svmul_f32_m(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fmul.nxv4f32")]
        fn _svmul_f32_m(pg: svbool4_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svmul_f32_m(pg.into(), op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmul))]
pub unsafe fn svmul_n_f32_m(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svfloat32_t {
    svmul_f32_m(pg, op1, svdup_n_f32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmul))]
pub unsafe fn svmul_f32_x(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    svmul_f32_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmul))]
pub unsafe fn svmul_n_f32_x(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svfloat32_t {
    svmul_f32_x(pg, op1, svdup_n_f32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmul))]
pub unsafe fn svmul_f32_z(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    svmul_f32_m(pg.clone(), svsel_f32(pg, op1, svdup_n_f32(0.0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmul))]
pub unsafe fn svmul_n_f32_z(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svfloat32_t {
    svmul_f32_z(pg, op1, svdup_n_f32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmul))]
pub unsafe fn svmul_f64_m(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fmul.nxv2f64")]
        fn _svmul_f64_m(pg: svbool2_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svmul_f64_m(pg.into(), op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmul))]
pub unsafe fn svmul_n_f64_m(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svfloat64_t {
    svmul_f64_m(pg, op1, svdup_n_f64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmul))]
pub unsafe fn svmul_f64_x(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    svmul_f64_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmul))]
pub unsafe fn svmul_n_f64_x(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svfloat64_t {
    svmul_f64_x(pg, op1, svdup_n_f64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmul))]
pub unsafe fn svmul_f64_z(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    svmul_f64_m(pg.clone(), svsel_f64(pg, op1, svdup_n_f64(0.0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmul))]
pub unsafe fn svmul_n_f64_z(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svfloat64_t {
    svmul_f64_z(pg, op1, svdup_n_f64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub unsafe fn svmul_s8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.mul.nxv16i8")]
        fn _svmul_s8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t;
    }
    unsafe { _svmul_s8_m(pg, op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub unsafe fn svmul_n_s8_m(pg: svbool_t, op1: svint8_t, op2: i8) -> svint8_t {
    svmul_s8_m(pg, op1, svdup_n_s8(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub unsafe fn svmul_s8_x(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t {
    svmul_s8_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub unsafe fn svmul_n_s8_x(pg: svbool_t, op1: svint8_t, op2: i8) -> svint8_t {
    svmul_s8_x(pg, op1, svdup_n_s8(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub unsafe fn svmul_s8_z(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t {
    svmul_s8_m(pg.clone(), svsel_s8(pg, op1, svdup_n_s8(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub unsafe fn svmul_n_s8_z(pg: svbool_t, op1: svint8_t, op2: i8) -> svint8_t {
    svmul_s8_z(pg, op1, svdup_n_s8(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub unsafe fn svmul_s16_m(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.mul.nxv8i16")]
        fn _svmul_s16_m(pg: svbool8_t, op1: svint16_t, op2: svint16_t) -> svint16_t;
    }
    unsafe { _svmul_s16_m(pg.into(), op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub unsafe fn svmul_n_s16_m(pg: svbool_t, op1: svint16_t, op2: i16) -> svint16_t {
    svmul_s16_m(pg, op1, svdup_n_s16(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub unsafe fn svmul_s16_x(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svint16_t {
    svmul_s16_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub unsafe fn svmul_n_s16_x(pg: svbool_t, op1: svint16_t, op2: i16) -> svint16_t {
    svmul_s16_x(pg, op1, svdup_n_s16(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub unsafe fn svmul_s16_z(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svint16_t {
    svmul_s16_m(pg.clone(), svsel_s16(pg, op1, svdup_n_s16(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub unsafe fn svmul_n_s16_z(pg: svbool_t, op1: svint16_t, op2: i16) -> svint16_t {
    svmul_s16_z(pg, op1, svdup_n_s16(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub unsafe fn svmul_s32_m(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.mul.nxv4i32")]
        fn _svmul_s32_m(pg: svbool4_t, op1: svint32_t, op2: svint32_t) -> svint32_t;
    }
    unsafe { _svmul_s32_m(pg.into(), op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub unsafe fn svmul_n_s32_m(pg: svbool_t, op1: svint32_t, op2: i32) -> svint32_t {
    svmul_s32_m(pg, op1, svdup_n_s32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub unsafe fn svmul_s32_x(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    svmul_s32_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub unsafe fn svmul_n_s32_x(pg: svbool_t, op1: svint32_t, op2: i32) -> svint32_t {
    svmul_s32_x(pg, op1, svdup_n_s32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub unsafe fn svmul_s32_z(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    svmul_s32_m(pg.clone(), svsel_s32(pg, op1, svdup_n_s32(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub unsafe fn svmul_n_s32_z(pg: svbool_t, op1: svint32_t, op2: i32) -> svint32_t {
    svmul_s32_z(pg, op1, svdup_n_s32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub unsafe fn svmul_s64_m(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.mul.nxv2i64")]
        fn _svmul_s64_m(pg: svbool2_t, op1: svint64_t, op2: svint64_t) -> svint64_t;
    }
    unsafe { _svmul_s64_m(pg.into(), op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub unsafe fn svmul_n_s64_m(pg: svbool_t, op1: svint64_t, op2: i64) -> svint64_t {
    svmul_s64_m(pg, op1, svdup_n_s64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub unsafe fn svmul_s64_x(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    svmul_s64_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub unsafe fn svmul_n_s64_x(pg: svbool_t, op1: svint64_t, op2: i64) -> svint64_t {
    svmul_s64_x(pg, op1, svdup_n_s64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub unsafe fn svmul_s64_z(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    svmul_s64_m(pg.clone(), svsel_s64(pg, op1, svdup_n_s64(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub unsafe fn svmul_n_s64_z(pg: svbool_t, op1: svint64_t, op2: i64) -> svint64_t {
    svmul_s64_z(pg, op1, svdup_n_s64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub unsafe fn svmul_u8_m(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    unsafe { svmul_s8_m(pg, op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub unsafe fn svmul_n_u8_m(pg: svbool_t, op1: svuint8_t, op2: u8) -> svuint8_t {
    svmul_u8_m(pg, op1, svdup_n_u8(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub unsafe fn svmul_u8_x(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    svmul_u8_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub unsafe fn svmul_n_u8_x(pg: svbool_t, op1: svuint8_t, op2: u8) -> svuint8_t {
    svmul_u8_x(pg, op1, svdup_n_u8(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub unsafe fn svmul_u8_z(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    svmul_u8_m(pg.clone(), svsel_u8(pg, op1, svdup_n_u8(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub unsafe fn svmul_n_u8_z(pg: svbool_t, op1: svuint8_t, op2: u8) -> svuint8_t {
    svmul_u8_z(pg, op1, svdup_n_u8(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub unsafe fn svmul_u16_m(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    unsafe { svmul_s16_m(pg, op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub unsafe fn svmul_n_u16_m(pg: svbool_t, op1: svuint16_t, op2: u16) -> svuint16_t {
    svmul_u16_m(pg, op1, svdup_n_u16(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub unsafe fn svmul_u16_x(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    svmul_u16_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub unsafe fn svmul_n_u16_x(pg: svbool_t, op1: svuint16_t, op2: u16) -> svuint16_t {
    svmul_u16_x(pg, op1, svdup_n_u16(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub unsafe fn svmul_u16_z(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    svmul_u16_m(pg.clone(), svsel_u16(pg, op1, svdup_n_u16(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub unsafe fn svmul_n_u16_z(pg: svbool_t, op1: svuint16_t, op2: u16) -> svuint16_t {
    svmul_u16_z(pg, op1, svdup_n_u16(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub unsafe fn svmul_u32_m(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    unsafe { svmul_s32_m(pg, op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub unsafe fn svmul_n_u32_m(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svmul_u32_m(pg, op1, svdup_n_u32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub unsafe fn svmul_u32_x(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    svmul_u32_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub unsafe fn svmul_n_u32_x(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svmul_u32_x(pg, op1, svdup_n_u32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub unsafe fn svmul_u32_z(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    svmul_u32_m(pg.clone(), svsel_u32(pg, op1, svdup_n_u32(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub unsafe fn svmul_n_u32_z(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svmul_u32_z(pg, op1, svdup_n_u32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub unsafe fn svmul_u64_m(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    unsafe { svmul_s64_m(pg, op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub unsafe fn svmul_n_u64_m(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svmul_u64_m(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub unsafe fn svmul_u64_x(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    svmul_u64_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub unsafe fn svmul_n_u64_x(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svmul_u64_x(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub unsafe fn svmul_u64_z(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    svmul_u64_m(pg.clone(), svsel_u64(pg, op1, svdup_n_u64(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub unsafe fn svmul_n_u64_z(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svmul_u64_z(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smulh))]
pub unsafe fn svmulh_s8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.smulh.nxv16i8")]
        fn _svmulh_s8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t;
    }
    unsafe { _svmulh_s8_m(pg, op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smulh))]
pub unsafe fn svmulh_n_s8_m(pg: svbool_t, op1: svint8_t, op2: i8) -> svint8_t {
    svmulh_s8_m(pg, op1, svdup_n_s8(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smulh))]
pub unsafe fn svmulh_s8_x(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t {
    svmulh_s8_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smulh))]
pub unsafe fn svmulh_n_s8_x(pg: svbool_t, op1: svint8_t, op2: i8) -> svint8_t {
    svmulh_s8_x(pg, op1, svdup_n_s8(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smulh))]
pub unsafe fn svmulh_s8_z(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t {
    svmulh_s8_m(pg.clone(), svsel_s8(pg, op1, svdup_n_s8(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smulh))]
pub unsafe fn svmulh_n_s8_z(pg: svbool_t, op1: svint8_t, op2: i8) -> svint8_t {
    svmulh_s8_z(pg, op1, svdup_n_s8(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smulh))]
pub unsafe fn svmulh_s16_m(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.smulh.nxv8i16")]
        fn _svmulh_s16_m(pg: svbool8_t, op1: svint16_t, op2: svint16_t) -> svint16_t;
    }
    unsafe { _svmulh_s16_m(pg.into(), op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smulh))]
pub unsafe fn svmulh_n_s16_m(pg: svbool_t, op1: svint16_t, op2: i16) -> svint16_t {
    svmulh_s16_m(pg, op1, svdup_n_s16(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smulh))]
pub unsafe fn svmulh_s16_x(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svint16_t {
    svmulh_s16_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smulh))]
pub unsafe fn svmulh_n_s16_x(pg: svbool_t, op1: svint16_t, op2: i16) -> svint16_t {
    svmulh_s16_x(pg, op1, svdup_n_s16(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smulh))]
pub unsafe fn svmulh_s16_z(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svint16_t {
    svmulh_s16_m(pg.clone(), svsel_s16(pg, op1, svdup_n_s16(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smulh))]
pub unsafe fn svmulh_n_s16_z(pg: svbool_t, op1: svint16_t, op2: i16) -> svint16_t {
    svmulh_s16_z(pg, op1, svdup_n_s16(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smulh))]
pub unsafe fn svmulh_s32_m(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.smulh.nxv4i32")]
        fn _svmulh_s32_m(pg: svbool4_t, op1: svint32_t, op2: svint32_t) -> svint32_t;
    }
    unsafe { _svmulh_s32_m(pg.into(), op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smulh))]
pub unsafe fn svmulh_n_s32_m(pg: svbool_t, op1: svint32_t, op2: i32) -> svint32_t {
    svmulh_s32_m(pg, op1, svdup_n_s32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smulh))]
pub unsafe fn svmulh_s32_x(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    svmulh_s32_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smulh))]
pub unsafe fn svmulh_n_s32_x(pg: svbool_t, op1: svint32_t, op2: i32) -> svint32_t {
    svmulh_s32_x(pg, op1, svdup_n_s32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smulh))]
pub unsafe fn svmulh_s32_z(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    svmulh_s32_m(pg.clone(), svsel_s32(pg, op1, svdup_n_s32(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smulh))]
pub unsafe fn svmulh_n_s32_z(pg: svbool_t, op1: svint32_t, op2: i32) -> svint32_t {
    svmulh_s32_z(pg, op1, svdup_n_s32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smulh))]
pub unsafe fn svmulh_s64_m(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.smulh.nxv2i64")]
        fn _svmulh_s64_m(pg: svbool2_t, op1: svint64_t, op2: svint64_t) -> svint64_t;
    }
    unsafe { _svmulh_s64_m(pg.into(), op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smulh))]
pub unsafe fn svmulh_n_s64_m(pg: svbool_t, op1: svint64_t, op2: i64) -> svint64_t {
    svmulh_s64_m(pg, op1, svdup_n_s64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smulh))]
pub unsafe fn svmulh_s64_x(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    svmulh_s64_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smulh))]
pub unsafe fn svmulh_n_s64_x(pg: svbool_t, op1: svint64_t, op2: i64) -> svint64_t {
    svmulh_s64_x(pg, op1, svdup_n_s64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smulh))]
pub unsafe fn svmulh_s64_z(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    svmulh_s64_m(pg.clone(), svsel_s64(pg, op1, svdup_n_s64(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smulh))]
pub unsafe fn svmulh_n_s64_z(pg: svbool_t, op1: svint64_t, op2: i64) -> svint64_t {
    svmulh_s64_z(pg, op1, svdup_n_s64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umulh))]
pub unsafe fn svmulh_u8_m(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.umulh.nxv16i8")]
        fn _svmulh_u8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t;
    }
    unsafe { _svmulh_u8_m(pg, op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umulh))]
pub unsafe fn svmulh_n_u8_m(pg: svbool_t, op1: svuint8_t, op2: u8) -> svuint8_t {
    svmulh_u8_m(pg, op1, svdup_n_u8(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umulh))]
pub unsafe fn svmulh_u8_x(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    svmulh_u8_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umulh))]
pub unsafe fn svmulh_n_u8_x(pg: svbool_t, op1: svuint8_t, op2: u8) -> svuint8_t {
    svmulh_u8_x(pg, op1, svdup_n_u8(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umulh))]
pub unsafe fn svmulh_u8_z(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    svmulh_u8_m(pg.clone(), svsel_u8(pg, op1, svdup_n_u8(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umulh))]
pub unsafe fn svmulh_n_u8_z(pg: svbool_t, op1: svuint8_t, op2: u8) -> svuint8_t {
    svmulh_u8_z(pg, op1, svdup_n_u8(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umulh))]
pub unsafe fn svmulh_u16_m(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.umulh.nxv8i16")]
        fn _svmulh_u16_m(pg: svbool8_t, op1: svint16_t, op2: svint16_t) -> svint16_t;
    }
    unsafe { _svmulh_u16_m(pg.into(), op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umulh))]
pub unsafe fn svmulh_n_u16_m(pg: svbool_t, op1: svuint16_t, op2: u16) -> svuint16_t {
    svmulh_u16_m(pg, op1, svdup_n_u16(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umulh))]
pub unsafe fn svmulh_u16_x(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    svmulh_u16_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umulh))]
pub unsafe fn svmulh_n_u16_x(pg: svbool_t, op1: svuint16_t, op2: u16) -> svuint16_t {
    svmulh_u16_x(pg, op1, svdup_n_u16(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umulh))]
pub unsafe fn svmulh_u16_z(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    svmulh_u16_m(pg.clone(), svsel_u16(pg, op1, svdup_n_u16(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umulh))]
pub unsafe fn svmulh_n_u16_z(pg: svbool_t, op1: svuint16_t, op2: u16) -> svuint16_t {
    svmulh_u16_z(pg, op1, svdup_n_u16(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umulh))]
pub unsafe fn svmulh_u32_m(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.umulh.nxv4i32")]
        fn _svmulh_u32_m(pg: svbool4_t, op1: svint32_t, op2: svint32_t) -> svint32_t;
    }
    unsafe { _svmulh_u32_m(pg.into(), op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umulh))]
pub unsafe fn svmulh_n_u32_m(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svmulh_u32_m(pg, op1, svdup_n_u32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umulh))]
pub unsafe fn svmulh_u32_x(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    svmulh_u32_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umulh))]
pub unsafe fn svmulh_n_u32_x(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svmulh_u32_x(pg, op1, svdup_n_u32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umulh))]
pub unsafe fn svmulh_u32_z(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    svmulh_u32_m(pg.clone(), svsel_u32(pg, op1, svdup_n_u32(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umulh))]
pub unsafe fn svmulh_n_u32_z(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svmulh_u32_z(pg, op1, svdup_n_u32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umulh))]
pub unsafe fn svmulh_u64_m(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.umulh.nxv2i64")]
        fn _svmulh_u64_m(pg: svbool2_t, op1: svint64_t, op2: svint64_t) -> svint64_t;
    }
    unsafe { _svmulh_u64_m(pg.into(), op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umulh))]
pub unsafe fn svmulh_n_u64_m(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svmulh_u64_m(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umulh))]
pub unsafe fn svmulh_u64_x(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    svmulh_u64_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umulh))]
pub unsafe fn svmulh_n_u64_x(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svmulh_u64_x(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umulh))]
pub unsafe fn svmulh_u64_z(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    svmulh_u64_m(pg.clone(), svsel_u64(pg, op1, svdup_n_u64(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umulh))]
pub unsafe fn svmulh_n_u64_z(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svmulh_u64_z(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmulx))]
pub unsafe fn svmulx_f32_m(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fmulx.nxv4f32")]
        fn _svmulx_f32_m(pg: svbool4_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svmulx_f32_m(pg.into(), op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmulx))]
pub unsafe fn svmulx_n_f32_m(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svfloat32_t {
    svmulx_f32_m(pg, op1, svdup_n_f32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmulx))]
pub unsafe fn svmulx_f32_x(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    svmulx_f32_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmulx))]
pub unsafe fn svmulx_n_f32_x(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svfloat32_t {
    svmulx_f32_x(pg, op1, svdup_n_f32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmulx))]
pub unsafe fn svmulx_f32_z(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    svmulx_f32_m(pg.clone(), svsel_f32(pg, op1, svdup_n_f32(0.0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmulx))]
pub unsafe fn svmulx_n_f32_z(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svfloat32_t {
    svmulx_f32_z(pg, op1, svdup_n_f32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmulx))]
pub unsafe fn svmulx_f64_m(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fmulx.nxv2f64")]
        fn _svmulx_f64_m(pg: svbool2_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svmulx_f64_m(pg.into(), op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmulx))]
pub unsafe fn svmulx_n_f64_m(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svfloat64_t {
    svmulx_f64_m(pg, op1, svdup_n_f64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmulx))]
pub unsafe fn svmulx_f64_x(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    svmulx_f64_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmulx))]
pub unsafe fn svmulx_n_f64_x(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svfloat64_t {
    svmulx_f64_x(pg, op1, svdup_n_f64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmulx))]
pub unsafe fn svmulx_f64_z(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    svmulx_f64_m(pg.clone(), svsel_f64(pg, op1, svdup_n_f64(0.0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmulx))]
pub unsafe fn svmulx_n_f64_z(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svfloat64_t {
    svmulx_f64_z(pg, op1, svdup_n_f64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(nand))]
pub unsafe fn svnand_b_z(pg: svbool_t, op1: svbool_t, op2: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.nand.z.nxv16i1")]
        fn _svnand_b_z(pg: svbool_t, op1: svbool_t, op2: svbool_t) -> svbool_t;
    }
    unsafe { _svnand_b_z(pg, op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fneg))]
pub unsafe fn svneg_f32_m(inactive: svfloat32_t, pg: svbool_t, op: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fneg.nxv4f32")]
        fn _svneg_f32_m(inactive: svfloat32_t, pg: svbool4_t, op: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svneg_f32_m(inactive, pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fneg))]
pub unsafe fn svneg_f32_x(pg: svbool_t, op: svfloat32_t) -> svfloat32_t {
    svneg_f32_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fneg))]
pub unsafe fn svneg_f32_z(pg: svbool_t, op: svfloat32_t) -> svfloat32_t {
    svneg_f32_m(svdup_n_f32(0.0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fneg))]
pub unsafe fn svneg_f64_m(inactive: svfloat64_t, pg: svbool_t, op: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fneg.nxv2f64")]
        fn _svneg_f64_m(inactive: svfloat64_t, pg: svbool2_t, op: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svneg_f64_m(inactive, pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fneg))]
pub unsafe fn svneg_f64_x(pg: svbool_t, op: svfloat64_t) -> svfloat64_t {
    svneg_f64_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fneg))]
pub unsafe fn svneg_f64_z(pg: svbool_t, op: svfloat64_t) -> svfloat64_t {
    svneg_f64_m(svdup_n_f64(0.0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(neg))]
pub unsafe fn svneg_s8_m(inactive: svint8_t, pg: svbool_t, op: svint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.neg.nxv16i8")]
        fn _svneg_s8_m(inactive: svint8_t, pg: svbool_t, op: svint8_t) -> svint8_t;
    }
    unsafe { _svneg_s8_m(inactive, pg, op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(neg))]
pub unsafe fn svneg_s8_x(pg: svbool_t, op: svint8_t) -> svint8_t {
    svneg_s8_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(neg))]
pub unsafe fn svneg_s8_z(pg: svbool_t, op: svint8_t) -> svint8_t {
    svneg_s8_m(svdup_n_s8(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(neg))]
pub unsafe fn svneg_s16_m(inactive: svint16_t, pg: svbool_t, op: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.neg.nxv8i16")]
        fn _svneg_s16_m(inactive: svint16_t, pg: svbool8_t, op: svint16_t) -> svint16_t;
    }
    unsafe { _svneg_s16_m(inactive, pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(neg))]
pub unsafe fn svneg_s16_x(pg: svbool_t, op: svint16_t) -> svint16_t {
    svneg_s16_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(neg))]
pub unsafe fn svneg_s16_z(pg: svbool_t, op: svint16_t) -> svint16_t {
    svneg_s16_m(svdup_n_s16(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(neg))]
pub unsafe fn svneg_s32_m(inactive: svint32_t, pg: svbool_t, op: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.neg.nxv4i32")]
        fn _svneg_s32_m(inactive: svint32_t, pg: svbool4_t, op: svint32_t) -> svint32_t;
    }
    unsafe { _svneg_s32_m(inactive, pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(neg))]
pub unsafe fn svneg_s32_x(pg: svbool_t, op: svint32_t) -> svint32_t {
    svneg_s32_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(neg))]
pub unsafe fn svneg_s32_z(pg: svbool_t, op: svint32_t) -> svint32_t {
    svneg_s32_m(svdup_n_s32(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(neg))]
pub unsafe fn svneg_s64_m(inactive: svint64_t, pg: svbool_t, op: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.neg.nxv2i64")]
        fn _svneg_s64_m(inactive: svint64_t, pg: svbool2_t, op: svint64_t) -> svint64_t;
    }
    unsafe { _svneg_s64_m(inactive, pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(neg))]
pub unsafe fn svneg_s64_x(pg: svbool_t, op: svint64_t) -> svint64_t {
    svneg_s64_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(neg))]
pub unsafe fn svneg_s64_z(pg: svbool_t, op: svint64_t) -> svint64_t {
    svneg_s64_m(svdup_n_s64(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmad))]
pub unsafe fn svnmad_f32_m(
    pg: svbool_t,
    op1: svfloat32_t,
    op2: svfloat32_t,
    op3: svfloat32_t,
) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fnmad.nxv4f32")]
        fn _svnmad_f32_m(
            pg: svbool4_t,
            op1: svfloat32_t,
            op2: svfloat32_t,
            op3: svfloat32_t,
        ) -> svfloat32_t;
    }
    unsafe { _svnmad_f32_m(pg.into(), op1, op2, op3) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmad))]
pub unsafe fn svnmad_n_f32_m(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t, op3: f32) -> svfloat32_t {
    svnmad_f32_m(pg, op1, op2, svdup_n_f32(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmad))]
pub unsafe fn svnmad_f32_x(
    pg: svbool_t,
    op1: svfloat32_t,
    op2: svfloat32_t,
    op3: svfloat32_t,
) -> svfloat32_t {
    svnmad_f32_m(pg, op1, op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmad))]
pub unsafe fn svnmad_n_f32_x(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t, op3: f32) -> svfloat32_t {
    svnmad_f32_x(pg, op1, op2, svdup_n_f32(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmad))]
pub unsafe fn svnmad_f32_z(
    pg: svbool_t,
    op1: svfloat32_t,
    op2: svfloat32_t,
    op3: svfloat32_t,
) -> svfloat32_t {
    svnmad_f32_m(pg.clone(), svsel_f32(pg, op1, svdup_n_f32(0.0)), op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmad))]
pub unsafe fn svnmad_n_f32_z(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t, op3: f32) -> svfloat32_t {
    svnmad_f32_z(pg, op1, op2, svdup_n_f32(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmad))]
pub unsafe fn svnmad_f64_m(
    pg: svbool_t,
    op1: svfloat64_t,
    op2: svfloat64_t,
    op3: svfloat64_t,
) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fnmad.nxv2f64")]
        fn _svnmad_f64_m(
            pg: svbool2_t,
            op1: svfloat64_t,
            op2: svfloat64_t,
            op3: svfloat64_t,
        ) -> svfloat64_t;
    }
    unsafe { _svnmad_f64_m(pg.into(), op1, op2, op3) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmad))]
pub unsafe fn svnmad_n_f64_m(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t, op3: f64) -> svfloat64_t {
    svnmad_f64_m(pg, op1, op2, svdup_n_f64(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmad))]
pub unsafe fn svnmad_f64_x(
    pg: svbool_t,
    op1: svfloat64_t,
    op2: svfloat64_t,
    op3: svfloat64_t,
) -> svfloat64_t {
    svnmad_f64_m(pg, op1, op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmad))]
pub unsafe fn svnmad_n_f64_x(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t, op3: f64) -> svfloat64_t {
    svnmad_f64_x(pg, op1, op2, svdup_n_f64(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmad))]
pub unsafe fn svnmad_f64_z(
    pg: svbool_t,
    op1: svfloat64_t,
    op2: svfloat64_t,
    op3: svfloat64_t,
) -> svfloat64_t {
    svnmad_f64_m(pg.clone(), svsel_f64(pg, op1, svdup_n_f64(0.0)), op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmad))]
pub unsafe fn svnmad_n_f64_z(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t, op3: f64) -> svfloat64_t {
    svnmad_f64_z(pg, op1, op2, svdup_n_f64(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmla))]
pub unsafe fn svnmla_f32_m(
    pg: svbool_t,
    op1: svfloat32_t,
    op2: svfloat32_t,
    op3: svfloat32_t,
) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fnmla.nxv4f32")]
        fn _svnmla_f32_m(
            pg: svbool4_t,
            op1: svfloat32_t,
            op2: svfloat32_t,
            op3: svfloat32_t,
        ) -> svfloat32_t;
    }
    unsafe { _svnmla_f32_m(pg.into(), op1, op2, op3) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmla))]
pub unsafe fn svnmla_n_f32_m(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t, op3: f32) -> svfloat32_t {
    svnmla_f32_m(pg, op1, op2, svdup_n_f32(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmla))]
pub unsafe fn svnmla_f32_x(
    pg: svbool_t,
    op1: svfloat32_t,
    op2: svfloat32_t,
    op3: svfloat32_t,
) -> svfloat32_t {
    svnmla_f32_m(pg, op1, op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmla))]
pub unsafe fn svnmla_n_f32_x(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t, op3: f32) -> svfloat32_t {
    svnmla_f32_x(pg, op1, op2, svdup_n_f32(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmla))]
pub unsafe fn svnmla_f32_z(
    pg: svbool_t,
    op1: svfloat32_t,
    op2: svfloat32_t,
    op3: svfloat32_t,
) -> svfloat32_t {
    svnmla_f32_m(pg.clone(), svsel_f32(pg, op1, svdup_n_f32(0.0)), op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmla))]
pub unsafe fn svnmla_n_f32_z(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t, op3: f32) -> svfloat32_t {
    svnmla_f32_z(pg, op1, op2, svdup_n_f32(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmla))]
pub unsafe fn svnmla_f64_m(
    pg: svbool_t,
    op1: svfloat64_t,
    op2: svfloat64_t,
    op3: svfloat64_t,
) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fnmla.nxv2f64")]
        fn _svnmla_f64_m(
            pg: svbool2_t,
            op1: svfloat64_t,
            op2: svfloat64_t,
            op3: svfloat64_t,
        ) -> svfloat64_t;
    }
    unsafe { _svnmla_f64_m(pg.into(), op1, op2, op3) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmla))]
pub unsafe fn svnmla_n_f64_m(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t, op3: f64) -> svfloat64_t {
    svnmla_f64_m(pg, op1, op2, svdup_n_f64(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmla))]
pub unsafe fn svnmla_f64_x(
    pg: svbool_t,
    op1: svfloat64_t,
    op2: svfloat64_t,
    op3: svfloat64_t,
) -> svfloat64_t {
    svnmla_f64_m(pg, op1, op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmla))]
pub unsafe fn svnmla_n_f64_x(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t, op3: f64) -> svfloat64_t {
    svnmla_f64_x(pg, op1, op2, svdup_n_f64(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmla))]
pub unsafe fn svnmla_f64_z(
    pg: svbool_t,
    op1: svfloat64_t,
    op2: svfloat64_t,
    op3: svfloat64_t,
) -> svfloat64_t {
    svnmla_f64_m(pg.clone(), svsel_f64(pg, op1, svdup_n_f64(0.0)), op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmla))]
pub unsafe fn svnmla_n_f64_z(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t, op3: f64) -> svfloat64_t {
    svnmla_f64_z(pg, op1, op2, svdup_n_f64(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmls))]
pub unsafe fn svnmls_f32_m(
    pg: svbool_t,
    op1: svfloat32_t,
    op2: svfloat32_t,
    op3: svfloat32_t,
) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fnmls.nxv4f32")]
        fn _svnmls_f32_m(
            pg: svbool4_t,
            op1: svfloat32_t,
            op2: svfloat32_t,
            op3: svfloat32_t,
        ) -> svfloat32_t;
    }
    unsafe { _svnmls_f32_m(pg.into(), op1, op2, op3) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmls))]
pub unsafe fn svnmls_n_f32_m(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t, op3: f32) -> svfloat32_t {
    svnmls_f32_m(pg, op1, op2, svdup_n_f32(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmls))]
pub unsafe fn svnmls_f32_x(
    pg: svbool_t,
    op1: svfloat32_t,
    op2: svfloat32_t,
    op3: svfloat32_t,
) -> svfloat32_t {
    svnmls_f32_m(pg, op1, op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmls))]
pub unsafe fn svnmls_n_f32_x(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t, op3: f32) -> svfloat32_t {
    svnmls_f32_x(pg, op1, op2, svdup_n_f32(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmls))]
pub unsafe fn svnmls_f32_z(
    pg: svbool_t,
    op1: svfloat32_t,
    op2: svfloat32_t,
    op3: svfloat32_t,
) -> svfloat32_t {
    svnmls_f32_m(pg.clone(), svsel_f32(pg, op1, svdup_n_f32(0.0)), op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmls))]
pub unsafe fn svnmls_n_f32_z(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t, op3: f32) -> svfloat32_t {
    svnmls_f32_z(pg, op1, op2, svdup_n_f32(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmls))]
pub unsafe fn svnmls_f64_m(
    pg: svbool_t,
    op1: svfloat64_t,
    op2: svfloat64_t,
    op3: svfloat64_t,
) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fnmls.nxv2f64")]
        fn _svnmls_f64_m(
            pg: svbool2_t,
            op1: svfloat64_t,
            op2: svfloat64_t,
            op3: svfloat64_t,
        ) -> svfloat64_t;
    }
    unsafe { _svnmls_f64_m(pg.into(), op1, op2, op3) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmls))]
pub unsafe fn svnmls_n_f64_m(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t, op3: f64) -> svfloat64_t {
    svnmls_f64_m(pg, op1, op2, svdup_n_f64(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmls))]
pub unsafe fn svnmls_f64_x(
    pg: svbool_t,
    op1: svfloat64_t,
    op2: svfloat64_t,
    op3: svfloat64_t,
) -> svfloat64_t {
    svnmls_f64_m(pg, op1, op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmls))]
pub unsafe fn svnmls_n_f64_x(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t, op3: f64) -> svfloat64_t {
    svnmls_f64_x(pg, op1, op2, svdup_n_f64(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmls))]
pub unsafe fn svnmls_f64_z(
    pg: svbool_t,
    op1: svfloat64_t,
    op2: svfloat64_t,
    op3: svfloat64_t,
) -> svfloat64_t {
    svnmls_f64_m(pg.clone(), svsel_f64(pg, op1, svdup_n_f64(0.0)), op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmls))]
pub unsafe fn svnmls_n_f64_z(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t, op3: f64) -> svfloat64_t {
    svnmls_f64_z(pg, op1, op2, svdup_n_f64(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmsb))]
pub unsafe fn svnmsb_f32_m(
    pg: svbool_t,
    op1: svfloat32_t,
    op2: svfloat32_t,
    op3: svfloat32_t,
) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fnmsb.nxv4f32")]
        fn _svnmsb_f32_m(
            pg: svbool4_t,
            op1: svfloat32_t,
            op2: svfloat32_t,
            op3: svfloat32_t,
        ) -> svfloat32_t;
    }
    unsafe { _svnmsb_f32_m(pg.into(), op1, op2, op3) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmsb))]
pub unsafe fn svnmsb_n_f32_m(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t, op3: f32) -> svfloat32_t {
    svnmsb_f32_m(pg, op1, op2, svdup_n_f32(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmsb))]
pub unsafe fn svnmsb_f32_x(
    pg: svbool_t,
    op1: svfloat32_t,
    op2: svfloat32_t,
    op3: svfloat32_t,
) -> svfloat32_t {
    svnmsb_f32_m(pg, op1, op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmsb))]
pub unsafe fn svnmsb_n_f32_x(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t, op3: f32) -> svfloat32_t {
    svnmsb_f32_x(pg, op1, op2, svdup_n_f32(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmsb))]
pub unsafe fn svnmsb_f32_z(
    pg: svbool_t,
    op1: svfloat32_t,
    op2: svfloat32_t,
    op3: svfloat32_t,
) -> svfloat32_t {
    svnmsb_f32_m(pg.clone(), svsel_f32(pg, op1, svdup_n_f32(0.0)), op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmsb))]
pub unsafe fn svnmsb_n_f32_z(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t, op3: f32) -> svfloat32_t {
    svnmsb_f32_z(pg, op1, op2, svdup_n_f32(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmsb))]
pub unsafe fn svnmsb_f64_m(
    pg: svbool_t,
    op1: svfloat64_t,
    op2: svfloat64_t,
    op3: svfloat64_t,
) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fnmsb.nxv2f64")]
        fn _svnmsb_f64_m(
            pg: svbool2_t,
            op1: svfloat64_t,
            op2: svfloat64_t,
            op3: svfloat64_t,
        ) -> svfloat64_t;
    }
    unsafe { _svnmsb_f64_m(pg.into(), op1, op2, op3) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmsb))]
pub unsafe fn svnmsb_n_f64_m(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t, op3: f64) -> svfloat64_t {
    svnmsb_f64_m(pg, op1, op2, svdup_n_f64(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmsb))]
pub unsafe fn svnmsb_f64_x(
    pg: svbool_t,
    op1: svfloat64_t,
    op2: svfloat64_t,
    op3: svfloat64_t,
) -> svfloat64_t {
    svnmsb_f64_m(pg, op1, op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmsb))]
pub unsafe fn svnmsb_n_f64_x(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t, op3: f64) -> svfloat64_t {
    svnmsb_f64_x(pg, op1, op2, svdup_n_f64(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmsb))]
pub unsafe fn svnmsb_f64_z(
    pg: svbool_t,
    op1: svfloat64_t,
    op2: svfloat64_t,
    op3: svfloat64_t,
) -> svfloat64_t {
    svnmsb_f64_m(pg.clone(), svsel_f64(pg, op1, svdup_n_f64(0.0)), op2, op3)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmsb))]
pub unsafe fn svnmsb_n_f64_z(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t, op3: f64) -> svfloat64_t {
    svnmsb_f64_z(pg, op1, op2, svdup_n_f64(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(nor))]
pub unsafe fn svnor_b_z(pg: svbool_t, op1: svbool_t, op2: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.nor.z.nxv16i1")]
        fn _svnor_b_z(pg: svbool_t, op1: svbool_t, op2: svbool_t) -> svbool_t;
    }
    unsafe { _svnor_b_z(pg, op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(not))]
pub unsafe fn svnot_b_z(pg: svbool_t, op: svbool_t) -> svbool_t {
    sveor_b_z(pg.clone(), op, pg)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(not))]
pub unsafe fn svnot_s8_m(inactive: svint8_t, pg: svbool_t, op: svint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.not.nxv16i8")]
        fn _svnot_s8_m(inactive: svint8_t, pg: svbool_t, op: svint8_t) -> svint8_t;
    }
    unsafe { _svnot_s8_m(inactive, pg, op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(not))]
pub unsafe fn svnot_s8_x(pg: svbool_t, op: svint8_t) -> svint8_t {
    svnot_s8_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(not))]
pub unsafe fn svnot_s8_z(pg: svbool_t, op: svint8_t) -> svint8_t {
    svnot_s8_m(svdup_n_s8(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(not))]
pub unsafe fn svnot_s16_m(inactive: svint16_t, pg: svbool_t, op: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.not.nxv8i16")]
        fn _svnot_s16_m(inactive: svint16_t, pg: svbool8_t, op: svint16_t) -> svint16_t;
    }
    unsafe { _svnot_s16_m(inactive, pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(not))]
pub unsafe fn svnot_s16_x(pg: svbool_t, op: svint16_t) -> svint16_t {
    svnot_s16_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(not))]
pub unsafe fn svnot_s16_z(pg: svbool_t, op: svint16_t) -> svint16_t {
    svnot_s16_m(svdup_n_s16(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(not))]
pub unsafe fn svnot_s32_m(inactive: svint32_t, pg: svbool_t, op: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.not.nxv4i32")]
        fn _svnot_s32_m(inactive: svint32_t, pg: svbool4_t, op: svint32_t) -> svint32_t;
    }
    unsafe { _svnot_s32_m(inactive, pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(not))]
pub unsafe fn svnot_s32_x(pg: svbool_t, op: svint32_t) -> svint32_t {
    svnot_s32_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(not))]
pub unsafe fn svnot_s32_z(pg: svbool_t, op: svint32_t) -> svint32_t {
    svnot_s32_m(svdup_n_s32(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(not))]
pub unsafe fn svnot_s64_m(inactive: svint64_t, pg: svbool_t, op: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.not.nxv2i64")]
        fn _svnot_s64_m(inactive: svint64_t, pg: svbool2_t, op: svint64_t) -> svint64_t;
    }
    unsafe { _svnot_s64_m(inactive, pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(not))]
pub unsafe fn svnot_s64_x(pg: svbool_t, op: svint64_t) -> svint64_t {
    svnot_s64_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(not))]
pub unsafe fn svnot_s64_z(pg: svbool_t, op: svint64_t) -> svint64_t {
    svnot_s64_m(svdup_n_s64(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(not))]
pub unsafe fn svnot_u8_m(inactive: svuint8_t, pg: svbool_t, op: svuint8_t) -> svuint8_t {
    unsafe { svnot_s8_m(inactive.as_signed(), pg, op.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(not))]
pub unsafe fn svnot_u8_x(pg: svbool_t, op: svuint8_t) -> svuint8_t {
    svnot_u8_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(not))]
pub unsafe fn svnot_u8_z(pg: svbool_t, op: svuint8_t) -> svuint8_t {
    svnot_u8_m(svdup_n_u8(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(not))]
pub unsafe fn svnot_u16_m(inactive: svuint16_t, pg: svbool_t, op: svuint16_t) -> svuint16_t {
    unsafe { svnot_s16_m(inactive.as_signed(), pg, op.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(not))]
pub unsafe fn svnot_u16_x(pg: svbool_t, op: svuint16_t) -> svuint16_t {
    svnot_u16_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(not))]
pub unsafe fn svnot_u16_z(pg: svbool_t, op: svuint16_t) -> svuint16_t {
    svnot_u16_m(svdup_n_u16(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(not))]
pub unsafe fn svnot_u32_m(inactive: svuint32_t, pg: svbool_t, op: svuint32_t) -> svuint32_t {
    unsafe { svnot_s32_m(inactive.as_signed(), pg, op.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(not))]
pub unsafe fn svnot_u32_x(pg: svbool_t, op: svuint32_t) -> svuint32_t {
    svnot_u32_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(not))]
pub unsafe fn svnot_u32_z(pg: svbool_t, op: svuint32_t) -> svuint32_t {
    svnot_u32_m(svdup_n_u32(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(not))]
pub unsafe fn svnot_u64_m(inactive: svuint64_t, pg: svbool_t, op: svuint64_t) -> svuint64_t {
    unsafe { svnot_s64_m(inactive.as_signed(), pg, op.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(not))]
pub unsafe fn svnot_u64_x(pg: svbool_t, op: svuint64_t) -> svuint64_t {
    svnot_u64_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(not))]
pub unsafe fn svnot_u64_z(pg: svbool_t, op: svuint64_t) -> svuint64_t {
    svnot_u64_m(svdup_n_u64(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orn))]
pub unsafe fn svorn_b_z(pg: svbool_t, op1: svbool_t, op2: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.orn.z.nvx16i1")]
        fn _svorn_b_z(pg: svbool_t, op1: svbool_t, op2: svbool_t) -> svbool_t;
    }
    unsafe { _svorn_b_z(pg, op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub unsafe fn svorr_b_z(pg: svbool_t, op1: svbool_t, op2: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.orr.z.nvx16i1")]
        fn _svorr_b_z(pg: svbool_t, op1: svbool_t, op2: svbool_t) -> svbool_t;
    }
    unsafe { _svorr_b_z(pg, op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub unsafe fn svorr_s8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.orr.nxv16i8")]
        fn _svorr_s8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t;
    }
    unsafe { _svorr_s8_m(pg, op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub unsafe fn svorr_n_s8_m(pg: svbool_t, op1: svint8_t, op2: i8) -> svint8_t {
    svorr_s8_m(pg, op1, svdup_n_s8(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub unsafe fn svorr_s8_x(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t {
    svorr_s8_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub unsafe fn svorr_n_s8_x(pg: svbool_t, op1: svint8_t, op2: i8) -> svint8_t {
    svorr_s8_x(pg, op1, svdup_n_s8(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub unsafe fn svorr_s8_z(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t {
    svorr_s8_m(pg.clone(), svsel_s8(pg, op1, svdup_n_s8(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub unsafe fn svorr_n_s8_z(pg: svbool_t, op1: svint8_t, op2: i8) -> svint8_t {
    svorr_s8_z(pg, op1, svdup_n_s8(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub unsafe fn svorr_s16_m(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.orr.nxv8i16")]
        fn _svorr_s16_m(pg: svbool8_t, op1: svint16_t, op2: svint16_t) -> svint16_t;
    }
    unsafe { _svorr_s16_m(pg.into(), op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub unsafe fn svorr_n_s16_m(pg: svbool_t, op1: svint16_t, op2: i16) -> svint16_t {
    svorr_s16_m(pg, op1, svdup_n_s16(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub unsafe fn svorr_s16_x(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svint16_t {
    svorr_s16_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub unsafe fn svorr_n_s16_x(pg: svbool_t, op1: svint16_t, op2: i16) -> svint16_t {
    svorr_s16_x(pg, op1, svdup_n_s16(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub unsafe fn svorr_s16_z(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svint16_t {
    svorr_s16_m(pg.clone(), svsel_s16(pg, op1, svdup_n_s16(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub unsafe fn svorr_n_s16_z(pg: svbool_t, op1: svint16_t, op2: i16) -> svint16_t {
    svorr_s16_z(pg, op1, svdup_n_s16(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub unsafe fn svorr_s32_m(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.orr.nxv4i32")]
        fn _svorr_s32_m(pg: svbool4_t, op1: svint32_t, op2: svint32_t) -> svint32_t;
    }
    unsafe { _svorr_s32_m(pg.into(), op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub unsafe fn svorr_n_s32_m(pg: svbool_t, op1: svint32_t, op2: i32) -> svint32_t {
    svorr_s32_m(pg, op1, svdup_n_s32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub unsafe fn svorr_s32_x(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    svorr_s32_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub unsafe fn svorr_n_s32_x(pg: svbool_t, op1: svint32_t, op2: i32) -> svint32_t {
    svorr_s32_x(pg, op1, svdup_n_s32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub unsafe fn svorr_s32_z(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    svorr_s32_m(pg.clone(), svsel_s32(pg, op1, svdup_n_s32(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub unsafe fn svorr_n_s32_z(pg: svbool_t, op1: svint32_t, op2: i32) -> svint32_t {
    svorr_s32_z(pg, op1, svdup_n_s32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub unsafe fn svorr_s64_m(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.orr.nxv2i64")]
        fn _svorr_s64_m(pg: svbool2_t, op1: svint64_t, op2: svint64_t) -> svint64_t;
    }
    unsafe { _svorr_s64_m(pg.into(), op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub unsafe fn svorr_n_s64_m(pg: svbool_t, op1: svint64_t, op2: i64) -> svint64_t {
    svorr_s64_m(pg, op1, svdup_n_s64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub unsafe fn svorr_s64_x(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    svorr_s64_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub unsafe fn svorr_n_s64_x(pg: svbool_t, op1: svint64_t, op2: i64) -> svint64_t {
    svorr_s64_x(pg, op1, svdup_n_s64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub unsafe fn svorr_s64_z(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    svorr_s64_m(pg.clone(), svsel_s64(pg, op1, svdup_n_s64(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub unsafe fn svorr_n_s64_z(pg: svbool_t, op1: svint64_t, op2: i64) -> svint64_t {
    svorr_s64_z(pg, op1, svdup_n_s64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub unsafe fn svorr_u8_m(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    unsafe { svorr_s8_m(pg, op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub unsafe fn svorr_n_u8_m(pg: svbool_t, op1: svuint8_t, op2: u8) -> svuint8_t {
    svorr_u8_m(pg, op1, svdup_n_u8(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub unsafe fn svorr_u8_x(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    svorr_u8_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub unsafe fn svorr_n_u8_x(pg: svbool_t, op1: svuint8_t, op2: u8) -> svuint8_t {
    svorr_u8_x(pg, op1, svdup_n_u8(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub unsafe fn svorr_u8_z(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    svorr_u8_m(pg.clone(), svsel_u8(pg, op1, svdup_n_u8(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub unsafe fn svorr_n_u8_z(pg: svbool_t, op1: svuint8_t, op2: u8) -> svuint8_t {
    svorr_u8_z(pg, op1, svdup_n_u8(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub unsafe fn svorr_u16_m(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    unsafe { svorr_s16_m(pg, op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub unsafe fn svorr_n_u16_m(pg: svbool_t, op1: svuint16_t, op2: u16) -> svuint16_t {
    svorr_u16_m(pg, op1, svdup_n_u16(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub unsafe fn svorr_u16_x(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    svorr_u16_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub unsafe fn svorr_n_u16_x(pg: svbool_t, op1: svuint16_t, op2: u16) -> svuint16_t {
    svorr_u16_x(pg, op1, svdup_n_u16(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub unsafe fn svorr_u16_z(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    svorr_u16_m(pg.clone(), svsel_u16(pg, op1, svdup_n_u16(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub unsafe fn svorr_n_u16_z(pg: svbool_t, op1: svuint16_t, op2: u16) -> svuint16_t {
    svorr_u16_z(pg, op1, svdup_n_u16(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub unsafe fn svorr_u32_m(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    unsafe { svorr_s32_m(pg, op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub unsafe fn svorr_n_u32_m(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svorr_u32_m(pg, op1, svdup_n_u32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub unsafe fn svorr_u32_x(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    svorr_u32_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub unsafe fn svorr_n_u32_x(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svorr_u32_x(pg, op1, svdup_n_u32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub unsafe fn svorr_u32_z(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    svorr_u32_m(pg.clone(), svsel_u32(pg, op1, svdup_n_u32(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub unsafe fn svorr_n_u32_z(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svorr_u32_z(pg, op1, svdup_n_u32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub unsafe fn svorr_u64_m(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    unsafe { svorr_s64_m(pg, op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub unsafe fn svorr_n_u64_m(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svorr_u64_m(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub unsafe fn svorr_u64_x(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    svorr_u64_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub unsafe fn svorr_n_u64_x(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svorr_u64_x(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub unsafe fn svorr_u64_z(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    svorr_u64_m(pg.clone(), svsel_u64(pg, op1, svdup_n_u64(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub unsafe fn svorr_n_u64_z(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svorr_u64_z(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orv))]
pub unsafe fn svorv_s8(pg: svbool_t, op: svint8_t) -> i8 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.orv.nxv16i8")]
        fn _svorv_s8(pg: svbool_t, op: svint8_t) -> i8;
    }
    unsafe { _svorv_s8(pg, op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orv))]
pub unsafe fn svorv_s16(pg: svbool_t, op: svint16_t) -> i16 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.orv.nxv8i16")]
        fn _svorv_s16(pg: svbool8_t, op: svint16_t) -> i16;
    }
    unsafe { _svorv_s16(pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orv))]
pub unsafe fn svorv_s32(pg: svbool_t, op: svint32_t) -> i32 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.orv.nxv4i32")]
        fn _svorv_s32(pg: svbool4_t, op: svint32_t) -> i32;
    }
    unsafe { _svorv_s32(pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orv))]
pub unsafe fn svorv_s64(pg: svbool_t, op: svint64_t) -> i64 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.orv.nxv2i64")]
        fn _svorv_s64(pg: svbool2_t, op: svint64_t) -> i64;
    }
    unsafe { _svorv_s64(pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orv))]
pub unsafe fn svorv_u8(pg: svbool_t, op: svuint8_t) -> u8 {
    unsafe { svorv_s8(pg, op.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orv))]
pub unsafe fn svorv_u16(pg: svbool_t, op: svuint16_t) -> u16 {
    unsafe { svorv_s16(pg, op.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orv))]
pub unsafe fn svorv_u32(pg: svbool_t, op: svuint32_t) -> u32 {
    unsafe { svorv_s32(pg, op.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orv))]
pub unsafe fn svorv_u64(pg: svbool_t, op: svuint64_t) -> u64 {
    unsafe { svorv_s64(pg, op.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(pfalse))]
pub unsafe fn svpfalse_b() -> svbool_t {
    svdupq_n_b8(
        false, false, false, false, false, false, false, false, false, false, false, false, false,
        false, false, false,
    )
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(pfirst))]
pub unsafe fn svpfirst_b(pg: svbool_t, op: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.pfirst.nxv16i1")]
        fn _svpfirst_b(pg: svbool_t, op: svbool_t) -> svbool_t;
    }
    unsafe { _svpfirst_b(pg, op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(pnext))]
pub unsafe fn svpnext_b8(pg: svbool_t, op: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.pnext.nxv16i1")]
        fn _svpnext_b8(pg: svbool_t, op: svbool_t) -> svbool_t;
    }
    unsafe { _svpnext_b8(pg, op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(pnext))]
pub unsafe fn svpnext_b16(pg: svbool_t, op: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.pnext.nxv8i1")]
        fn _svpnext_b16(pg: svbool8_t, op: svbool8_t) -> svbool8_t;
    }
    unsafe { _svpnext_b16(pg.into(), op.into()).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(pnext))]
pub unsafe fn svpnext_b32(pg: svbool_t, op: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.pnext.nxv4i1")]
        fn _svpnext_b32(pg: svbool4_t, op: svbool4_t) -> svbool4_t;
    }
    unsafe { _svpnext_b32(pg.into(), op.into()).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(pnext))]
pub unsafe fn svpnext_b64(pg: svbool_t, op: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.pnext.nxv2i1")]
        fn _svpnext_b64(pg: svbool2_t, op: svbool2_t) -> svbool2_t;
    }
    unsafe { _svpnext_b64(pg.into(), op.into()).into() }
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfb , OP = { svprfop :: SV_PLDL1KEEP } , T = i64))]
pub unsafe fn svprfb<const OP: u8, T>(pg: svbool_t, base: *const T) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.prf.nxv16i1")]
        fn _svprfb(pg: svbool_t, base: *const crate::ffi::c_void, op: u8);
    }
    _svprfb(pg, base as *const crate::ffi::c_void, OP)
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfh , OP = { svprfop :: SV_PLDL1KEEP } , T = i64))]
pub unsafe fn svprfh<const OP: u8, T>(pg: svbool_t, base: *const T) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.prf.nxv8i1")]
        fn _svprfh(pg: svbool8_t, base: *const crate::ffi::c_void, op: u8);
    }
    _svprfh(pg.into(), base as *const crate::ffi::c_void, OP)
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfw , OP = { svprfop :: SV_PLDL1KEEP } , T = i64))]
pub unsafe fn svprfw<const OP: u8, T>(pg: svbool_t, base: *const T) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.prf.nxv4i1")]
        fn _svprfw(pg: svbool4_t, base: *const crate::ffi::c_void, op: u8);
    }
    _svprfw(pg.into(), base as *const crate::ffi::c_void, OP)
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfd , OP = { svprfop :: SV_PLDL1KEEP } , T = i64))]
pub unsafe fn svprfd<const OP: u8, T>(pg: svbool_t, base: *const T) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.prf.nxv2i1")]
        fn _svprfd(pg: svbool2_t, base: *const crate::ffi::c_void, op: u8);
    }
    _svprfd(pg.into(), base as *const crate::ffi::c_void, OP)
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfb , OP = { svprfop :: SV_PLDL1KEEP } , T = i64))]
pub unsafe fn svprfb_gather_s32offset<const OP: u8, T>(
    pg: svbool_t,
    base: *const T,
    offsets: svint32_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.prfb.gather.sxtw.index.nxv4i32"
        )]
        fn _svprfb_gather_s32offset(
            pg: svbool4_t,
            base: *const crate::ffi::c_void,
            offsets: svint32_t,
            op: u8,
        );
    }
    _svprfb_gather_s32offset(pg.into(), base as *const crate::ffi::c_void, offsets, OP)
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfh , OP = { svprfop :: SV_PLDL1KEEP } , T = i64))]
pub unsafe fn svprfh_gather_s32index<const OP: u8, T>(
    pg: svbool_t,
    base: *const T,
    indices: svint32_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.prfh.gather.sxtw.index.nxv4i32"
        )]
        fn _svprfh_gather_s32index(
            pg: svbool4_t,
            base: *const crate::ffi::c_void,
            indices: svint32_t,
            op: u8,
        );
    }
    _svprfh_gather_s32index(pg.into(), base as *const crate::ffi::c_void, indices, OP)
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfw , OP = { svprfop :: SV_PLDL1KEEP } , T = i64))]
pub unsafe fn svprfw_gather_s32index<const OP: u8, T>(
    pg: svbool_t,
    base: *const T,
    indices: svint32_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.prfw.gather.sxtw.index.nxv4i32"
        )]
        fn _svprfw_gather_s32index(
            pg: svbool4_t,
            base: *const crate::ffi::c_void,
            indices: svint32_t,
            op: u8,
        );
    }
    _svprfw_gather_s32index(pg.into(), base as *const crate::ffi::c_void, indices, OP)
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfd , OP = { svprfop :: SV_PLDL1KEEP } , T = i64))]
pub unsafe fn svprfd_gather_s32index<const OP: u8, T>(
    pg: svbool_t,
    base: *const T,
    indices: svint32_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.prfd.gather.sxtw.index.nxv4i32"
        )]
        fn _svprfd_gather_s32index(
            pg: svbool4_t,
            base: *const crate::ffi::c_void,
            indices: svint32_t,
            op: u8,
        );
    }
    _svprfd_gather_s32index(pg.into(), base as *const crate::ffi::c_void, indices, OP)
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfb , OP = { svprfop :: SV_PLDL1KEEP } , T = i64))]
pub unsafe fn svprfb_gather_s64offset<const OP: u8, T>(
    pg: svbool_t,
    base: *const T,
    offsets: svint64_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.prfb.gather.index.nxv2i64"
        )]
        fn _svprfb_gather_s64offset(
            pg: svbool2_t,
            base: *const crate::ffi::c_void,
            offsets: svint64_t,
            op: u8,
        );
    }
    _svprfb_gather_s64offset(pg.into(), base as *const crate::ffi::c_void, offsets, OP)
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfh , OP = { svprfop :: SV_PLDL1KEEP } , T = i64))]
pub unsafe fn svprfh_gather_s64index<const OP: u8, T>(
    pg: svbool_t,
    base: *const T,
    indices: svint64_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.prfh.gather.index.nxv2i64"
        )]
        fn _svprfh_gather_s64index(
            pg: svbool2_t,
            base: *const crate::ffi::c_void,
            indices: svint64_t,
            op: u8,
        );
    }
    _svprfh_gather_s64index(pg.into(), base as *const crate::ffi::c_void, indices, OP)
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfw , OP = { svprfop :: SV_PLDL1KEEP } , T = i64))]
pub unsafe fn svprfw_gather_s64index<const OP: u8, T>(
    pg: svbool_t,
    base: *const T,
    indices: svint64_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.prfw.gather.index.nxv2i64"
        )]
        fn _svprfw_gather_s64index(
            pg: svbool2_t,
            base: *const crate::ffi::c_void,
            indices: svint64_t,
            op: u8,
        );
    }
    _svprfw_gather_s64index(pg.into(), base as *const crate::ffi::c_void, indices, OP)
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfd , OP = { svprfop :: SV_PLDL1KEEP } , T = i64))]
pub unsafe fn svprfd_gather_s64index<const OP: u8, T>(
    pg: svbool_t,
    base: *const T,
    indices: svint64_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.prfd.gather.index.nxv2i64"
        )]
        fn _svprfd_gather_s64index(
            pg: svbool2_t,
            base: *const crate::ffi::c_void,
            indices: svint64_t,
            op: u8,
        );
    }
    _svprfd_gather_s64index(pg.into(), base as *const crate::ffi::c_void, indices, OP)
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfb , OP = { svprfop :: SV_PLDL1KEEP } , T = i64))]
pub unsafe fn svprfb_gather_u32offset<const OP: u8, T>(
    pg: svbool_t,
    base: *const T,
    offsets: svuint32_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.prfb.gather.uxtw.index.nxv4i32"
        )]
        fn _svprfb_gather_u32offset(
            pg: svbool4_t,
            base: *const crate::ffi::c_void,
            offsets: svint32_t,
            op: u8,
        );
    }
    _svprfb_gather_u32offset(
        pg.into(),
        base as *const crate::ffi::c_void,
        offsets.as_signed(),
        OP,
    )
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfh , OP = { svprfop :: SV_PLDL1KEEP } , T = i64))]
pub unsafe fn svprfh_gather_u32index<const OP: u8, T>(
    pg: svbool_t,
    base: *const T,
    indices: svuint32_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.prfh.gather.uxtw.index.nxv4i32"
        )]
        fn _svprfh_gather_u32index(
            pg: svbool4_t,
            base: *const crate::ffi::c_void,
            indices: svint32_t,
            op: u8,
        );
    }
    _svprfh_gather_u32index(
        pg.into(),
        base as *const crate::ffi::c_void,
        indices.as_signed(),
        OP,
    )
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfw , OP = { svprfop :: SV_PLDL1KEEP } , T = i64))]
pub unsafe fn svprfw_gather_u32index<const OP: u8, T>(
    pg: svbool_t,
    base: *const T,
    indices: svuint32_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.prfw.gather.uxtw.index.nxv4i32"
        )]
        fn _svprfw_gather_u32index(
            pg: svbool4_t,
            base: *const crate::ffi::c_void,
            indices: svint32_t,
            op: u8,
        );
    }
    _svprfw_gather_u32index(
        pg.into(),
        base as *const crate::ffi::c_void,
        indices.as_signed(),
        OP,
    )
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfd , OP = { svprfop :: SV_PLDL1KEEP } , T = i64))]
pub unsafe fn svprfd_gather_u32index<const OP: u8, T>(
    pg: svbool_t,
    base: *const T,
    indices: svuint32_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.prfd.gather.uxtw.index.nxv4i32"
        )]
        fn _svprfd_gather_u32index(
            pg: svbool4_t,
            base: *const crate::ffi::c_void,
            indices: svint32_t,
            op: u8,
        );
    }
    _svprfd_gather_u32index(
        pg.into(),
        base as *const crate::ffi::c_void,
        indices.as_signed(),
        OP,
    )
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfb , OP = { svprfop :: SV_PLDL1KEEP } , T = i64))]
pub unsafe fn svprfb_gather_u64offset<const OP: u8, T>(
    pg: svbool_t,
    base: *const T,
    offsets: svuint64_t,
) {
    svprfb_gather_s64offset::<OP, T>(pg, base, offsets.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfh , OP = { svprfop :: SV_PLDL1KEEP } , T = i64))]
pub unsafe fn svprfh_gather_u64index<const OP: u8, T>(
    pg: svbool_t,
    base: *const T,
    indices: svuint64_t,
) {
    svprfh_gather_s64index::<OP, T>(pg, base, indices.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfw , OP = { svprfop :: SV_PLDL1KEEP } , T = i64))]
pub unsafe fn svprfw_gather_u64index<const OP: u8, T>(
    pg: svbool_t,
    base: *const T,
    indices: svuint64_t,
) {
    svprfw_gather_s64index::<OP, T>(pg, base, indices.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfd , OP = { svprfop :: SV_PLDL1KEEP } , T = i64))]
pub unsafe fn svprfd_gather_u64index<const OP: u8, T>(
    pg: svbool_t,
    base: *const T,
    indices: svuint64_t,
) {
    svprfd_gather_s64index::<OP, T>(pg, base, indices.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfb , OP = { svprfop :: SV_PLDL1KEEP }))]
pub unsafe fn svprfb_gather_u32base<const OP: u8>(pg: svbool_t, bases: svuint32_t) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.prfb.gather.scalar.offset.nxv4i32"
        )]
        fn _svprfb_gather_u32base(pg: svbool4_t, bases: svint32_t, index: i64, op: u8);
    }
    _svprfb_gather_u32base(pg.into(), bases.as_signed(), 0, OP)
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfh , OP = { svprfop :: SV_PLDL1KEEP }))]
pub unsafe fn svprfh_gather_u32base<const OP: u8>(pg: svbool_t, bases: svuint32_t) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.prfh.gather.scalar.offset.nxv4i32"
        )]
        fn _svprfh_gather_u32base(pg: svbool4_t, bases: svint32_t, index: i64, op: u8);
    }
    _svprfh_gather_u32base(pg.into(), bases.as_signed(), 0, OP)
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfw , OP = { svprfop :: SV_PLDL1KEEP }))]
pub unsafe fn svprfw_gather_u32base<const OP: u8>(pg: svbool_t, bases: svuint32_t) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.prfw.gather.scalar.offset.nxv4i32"
        )]
        fn _svprfw_gather_u32base(pg: svbool4_t, bases: svint32_t, index: i64, op: u8);
    }
    _svprfw_gather_u32base(pg.into(), bases.as_signed(), 0, OP)
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfd , OP = { svprfop :: SV_PLDL1KEEP }))]
pub unsafe fn svprfd_gather_u32base<const OP: u8>(pg: svbool_t, bases: svuint32_t) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.prfd.gather.scalar.offset.nxv4i32"
        )]
        fn _svprfd_gather_u32base(pg: svbool4_t, bases: svint32_t, index: i64, op: u8);
    }
    _svprfd_gather_u32base(pg.into(), bases.as_signed(), 0, OP)
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfb , OP = { svprfop :: SV_PLDL1KEEP }))]
pub unsafe fn svprfb_gather_u64base<const OP: u8>(pg: svbool_t, bases: svuint64_t) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.prfb.gather.scalar.offset.nxv2i64"
        )]
        fn _svprfb_gather_u64base(pg: svbool2_t, bases: svint64_t, index: i64, op: u8);
    }
    _svprfb_gather_u64base(pg.into(), bases.as_signed(), 0, OP)
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfh , OP = { svprfop :: SV_PLDL1KEEP }))]
pub unsafe fn svprfh_gather_u64base<const OP: u8>(pg: svbool_t, bases: svuint64_t) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.prfh.gather.scalar.offset.nxv2i64"
        )]
        fn _svprfh_gather_u64base(pg: svbool2_t, bases: svint64_t, index: i64, op: u8);
    }
    _svprfh_gather_u64base(pg.into(), bases.as_signed(), 0, OP)
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfw , OP = { svprfop :: SV_PLDL1KEEP }))]
pub unsafe fn svprfw_gather_u64base<const OP: u8>(pg: svbool_t, bases: svuint64_t) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.prfw.gather.scalar.offset.nxv2i64"
        )]
        fn _svprfw_gather_u64base(pg: svbool2_t, bases: svint64_t, index: i64, op: u8);
    }
    _svprfw_gather_u64base(pg.into(), bases.as_signed(), 0, OP)
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfd , OP = { svprfop :: SV_PLDL1KEEP }))]
pub unsafe fn svprfd_gather_u64base<const OP: u8>(pg: svbool_t, bases: svuint64_t) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.prfd.gather.scalar.offset.nxv2i64"
        )]
        fn _svprfd_gather_u64base(pg: svbool2_t, bases: svint64_t, index: i64, op: u8);
    }
    _svprfd_gather_u64base(pg.into(), bases.as_signed(), 0, OP)
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfb , OP = { svprfop :: SV_PLDL1KEEP }))]
pub unsafe fn svprfb_gather_u32base_offset<const OP: u8>(
    pg: svbool_t,
    bases: svuint32_t,
    offset: i64,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.prfb.gather.scalar.offset.nxv4i32"
        )]
        fn _svprfb_gather_u32base_offset(pg: svbool4_t, bases: svint32_t, offset: i64, op: u8);
    }
    _svprfb_gather_u32base_offset(pg.into(), bases.as_signed(), offset, OP)
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfb , OP = { svprfop :: SV_PLDL1KEEP }))]
pub unsafe fn svprfh_gather_u32base_index<const OP: u8>(
    pg: svbool_t,
    bases: svuint32_t,
    index: i64,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.prfh.gather.scalar.offset.nxv4i32"
        )]
        fn _svprfh_gather_u32base_index(pg: svbool4_t, bases: svint32_t, index: i64, op: u8);
    }
    _svprfh_gather_u32base_index(pg.into(), bases.as_signed(), index.unchecked_shl(1), OP)
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfb , OP = { svprfop :: SV_PLDL1KEEP }))]
pub unsafe fn svprfw_gather_u32base_index<const OP: u8>(
    pg: svbool_t,
    bases: svuint32_t,
    index: i64,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.prfw.gather.scalar.offset.nxv4i32"
        )]
        fn _svprfw_gather_u32base_index(pg: svbool4_t, bases: svint32_t, index: i64, op: u8);
    }
    _svprfw_gather_u32base_index(pg.into(), bases.as_signed(), index.unchecked_shl(2), OP)
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfb , OP = { svprfop :: SV_PLDL1KEEP }))]
pub unsafe fn svprfd_gather_u32base_index<const OP: u8>(
    pg: svbool_t,
    bases: svuint32_t,
    index: i64,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.prfd.gather.scalar.offset.nxv4i32"
        )]
        fn _svprfd_gather_u32base_index(pg: svbool4_t, bases: svint32_t, index: i64, op: u8);
    }
    _svprfd_gather_u32base_index(pg.into(), bases.as_signed(), index.unchecked_shl(3), OP)
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfb , OP = { svprfop :: SV_PLDL1KEEP }))]
pub unsafe fn svprfb_gather_u64base_offset<const OP: u8>(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.prfb.gather.scalar.offset.nxv2i64"
        )]
        fn _svprfb_gather_u64base_offset(pg: svbool2_t, bases: svint64_t, offset: i64, op: u8);
    }
    _svprfb_gather_u64base_offset(pg.into(), bases.as_signed(), offset, OP)
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfb , OP = { svprfop :: SV_PLDL1KEEP }))]
pub unsafe fn svprfh_gather_u64base_index<const OP: u8>(
    pg: svbool_t,
    bases: svuint64_t,
    index: i64,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.prfh.gather.scalar.offset.nxv2i64"
        )]
        fn _svprfh_gather_u64base_index(pg: svbool2_t, bases: svint64_t, index: i64, op: u8);
    }
    _svprfh_gather_u64base_index(pg.into(), bases.as_signed(), index.unchecked_shl(1), OP)
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfb , OP = { svprfop :: SV_PLDL1KEEP }))]
pub unsafe fn svprfw_gather_u64base_index<const OP: u8>(
    pg: svbool_t,
    bases: svuint64_t,
    index: i64,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.prfw.gather.scalar.offset.nxv2i64"
        )]
        fn _svprfw_gather_u64base_index(pg: svbool2_t, bases: svint64_t, index: i64, op: u8);
    }
    _svprfw_gather_u64base_index(pg.into(), bases.as_signed(), index.unchecked_shl(2), OP)
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfb , OP = { svprfop :: SV_PLDL1KEEP }))]
pub unsafe fn svprfd_gather_u64base_index<const OP: u8>(
    pg: svbool_t,
    bases: svuint64_t,
    index: i64,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.prfd.gather.scalar.offset.nxv2i64"
        )]
        fn _svprfd_gather_u64base_index(pg: svbool2_t, bases: svint64_t, index: i64, op: u8);
    }
    _svprfd_gather_u64base_index(pg.into(), bases.as_signed(), index.unchecked_shl(3), OP)
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfb , OP = { svprfop :: SV_PLDL1KEEP } , T = i64))]
pub unsafe fn svprfb_vnum<const OP: u8, T>(pg: svbool_t, base: *const T, vnum: i64) {
    svprfb::<OP, _>(pg, base.offset(svcntb() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfh , OP = { svprfop :: SV_PLDL1KEEP } , T = i64))]
pub unsafe fn svprfh_vnum<const OP: u8, T>(pg: svbool_t, base: *const T, vnum: i64) {
    svprfh::<OP, _>(pg, base.offset(svcnth() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfw , OP = { svprfop :: SV_PLDL1KEEP } , T = i64))]
pub unsafe fn svprfw_vnum<const OP: u8, T>(pg: svbool_t, base: *const T, vnum: i64) {
    svprfw::<OP, _>(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfd , OP = { svprfop :: SV_PLDL1KEEP } , T = i64))]
pub unsafe fn svprfd_vnum<const OP: u8, T>(pg: svbool_t, base: *const T, vnum: i64) {
    svprfd::<OP, _>(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ptest))]
pub unsafe fn svptest_any(pg: svbool_t, op: svbool_t) -> bool {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ptest.any.nxv16i1"
        )]
        fn _svptest_any(pg: svbool_t, op: svbool_t) -> bool;
    }
    unsafe { _svptest_any(pg, op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ptest))]
pub unsafe fn svptest_first(pg: svbool_t, op: svbool_t) -> bool {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ptest.first.nxv16i1"
        )]
        fn _svptest_first(pg: svbool_t, op: svbool_t) -> bool;
    }
    unsafe { _svptest_first(pg, op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ptest))]
pub unsafe fn svptest_last(pg: svbool_t, op: svbool_t) -> bool {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ptest.last.nxv16i1"
        )]
        fn _svptest_last(pg: svbool_t, op: svbool_t) -> bool;
    }
    unsafe { _svptest_last(pg, op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ptrue))]
pub unsafe fn svptrue_b8() -> svbool_t {
    svptrue_pat_b8(svpattern::SV_ALL)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ptrue))]
pub unsafe fn svptrue_b16() -> svbool_t {
    svptrue_pat_b16(svpattern::SV_ALL)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ptrue))]
pub unsafe fn svptrue_b32() -> svbool_t {
    svptrue_pat_b32(svpattern::SV_ALL)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ptrue))]
pub unsafe fn svptrue_b64() -> svbool_t {
    svptrue_pat_b64(svpattern::SV_ALL)
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (ptrue , PATTERN = { svpattern :: SV_ALL }))]
pub unsafe fn svptrue_pat_b8(pattern: svpattern) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ptrue.nxv16i1")]
        fn _svptrue_pat_b8(pattern: svpattern) -> svbool_t;
    }
    unsafe { _svptrue_pat_b8(pattern) }
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (ptrue , PATTERN = { svpattern :: SV_ALL }))]
pub unsafe fn svptrue_pat_b16(pattern: svpattern) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ptrue.nxv8i1")]
        fn _svptrue_pat_b16(pattern: svpattern) -> svbool8_t;
    }
    unsafe { _svptrue_pat_b16(pattern).into() }
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (ptrue , PATTERN = { svpattern :: SV_ALL }))]
pub unsafe fn svptrue_pat_b32(pattern: svpattern) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ptrue.nxv4i1")]
        fn _svptrue_pat_b32(pattern: svpattern) -> svbool4_t;
    }
    unsafe { _svptrue_pat_b32(pattern).into() }
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (ptrue , PATTERN = { svpattern :: SV_ALL }))]
pub unsafe fn svptrue_pat_b64(pattern: svpattern) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ptrue.nxv2i1")]
        fn _svptrue_pat_b64(pattern: svpattern) -> svbool2_t;
    }
    unsafe { _svptrue_pat_b64(pattern).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqadd))]
pub unsafe fn svqadd_s8(op1: svint8_t, op2: svint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.sqadd.x.nxv16i8"
        )]
        fn _svqadd_s8(op1: svint8_t, op2: svint8_t) -> svint8_t;
    }
    unsafe { _svqadd_s8(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqadd))]
pub unsafe fn svqadd_n_s8(op1: svint8_t, op2: i8) -> svint8_t {
    svqadd_s8(op1, svdup_n_s8(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqadd))]
pub unsafe fn svqadd_s16(op1: svint16_t, op2: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.sqadd.x.nxv8i16"
        )]
        fn _svqadd_s16(op1: svint16_t, op2: svint16_t) -> svint16_t;
    }
    unsafe { _svqadd_s16(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqadd))]
pub unsafe fn svqadd_n_s16(op1: svint16_t, op2: i16) -> svint16_t {
    svqadd_s16(op1, svdup_n_s16(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqadd))]
pub unsafe fn svqadd_s32(op1: svint32_t, op2: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.sqadd.x.nxv4i32"
        )]
        fn _svqadd_s32(op1: svint32_t, op2: svint32_t) -> svint32_t;
    }
    unsafe { _svqadd_s32(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqadd))]
pub unsafe fn svqadd_n_s32(op1: svint32_t, op2: i32) -> svint32_t {
    svqadd_s32(op1, svdup_n_s32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqadd))]
pub unsafe fn svqadd_s64(op1: svint64_t, op2: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.sqadd.x.nxv2i64"
        )]
        fn _svqadd_s64(op1: svint64_t, op2: svint64_t) -> svint64_t;
    }
    unsafe { _svqadd_s64(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqadd))]
pub unsafe fn svqadd_n_s64(op1: svint64_t, op2: i64) -> svint64_t {
    svqadd_s64(op1, svdup_n_s64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqadd))]
pub unsafe fn svqadd_u8(op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.uqadd.x.nxv16i8"
        )]
        fn _svqadd_u8(op1: svint8_t, op2: svint8_t) -> svint8_t;
    }
    unsafe { _svqadd_u8(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqadd))]
pub unsafe fn svqadd_n_u8(op1: svuint8_t, op2: u8) -> svuint8_t {
    svqadd_u8(op1, svdup_n_u8(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqadd))]
pub unsafe fn svqadd_u16(op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.uqadd.x.nxv8i16"
        )]
        fn _svqadd_u16(op1: svint16_t, op2: svint16_t) -> svint16_t;
    }
    unsafe { _svqadd_u16(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqadd))]
pub unsafe fn svqadd_n_u16(op1: svuint16_t, op2: u16) -> svuint16_t {
    svqadd_u16(op1, svdup_n_u16(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqadd))]
pub unsafe fn svqadd_u32(op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.uqadd.x.nxv4i32"
        )]
        fn _svqadd_u32(op1: svint32_t, op2: svint32_t) -> svint32_t;
    }
    unsafe { _svqadd_u32(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqadd))]
pub unsafe fn svqadd_n_u32(op1: svuint32_t, op2: u32) -> svuint32_t {
    svqadd_u32(op1, svdup_n_u32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqadd))]
pub unsafe fn svqadd_u64(op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.uqadd.x.nxv2i64"
        )]
        fn _svqadd_u64(op1: svint64_t, op2: svint64_t) -> svint64_t;
    }
    unsafe { _svqadd_u64(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqadd))]
pub unsafe fn svqadd_n_u64(op1: svuint64_t, op2: u64) -> svuint64_t {
    svqadd_u64(op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqdecb, IMM_FACTOR = 1))]
pub unsafe fn svqdecb_n_s32<const IMM_FACTOR: i32>(op: i32) -> i32 {
    svqdecb_pat_n_s32(svpattern::SV_ALL , IMM_FACTOR,op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqdech, IMM_FACTOR = 1))]
pub unsafe fn svqdech_n_s32<const IMM_FACTOR: i32>(op: i32) -> i32 {
    svqdech_pat_n_s32(svpattern::SV_ALL , IMM_FACTOR,op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqdecw, IMM_FACTOR = 1))]
pub unsafe fn svqdecw_n_s32<const IMM_FACTOR: i32>(op: i32) -> i32 {
    svqdecw_pat_n_s32(svpattern::SV_ALL , IMM_FACTOR,op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqdecd, IMM_FACTOR = 1))]
pub unsafe fn svqdecd_n_s32<const IMM_FACTOR: i32>(op: i32) -> i32 {
    svqdecd_pat_n_s32(svpattern::SV_ALL , IMM_FACTOR,op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqdecb, IMM_FACTOR = 1))]
pub unsafe fn svqdecb_n_s64<const IMM_FACTOR: i32>(op: i64) -> i64 {
    svqdecb_pat_n_s64(svpattern::SV_ALL , IMM_FACTOR,op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqdech, IMM_FACTOR = 1))]
pub unsafe fn svqdech_n_s64<const IMM_FACTOR: i32>(op: i64) -> i64 {
    svqdech_pat_n_s64(svpattern::SV_ALL , IMM_FACTOR,op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqdecw, IMM_FACTOR = 1))]
pub unsafe fn svqdecw_n_s64<const IMM_FACTOR: i32>(op: i64) -> i64 {
    svqdecw_pat_n_s64(svpattern::SV_ALL , IMM_FACTOR,op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqdecd, IMM_FACTOR = 1))]
pub unsafe fn svqdecd_n_s64<const IMM_FACTOR: i32>(op: i64) -> i64 {
    svqdecd_pat_n_s64(svpattern::SV_ALL , IMM_FACTOR,op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqdecb, IMM_FACTOR = 1))]
pub unsafe fn svqdecb_n_u32<const IMM_FACTOR: i32>(op: u32) -> u32 {
    svqdecb_pat_n_u32(svpattern::SV_ALL , IMM_FACTOR,op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqdech, IMM_FACTOR = 1))]
pub unsafe fn svqdech_n_u32<const IMM_FACTOR: i32>(op: u32) -> u32 {
    svqdech_pat_n_u32(svpattern::SV_ALL , IMM_FACTOR,op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqdecw, IMM_FACTOR = 1))]
pub unsafe fn svqdecw_n_u32<const IMM_FACTOR: i32>(op: u32) -> u32 {
    svqdecw_pat_n_u32(svpattern::SV_ALL , IMM_FACTOR,op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqdecd, IMM_FACTOR = 1))]
pub unsafe fn svqdecd_n_u32<const IMM_FACTOR: i32>(op: u32) -> u32 {
    svqdecd_pat_n_u32(svpattern::SV_ALL , IMM_FACTOR,op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqdecb, IMM_FACTOR = 1))]
pub unsafe fn svqdecb_n_u64<const IMM_FACTOR: i32>(op: u64) -> u64 {
    svqdecb_pat_n_u64(svpattern::SV_ALL , IMM_FACTOR,op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqdech, IMM_FACTOR = 1))]
pub unsafe fn svqdech_n_u64<const IMM_FACTOR: i32>(op: u64) -> u64 {
    svqdech_pat_n_u64(svpattern::SV_ALL , IMM_FACTOR,op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqdecw, IMM_FACTOR = 1))]
pub unsafe fn svqdecw_n_u64<const IMM_FACTOR: i32>(op: u64) -> u64 {
    svqdecw_pat_n_u64(svpattern::SV_ALL , IMM_FACTOR,op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqdecd, IMM_FACTOR = 1))]
pub unsafe fn svqdecd_n_u64<const IMM_FACTOR: i32>(op: u64) -> u64 {
    svqdecd_pat_n_u64(svpattern::SV_ALL , IMM_FACTOR,op)
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (sqdecb , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub unsafe fn svqdecb_pat_n_s32(pattern: svpattern,imm_factor: i32,op: i32) -> i32 {
    static_assert_range!(imm_factor, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sqdecb.n32")]
        fn _svqdecb_pat_n_s32(op: i32, pattern: svpattern, imm_factor: i32) -> i32;
    }
    unsafe { _svqdecb_pat_n_s32(op, pattern, imm_factor) }
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (sqdech , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub unsafe fn svqdech_pat_n_s32(pattern: svpattern,imm_factor: i32,op: i32) -> i32 {
    static_assert_range!(imm_factor, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sqdech.n32")]
        fn _svqdech_pat_n_s32(op: i32, pattern: svpattern, imm_factor: i32) -> i32;
    }
    unsafe { _svqdech_pat_n_s32(op, pattern, imm_factor) }
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (sqdecw , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub unsafe fn svqdecw_pat_n_s32(pattern: svpattern,imm_factor: i32,op: i32) -> i32 {
    static_assert_range!(imm_factor, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sqdecw.n32")]
        fn _svqdecw_pat_n_s32(op: i32, pattern: svpattern, imm_factor: i32) -> i32;
    }
    unsafe { _svqdecw_pat_n_s32(op, pattern, imm_factor) }
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (sqdecd , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub unsafe fn svqdecd_pat_n_s32(pattern: svpattern,imm_factor: i32,op: i32) -> i32 {
    static_assert_range!(imm_factor, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sqdecd.n32")]
        fn _svqdecd_pat_n_s32(op: i32, pattern: svpattern, imm_factor: i32) -> i32;
    }
    unsafe { _svqdecd_pat_n_s32(op, pattern, imm_factor) }
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (sqdecb , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub unsafe fn svqdecb_pat_n_s64(pattern: svpattern,imm_factor: i32,op: i64) -> i64 {
    static_assert_range!(imm_factor, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sqdecb.n64")]
        fn _svqdecb_pat_n_s64(op: i64, pattern: svpattern, imm_factor: i32) -> i64;
    }
    unsafe { _svqdecb_pat_n_s64(op, pattern, imm_factor) }
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (sqdech , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub unsafe fn svqdech_pat_n_s64(pattern: svpattern,imm_factor: i32,op: i64) -> i64 {
    static_assert_range!(imm_factor, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sqdech.n64")]
        fn _svqdech_pat_n_s64(op: i64, pattern: svpattern, imm_factor: i32) -> i64;
    }
    unsafe { _svqdech_pat_n_s64(op, pattern, imm_factor) }
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (sqdecw , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub unsafe fn svqdecw_pat_n_s64(pattern: svpattern,imm_factor: i32,op: i64) -> i64 {
    static_assert_range!(imm_factor, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sqdecw.n64")]
        fn _svqdecw_pat_n_s64(op: i64, pattern: svpattern, imm_factor: i32) -> i64;
    }
    unsafe { _svqdecw_pat_n_s64(op, pattern, imm_factor) }
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (sqdecd , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub unsafe fn svqdecd_pat_n_s64(pattern: svpattern,imm_factor: i32,op: i64) -> i64 {
    static_assert_range!(imm_factor, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sqdecd.n64")]
        fn _svqdecd_pat_n_s64(op: i64, pattern: svpattern, imm_factor: i32) -> i64;
    }
    unsafe { _svqdecd_pat_n_s64(op, pattern, imm_factor) }
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (uqdecb , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub unsafe fn svqdecb_pat_n_u32(pattern: svpattern,imm_factor: i32,op: u32) -> u32 {
    static_assert_range!(imm_factor, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uqdecb.n32")]
        fn _svqdecb_pat_n_u32(op: i32, pattern: svpattern, imm_factor: i32) -> i32;
    }
    unsafe { _svqdecb_pat_n_u32(op.as_signed(), pattern, imm_factor).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (uqdech , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub unsafe fn svqdech_pat_n_u32(pattern: svpattern,imm_factor: i32,op: u32) -> u32 {
    static_assert_range!(imm_factor, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uqdech.n32")]
        fn _svqdech_pat_n_u32(op: i32, pattern: svpattern, imm_factor: i32) -> i32;
    }
    unsafe { _svqdech_pat_n_u32(op.as_signed(), pattern, imm_factor).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (uqdecw , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub unsafe fn svqdecw_pat_n_u32(pattern: svpattern,imm_factor: i32,op: u32) -> u32 {
    static_assert_range!(imm_factor, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uqdecw.n32")]
        fn _svqdecw_pat_n_u32(op: i32, pattern: svpattern, imm_factor: i32) -> i32;
    }
    unsafe { _svqdecw_pat_n_u32(op.as_signed(), pattern, imm_factor).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (uqdecd , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub unsafe fn svqdecd_pat_n_u32(pattern: svpattern,imm_factor: i32,op: u32) -> u32 {
    static_assert_range!(imm_factor, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uqdecd.n32")]
        fn _svqdecd_pat_n_u32(op: i32, pattern: svpattern, imm_factor: i32) -> i32;
    }
    unsafe { _svqdecd_pat_n_u32(op.as_signed(), pattern, imm_factor).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (uqdecb , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub unsafe fn svqdecb_pat_n_u64(pattern: svpattern,imm_factor: i32,op: u64) -> u64 {
    static_assert_range!(imm_factor, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uqdecb.n64")]
        fn _svqdecb_pat_n_u64(op: i64, pattern: svpattern, imm_factor: i32) -> i64;
    }
    unsafe { _svqdecb_pat_n_u64(op.as_signed(), pattern, imm_factor).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (uqdech , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub unsafe fn svqdech_pat_n_u64(pattern: svpattern,imm_factor: i32,op: u64) -> u64 {
    static_assert_range!(imm_factor, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uqdech.n64")]
        fn _svqdech_pat_n_u64(op: i64, pattern: svpattern, imm_factor: i32) -> i64;
    }
    unsafe { _svqdech_pat_n_u64(op.as_signed(), pattern, imm_factor).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (uqdecw , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub unsafe fn svqdecw_pat_n_u64(pattern: svpattern,imm_factor: i32,op: u64) -> u64 {
    static_assert_range!(imm_factor, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uqdecw.n64")]
        fn _svqdecw_pat_n_u64(op: i64, pattern: svpattern, imm_factor: i32) -> i64;
    }
    unsafe { _svqdecw_pat_n_u64(op.as_signed(), pattern, imm_factor).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (uqdecd , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub unsafe fn svqdecd_pat_n_u64(pattern: svpattern,imm_factor: i32,op: u64) -> u64 {
    static_assert_range!(imm_factor, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uqdecd.n64")]
        fn _svqdecd_pat_n_u64(op: i64, pattern: svpattern, imm_factor: i32) -> i64;
    }
    unsafe { _svqdecd_pat_n_u64(op.as_signed(), pattern, imm_factor).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (sqdech , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub unsafe fn svqdech_pat_s16(pattern: svpattern,imm_factor: i32,
    op: svint16_t,
) -> svint16_t {
    static_assert_range!(imm_factor, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sqdech.nxv8i16")]
        fn _svqdech_pat_s16(op: svint16_t, pattern: svpattern, imm_factor: i32) -> svint16_t;
    }
    unsafe { _svqdech_pat_s16(op, pattern, imm_factor) }
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (sqdecw , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub unsafe fn svqdecw_pat_s32(pattern: svpattern,imm_factor: i32,
    op: svint32_t,
) -> svint32_t {
    static_assert_range!(imm_factor, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sqdecw.nxv4i32")]
        fn _svqdecw_pat_s32(op: svint32_t, pattern: svpattern, imm_factor: i32) -> svint32_t;
    }
    unsafe { _svqdecw_pat_s32(op, pattern, imm_factor) }
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (sqdecd , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub unsafe fn svqdecd_pat_s64(pattern: svpattern,imm_factor: i32,
    op: svint64_t,
) -> svint64_t {
    static_assert_range!(imm_factor, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sqdecd.nxv2i64")]
        fn _svqdecd_pat_s64(op: svint64_t, pattern: svpattern, imm_factor: i32) -> svint64_t;
    }
    unsafe { _svqdecd_pat_s64(op, pattern, imm_factor) }
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (uqdech , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub unsafe fn svqdech_pat_u16(pattern: svpattern,imm_factor: i32,
    op: svuint16_t,
) -> svuint16_t {
    static_assert_range!(imm_factor, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uqdech.nxv8i16")]
        fn _svqdech_pat_u16(op: svint16_t, pattern: svpattern, imm_factor: i32) -> svint16_t;
    }
    unsafe { _svqdech_pat_u16(op.as_signed(), pattern, imm_factor).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (uqdecw , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub unsafe fn svqdecw_pat_u32(pattern: svpattern,imm_factor: i32,
    op: svuint32_t,
) -> svuint32_t {
    static_assert_range!(imm_factor, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uqdecw.nxv4i32")]
        fn _svqdecw_pat_u32(op: svint32_t, pattern: svpattern, imm_factor: i32) -> svint32_t;
    }
    unsafe { _svqdecw_pat_u32(op.as_signed(), pattern, imm_factor).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (uqdecd , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub unsafe fn svqdecd_pat_u64(pattern: svpattern,imm_factor: i32,
    op: svuint64_t,
) -> svuint64_t {
    static_assert_range!(imm_factor, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uqdecd.nxv2i64")]
        fn _svqdecd_pat_u64(op: svint64_t, pattern: svpattern, imm_factor: i32) -> svint64_t;
    }
    unsafe { _svqdecd_pat_u64(op.as_signed(), pattern, imm_factor).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqdech, IMM_FACTOR = 1))]
pub unsafe fn svqdech_s16<const IMM_FACTOR: i32>(op: svint16_t) -> svint16_t {
    svqdech_pat_s16(svpattern::SV_ALL , IMM_FACTOR,op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqdecw, IMM_FACTOR = 1))]
pub unsafe fn svqdecw_s32<const IMM_FACTOR: i32>(op: svint32_t) -> svint32_t {
    svqdecw_pat_s32(svpattern::SV_ALL , IMM_FACTOR,op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqdecd, IMM_FACTOR = 1))]
pub unsafe fn svqdecd_s64<const IMM_FACTOR: i32>(op: svint64_t) -> svint64_t {
    svqdecd_pat_s64(svpattern::SV_ALL , IMM_FACTOR,op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqdech, IMM_FACTOR = 1))]
pub unsafe fn svqdech_u16<const IMM_FACTOR: i32>(op: svuint16_t) -> svuint16_t {
    svqdech_pat_u16(svpattern::SV_ALL , IMM_FACTOR,op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqdecw, IMM_FACTOR = 1))]
pub unsafe fn svqdecw_u32<const IMM_FACTOR: i32>(op: svuint32_t) -> svuint32_t {
    svqdecw_pat_u32(svpattern::SV_ALL , IMM_FACTOR,op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqdecd, IMM_FACTOR = 1))]
pub unsafe fn svqdecd_u64<const IMM_FACTOR: i32>(op: svuint64_t) -> svuint64_t {
    svqdecd_pat_u64(svpattern::SV_ALL , IMM_FACTOR,op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqdecp))]
pub unsafe fn svqdecp_n_s32_b8(op: i32, pg: svbool_t) -> i32 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.sqdecp.n32.nxv16i1"
        )]
        fn _svqdecp_n_s32_b8(op: i32, pg: svbool_t) -> i32;
    }
    unsafe { _svqdecp_n_s32_b8(op, pg) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqdecp))]
pub unsafe fn svqdecp_n_s32_b16(op: i32, pg: svbool_t) -> i32 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.sqdecp.n32.nxv8i1"
        )]
        fn _svqdecp_n_s32_b16(op: i32, pg: svbool8_t) -> i32;
    }
    unsafe { _svqdecp_n_s32_b16(op, pg.into()) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqdecp))]
pub unsafe fn svqdecp_n_s32_b32(op: i32, pg: svbool_t) -> i32 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.sqdecp.n32.nxv4i1"
        )]
        fn _svqdecp_n_s32_b32(op: i32, pg: svbool4_t) -> i32;
    }
    unsafe { _svqdecp_n_s32_b32(op, pg.into()) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqdecp))]
pub unsafe fn svqdecp_n_s32_b64(op: i32, pg: svbool_t) -> i32 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.sqdecp.n32.nxv2i1"
        )]
        fn _svqdecp_n_s32_b64(op: i32, pg: svbool2_t) -> i32;
    }
    unsafe { _svqdecp_n_s32_b64(op, pg.into()) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqdecp))]
pub unsafe fn svqdecp_n_s64_b8(op: i64, pg: svbool_t) -> i64 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.sqdecp.n64.nxv16i1"
        )]
        fn _svqdecp_n_s64_b8(op: i64, pg: svbool_t) -> i64;
    }
    unsafe { _svqdecp_n_s64_b8(op, pg) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqdecp))]
pub unsafe fn svqdecp_n_s64_b16(op: i64, pg: svbool_t) -> i64 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.sqdecp.n64.nxv8i1"
        )]
        fn _svqdecp_n_s64_b16(op: i64, pg: svbool8_t) -> i64;
    }
    unsafe { _svqdecp_n_s64_b16(op, pg.into()) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqdecp))]
pub unsafe fn svqdecp_n_s64_b32(op: i64, pg: svbool_t) -> i64 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.sqdecp.n64.nxv4i1"
        )]
        fn _svqdecp_n_s64_b32(op: i64, pg: svbool4_t) -> i64;
    }
    unsafe { _svqdecp_n_s64_b32(op, pg.into()) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqdecp))]
pub unsafe fn svqdecp_n_s64_b64(op: i64, pg: svbool_t) -> i64 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.sqdecp.n64.nxv2i1"
        )]
        fn _svqdecp_n_s64_b64(op: i64, pg: svbool2_t) -> i64;
    }
    unsafe { _svqdecp_n_s64_b64(op, pg.into()) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqdecp))]
pub unsafe fn svqdecp_n_u32_b8(op: u32, pg: svbool_t) -> u32 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.uqdecp.n32.nxv16i1"
        )]
        fn _svqdecp_n_u32_b8(op: i32, pg: svbool_t) -> i32;
    }
    unsafe { _svqdecp_n_u32_b8(op.as_signed(), pg).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqdecp))]
pub unsafe fn svqdecp_n_u32_b16(op: u32, pg: svbool_t) -> u32 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.uqdecp.n32.nxv8i1"
        )]
        fn _svqdecp_n_u32_b16(op: i32, pg: svbool8_t) -> i32;
    }
    unsafe { _svqdecp_n_u32_b16(op.as_signed(), pg.into()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqdecp))]
pub unsafe fn svqdecp_n_u32_b32(op: u32, pg: svbool_t) -> u32 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.uqdecp.n32.nxv4i1"
        )]
        fn _svqdecp_n_u32_b32(op: i32, pg: svbool4_t) -> i32;
    }
    unsafe { _svqdecp_n_u32_b32(op.as_signed(), pg.into()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqdecp))]
pub unsafe fn svqdecp_n_u32_b64(op: u32, pg: svbool_t) -> u32 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.uqdecp.n32.nxv2i1"
        )]
        fn _svqdecp_n_u32_b64(op: i32, pg: svbool2_t) -> i32;
    }
    unsafe { _svqdecp_n_u32_b64(op.as_signed(), pg.into()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqdecp))]
pub unsafe fn svqdecp_n_u64_b8(op: u64, pg: svbool_t) -> u64 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.uqdecp.n64.nxv16i1"
        )]
        fn _svqdecp_n_u64_b8(op: i64, pg: svbool_t) -> i64;
    }
    unsafe { _svqdecp_n_u64_b8(op.as_signed(), pg).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqdecp))]
pub unsafe fn svqdecp_n_u64_b16(op: u64, pg: svbool_t) -> u64 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.uqdecp.n64.nxv8i1"
        )]
        fn _svqdecp_n_u64_b16(op: i64, pg: svbool8_t) -> i64;
    }
    unsafe { _svqdecp_n_u64_b16(op.as_signed(), pg.into()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqdecp))]
pub unsafe fn svqdecp_n_u64_b32(op: u64, pg: svbool_t) -> u64 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.uqdecp.n64.nxv4i1"
        )]
        fn _svqdecp_n_u64_b32(op: i64, pg: svbool4_t) -> i64;
    }
    unsafe { _svqdecp_n_u64_b32(op.as_signed(), pg.into()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqdecp))]
pub unsafe fn svqdecp_n_u64_b64(op: u64, pg: svbool_t) -> u64 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.uqdecp.n64.nxv2i1"
        )]
        fn _svqdecp_n_u64_b64(op: i64, pg: svbool2_t) -> i64;
    }
    unsafe { _svqdecp_n_u64_b64(op.as_signed(), pg.into()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqdecp))]
pub unsafe fn svqdecp_s16(op: svint16_t, pg: svbool_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sqdecp.nxv8i16")]
        fn _svqdecp_s16(op: svint16_t, pg: svbool8_t) -> svint16_t;
    }
    unsafe { _svqdecp_s16(op, pg.into()) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqdecp))]
pub unsafe fn svqdecp_s32(op: svint32_t, pg: svbool_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sqdecp.nxv4i32")]
        fn _svqdecp_s32(op: svint32_t, pg: svbool4_t) -> svint32_t;
    }
    unsafe { _svqdecp_s32(op, pg.into()) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqdecp))]
pub unsafe fn svqdecp_s64(op: svint64_t, pg: svbool_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sqdecp.nxv2i64")]
        fn _svqdecp_s64(op: svint64_t, pg: svbool2_t) -> svint64_t;
    }
    unsafe { _svqdecp_s64(op, pg.into()) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqdecp))]
pub unsafe fn svqdecp_u16(op: svuint16_t, pg: svbool_t) -> svuint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uqdecp.nxv8i16")]
        fn _svqdecp_u16(op: svint16_t, pg: svbool8_t) -> svint16_t;
    }
    unsafe { _svqdecp_u16(op.as_signed(), pg.into()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqdecp))]
pub unsafe fn svqdecp_u32(op: svuint32_t, pg: svbool_t) -> svuint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uqdecp.nxv4i32")]
        fn _svqdecp_u32(op: svint32_t, pg: svbool4_t) -> svint32_t;
    }
    unsafe { _svqdecp_u32(op.as_signed(), pg.into()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqdecp))]
pub unsafe fn svqdecp_u64(op: svuint64_t, pg: svbool_t) -> svuint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uqdecp.nxv2i64")]
        fn _svqdecp_u64(op: svint64_t, pg: svbool2_t) -> svint64_t;
    }
    unsafe { _svqdecp_u64(op.as_signed(), pg.into()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqincb, IMM_FACTOR = 1))]
pub unsafe fn svqincb_n_s32<const IMM_FACTOR: i32>(op: i32) -> i32 {
    svqincb_pat_n_s32(svpattern::SV_ALL , IMM_FACTOR,op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqinch, IMM_FACTOR = 1))]
pub unsafe fn svqinch_n_s32<const IMM_FACTOR: i32>(op: i32) -> i32 {
    svqinch_pat_n_s32(svpattern::SV_ALL , IMM_FACTOR,op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqincw, IMM_FACTOR = 1))]
pub unsafe fn svqincw_n_s32<const IMM_FACTOR: i32>(op: i32) -> i32 {
    svqincw_pat_n_s32(svpattern::SV_ALL , IMM_FACTOR,op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqincd, IMM_FACTOR = 1))]
pub unsafe fn svqincd_n_s32<const IMM_FACTOR: i32>(op: i32) -> i32 {
    svqincd_pat_n_s32(svpattern::SV_ALL , IMM_FACTOR,op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqincb, IMM_FACTOR = 1))]
pub unsafe fn svqincb_n_s64<const IMM_FACTOR: i32>(op: i64) -> i64 {
    svqincb_pat_n_s64(svpattern::SV_ALL , IMM_FACTOR,op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqinch, IMM_FACTOR = 1))]
pub unsafe fn svqinch_n_s64<const IMM_FACTOR: i32>(op: i64) -> i64 {
    svqinch_pat_n_s64(svpattern::SV_ALL , IMM_FACTOR,op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqincw, IMM_FACTOR = 1))]
pub unsafe fn svqincw_n_s64<const IMM_FACTOR: i32>(op: i64) -> i64 {
    svqincw_pat_n_s64(svpattern::SV_ALL , IMM_FACTOR,op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqincd, IMM_FACTOR = 1))]
pub unsafe fn svqincd_n_s64<const IMM_FACTOR: i32>(op: i64) -> i64 {
    svqincd_pat_n_s64(svpattern::SV_ALL , IMM_FACTOR,op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqincb, IMM_FACTOR = 1))]
pub unsafe fn svqincb_n_u32<const IMM_FACTOR: i32>(op: u32) -> u32 {
    svqincb_pat_n_u32(svpattern::SV_ALL , IMM_FACTOR,op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqinch, IMM_FACTOR = 1))]
pub unsafe fn svqinch_n_u32<const IMM_FACTOR: i32>(op: u32) -> u32 {
    svqinch_pat_n_u32(svpattern::SV_ALL , IMM_FACTOR,op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqincw, IMM_FACTOR = 1))]
pub unsafe fn svqincw_n_u32<const IMM_FACTOR: i32>(op: u32) -> u32 {
    svqincw_pat_n_u32(svpattern::SV_ALL , IMM_FACTOR,op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqincd, IMM_FACTOR = 1))]
pub unsafe fn svqincd_n_u32<const IMM_FACTOR: i32>(op: u32) -> u32 {
    svqincd_pat_n_u32(svpattern::SV_ALL , IMM_FACTOR,op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqincb, IMM_FACTOR = 1))]
pub unsafe fn svqincb_n_u64<const IMM_FACTOR: i32>(op: u64) -> u64 {
    svqincb_pat_n_u64(svpattern::SV_ALL , IMM_FACTOR,op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqinch, IMM_FACTOR = 1))]
pub unsafe fn svqinch_n_u64<const IMM_FACTOR: i32>(op: u64) -> u64 {
    svqinch_pat_n_u64(svpattern::SV_ALL , IMM_FACTOR,op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqincw, IMM_FACTOR = 1))]
pub unsafe fn svqincw_n_u64<const IMM_FACTOR: i32>(op: u64) -> u64 {
    svqincw_pat_n_u64(svpattern::SV_ALL , IMM_FACTOR,op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqincd, IMM_FACTOR = 1))]
pub unsafe fn svqincd_n_u64<const IMM_FACTOR: i32>(op: u64) -> u64 {
    svqincd_pat_n_u64(svpattern::SV_ALL , IMM_FACTOR,op)
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (sqincb , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub unsafe fn svqincb_pat_n_s32(pattern: svpattern,imm_factor: i32,op: i32) -> i32 {
    static_assert_range!(imm_factor, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sqincb.n32")]
        fn _svqincb_pat_n_s32(op: i32, pattern: svpattern, imm_factor: i32) -> i32;
    }
    unsafe { _svqincb_pat_n_s32(op, pattern, imm_factor) }
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (sqinch , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub unsafe fn svqinch_pat_n_s32(pattern: svpattern,imm_factor: i32,op: i32) -> i32 {
    static_assert_range!(imm_factor, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sqinch.n32")]
        fn _svqinch_pat_n_s32(op: i32, pattern: svpattern, imm_factor: i32) -> i32;
    }
    unsafe { _svqinch_pat_n_s32(op, pattern, imm_factor) }
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (sqincw , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub unsafe fn svqincw_pat_n_s32(pattern: svpattern,imm_factor: i32,op: i32) -> i32 {
    static_assert_range!(imm_factor, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sqincw.n32")]
        fn _svqincw_pat_n_s32(op: i32, pattern: svpattern, imm_factor: i32) -> i32;
    }
    unsafe { _svqincw_pat_n_s32(op, pattern, imm_factor) }
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (sqincd , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub unsafe fn svqincd_pat_n_s32(pattern: svpattern,imm_factor: i32,op: i32) -> i32 {
    static_assert_range!(imm_factor, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sqincd.n32")]
        fn _svqincd_pat_n_s32(op: i32, pattern: svpattern, imm_factor: i32) -> i32;
    }
    unsafe { _svqincd_pat_n_s32(op, pattern, imm_factor) }
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (sqincb , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub unsafe fn svqincb_pat_n_s64(pattern: svpattern,imm_factor: i32,op: i64) -> i64 {
    static_assert_range!(imm_factor, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sqincb.n64")]
        fn _svqincb_pat_n_s64(op: i64, pattern: svpattern, imm_factor: i32) -> i64;
    }
    unsafe { _svqincb_pat_n_s64(op, pattern, imm_factor) }
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (sqinch , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub unsafe fn svqinch_pat_n_s64(pattern: svpattern,imm_factor: i32,op: i64) -> i64 {
    static_assert_range!(imm_factor, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sqinch.n64")]
        fn _svqinch_pat_n_s64(op: i64, pattern: svpattern, imm_factor: i32) -> i64;
    }
    unsafe { _svqinch_pat_n_s64(op, pattern, imm_factor) }
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (sqincw , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub unsafe fn svqincw_pat_n_s64(pattern: svpattern,imm_factor: i32,op: i64) -> i64 {
    static_assert_range!(imm_factor, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sqincw.n64")]
        fn _svqincw_pat_n_s64(op: i64, pattern: svpattern, imm_factor: i32) -> i64;
    }
    unsafe { _svqincw_pat_n_s64(op, pattern, imm_factor) }
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (sqincd , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub unsafe fn svqincd_pat_n_s64(pattern: svpattern,imm_factor: i32,op: i64) -> i64 {
    static_assert_range!(imm_factor, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sqincd.n64")]
        fn _svqincd_pat_n_s64(op: i64, pattern: svpattern, imm_factor: i32) -> i64;
    }
    unsafe { _svqincd_pat_n_s64(op, pattern, imm_factor) }
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (uqincb , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub unsafe fn svqincb_pat_n_u32(pattern: svpattern,imm_factor: i32,op: u32) -> u32 {
    static_assert_range!(imm_factor, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uqincb.n32")]
        fn _svqincb_pat_n_u32(op: i32, pattern: svpattern, imm_factor: i32) -> i32;
    }
    unsafe { _svqincb_pat_n_u32(op.as_signed(), pattern, imm_factor).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (uqinch , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub unsafe fn svqinch_pat_n_u32(pattern: svpattern,imm_factor: i32,op: u32) -> u32 {
    static_assert_range!(imm_factor, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uqinch.n32")]
        fn _svqinch_pat_n_u32(op: i32, pattern: svpattern, imm_factor: i32) -> i32;
    }
    unsafe { _svqinch_pat_n_u32(op.as_signed(), pattern, imm_factor).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (uqincw , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub unsafe fn svqincw_pat_n_u32(pattern: svpattern,imm_factor: i32,op: u32) -> u32 {
    static_assert_range!(imm_factor, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uqincw.n32")]
        fn _svqincw_pat_n_u32(op: i32, pattern: svpattern, imm_factor: i32) -> i32;
    }
    unsafe { _svqincw_pat_n_u32(op.as_signed(), pattern, imm_factor).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (uqincd , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub unsafe fn svqincd_pat_n_u32(pattern: svpattern,imm_factor: i32,op: u32) -> u32 {
    static_assert_range!(imm_factor, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uqincd.n32")]
        fn _svqincd_pat_n_u32(op: i32, pattern: svpattern, imm_factor: i32) -> i32;
    }
    unsafe { _svqincd_pat_n_u32(op.as_signed(),pattern, imm_factor).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (uqincb , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub unsafe fn svqincb_pat_n_u64(pattern: svpattern,imm_factor: i32,op: u64) -> u64 {
    static_assert_range!(imm_factor, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uqincb.n64")]
        fn _svqincb_pat_n_u64(op: i64, pattern: svpattern, imm_factor: i32) -> i64;
    }
    unsafe { _svqincb_pat_n_u64(op.as_signed(), pattern, imm_factor).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (uqinch , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub unsafe fn svqinch_pat_n_u64(pattern: svpattern,imm_factor: i32,op: u64) -> u64 {
    static_assert_range!(imm_factor, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uqinch.n64")]
        fn _svqinch_pat_n_u64(op: i64, pattern: svpattern, imm_factor: i32) -> i64;
    }
    unsafe { _svqinch_pat_n_u64(op.as_signed(), pattern, imm_factor).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (uqincw , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub unsafe fn svqincw_pat_n_u64(pattern: svpattern,imm_factor: i32,op: u64) -> u64 {
    static_assert_range!(imm_factor, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uqincw.n64")]
        fn _svqincw_pat_n_u64(op: i64, pattern: svpattern, imm_factor: i32) -> i64;
    }
    unsafe { _svqincw_pat_n_u64(op.as_signed(), pattern, imm_factor).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (uqincd , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub unsafe fn svqincd_pat_n_u64(pattern: svpattern,imm_factor: i32,op: u64) -> u64 {
    static_assert_range!(imm_factor, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uqincd.n64")]
        fn _svqincd_pat_n_u64(op: i64, pattern: svpattern, imm_factor: i32) -> i64;
    }
    unsafe { _svqincd_pat_n_u64(op.as_signed(),pattern, imm_factor).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (sqinch , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub unsafe fn svqinch_pat_s16(pattern: svpattern,imm_factor: i32,
    op: svint16_t,
) -> svint16_t {
    static_assert_range!(imm_factor, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sqinch.nxv8i16")]
        fn _svqinch_pat_s16(op: svint16_t, pattern: svpattern, imm_factor: i32) -> svint16_t;
    }
    unsafe { _svqinch_pat_s16(op,  pattern, imm_factor) }
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (sqincw , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub unsafe fn svqincw_pat_s32(pattern: svpattern,imm_factor: i32,
    op: svint32_t,
) -> svint32_t {
    static_assert_range!(imm_factor, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sqincw.nxv4i32")]
        fn _svqincw_pat_s32(op: svint32_t, pattern: svpattern, imm_factor: i32) -> svint32_t;
    }
    unsafe { _svqincw_pat_s32(op,  pattern, imm_factor) }
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (sqincd , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub unsafe fn svqincd_pat_s64(pattern: svpattern,imm_factor: i32,
    op: svint64_t,
) -> svint64_t {
    static_assert_range!(imm_factor, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sqincd.nxv2i64")]
        fn _svqincd_pat_s64(op: svint64_t, pattern: svpattern, imm_factor: i32) -> svint64_t;
    }
    unsafe { _svqincd_pat_s64(op,  pattern, imm_factor) }
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (uqinch , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub unsafe fn svqinch_pat_u16(pattern: svpattern,imm_factor: i32,
    op: svuint16_t,
) -> svuint16_t {
    static_assert_range!(imm_factor, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uqinch.nxv8i16")]
        fn _svqinch_pat_u16(op: svint16_t, pattern: svpattern, imm_factor: i32) -> svint16_t;
    }
    unsafe { _svqinch_pat_u16(op.as_signed(),  pattern, imm_factor).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (uqincw , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub unsafe fn svqincw_pat_u32(pattern: svpattern,imm_factor: i32,
    op: svuint32_t,
) -> svuint32_t {
    static_assert_range!(imm_factor, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uqincw.nxv4i32")]
        fn _svqincw_pat_u32(op: svint32_t, pattern: svpattern, imm_factor: i32) -> svint32_t;
    }
    unsafe { _svqincw_pat_u32(op.as_signed(),  pattern, imm_factor).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (uqincd , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub unsafe fn svqincd_pat_u64(pattern: svpattern,imm_factor: i32,
    op: svuint64_t,
) -> svuint64_t {
    static_assert_range!(imm_factor, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uqincd.nxv2i64")]
        fn _svqincd_pat_u64(op: svint64_t, pattern: svpattern, imm_factor: i32) -> svint64_t;
    }
    unsafe { _svqincd_pat_u64(op.as_signed(),  pattern, imm_factor).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqinch, IMM_FACTOR = 1))]
pub unsafe fn svqinch_s16<const IMM_FACTOR: i32>(op: svint16_t) -> svint16_t {
    svqinch_pat_s16(svpattern::SV_ALL , IMM_FACTOR,op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqincw, IMM_FACTOR = 1))]
pub unsafe fn svqincw_s32<const IMM_FACTOR: i32>(op: svint32_t) -> svint32_t {
    svqincw_pat_s32(svpattern::SV_ALL , IMM_FACTOR,op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqincd, IMM_FACTOR = 1))]
pub unsafe fn svqincd_s64<const IMM_FACTOR: i32>(op: svint64_t) -> svint64_t {
    svqincd_pat_s64(svpattern::SV_ALL , IMM_FACTOR,op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqinch, IMM_FACTOR = 1))]
pub unsafe fn svqinch_u16<const IMM_FACTOR: i32>(op: svuint16_t) -> svuint16_t {
    svqinch_pat_u16(svpattern::SV_ALL , IMM_FACTOR,op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqincw, IMM_FACTOR = 1))]
pub unsafe fn svqincw_u32<const IMM_FACTOR: i32>(op: svuint32_t) -> svuint32_t {
    svqincw_pat_u32(svpattern::SV_ALL , IMM_FACTOR,op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqincd, IMM_FACTOR = 1))]
pub unsafe fn svqincd_u64<const IMM_FACTOR: i32>(op: svuint64_t) -> svuint64_t {
    svqincd_pat_u64(svpattern::SV_ALL , IMM_FACTOR,op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqincp))]
pub unsafe fn svqincp_n_s32_b8(op: i32, pg: svbool_t) -> i32 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.sqincp.n32.nxv16i1"
        )]
        fn _svqincp_n_s32_b8(op: i32, pg: svbool_t) -> i32;
    }
    unsafe { _svqincp_n_s32_b8(op, pg) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqincp))]
pub unsafe fn svqincp_n_s32_b16(op: i32, pg: svbool_t) -> i32 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.sqincp.n32.nxv8i1"
        )]
        fn _svqincp_n_s32_b16(op: i32, pg: svbool8_t) -> i32;
    }
    unsafe { _svqincp_n_s32_b16(op, pg.into()) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqincp))]
pub unsafe fn svqincp_n_s32_b32(op: i32, pg: svbool_t) -> i32 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.sqincp.n32.nxv4i1"
        )]
        fn _svqincp_n_s32_b32(op: i32, pg: svbool4_t) -> i32;
    }
    unsafe { _svqincp_n_s32_b32(op, pg.into()) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqincp))]
pub unsafe fn svqincp_n_s32_b64(op: i32, pg: svbool_t) -> i32 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.sqincp.n32.nxv2i1"
        )]
        fn _svqincp_n_s32_b64(op: i32, pg: svbool2_t) -> i32;
    }
    unsafe { _svqincp_n_s32_b64(op, pg.into()) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqincp))]
pub unsafe fn svqincp_n_s64_b8(op: i64, pg: svbool_t) -> i64 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.sqincp.n64.nxv16i1"
        )]
        fn _svqincp_n_s64_b8(op: i64, pg: svbool_t) -> i64;
    }
    unsafe { _svqincp_n_s64_b8(op, pg) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqincp))]
pub unsafe fn svqincp_n_s64_b16(op: i64, pg: svbool_t) -> i64 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.sqincp.n64.nxv8i1"
        )]
        fn _svqincp_n_s64_b16(op: i64, pg: svbool8_t) -> i64;
    }
    unsafe { _svqincp_n_s64_b16(op, pg.into()) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqincp))]
pub unsafe fn svqincp_n_s64_b32(op: i64, pg: svbool_t) -> i64 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.sqincp.n64.nxv4i1"
        )]
        fn _svqincp_n_s64_b32(op: i64, pg: svbool4_t) -> i64;
    }
    unsafe { _svqincp_n_s64_b32(op, pg.into()) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqincp))]
pub unsafe fn svqincp_n_s64_b64(op: i64, pg: svbool_t) -> i64 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.sqincp.n64.nxv2i1"
        )]
        fn _svqincp_n_s64_b64(op: i64, pg: svbool2_t) -> i64;
    }
    unsafe { _svqincp_n_s64_b64(op, pg.into()) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqincp))]
pub unsafe fn svqincp_n_u32_b8(op: u32, pg: svbool_t) -> u32 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.uqincp.n32.nxv16i1"
        )]
        fn _svqincp_n_u32_b8(op: i32, pg: svbool_t) -> i32;
    }
    unsafe { _svqincp_n_u32_b8(op.as_signed(), pg).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqincp))]
pub unsafe fn svqincp_n_u32_b16(op: u32, pg: svbool_t) -> u32 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.uqincp.n32.nxv8i1"
        )]
        fn _svqincp_n_u32_b16(op: i32, pg: svbool8_t) -> i32;
    }
    unsafe { _svqincp_n_u32_b16(op.as_signed(), pg.into()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqincp))]
pub unsafe fn svqincp_n_u32_b32(op: u32, pg: svbool_t) -> u32 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.uqincp.n32.nxv4i1"
        )]
        fn _svqincp_n_u32_b32(op: i32, pg: svbool4_t) -> i32;
    }
    unsafe { _svqincp_n_u32_b32(op.as_signed(), pg.into()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqincp))]
pub unsafe fn svqincp_n_u32_b64(op: u32, pg: svbool_t) -> u32 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.uqincp.n32.nxv2i1"
        )]
        fn _svqincp_n_u32_b64(op: i32, pg: svbool2_t) -> i32;
    }
    unsafe { _svqincp_n_u32_b64(op.as_signed(), pg.into()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqincp))]
pub unsafe fn svqincp_n_u64_b8(op: u64, pg: svbool_t) -> u64 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.uqincp.n64.nxv16i1"
        )]
        fn _svqincp_n_u64_b8(op: i64, pg: svbool_t) -> i64;
    }
    unsafe { _svqincp_n_u64_b8(op.as_signed(), pg).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqincp))]
pub unsafe fn svqincp_n_u64_b16(op: u64, pg: svbool_t) -> u64 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.uqincp.n64.nxv8i1"
        )]
        fn _svqincp_n_u64_b16(op: i64, pg: svbool8_t) -> i64;
    }
    unsafe { _svqincp_n_u64_b16(op.as_signed(), pg.into()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqincp))]
pub unsafe fn svqincp_n_u64_b32(op: u64, pg: svbool_t) -> u64 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.uqincp.n64.nxv4i1"
        )]
        fn _svqincp_n_u64_b32(op: i64, pg: svbool4_t) -> i64;
    }
    unsafe { _svqincp_n_u64_b32(op.as_signed(), pg.into()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqincp))]
pub unsafe fn svqincp_n_u64_b64(op: u64, pg: svbool_t) -> u64 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.uqincp.n64.nxv2i1"
        )]
        fn _svqincp_n_u64_b64(op: i64, pg: svbool2_t) -> i64;
    }
    unsafe { _svqincp_n_u64_b64(op.as_signed(), pg.into()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqincp))]
pub unsafe fn svqincp_s16(op: svint16_t, pg: svbool_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sqincp.nxv8i16")]
        fn _svqincp_s16(op: svint16_t, pg: svbool8_t) -> svint16_t;
    }
    unsafe { _svqincp_s16(op, pg.into()) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqincp))]
pub unsafe fn svqincp_s32(op: svint32_t, pg: svbool_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sqincp.nxv4i32")]
        fn _svqincp_s32(op: svint32_t, pg: svbool4_t) -> svint32_t;
    }
    unsafe { _svqincp_s32(op, pg.into()) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqincp))]
pub unsafe fn svqincp_s64(op: svint64_t, pg: svbool_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sqincp.nxv2i64")]
        fn _svqincp_s64(op: svint64_t, pg: svbool2_t) -> svint64_t;
    }
    unsafe { _svqincp_s64(op, pg.into()) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqincp))]
pub unsafe fn svqincp_u16(op: svuint16_t, pg: svbool_t) -> svuint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uqincp.nxv8i16")]
        fn _svqincp_u16(op: svint16_t, pg: svbool8_t) -> svint16_t;
    }
    unsafe { _svqincp_u16(op.as_signed(), pg.into()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqincp))]
pub unsafe fn svqincp_u32(op: svuint32_t, pg: svbool_t) -> svuint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uqincp.nxv4i32")]
        fn _svqincp_u32(op: svint32_t, pg: svbool4_t) -> svint32_t;
    }
    unsafe { _svqincp_u32(op.as_signed(), pg.into()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqincp))]
pub unsafe fn svqincp_u64(op: svuint64_t, pg: svbool_t) -> svuint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uqincp.nxv2i64")]
        fn _svqincp_u64(op: svint64_t, pg: svbool2_t) -> svint64_t;
    }
    unsafe { _svqincp_u64(op.as_signed(), pg.into()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqsub))]
pub unsafe fn svqsub_s8(op1: svint8_t, op2: svint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.sqsub.x.nxv16i8"
        )]
        fn _svqsub_s8(op1: svint8_t, op2: svint8_t) -> svint8_t;
    }
    unsafe { _svqsub_s8(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqsub))]
pub unsafe fn svqsub_n_s8(op1: svint8_t, op2: i8) -> svint8_t {
    svqsub_s8(op1, svdup_n_s8(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqsub))]
pub unsafe fn svqsub_s16(op1: svint16_t, op2: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.sqsub.x.nxv8i16"
        )]
        fn _svqsub_s16(op1: svint16_t, op2: svint16_t) -> svint16_t;
    }
    unsafe { _svqsub_s16(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqsub))]
pub unsafe fn svqsub_n_s16(op1: svint16_t, op2: i16) -> svint16_t {
    svqsub_s16(op1, svdup_n_s16(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqsub))]
pub unsafe fn svqsub_s32(op1: svint32_t, op2: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.sqsub.x.nxv4i32"
        )]
        fn _svqsub_s32(op1: svint32_t, op2: svint32_t) -> svint32_t;
    }
    unsafe { _svqsub_s32(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqsub))]
pub unsafe fn svqsub_n_s32(op1: svint32_t, op2: i32) -> svint32_t {
    svqsub_s32(op1, svdup_n_s32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqsub))]
pub unsafe fn svqsub_s64(op1: svint64_t, op2: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.sqsub.x.nxv2i64"
        )]
        fn _svqsub_s64(op1: svint64_t, op2: svint64_t) -> svint64_t;
    }
    unsafe { _svqsub_s64(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqsub))]
pub unsafe fn svqsub_n_s64(op1: svint64_t, op2: i64) -> svint64_t {
    svqsub_s64(op1, svdup_n_s64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqsub))]
pub unsafe fn svqsub_u8(op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.uqsub.x.nxv16i8"
        )]
        fn _svqsub_u8(op1: svint8_t, op2: svint8_t) -> svint8_t;
    }
    unsafe { _svqsub_u8(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqsub))]
pub unsafe fn svqsub_n_u8(op1: svuint8_t, op2: u8) -> svuint8_t {
    svqsub_u8(op1, svdup_n_u8(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqsub))]
pub unsafe fn svqsub_u16(op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.uqsub.x.nxv8i16"
        )]
        fn _svqsub_u16(op1: svint16_t, op2: svint16_t) -> svint16_t;
    }
    unsafe { _svqsub_u16(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqsub))]
pub unsafe fn svqsub_n_u16(op1: svuint16_t, op2: u16) -> svuint16_t {
    svqsub_u16(op1, svdup_n_u16(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqsub))]
pub unsafe fn svqsub_u32(op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.uqsub.x.nxv4i32"
        )]
        fn _svqsub_u32(op1: svint32_t, op2: svint32_t) -> svint32_t;
    }
    unsafe { _svqsub_u32(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqsub))]
pub unsafe fn svqsub_n_u32(op1: svuint32_t, op2: u32) -> svuint32_t {
    svqsub_u32(op1, svdup_n_u32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqsub))]
pub unsafe fn svqsub_u64(op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.uqsub.x.nxv2i64"
        )]
        fn _svqsub_u64(op1: svint64_t, op2: svint64_t) -> svint64_t;
    }
    unsafe { _svqsub_u64(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqsub))]
pub unsafe fn svqsub_n_u64(op1: svuint64_t, op2: u64) -> svuint64_t {
    svqsub_u64(op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rbit))]
pub unsafe fn svrbit_s8_m(inactive: svint8_t, pg: svbool_t, op: svint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.rbit.nxv16i8")]
        fn _svrbit_s8_m(inactive: svint8_t, pg: svbool_t, op: svint8_t) -> svint8_t;
    }
    unsafe { _svrbit_s8_m(inactive, pg, op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rbit))]
pub unsafe fn svrbit_s8_x(pg: svbool_t, op: svint8_t) -> svint8_t {
    svrbit_s8_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rbit))]
pub unsafe fn svrbit_s8_z(pg: svbool_t, op: svint8_t) -> svint8_t {
    svrbit_s8_m(svdup_n_s8(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rbit))]
pub unsafe fn svrbit_s16_m(inactive: svint16_t, pg: svbool_t, op: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.rbit.nxv8i16")]
        fn _svrbit_s16_m(inactive: svint16_t, pg: svbool8_t, op: svint16_t) -> svint16_t;
    }
    unsafe { _svrbit_s16_m(inactive, pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rbit))]
pub unsafe fn svrbit_s16_x(pg: svbool_t, op: svint16_t) -> svint16_t {
    svrbit_s16_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rbit))]
pub unsafe fn svrbit_s16_z(pg: svbool_t, op: svint16_t) -> svint16_t {
    svrbit_s16_m(svdup_n_s16(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rbit))]
pub unsafe fn svrbit_s32_m(inactive: svint32_t, pg: svbool_t, op: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.rbit.nxv4i32")]
        fn _svrbit_s32_m(inactive: svint32_t, pg: svbool4_t, op: svint32_t) -> svint32_t;
    }
    unsafe { _svrbit_s32_m(inactive, pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rbit))]
pub unsafe fn svrbit_s32_x(pg: svbool_t, op: svint32_t) -> svint32_t {
    svrbit_s32_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rbit))]
pub unsafe fn svrbit_s32_z(pg: svbool_t, op: svint32_t) -> svint32_t {
    svrbit_s32_m(svdup_n_s32(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rbit))]
pub unsafe fn svrbit_s64_m(inactive: svint64_t, pg: svbool_t, op: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.rbit.nxv2i64")]
        fn _svrbit_s64_m(inactive: svint64_t, pg: svbool2_t, op: svint64_t) -> svint64_t;
    }
    unsafe { _svrbit_s64_m(inactive, pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rbit))]
pub unsafe fn svrbit_s64_x(pg: svbool_t, op: svint64_t) -> svint64_t {
    svrbit_s64_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rbit))]
pub unsafe fn svrbit_s64_z(pg: svbool_t, op: svint64_t) -> svint64_t {
    svrbit_s64_m(svdup_n_s64(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rbit))]
pub unsafe fn svrbit_u8_m(inactive: svuint8_t, pg: svbool_t, op: svuint8_t) -> svuint8_t {
    unsafe { svrbit_s8_m(inactive.as_signed(), pg, op.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rbit))]
pub unsafe fn svrbit_u8_x(pg: svbool_t, op: svuint8_t) -> svuint8_t {
    svrbit_u8_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rbit))]
pub unsafe fn svrbit_u8_z(pg: svbool_t, op: svuint8_t) -> svuint8_t {
    svrbit_u8_m(svdup_n_u8(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rbit))]
pub unsafe fn svrbit_u16_m(inactive: svuint16_t, pg: svbool_t, op: svuint16_t) -> svuint16_t {
    unsafe { svrbit_s16_m(inactive.as_signed(), pg, op.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rbit))]
pub unsafe fn svrbit_u16_x(pg: svbool_t, op: svuint16_t) -> svuint16_t {
    svrbit_u16_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rbit))]
pub unsafe fn svrbit_u16_z(pg: svbool_t, op: svuint16_t) -> svuint16_t {
    svrbit_u16_m(svdup_n_u16(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rbit))]
pub unsafe fn svrbit_u32_m(inactive: svuint32_t, pg: svbool_t, op: svuint32_t) -> svuint32_t {
    unsafe { svrbit_s32_m(inactive.as_signed(), pg, op.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rbit))]
pub unsafe fn svrbit_u32_x(pg: svbool_t, op: svuint32_t) -> svuint32_t {
    svrbit_u32_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rbit))]
pub unsafe fn svrbit_u32_z(pg: svbool_t, op: svuint32_t) -> svuint32_t {
    svrbit_u32_m(svdup_n_u32(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rbit))]
pub unsafe fn svrbit_u64_m(inactive: svuint64_t, pg: svbool_t, op: svuint64_t) -> svuint64_t {
    unsafe { svrbit_s64_m(inactive.as_signed(), pg, op.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rbit))]
pub unsafe fn svrbit_u64_x(pg: svbool_t, op: svuint64_t) -> svuint64_t {
    svrbit_u64_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rbit))]
pub unsafe fn svrbit_u64_z(pg: svbool_t, op: svuint64_t) -> svuint64_t {
    svrbit_u64_m(svdup_n_u64(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rdffr))]
pub unsafe fn svrdffr() -> svbool_t {
    svrdffr_z(svptrue_b8())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rdffr))]
pub unsafe fn svrdffr_z(pg: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.rdffr.z")]
        fn _svrdffr_z(pg: svbool_t) -> svbool_t;
    }
    unsafe { _svrdffr_z(pg) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frecpe))]
pub unsafe fn svrecpe_f32(op: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.frecpe.x.nxv4f32"
        )]
        fn _svrecpe_f32(op: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svrecpe_f32(op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frecpe))]
pub unsafe fn svrecpe_f64(op: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.frecpe.x.nxv2f64"
        )]
        fn _svrecpe_f64(op: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svrecpe_f64(op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frecps))]
pub unsafe fn svrecps_f32(op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.frecps.x.nxv4f32"
        )]
        fn _svrecps_f32(op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svrecps_f32(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frecps))]
pub unsafe fn svrecps_f64(op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.frecps.x.nxv2f64"
        )]
        fn _svrecps_f64(op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svrecps_f64(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frecpx))]
pub unsafe fn svrecpx_f32_m(inactive: svfloat32_t, pg: svbool_t, op: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.frecpx.x.nxv4f32"
        )]
        fn _svrecpx_f32_m(inactive: svfloat32_t, pg: svbool4_t, op: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svrecpx_f32_m(inactive, pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frecpx))]
pub unsafe fn svrecpx_f32_x(pg: svbool_t, op: svfloat32_t) -> svfloat32_t {
    svrecpx_f32_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frecpx))]
pub unsafe fn svrecpx_f32_z(pg: svbool_t, op: svfloat32_t) -> svfloat32_t {
    svrecpx_f32_m(svdup_n_f32(0.0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frecpx))]
pub unsafe fn svrecpx_f64_m(inactive: svfloat64_t, pg: svbool_t, op: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.frecpx.x.nxv2f64"
        )]
        fn _svrecpx_f64_m(inactive: svfloat64_t, pg: svbool2_t, op: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svrecpx_f64_m(inactive, pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frecpx))]
pub unsafe fn svrecpx_f64_x(pg: svbool_t, op: svfloat64_t) -> svfloat64_t {
    svrecpx_f64_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frecpx))]
pub unsafe fn svrecpx_f64_z(pg: svbool_t, op: svfloat64_t) -> svfloat64_t {
    svrecpx_f64_m(svdup_n_f64(0.0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_f32_f32(op: svfloat32_t) -> svfloat32_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_f32_f64(op: svfloat64_t) -> svfloat32_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_f32_s8(op: svint8_t) -> svfloat32_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_f32_s16(op: svint16_t) -> svfloat32_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_f32_s32(op: svint32_t) -> svfloat32_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_f32_s64(op: svint64_t) -> svfloat32_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_f32_u8(op: svuint8_t) -> svfloat32_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_f32_u16(op: svuint16_t) -> svfloat32_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_f32_u32(op: svuint32_t) -> svfloat32_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_f32_u64(op: svuint64_t) -> svfloat32_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_f64_f32(op: svfloat32_t) -> svfloat64_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_f64_f64(op: svfloat64_t) -> svfloat64_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_f64_s8(op: svint8_t) -> svfloat64_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_f64_s16(op: svint16_t) -> svfloat64_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_f64_s32(op: svint32_t) -> svfloat64_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_f64_s64(op: svint64_t) -> svfloat64_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_f64_u8(op: svuint8_t) -> svfloat64_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_f64_u16(op: svuint16_t) -> svfloat64_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_f64_u32(op: svuint32_t) -> svfloat64_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_f64_u64(op: svuint64_t) -> svfloat64_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_s8_f32(op: svfloat32_t) -> svint8_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_s8_f64(op: svfloat64_t) -> svint8_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_s8_s8(op: svint8_t) -> svint8_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_s8_s16(op: svint16_t) -> svint8_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_s8_s32(op: svint32_t) -> svint8_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_s8_s64(op: svint64_t) -> svint8_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_s8_u8(op: svuint8_t) -> svint8_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_s8_u16(op: svuint16_t) -> svint8_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_s8_u32(op: svuint32_t) -> svint8_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_s8_u64(op: svuint64_t) -> svint8_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_s16_f32(op: svfloat32_t) -> svint16_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_s16_f64(op: svfloat64_t) -> svint16_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_s16_s8(op: svint8_t) -> svint16_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_s16_s16(op: svint16_t) -> svint16_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_s16_s32(op: svint32_t) -> svint16_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_s16_s64(op: svint64_t) -> svint16_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_s16_u8(op: svuint8_t) -> svint16_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_s16_u16(op: svuint16_t) -> svint16_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_s16_u32(op: svuint32_t) -> svint16_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_s16_u64(op: svuint64_t) -> svint16_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_s32_f32(op: svfloat32_t) -> svint32_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_s32_f64(op: svfloat64_t) -> svint32_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_s32_s8(op: svint8_t) -> svint32_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_s32_s16(op: svint16_t) -> svint32_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_s32_s32(op: svint32_t) -> svint32_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_s32_s64(op: svint64_t) -> svint32_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_s32_u8(op: svuint8_t) -> svint32_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_s32_u16(op: svuint16_t) -> svint32_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_s32_u32(op: svuint32_t) -> svint32_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_s32_u64(op: svuint64_t) -> svint32_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_s64_f32(op: svfloat32_t) -> svint64_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_s64_f64(op: svfloat64_t) -> svint64_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_s64_s8(op: svint8_t) -> svint64_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_s64_s16(op: svint16_t) -> svint64_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_s64_s32(op: svint32_t) -> svint64_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_s64_s64(op: svint64_t) -> svint64_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_s64_u8(op: svuint8_t) -> svint64_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_s64_u16(op: svuint16_t) -> svint64_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_s64_u32(op: svuint32_t) -> svint64_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_s64_u64(op: svuint64_t) -> svint64_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_u8_f32(op: svfloat32_t) -> svuint8_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_u8_f64(op: svfloat64_t) -> svuint8_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_u8_s8(op: svint8_t) -> svuint8_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_u8_s16(op: svint16_t) -> svuint8_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_u8_s32(op: svint32_t) -> svuint8_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_u8_s64(op: svint64_t) -> svuint8_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_u8_u8(op: svuint8_t) -> svuint8_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_u8_u16(op: svuint16_t) -> svuint8_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_u8_u32(op: svuint32_t) -> svuint8_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_u8_u64(op: svuint64_t) -> svuint8_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_u16_f32(op: svfloat32_t) -> svuint16_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_u16_f64(op: svfloat64_t) -> svuint16_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_u16_s8(op: svint8_t) -> svuint16_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_u16_s16(op: svint16_t) -> svuint16_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_u16_s32(op: svint32_t) -> svuint16_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_u16_s64(op: svint64_t) -> svuint16_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_u16_u8(op: svuint8_t) -> svuint16_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_u16_u16(op: svuint16_t) -> svuint16_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_u16_u32(op: svuint32_t) -> svuint16_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_u16_u64(op: svuint64_t) -> svuint16_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_u32_f32(op: svfloat32_t) -> svuint32_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_u32_f64(op: svfloat64_t) -> svuint32_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_u32_s8(op: svint8_t) -> svuint32_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_u32_s16(op: svint16_t) -> svuint32_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_u32_s32(op: svint32_t) -> svuint32_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_u32_s64(op: svint64_t) -> svuint32_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_u32_u8(op: svuint8_t) -> svuint32_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_u32_u16(op: svuint16_t) -> svuint32_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_u32_u32(op: svuint32_t) -> svuint32_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_u32_u64(op: svuint64_t) -> svuint32_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_u64_f32(op: svfloat32_t) -> svuint64_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_u64_f64(op: svfloat64_t) -> svuint64_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_u64_s8(op: svint8_t) -> svuint64_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_u64_s16(op: svint16_t) -> svuint64_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_u64_s32(op: svint32_t) -> svuint64_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_u64_s64(op: svint64_t) -> svuint64_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_u64_u8(op: svuint8_t) -> svuint64_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_u64_u16(op: svuint16_t) -> svuint64_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_u64_u32(op: svuint32_t) -> svuint64_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svreinterpret_u64_u64(op: svuint64_t) -> svuint64_t {
    unsafe { simd_reinterpret(op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rev))]
pub unsafe fn svrev_b8(op: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.rev.nxv16i1")]
        fn _svrev_b8(op: svbool_t) -> svbool_t;
    }
    unsafe { _svrev_b8(op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rev))]
pub unsafe fn svrev_b16(op: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.rev.nxv8i1")]
        fn _svrev_b16(op: svbool8_t) -> svbool8_t;
    }
    unsafe { _svrev_b16(op.into()).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rev))]
pub unsafe fn svrev_b32(op: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.rev.nxv4i1")]
        fn _svrev_b32(op: svbool4_t) -> svbool4_t;
    }
    unsafe { _svrev_b32(op.into()).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rev))]
pub unsafe fn svrev_b64(op: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.rev.nxv2i1")]
        fn _svrev_b64(op: svbool2_t) -> svbool2_t;
    }
    unsafe { _svrev_b64(op.into()).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rev))]
pub unsafe fn svrev_f32(op: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.rev.nxv4f32")]
        fn _svrev_f32(op: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svrev_f32(op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rev))]
pub unsafe fn svrev_f64(op: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.rev.nxv2f64")]
        fn _svrev_f64(op: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svrev_f64(op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rev))]
pub unsafe fn svrev_s8(op: svint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.rev.nxv16i8")]
        fn _svrev_s8(op: svint8_t) -> svint8_t;
    }
    unsafe { _svrev_s8(op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rev))]
pub unsafe fn svrev_s16(op: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.rev.nxv8i16")]
        fn _svrev_s16(op: svint16_t) -> svint16_t;
    }
    unsafe { _svrev_s16(op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rev))]
pub unsafe fn svrev_s32(op: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.rev.nxv4i32")]
        fn _svrev_s32(op: svint32_t) -> svint32_t;
    }
    unsafe { _svrev_s32(op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rev))]
pub unsafe fn svrev_s64(op: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.rev.nxv2i64")]
        fn _svrev_s64(op: svint64_t) -> svint64_t;
    }
    unsafe { _svrev_s64(op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rev))]
pub unsafe fn svrev_u8(op: svuint8_t) -> svuint8_t {
    unsafe { svrev_s8(op.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rev))]
pub unsafe fn svrev_u16(op: svuint16_t) -> svuint16_t {
    unsafe { svrev_s16(op.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rev))]
pub unsafe fn svrev_u32(op: svuint32_t) -> svuint32_t {
    unsafe { svrev_s32(op.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rev))]
pub unsafe fn svrev_u64(op: svuint64_t) -> svuint64_t {
    unsafe { svrev_s64(op.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(revb))]
pub unsafe fn svrevb_s16_m(inactive: svint16_t, pg: svbool_t, op: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.revb.nxv8i16")]
        fn _svrevb_s16_m(inactive: svint16_t, pg: svbool8_t, op: svint16_t) -> svint16_t;
    }
    unsafe { _svrevb_s16_m(inactive, pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(revb))]
pub unsafe fn svrevb_s16_x(pg: svbool_t, op: svint16_t) -> svint16_t {
    svrevb_s16_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(revb))]
pub unsafe fn svrevb_s16_z(pg: svbool_t, op: svint16_t) -> svint16_t {
    svrevb_s16_m(svdup_n_s16(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(revb))]
pub unsafe fn svrevb_s32_m(inactive: svint32_t, pg: svbool_t, op: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.revb.nxv4i32")]
        fn _svrevb_s32_m(inactive: svint32_t, pg: svbool4_t, op: svint32_t) -> svint32_t;
    }
    unsafe { _svrevb_s32_m(inactive, pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(revb))]
pub unsafe fn svrevb_s32_x(pg: svbool_t, op: svint32_t) -> svint32_t {
    svrevb_s32_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(revb))]
pub unsafe fn svrevb_s32_z(pg: svbool_t, op: svint32_t) -> svint32_t {
    svrevb_s32_m(svdup_n_s32(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(revb))]
pub unsafe fn svrevb_s64_m(inactive: svint64_t, pg: svbool_t, op: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.revb.nxv2i64")]
        fn _svrevb_s64_m(inactive: svint64_t, pg: svbool2_t, op: svint64_t) -> svint64_t;
    }
    unsafe { _svrevb_s64_m(inactive, pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(revb))]
pub unsafe fn svrevb_s64_x(pg: svbool_t, op: svint64_t) -> svint64_t {
    svrevb_s64_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(revb))]
pub unsafe fn svrevb_s64_z(pg: svbool_t, op: svint64_t) -> svint64_t {
    svrevb_s64_m(svdup_n_s64(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(revb))]
pub unsafe fn svrevb_u16_m(inactive: svuint16_t, pg: svbool_t, op: svuint16_t) -> svuint16_t {
    unsafe { svrevb_s16_m(inactive.as_signed(), pg, op.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(revb))]
pub unsafe fn svrevb_u16_x(pg: svbool_t, op: svuint16_t) -> svuint16_t {
    svrevb_u16_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(revb))]
pub unsafe fn svrevb_u16_z(pg: svbool_t, op: svuint16_t) -> svuint16_t {
    svrevb_u16_m(svdup_n_u16(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(revb))]
pub unsafe fn svrevb_u32_m(inactive: svuint32_t, pg: svbool_t, op: svuint32_t) -> svuint32_t {
    unsafe { svrevb_s32_m(inactive.as_signed(), pg, op.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(revb))]
pub unsafe fn svrevb_u32_x(pg: svbool_t, op: svuint32_t) -> svuint32_t {
    svrevb_u32_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(revb))]
pub unsafe fn svrevb_u32_z(pg: svbool_t, op: svuint32_t) -> svuint32_t {
    svrevb_u32_m(svdup_n_u32(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(revb))]
pub unsafe fn svrevb_u64_m(inactive: svuint64_t, pg: svbool_t, op: svuint64_t) -> svuint64_t {
    unsafe { svrevb_s64_m(inactive.as_signed(), pg, op.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(revb))]
pub unsafe fn svrevb_u64_x(pg: svbool_t, op: svuint64_t) -> svuint64_t {
    svrevb_u64_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(revb))]
pub unsafe fn svrevb_u64_z(pg: svbool_t, op: svuint64_t) -> svuint64_t {
    svrevb_u64_m(svdup_n_u64(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(revh))]
pub unsafe fn svrevh_s32_m(inactive: svint32_t, pg: svbool_t, op: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.revh.nxv4i32")]
        fn _svrevh_s32_m(inactive: svint32_t, pg: svbool4_t, op: svint32_t) -> svint32_t;
    }
    unsafe { _svrevh_s32_m(inactive, pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(revh))]
pub unsafe fn svrevh_s32_x(pg: svbool_t, op: svint32_t) -> svint32_t {
    svrevh_s32_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(revh))]
pub unsafe fn svrevh_s32_z(pg: svbool_t, op: svint32_t) -> svint32_t {
    svrevh_s32_m(svdup_n_s32(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(revh))]
pub unsafe fn svrevh_s64_m(inactive: svint64_t, pg: svbool_t, op: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.revh.nxv2i64")]
        fn _svrevh_s64_m(inactive: svint64_t, pg: svbool2_t, op: svint64_t) -> svint64_t;
    }
    unsafe { _svrevh_s64_m(inactive, pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(revh))]
pub unsafe fn svrevh_s64_x(pg: svbool_t, op: svint64_t) -> svint64_t {
    svrevh_s64_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(revh))]
pub unsafe fn svrevh_s64_z(pg: svbool_t, op: svint64_t) -> svint64_t {
    svrevh_s64_m(svdup_n_s64(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(revh))]
pub unsafe fn svrevh_u32_m(inactive: svuint32_t, pg: svbool_t, op: svuint32_t) -> svuint32_t {
    unsafe { svrevh_s32_m(inactive.as_signed(), pg, op.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(revh))]
pub unsafe fn svrevh_u32_x(pg: svbool_t, op: svuint32_t) -> svuint32_t {
    svrevh_u32_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(revh))]
pub unsafe fn svrevh_u32_z(pg: svbool_t, op: svuint32_t) -> svuint32_t {
    svrevh_u32_m(svdup_n_u32(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(revh))]
pub unsafe fn svrevh_u64_m(inactive: svuint64_t, pg: svbool_t, op: svuint64_t) -> svuint64_t {
    unsafe { svrevh_s64_m(inactive.as_signed(), pg, op.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(revh))]
pub unsafe fn svrevh_u64_x(pg: svbool_t, op: svuint64_t) -> svuint64_t {
    svrevh_u64_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(revh))]
pub unsafe fn svrevh_u64_z(pg: svbool_t, op: svuint64_t) -> svuint64_t {
    svrevh_u64_m(svdup_n_u64(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(revw))]
pub unsafe fn svrevw_s64_m(inactive: svint64_t, pg: svbool_t, op: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.revw.nxv2i64")]
        fn _svrevw_s64_m(inactive: svint64_t, pg: svbool2_t, op: svint64_t) -> svint64_t;
    }
    unsafe { _svrevw_s64_m(inactive, pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(revw))]
pub unsafe fn svrevw_s64_x(pg: svbool_t, op: svint64_t) -> svint64_t {
    svrevw_s64_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(revw))]
pub unsafe fn svrevw_s64_z(pg: svbool_t, op: svint64_t) -> svint64_t {
    svrevw_s64_m(svdup_n_s64(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(revw))]
pub unsafe fn svrevw_u64_m(inactive: svuint64_t, pg: svbool_t, op: svuint64_t) -> svuint64_t {
    unsafe { svrevw_s64_m(inactive.as_signed(), pg, op.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(revw))]
pub unsafe fn svrevw_u64_x(pg: svbool_t, op: svuint64_t) -> svuint64_t {
    svrevw_u64_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(revw))]
pub unsafe fn svrevw_u64_z(pg: svbool_t, op: svuint64_t) -> svuint64_t {
    svrevw_u64_m(svdup_n_u64(0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frinta))]
pub unsafe fn svrinta_f32_m(inactive: svfloat32_t, pg: svbool_t, op: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.frinta.nxv4f32")]
        fn _svrinta_f32_m(inactive: svfloat32_t, pg: svbool4_t, op: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svrinta_f32_m(inactive, pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frinta))]
pub unsafe fn svrinta_f32_x(pg: svbool_t, op: svfloat32_t) -> svfloat32_t {
    svrinta_f32_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frinta))]
pub unsafe fn svrinta_f32_z(pg: svbool_t, op: svfloat32_t) -> svfloat32_t {
    svrinta_f32_m(svdup_n_f32(0.0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frinta))]
pub unsafe fn svrinta_f64_m(inactive: svfloat64_t, pg: svbool_t, op: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.frinta.nxv2f64")]
        fn _svrinta_f64_m(inactive: svfloat64_t, pg: svbool2_t, op: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svrinta_f64_m(inactive, pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frinta))]
pub unsafe fn svrinta_f64_x(pg: svbool_t, op: svfloat64_t) -> svfloat64_t {
    svrinta_f64_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frinta))]
pub unsafe fn svrinta_f64_z(pg: svbool_t, op: svfloat64_t) -> svfloat64_t {
    svrinta_f64_m(svdup_n_f64(0.0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frinti))]
pub unsafe fn svrinti_f32_m(inactive: svfloat32_t, pg: svbool_t, op: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.frinti.nxv4f32")]
        fn _svrinti_f32_m(inactive: svfloat32_t, pg: svbool4_t, op: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svrinti_f32_m(inactive, pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frinti))]
pub unsafe fn svrinti_f32_x(pg: svbool_t, op: svfloat32_t) -> svfloat32_t {
    svrinti_f32_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frinti))]
pub unsafe fn svrinti_f32_z(pg: svbool_t, op: svfloat32_t) -> svfloat32_t {
    svrinti_f32_m(svdup_n_f32(0.0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frinti))]
pub unsafe fn svrinti_f64_m(inactive: svfloat64_t, pg: svbool_t, op: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.frinti.nxv2f64")]
        fn _svrinti_f64_m(inactive: svfloat64_t, pg: svbool2_t, op: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svrinti_f64_m(inactive, pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frinti))]
pub unsafe fn svrinti_f64_x(pg: svbool_t, op: svfloat64_t) -> svfloat64_t {
    svrinti_f64_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frinti))]
pub unsafe fn svrinti_f64_z(pg: svbool_t, op: svfloat64_t) -> svfloat64_t {
    svrinti_f64_m(svdup_n_f64(0.0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frintm))]
pub unsafe fn svrintm_f32_m(inactive: svfloat32_t, pg: svbool_t, op: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.frintm.nxv4f32")]
        fn _svrintm_f32_m(inactive: svfloat32_t, pg: svbool4_t, op: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svrintm_f32_m(inactive, pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frintm))]
pub unsafe fn svrintm_f32_x(pg: svbool_t, op: svfloat32_t) -> svfloat32_t {
    svrintm_f32_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frintm))]
pub unsafe fn svrintm_f32_z(pg: svbool_t, op: svfloat32_t) -> svfloat32_t {
    svrintm_f32_m(svdup_n_f32(0.0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frintm))]
pub unsafe fn svrintm_f64_m(inactive: svfloat64_t, pg: svbool_t, op: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.frintm.nxv2f64")]
        fn _svrintm_f64_m(inactive: svfloat64_t, pg: svbool2_t, op: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svrintm_f64_m(inactive, pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frintm))]
pub unsafe fn svrintm_f64_x(pg: svbool_t, op: svfloat64_t) -> svfloat64_t {
    svrintm_f64_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frintm))]
pub unsafe fn svrintm_f64_z(pg: svbool_t, op: svfloat64_t) -> svfloat64_t {
    svrintm_f64_m(svdup_n_f64(0.0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frintn))]
pub unsafe fn svrintn_f32_m(inactive: svfloat32_t, pg: svbool_t, op: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.frintn.nxv4f32")]
        fn _svrintn_f32_m(inactive: svfloat32_t, pg: svbool4_t, op: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svrintn_f32_m(inactive, pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frintn))]
pub unsafe fn svrintn_f32_x(pg: svbool_t, op: svfloat32_t) -> svfloat32_t {
    svrintn_f32_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frintn))]
pub unsafe fn svrintn_f32_z(pg: svbool_t, op: svfloat32_t) -> svfloat32_t {
    svrintn_f32_m(svdup_n_f32(0.0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frintn))]
pub unsafe fn svrintn_f64_m(inactive: svfloat64_t, pg: svbool_t, op: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.frintn.nxv2f64")]
        fn _svrintn_f64_m(inactive: svfloat64_t, pg: svbool2_t, op: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svrintn_f64_m(inactive, pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frintn))]
pub unsafe fn svrintn_f64_x(pg: svbool_t, op: svfloat64_t) -> svfloat64_t {
    svrintn_f64_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frintn))]
pub unsafe fn svrintn_f64_z(pg: svbool_t, op: svfloat64_t) -> svfloat64_t {
    svrintn_f64_m(svdup_n_f64(0.0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frintp))]
pub unsafe fn svrintp_f32_m(inactive: svfloat32_t, pg: svbool_t, op: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.frintp.nxv4f32")]
        fn _svrintp_f32_m(inactive: svfloat32_t, pg: svbool4_t, op: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svrintp_f32_m(inactive, pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frintp))]
pub unsafe fn svrintp_f32_x(pg: svbool_t, op: svfloat32_t) -> svfloat32_t {
    svrintp_f32_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frintp))]
pub unsafe fn svrintp_f32_z(pg: svbool_t, op: svfloat32_t) -> svfloat32_t {
    svrintp_f32_m(svdup_n_f32(0.0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frintp))]
pub unsafe fn svrintp_f64_m(inactive: svfloat64_t, pg: svbool_t, op: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.frintp.nxv2f64")]
        fn _svrintp_f64_m(inactive: svfloat64_t, pg: svbool2_t, op: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svrintp_f64_m(inactive, pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frintp))]
pub unsafe fn svrintp_f64_x(pg: svbool_t, op: svfloat64_t) -> svfloat64_t {
    svrintp_f64_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frintp))]
pub unsafe fn svrintp_f64_z(pg: svbool_t, op: svfloat64_t) -> svfloat64_t {
    svrintp_f64_m(svdup_n_f64(0.0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frintx))]
pub unsafe fn svrintx_f32_m(inactive: svfloat32_t, pg: svbool_t, op: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.frintx.nxv4f32")]
        fn _svrintx_f32_m(inactive: svfloat32_t, pg: svbool4_t, op: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svrintx_f32_m(inactive, pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frintx))]
pub unsafe fn svrintx_f32_x(pg: svbool_t, op: svfloat32_t) -> svfloat32_t {
    svrintx_f32_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frintx))]
pub unsafe fn svrintx_f32_z(pg: svbool_t, op: svfloat32_t) -> svfloat32_t {
    svrintx_f32_m(svdup_n_f32(0.0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frintx))]
pub unsafe fn svrintx_f64_m(inactive: svfloat64_t, pg: svbool_t, op: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.frintx.nxv2f64")]
        fn _svrintx_f64_m(inactive: svfloat64_t, pg: svbool2_t, op: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svrintx_f64_m(inactive, pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frintx))]
pub unsafe fn svrintx_f64_x(pg: svbool_t, op: svfloat64_t) -> svfloat64_t {
    svrintx_f64_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frintx))]
pub unsafe fn svrintx_f64_z(pg: svbool_t, op: svfloat64_t) -> svfloat64_t {
    svrintx_f64_m(svdup_n_f64(0.0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frintz))]
pub unsafe fn svrintz_f32_m(inactive: svfloat32_t, pg: svbool_t, op: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.frintz.nxv4f32")]
        fn _svrintz_f32_m(inactive: svfloat32_t, pg: svbool4_t, op: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svrintz_f32_m(inactive, pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frintz))]
pub unsafe fn svrintz_f32_x(pg: svbool_t, op: svfloat32_t) -> svfloat32_t {
    svrintz_f32_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frintz))]
pub unsafe fn svrintz_f32_z(pg: svbool_t, op: svfloat32_t) -> svfloat32_t {
    svrintz_f32_m(svdup_n_f32(0.0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frintz))]
pub unsafe fn svrintz_f64_m(inactive: svfloat64_t, pg: svbool_t, op: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.frintz.nxv2f64")]
        fn _svrintz_f64_m(inactive: svfloat64_t, pg: svbool2_t, op: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svrintz_f64_m(inactive, pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frintz))]
pub unsafe fn svrintz_f64_x(pg: svbool_t, op: svfloat64_t) -> svfloat64_t {
    svrintz_f64_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frintz))]
pub unsafe fn svrintz_f64_z(pg: svbool_t, op: svfloat64_t) -> svfloat64_t {
    svrintz_f64_m(svdup_n_f64(0.0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frsqrte))]
pub unsafe fn svrsqrte_f32(op: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.frsqrte.x.nxv4f32"
        )]
        fn _svrsqrte_f32(op: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svrsqrte_f32(op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frsqrte))]
pub unsafe fn svrsqrte_f64(op: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.frsqrte.x.nxv2f64"
        )]
        fn _svrsqrte_f64(op: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svrsqrte_f64(op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frsqrts))]
pub unsafe fn svrsqrts_f32(op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.frsqrts.x.nxv4f32"
        )]
        fn _svrsqrts_f32(op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svrsqrts_f32(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frsqrts))]
pub unsafe fn svrsqrts_f64(op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.frsqrts.x.nxv2f64"
        )]
        fn _svrsqrts_f64(op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svrsqrts_f64(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fscale))]
pub unsafe fn svscale_f32_m(pg: svbool_t, op1: svfloat32_t, op2: svint32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fscale.nxv4f32")]
        fn _svscale_f32_m(pg: svbool4_t, op1: svfloat32_t, op2: svint32_t) -> svfloat32_t;
    }
    unsafe { _svscale_f32_m(pg.into(), op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fscale))]
pub unsafe fn svscale_n_f32_m(pg: svbool_t, op1: svfloat32_t, op2: i32) -> svfloat32_t {
    svscale_f32_m(pg, op1, svdup_n_s32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fscale))]
pub unsafe fn svscale_f32_x(pg: svbool_t, op1: svfloat32_t, op2: svint32_t) -> svfloat32_t {
    svscale_f32_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fscale))]
pub unsafe fn svscale_n_f32_x(pg: svbool_t, op1: svfloat32_t, op2: i32) -> svfloat32_t {
    svscale_f32_x(pg, op1, svdup_n_s32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fscale))]
pub unsafe fn svscale_f32_z(pg: svbool_t, op1: svfloat32_t, op2: svint32_t) -> svfloat32_t {
    svscale_f32_m(pg.clone(), svsel_f32(pg, op1, svdup_n_f32(0.0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fscale))]
pub unsafe fn svscale_n_f32_z(pg: svbool_t, op1: svfloat32_t, op2: i32) -> svfloat32_t {
    svscale_f32_z(pg, op1, svdup_n_s32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fscale))]
pub unsafe fn svscale_f64_m(pg: svbool_t, op1: svfloat64_t, op2: svint64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fscale.nxv2f64")]
        fn _svscale_f64_m(pg: svbool2_t, op1: svfloat64_t, op2: svint64_t) -> svfloat64_t;
    }
    unsafe { _svscale_f64_m(pg.into(), op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fscale))]
pub unsafe fn svscale_n_f64_m(pg: svbool_t, op1: svfloat64_t, op2: i64) -> svfloat64_t {
    svscale_f64_m(pg, op1, svdup_n_s64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fscale))]
pub unsafe fn svscale_f64_x(pg: svbool_t, op1: svfloat64_t, op2: svint64_t) -> svfloat64_t {
    svscale_f64_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fscale))]
pub unsafe fn svscale_n_f64_x(pg: svbool_t, op1: svfloat64_t, op2: i64) -> svfloat64_t {
    svscale_f64_x(pg, op1, svdup_n_s64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fscale))]
pub unsafe fn svscale_f64_z(pg: svbool_t, op1: svfloat64_t, op2: svint64_t) -> svfloat64_t {
    svscale_f64_m(pg.clone(), svsel_f64(pg, op1, svdup_n_f64(0.0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fscale))]
pub unsafe fn svscale_n_f64_z(pg: svbool_t, op1: svfloat64_t, op2: i64) -> svfloat64_t {
    svscale_f64_z(pg, op1, svdup_n_s64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sel))]
pub unsafe fn svsel_b(pg: svbool_t, op1: svbool_t, op2: svbool_t) -> svbool_t {
    unsafe { simd_select(pg, op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sel))]
pub unsafe fn svsel_f32(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    unsafe { simd_select::<svbool4_t, _>(pg.into(), op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sel))]
pub unsafe fn svsel_f64(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    unsafe { simd_select::<svbool2_t, _>(pg.into(), op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sel))]
pub unsafe fn svsel_s8(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t {
    unsafe { simd_select::<svbool_t, _>(pg, op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sel))]
pub unsafe fn svsel_s16(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svint16_t {
    unsafe { simd_select::<svbool8_t, _>(pg.into(), op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sel))]
pub unsafe fn svsel_s32(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    unsafe { simd_select::<svbool4_t, _>(pg.into(), op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sel))]
pub unsafe fn svsel_s64(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    unsafe { simd_select::<svbool2_t, _>(pg.into(), op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sel))]
pub unsafe fn svsel_u8(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    unsafe { simd_select::<svbool_t, _>(pg, op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sel))]
pub unsafe fn svsel_u16(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    unsafe { simd_select::<svbool8_t, _>(pg.into(), op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sel))]
pub unsafe fn svsel_u32(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    unsafe { simd_select::<svbool4_t, _>(pg.into(), op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sel))]
pub unsafe fn svsel_u64(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    unsafe { simd_select::<svbool2_t, _>(pg.into(), op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svset2_f32<const IMM_INDEX: i32>(tuple: svfloat32x2_t, x: svfloat32_t) -> svfloat32x2_t {
    static_assert_range!(IMM_INDEX, 0, 1);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.set.nxv8f32.nxv4f32"
        )]
        fn _svset2_f32(tuple: svfloat32x2_t, imm_index: i32, x: svfloat32_t) -> svfloat32x2_t;
    }
    unsafe { _svset2_f32(tuple, IMM_INDEX, x) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svset2_f64<const IMM_INDEX: i32>(tuple: svfloat64x2_t, x: svfloat64_t) -> svfloat64x2_t {
    static_assert_range!(IMM_INDEX, 0, 1);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.set.nxv4f64.nxv2f64"
        )]
        fn _svset2_f64(tuple: svfloat64x2_t, imm_index: i32, x: svfloat64_t) -> svfloat64x2_t;
    }
    unsafe { _svset2_f64(tuple, IMM_INDEX, x) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svset2_s8<const IMM_INDEX: i32>(tuple: svint8x2_t, x: svint8_t) -> svint8x2_t {
    static_assert_range!(IMM_INDEX, 0, 1);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.set.nxv32i8.nxv16i8"
        )]
        fn _svset2_s8(tuple: svint8x2_t, imm_index: i32, x: svint8_t) -> svint8x2_t;
    }
    unsafe { _svset2_s8(tuple, IMM_INDEX, x) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svset2_s16<const IMM_INDEX: i32>(tuple: svint16x2_t, x: svint16_t) -> svint16x2_t {
    static_assert_range!(IMM_INDEX, 0, 1);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.set.nxv16i16.nxv8i16"
        )]
        fn _svset2_s16(tuple: svint16x2_t, imm_index: i32, x: svint16_t) -> svint16x2_t;
    }
    unsafe { _svset2_s16(tuple, IMM_INDEX, x) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svset2_s32<const IMM_INDEX: i32>(tuple: svint32x2_t, x: svint32_t) -> svint32x2_t {
    static_assert_range!(IMM_INDEX, 0, 1);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.set.nxv8i32.nxv4i32"
        )]
        fn _svset2_s32(tuple: svint32x2_t, imm_index: i32, x: svint32_t) -> svint32x2_t;
    }
    unsafe { _svset2_s32(tuple, IMM_INDEX, x) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svset2_s64<const IMM_INDEX: i32>(tuple: svint64x2_t, x: svint64_t) -> svint64x2_t {
    static_assert_range!(IMM_INDEX, 0, 1);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.set.nxv4i64.nxv2i64"
        )]
        fn _svset2_s64(tuple: svint64x2_t, imm_index: i32, x: svint64_t) -> svint64x2_t;
    }
    unsafe { _svset2_s64(tuple, IMM_INDEX, x) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svset2_u8<const IMM_INDEX: i32>(tuple: svuint8x2_t, x: svuint8_t) -> svuint8x2_t {
    static_assert_range!(IMM_INDEX, 0, 1);
    unsafe { svset2_s8::<IMM_INDEX>(tuple.as_signed(), x.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svset2_u16<const IMM_INDEX: i32>(tuple: svuint16x2_t, x: svuint16_t) -> svuint16x2_t {
    static_assert_range!(IMM_INDEX, 0, 1);
    unsafe { svset2_s16::<IMM_INDEX>(tuple.as_signed(), x.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svset2_u32<const IMM_INDEX: i32>(tuple: svuint32x2_t, x: svuint32_t) -> svuint32x2_t {
    static_assert_range!(IMM_INDEX, 0, 1);
    unsafe { svset2_s32::<IMM_INDEX>(tuple.as_signed(), x.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svset2_u64<const IMM_INDEX: i32>(tuple: svuint64x2_t, x: svuint64_t) -> svuint64x2_t {
    static_assert_range!(IMM_INDEX, 0, 1);
    unsafe { svset2_s64::<IMM_INDEX>(tuple.as_signed(), x.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svset3_f32<const IMM_INDEX: i32>(tuple: svfloat32x3_t, x: svfloat32_t) -> svfloat32x3_t {
    static_assert_range!(IMM_INDEX, 0, 2);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.set.nxv12f32.nxv4f32"
        )]
        fn _svset3_f32(tuple: svfloat32x3_t, imm_index: i32, x: svfloat32_t) -> svfloat32x3_t;
    }
    unsafe { _svset3_f32(tuple, IMM_INDEX, x) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svset3_f64<const IMM_INDEX: i32>(tuple: svfloat64x3_t, x: svfloat64_t) -> svfloat64x3_t {
    static_assert_range!(IMM_INDEX, 0, 2);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.set.nxv6f64.nxv2f64"
        )]
        fn _svset3_f64(tuple: svfloat64x3_t, imm_index: i32, x: svfloat64_t) -> svfloat64x3_t;
    }
    unsafe { _svset3_f64(tuple, IMM_INDEX, x) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svset3_s8<const IMM_INDEX: i32>(tuple: svint8x3_t, x: svint8_t) -> svint8x3_t {
    static_assert_range!(IMM_INDEX, 0, 2);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.set.nxv48i8.nxv16i8"
        )]
        fn _svset3_s8(tuple: svint8x3_t, imm_index: i32, x: svint8_t) -> svint8x3_t;
    }
    unsafe { _svset3_s8(tuple, IMM_INDEX, x) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svset3_s16<const IMM_INDEX: i32>(tuple: svint16x3_t, x: svint16_t) -> svint16x3_t {
    static_assert_range!(IMM_INDEX, 0, 2);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.set.nxv24i16.nxv8i16"
        )]
        fn _svset3_s16(tuple: svint16x3_t, imm_index: i32, x: svint16_t) -> svint16x3_t;
    }
    unsafe { _svset3_s16(tuple, IMM_INDEX, x) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svset3_s32<const IMM_INDEX: i32>(tuple: svint32x3_t, x: svint32_t) -> svint32x3_t {
    static_assert_range!(IMM_INDEX, 0, 2);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.set.nxv12i32.nxv4i32"
        )]
        fn _svset3_s32(tuple: svint32x3_t, imm_index: i32, x: svint32_t) -> svint32x3_t;
    }
    unsafe { _svset3_s32(tuple, IMM_INDEX, x) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svset3_s64<const IMM_INDEX: i32>(tuple: svint64x3_t, x: svint64_t) -> svint64x3_t {
    static_assert_range!(IMM_INDEX, 0, 2);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.set.nxv6i64.nxv2i64"
        )]
        fn _svset3_s64(tuple: svint64x3_t, imm_index: i32, x: svint64_t) -> svint64x3_t;
    }
    unsafe { _svset3_s64(tuple, IMM_INDEX, x) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svset3_u8<const IMM_INDEX: i32>(tuple: svuint8x3_t, x: svuint8_t) -> svuint8x3_t {
    static_assert_range!(IMM_INDEX, 0, 2);
    unsafe { svset3_s8::<IMM_INDEX>(tuple.as_signed(), x.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svset3_u16<const IMM_INDEX: i32>(tuple: svuint16x3_t, x: svuint16_t) -> svuint16x3_t {
    static_assert_range!(IMM_INDEX, 0, 2);
    unsafe { svset3_s16::<IMM_INDEX>(tuple.as_signed(), x.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svset3_u32<const IMM_INDEX: i32>(tuple: svuint32x3_t, x: svuint32_t) -> svuint32x3_t {
    static_assert_range!(IMM_INDEX, 0, 2);
    unsafe { svset3_s32::<IMM_INDEX>(tuple.as_signed(), x.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svset3_u64<const IMM_INDEX: i32>(tuple: svuint64x3_t, x: svuint64_t) -> svuint64x3_t {
    static_assert_range!(IMM_INDEX, 0, 2);
    unsafe { svset3_s64::<IMM_INDEX>(tuple.as_signed(), x.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svset4_f32<const IMM_INDEX: i32>(tuple: svfloat32x4_t, x: svfloat32_t) -> svfloat32x4_t {
    static_assert_range!(IMM_INDEX, 0, 3);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.set.nxv16f32.nxv4f32"
        )]
        fn _svset4_f32(tuple: svfloat32x4_t, imm_index: i32, x: svfloat32_t) -> svfloat32x4_t;
    }
    unsafe { _svset4_f32(tuple, IMM_INDEX, x) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svset4_f64<const IMM_INDEX: i32>(tuple: svfloat64x4_t, x: svfloat64_t) -> svfloat64x4_t {
    static_assert_range!(IMM_INDEX, 0, 3);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.set.nxv8f64.nxv2f64"
        )]
        fn _svset4_f64(tuple: svfloat64x4_t, imm_index: i32, x: svfloat64_t) -> svfloat64x4_t;
    }
    unsafe { _svset4_f64(tuple, IMM_INDEX, x) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svset4_s8<const IMM_INDEX: i32>(tuple: svint8x4_t, x: svint8_t) -> svint8x4_t {
    static_assert_range!(IMM_INDEX, 0, 3);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.set.nxv64i8.nxv16i8"
        )]
        fn _svset4_s8(tuple: svint8x4_t, imm_index: i32, x: svint8_t) -> svint8x4_t;
    }
    unsafe { _svset4_s8(tuple, IMM_INDEX, x) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svset4_s16<const IMM_INDEX: i32>(tuple: svint16x4_t, x: svint16_t) -> svint16x4_t {
    static_assert_range!(IMM_INDEX, 0, 3);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.set.nxv32i16.nxv8i16"
        )]
        fn _svset4_s16(tuple: svint16x4_t, imm_index: i32, x: svint16_t) -> svint16x4_t;
    }
    unsafe { _svset4_s16(tuple, IMM_INDEX, x) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svset4_s32<const IMM_INDEX: i32>(tuple: svint32x4_t, x: svint32_t) -> svint32x4_t {
    static_assert_range!(IMM_INDEX, 0, 3);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.set.nxv16i32.nxv4i32"
        )]
        fn _svset4_s32(tuple: svint32x4_t, imm_index: i32, x: svint32_t) -> svint32x4_t;
    }
    unsafe { _svset4_s32(tuple, IMM_INDEX, x) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svset4_s64<const IMM_INDEX: i32>(tuple: svint64x4_t, x: svint64_t) -> svint64x4_t {
    static_assert_range!(IMM_INDEX, 0, 3);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.set.nxv8i64.nxv2i64"
        )]
        fn _svset4_s64(tuple: svint64x4_t, imm_index: i32, x: svint64_t) -> svint64x4_t;
    }
    unsafe { _svset4_s64(tuple, IMM_INDEX, x) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svset4_u8<const IMM_INDEX: i32>(tuple: svuint8x4_t, x: svuint8_t) -> svuint8x4_t {
    static_assert_range!(IMM_INDEX, 0, 3);
    unsafe { svset4_s8::<IMM_INDEX>(tuple.as_signed(), x.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svset4_u16<const IMM_INDEX: i32>(tuple: svuint16x4_t, x: svuint16_t) -> svuint16x4_t {
    static_assert_range!(IMM_INDEX, 0, 3);
    unsafe { svset4_s16::<IMM_INDEX>(tuple.as_signed(), x.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svset4_u32<const IMM_INDEX: i32>(tuple: svuint32x4_t, x: svuint32_t) -> svuint32x4_t {
    static_assert_range!(IMM_INDEX, 0, 3);
    unsafe { svset4_s32::<IMM_INDEX>(tuple.as_signed(), x.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svset4_u64<const IMM_INDEX: i32>(tuple: svuint64x4_t, x: svuint64_t) -> svuint64x4_t {
    static_assert_range!(IMM_INDEX, 0, 3);
    unsafe { svset4_s64::<IMM_INDEX>(tuple.as_signed(), x.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(setffr))]
pub unsafe fn svsetffr() {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.setffr")]
        fn _svsetffr();
    }
    unsafe { _svsetffr() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(splice))]
pub unsafe fn svsplice_f32(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.splice.nxv4f32")]
        fn _svsplice_f32(pg: svbool4_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svsplice_f32(pg.into(), op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(splice))]
pub unsafe fn svsplice_f64(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.splice.nxv2f64")]
        fn _svsplice_f64(pg: svbool2_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svsplice_f64(pg.into(), op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(splice))]
pub unsafe fn svsplice_s8(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.splice.nxv16i8")]
        fn _svsplice_s8(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t;
    }
    unsafe { _svsplice_s8(pg, op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(splice))]
pub unsafe fn svsplice_s16(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.splice.nxv8i16")]
        fn _svsplice_s16(pg: svbool8_t, op1: svint16_t, op2: svint16_t) -> svint16_t;
    }
    unsafe { _svsplice_s16(pg.into(), op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(splice))]
pub unsafe fn svsplice_s32(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.splice.nxv4i32")]
        fn _svsplice_s32(pg: svbool4_t, op1: svint32_t, op2: svint32_t) -> svint32_t;
    }
    unsafe { _svsplice_s32(pg.into(), op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(splice))]
pub unsafe fn svsplice_s64(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.splice.nxv2i64")]
        fn _svsplice_s64(pg: svbool2_t, op1: svint64_t, op2: svint64_t) -> svint64_t;
    }
    unsafe { _svsplice_s64(pg.into(), op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(splice))]
pub unsafe fn svsplice_u8(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    unsafe { svsplice_s8(pg, op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(splice))]
pub unsafe fn svsplice_u16(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    unsafe { svsplice_s16(pg, op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(splice))]
pub unsafe fn svsplice_u32(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    unsafe { svsplice_s32(pg, op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(splice))]
pub unsafe fn svsplice_u64(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    unsafe { svsplice_s64(pg, op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fsqrt))]
pub unsafe fn svsqrt_f32_m(inactive: svfloat32_t, pg: svbool_t, op: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fsqrt.nxv4f32")]
        fn _svsqrt_f32_m(inactive: svfloat32_t, pg: svbool4_t, op: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svsqrt_f32_m(inactive, pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fsqrt))]
pub unsafe fn svsqrt_f32_x(pg: svbool_t, op: svfloat32_t) -> svfloat32_t {
    svsqrt_f32_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fsqrt))]
pub unsafe fn svsqrt_f32_z(pg: svbool_t, op: svfloat32_t) -> svfloat32_t {
    svsqrt_f32_m(svdup_n_f32(0.0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fsqrt))]
pub unsafe fn svsqrt_f64_m(inactive: svfloat64_t, pg: svbool_t, op: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fsqrt.nxv2f64")]
        fn _svsqrt_f64_m(inactive: svfloat64_t, pg: svbool2_t, op: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svsqrt_f64_m(inactive, pg.into(), op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fsqrt))]
pub unsafe fn svsqrt_f64_x(pg: svbool_t, op: svfloat64_t) -> svfloat64_t {
    svsqrt_f64_m(op, pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fsqrt))]
pub unsafe fn svsqrt_f64_z(pg: svbool_t, op: svfloat64_t) -> svfloat64_t {
    svsqrt_f64_m(svdup_n_f64(0.0), pg, op)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1_f32(pg: svbool_t, base: *mut f32, data: svfloat32_t) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.st1.nxv4f32")]
        fn _svst1_f32(data: svfloat32_t, pg: svbool4_t, ptr: *mut f32);
    }
    _svst1_f32(data, pg.into(), base)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1d))]
pub unsafe fn svst1_f64(pg: svbool_t, base: *mut f64, data: svfloat64_t) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.st1.nxv2f64")]
        fn _svst1_f64(data: svfloat64_t, pg: svbool2_t, ptr: *mut f64);
    }
    _svst1_f64(data, pg.into(), base)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1b))]
pub unsafe fn svst1_s8(pg: svbool_t, base: *mut i8, data: svint8_t) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.st1.nxv16i8")]
        fn _svst1_s8(data: svint8_t, pg: svbool_t, ptr: *mut i8);
    }
    _svst1_s8(data, pg, base)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1_s16(pg: svbool_t, base: *mut i16, data: svint16_t) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.st1.nxv8i16")]
        fn _svst1_s16(data: svint16_t, pg: svbool8_t, ptr: *mut i16);
    }
    _svst1_s16(data, pg.into(), base)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1_s32(pg: svbool_t, base: *mut i32, data: svint32_t) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.st1.nxv4i32")]
        fn _svst1_s32(data: svint32_t, pg: svbool4_t, ptr: *mut i32);
    }
    _svst1_s32(data, pg.into(), base)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1d))]
pub unsafe fn svst1_s64(pg: svbool_t, base: *mut i64, data: svint64_t) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.st1.nxv2i64")]
        fn _svst1_s64(data: svint64_t, pg: svbool2_t, ptr: *mut i64);
    }
    _svst1_s64(data, pg.into(), base)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1b))]
pub unsafe fn svst1_u8(pg: svbool_t, base: *mut u8, data: svuint8_t) {
    svst1_s8(pg, base as *mut i8, data.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1_u16(pg: svbool_t, base: *mut u16, data: svuint16_t) {
    svst1_s16(pg, base as *mut i16, data.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1_u32(pg: svbool_t, base: *mut u32, data: svuint32_t) {
    svst1_s32(pg, base as *mut i32, data.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1d))]
pub unsafe fn svst1_u64(pg: svbool_t, base: *mut u64, data: svuint64_t) {
    svst1_s64(pg, base as *mut i64, data.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1_scatter_s32index_f32(
    pg: svbool_t,
    base: *mut f32,
    indices: svint32_t,
    data: svfloat32_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.st1.scatter.sxtw.index.nxv4f32"
        )]
        fn _svst1_scatter_s32index_f32(
            data: svfloat32_t,
            pg: svbool4_t,
            base: *mut f32,
            indices: svint32_t,
        );
    }
    _svst1_scatter_s32index_f32(data, pg.into(), base, indices)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1_scatter_s32index_s32(
    pg: svbool_t,
    base: *mut i32,
    indices: svint32_t,
    data: svint32_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.st1.scatter.sxtw.index.nxv4i32"
        )]
        fn _svst1_scatter_s32index_s32(
            data: svint32_t,
            pg: svbool4_t,
            base: *mut i32,
            indices: svint32_t,
        );
    }
    _svst1_scatter_s32index_s32(data, pg.into(), base, indices)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1_scatter_s32index_u32(
    pg: svbool_t,
    base: *mut u32,
    indices: svint32_t,
    data: svuint32_t,
) {
    svst1_scatter_s32index_s32(pg, base as *mut i32, indices, data.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1d))]
pub unsafe fn svst1_scatter_s64index_f64(
    pg: svbool_t,
    base: *mut f64,
    indices: svint64_t,
    data: svfloat64_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.st1.scatter.index.nxv2f64"
        )]
        fn _svst1_scatter_s64index_f64(
            data: svfloat64_t,
            pg: svbool2_t,
            base: *mut f64,
            indices: svint64_t,
        );
    }
    _svst1_scatter_s64index_f64(data, pg.into(), base, indices)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1d))]
pub unsafe fn svst1_scatter_s64index_s64(
    pg: svbool_t,
    base: *mut i64,
    indices: svint64_t,
    data: svint64_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.st1.scatter.index.nxv2i64"
        )]
        fn _svst1_scatter_s64index_s64(
            data: svint64_t,
            pg: svbool2_t,
            base: *mut i64,
            indices: svint64_t,
        );
    }
    _svst1_scatter_s64index_s64(data, pg.into(), base, indices)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1d))]
pub unsafe fn svst1_scatter_s64index_u64(
    pg: svbool_t,
    base: *mut u64,
    indices: svint64_t,
    data: svuint64_t,
) {
    svst1_scatter_s64index_s64(pg, base as *mut i64, indices, data.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1_scatter_u32index_f32(
    pg: svbool_t,
    base: *mut f32,
    indices: svuint32_t,
    data: svfloat32_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.st1.scatter.uxtw.index.nxv4f32"
        )]
        fn _svst1_scatter_u32index_f32(
            data: svfloat32_t,
            pg: svbool4_t,
            base: *mut f32,
            indices: svint32_t,
        );
    }
    _svst1_scatter_u32index_f32(data, pg.into(), base, indices.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1_scatter_u32index_s32(
    pg: svbool_t,
    base: *mut i32,
    indices: svuint32_t,
    data: svint32_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.st1.scatter.uxtw.index.nxv4i32"
        )]
        fn _svst1_scatter_u32index_s32(
            data: svint32_t,
            pg: svbool4_t,
            base: *mut i32,
            indices: svint32_t,
        );
    }
    _svst1_scatter_u32index_s32(data, pg.into(), base, indices.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1_scatter_u32index_u32(
    pg: svbool_t,
    base: *mut u32,
    indices: svuint32_t,
    data: svuint32_t,
) {
    svst1_scatter_u32index_s32(pg, base as *mut i32, indices, data.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1d))]
pub unsafe fn svst1_scatter_u64index_f64(
    pg: svbool_t,
    base: *mut f64,
    indices: svuint64_t,
    data: svfloat64_t,
) {
    svst1_scatter_s64index_f64(pg, base, indices.as_signed(), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1d))]
pub unsafe fn svst1_scatter_u64index_s64(
    pg: svbool_t,
    base: *mut i64,
    indices: svuint64_t,
    data: svint64_t,
) {
    svst1_scatter_s64index_s64(pg, base, indices.as_signed(), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1d))]
pub unsafe fn svst1_scatter_u64index_u64(
    pg: svbool_t,
    base: *mut u64,
    indices: svuint64_t,
    data: svuint64_t,
) {
    svst1_scatter_s64index_s64(pg, base as *mut i64, indices.as_signed(), data.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1_scatter_s32offset_f32(
    pg: svbool_t,
    base: *mut f32,
    offsets: svint32_t,
    data: svfloat32_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.st1.scatter.sxtw.nxv4f32"
        )]
        fn _svst1_scatter_s32offset_f32(
            data: svfloat32_t,
            pg: svbool4_t,
            base: *mut f32,
            offsets: svint32_t,
        );
    }
    _svst1_scatter_s32offset_f32(data, pg.into(), base, offsets)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1_scatter_s32offset_s32(
    pg: svbool_t,
    base: *mut i32,
    offsets: svint32_t,
    data: svint32_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.st1.scatter.sxtw.nxv4i32"
        )]
        fn _svst1_scatter_s32offset_s32(
            data: svint32_t,
            pg: svbool4_t,
            base: *mut i32,
            offsets: svint32_t,
        );
    }
    _svst1_scatter_s32offset_s32(data, pg.into(), base, offsets)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1_scatter_s32offset_u32(
    pg: svbool_t,
    base: *mut u32,
    offsets: svint32_t,
    data: svuint32_t,
) {
    svst1_scatter_s32offset_s32(pg, base as *mut i32, offsets, data.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1d))]
pub unsafe fn svst1_scatter_s64offset_f64(
    pg: svbool_t,
    base: *mut f64,
    offsets: svint64_t,
    data: svfloat64_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.st1.scatter.nxv2f64"
        )]
        fn _svst1_scatter_s64offset_f64(
            data: svfloat64_t,
            pg: svbool2_t,
            base: *mut f64,
            offsets: svint64_t,
        );
    }
    _svst1_scatter_s64offset_f64(data, pg.into(), base, offsets)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1d))]
pub unsafe fn svst1_scatter_s64offset_s64(
    pg: svbool_t,
    base: *mut i64,
    offsets: svint64_t,
    data: svint64_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.st1.scatter.nxv2i64"
        )]
        fn _svst1_scatter_s64offset_s64(
            data: svint64_t,
            pg: svbool2_t,
            base: *mut i64,
            offsets: svint64_t,
        );
    }
    _svst1_scatter_s64offset_s64(data, pg.into(), base, offsets)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1d))]
pub unsafe fn svst1_scatter_s64offset_u64(
    pg: svbool_t,
    base: *mut u64,
    offsets: svint64_t,
    data: svuint64_t,
) {
    svst1_scatter_s64offset_s64(pg, base as *mut i64, offsets, data.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1_scatter_u32offset_f32(
    pg: svbool_t,
    base: *mut f32,
    offsets: svuint32_t,
    data: svfloat32_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.st1.scatter.uxtw.nxv4f32"
        )]
        fn _svst1_scatter_u32offset_f32(
            data: svfloat32_t,
            pg: svbool4_t,
            base: *mut f32,
            offsets: svint32_t,
        );
    }
    _svst1_scatter_u32offset_f32(data, pg.into(), base, offsets.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1_scatter_u32offset_s32(
    pg: svbool_t,
    base: *mut i32,
    offsets: svuint32_t,
    data: svint32_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.st1.scatter.uxtw.nxv4i32"
        )]
        fn _svst1_scatter_u32offset_s32(
            data: svint32_t,
            pg: svbool4_t,
            base: *mut i32,
            offsets: svint32_t,
        );
    }
    _svst1_scatter_u32offset_s32(data, pg.into(), base, offsets.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1_scatter_u32offset_u32(
    pg: svbool_t,
    base: *mut u32,
    offsets: svuint32_t,
    data: svuint32_t,
) {
    svst1_scatter_u32offset_s32(pg, base as *mut i32, offsets, data.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1d))]
pub unsafe fn svst1_scatter_u64offset_f64(
    pg: svbool_t,
    base: *mut f64,
    offsets: svuint64_t,
    data: svfloat64_t,
) {
    svst1_scatter_s64offset_f64(pg, base, offsets.as_signed(), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1d))]
pub unsafe fn svst1_scatter_u64offset_s64(
    pg: svbool_t,
    base: *mut i64,
    offsets: svuint64_t,
    data: svint64_t,
) {
    svst1_scatter_s64offset_s64(pg, base, offsets.as_signed(), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1d))]
pub unsafe fn svst1_scatter_u64offset_u64(
    pg: svbool_t,
    base: *mut u64,
    offsets: svuint64_t,
    data: svuint64_t,
) {
    svst1_scatter_s64offset_s64(pg, base as *mut i64, offsets.as_signed(), data.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1_scatter_u32base_f32(pg: svbool_t, bases: svuint32_t, data: svfloat32_t) {
    svst1_scatter_u32base_offset_f32(pg, bases, 0, data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1_scatter_u32base_s32(pg: svbool_t, bases: svuint32_t, data: svint32_t) {
    svst1_scatter_u32base_offset_s32(pg, bases, 0, data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1_scatter_u32base_u32(pg: svbool_t, bases: svuint32_t, data: svuint32_t) {
    svst1_scatter_u32base_offset_u32(pg, bases, 0, data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1d))]
pub unsafe fn svst1_scatter_u64base_f64(pg: svbool_t, bases: svuint64_t, data: svfloat64_t) {
    svst1_scatter_u64base_offset_f64(pg, bases, 0, data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1d))]
pub unsafe fn svst1_scatter_u64base_s64(pg: svbool_t, bases: svuint64_t, data: svint64_t) {
    svst1_scatter_u64base_offset_s64(pg, bases, 0, data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1d))]
pub unsafe fn svst1_scatter_u64base_u64(pg: svbool_t, bases: svuint64_t, data: svuint64_t) {
    svst1_scatter_u64base_offset_u64(pg, bases, 0, data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1_scatter_u32base_index_f32(
    pg: svbool_t,
    bases: svuint32_t,
    index: i64,
    data: svfloat32_t,
) {
    svst1_scatter_u32base_offset_f32(pg, bases, index.unchecked_shl(2), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1_scatter_u32base_index_s32(
    pg: svbool_t,
    bases: svuint32_t,
    index: i64,
    data: svint32_t,
) {
    svst1_scatter_u32base_offset_s32(pg, bases, index.unchecked_shl(2), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1_scatter_u32base_index_u32(
    pg: svbool_t,
    bases: svuint32_t,
    index: i64,
    data: svuint32_t,
) {
    svst1_scatter_u32base_offset_u32(pg, bases, index.unchecked_shl(2), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1d))]
pub unsafe fn svst1_scatter_u64base_index_f64(
    pg: svbool_t,
    bases: svuint64_t,
    index: i64,
    data: svfloat64_t,
) {
    svst1_scatter_u64base_offset_f64(pg, bases, index.unchecked_shl(3), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1d))]
pub unsafe fn svst1_scatter_u64base_index_s64(
    pg: svbool_t,
    bases: svuint64_t,
    index: i64,
    data: svint64_t,
) {
    svst1_scatter_u64base_offset_s64(pg, bases, index.unchecked_shl(3), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1d))]
pub unsafe fn svst1_scatter_u64base_index_u64(
    pg: svbool_t,
    bases: svuint64_t,
    index: i64,
    data: svuint64_t,
) {
    svst1_scatter_u64base_offset_u64(pg, bases, index.unchecked_shl(3), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1_scatter_u32base_offset_f32(
    pg: svbool_t,
    bases: svuint32_t,
    offset: i64,
    data: svfloat32_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.st1.scatter.scalar.offset.nxv4f32.nxv4i32"
        )]
        fn _svst1_scatter_u32base_offset_f32(
            data: svfloat32_t,
            pg: svbool4_t,
            bases: svint32_t,
            offset: i64,
        );
    }
    _svst1_scatter_u32base_offset_f32(data, pg.into(), bases.as_signed(), offset)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1_scatter_u32base_offset_s32(
    pg: svbool_t,
    bases: svuint32_t,
    offset: i64,
    data: svint32_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.st1.scatter.scalar.offset.nxv4i32.nxv4i32"
        )]
        fn _svst1_scatter_u32base_offset_s32(
            data: svint32_t,
            pg: svbool4_t,
            bases: svint32_t,
            offset: i64,
        );
    }
    _svst1_scatter_u32base_offset_s32(data, pg.into(), bases.as_signed(), offset)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1_scatter_u32base_offset_u32(
    pg: svbool_t,
    bases: svuint32_t,
    offset: i64,
    data: svuint32_t,
) {
    svst1_scatter_u32base_offset_s32(pg, bases, offset, data.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1d))]
pub unsafe fn svst1_scatter_u64base_offset_f64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
    data: svfloat64_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.st1.scatter.scalar.offset.nxv2f64.nxv2i64"
        )]
        fn _svst1_scatter_u64base_offset_f64(
            data: svfloat64_t,
            pg: svbool2_t,
            bases: svint64_t,
            offset: i64,
        );
    }
    _svst1_scatter_u64base_offset_f64(data, pg.into(), bases.as_signed(), offset)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1d))]
pub unsafe fn svst1_scatter_u64base_offset_s64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
    data: svint64_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.st1.scatter.scalar.offset.nxv2i64.nxv2i64"
        )]
        fn _svst1_scatter_u64base_offset_s64(
            data: svint64_t,
            pg: svbool2_t,
            bases: svint64_t,
            offset: i64,
        );
    }
    _svst1_scatter_u64base_offset_s64(data, pg.into(), bases.as_signed(), offset)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1d))]
pub unsafe fn svst1_scatter_u64base_offset_u64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
    data: svuint64_t,
) {
    svst1_scatter_u64base_offset_s64(pg, bases, offset, data.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1_vnum_f32(pg: svbool_t, base: *mut f32, vnum: i64, data: svfloat32_t) {
    svst1_f32(pg, base.offset(svcntw() as isize * vnum as isize), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1d))]
pub unsafe fn svst1_vnum_f64(pg: svbool_t, base: *mut f64, vnum: i64, data: svfloat64_t) {
    svst1_f64(pg, base.offset(svcntd() as isize * vnum as isize), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1b))]
pub unsafe fn svst1_vnum_s8(pg: svbool_t, base: *mut i8, vnum: i64, data: svint8_t) {
    svst1_s8(pg, base.offset(svcntb() as isize * vnum as isize), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1_vnum_s16(pg: svbool_t, base: *mut i16, vnum: i64, data: svint16_t) {
    svst1_s16(pg, base.offset(svcnth() as isize * vnum as isize), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1_vnum_s32(pg: svbool_t, base: *mut i32, vnum: i64, data: svint32_t) {
    svst1_s32(pg, base.offset(svcntw() as isize * vnum as isize), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1d))]
pub unsafe fn svst1_vnum_s64(pg: svbool_t, base: *mut i64, vnum: i64, data: svint64_t) {
    svst1_s64(pg, base.offset(svcntd() as isize * vnum as isize), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1b))]
pub unsafe fn svst1_vnum_u8(pg: svbool_t, base: *mut u8, vnum: i64, data: svuint8_t) {
    svst1_u8(pg, base.offset(svcntb() as isize * vnum as isize), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1_vnum_u16(pg: svbool_t, base: *mut u16, vnum: i64, data: svuint16_t) {
    svst1_u16(pg, base.offset(svcnth() as isize * vnum as isize), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1_vnum_u32(pg: svbool_t, base: *mut u32, vnum: i64, data: svuint32_t) {
    svst1_u32(pg, base.offset(svcntw() as isize * vnum as isize), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1d))]
pub unsafe fn svst1_vnum_u64(pg: svbool_t, base: *mut u64, vnum: i64, data: svuint64_t) {
    svst1_u64(pg, base.offset(svcntd() as isize * vnum as isize), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1b))]
pub unsafe fn svst1b_s16(pg: svbool_t, base: *mut i8, data: svint16_t) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.st1.nxv8i8")]
        fn _svst1b_s16(data: nxv8i8, pg: svbool8_t, ptr: *mut i8);
    }
    _svst1b_s16(simd_cast(data), pg.into(), base)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1b))]
pub unsafe fn svst1b_s32(pg: svbool_t, base: *mut i8, data: svint32_t) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.st1.nxv4i8")]
        fn _svst1b_s32(data: nxv4i8, pg: svbool4_t, ptr: *mut i8);
    }
    _svst1b_s32(simd_cast(data), pg.into(), base)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1h_s32(pg: svbool_t, base: *mut i16, data: svint32_t) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.st1.nxv4i16")]
        fn _svst1h_s32(data: nxv4i16, pg: svbool4_t, ptr: *mut i16);
    }
    _svst1h_s32(simd_cast(data), pg.into(), base)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1b))]
pub unsafe fn svst1b_s64(pg: svbool_t, base: *mut i8, data: svint64_t) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.st1.nxv2i8")]
        fn _svst1b_s64(data: nxv2i8, pg: svbool2_t, ptr: *mut i8);
    }
    _svst1b_s64(simd_cast(data), pg.into(), base)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1h_s64(pg: svbool_t, base: *mut i16, data: svint64_t) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.st1.nxv2i16")]
        fn _svst1h_s64(data: nxv2i16, pg: svbool2_t, ptr: *mut i16);
    }
    _svst1h_s64(simd_cast(data), pg.into(), base)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1w_s64(pg: svbool_t, base: *mut i32, data: svint64_t) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.st1.nxv2i32")]
        fn _svst1w_s64(data: nxv2i32, pg: svbool2_t, ptr: *mut i32);
    }
    _svst1w_s64(simd_cast(data), pg.into(), base)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1b))]
pub unsafe fn svst1b_u16(pg: svbool_t, base: *mut u8, data: svuint16_t) {
    svst1b_s16(pg, base as *mut i16, data.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1b))]
pub unsafe fn svst1b_u32(pg: svbool_t, base: *mut u8, data: svuint32_t) {
    svst1b_s32(pg, base as *mut i32, data.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1h_u32(pg: svbool_t, base: *mut u16, data: svuint32_t) {
    svst1h_s32(pg, base as *mut i32, data.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1b))]
pub unsafe fn svst1b_u64(pg: svbool_t, base: *mut u8, data: svuint64_t) {
    svst1b_s64(pg, base as *mut i64, data.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1h_u64(pg: svbool_t, base: *mut u16, data: svuint64_t) {
    svst1h_s64(pg, base as *mut i64, data.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1w_u64(pg: svbool_t, base: *mut u32, data: svuint64_t) {
    svst1w_s64(pg, base as *mut i64, data.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1b))]
pub unsafe fn svst1b_scatter_s32offset_s32(
    pg: svbool_t,
    base: *mut i8,
    offsets: svint32_t,
    data: svint32_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.st1.scatter.sxtw.nxv4i8"
        )]
        fn _svst1b_scatter_s32offset_s32(
            data: nxv4i8,
            pg: svbool4_t,
            base: *mut i8,
            offsets: svint32_t,
        );
    }
    _svst1b_scatter_s32offset_s32(simd_cast(data), pg.into(), base, offsets)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1h_scatter_s32offset_s32(
    pg: svbool_t,
    base: *mut i16,
    offsets: svint32_t,
    data: svint32_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.st1.scatter.sxtw.nxv4i16"
        )]
        fn _svst1h_scatter_s32offset_s32(
            data: nxv4i16,
            pg: svbool4_t,
            base: *mut i16,
            offsets: svint32_t,
        );
    }
    _svst1h_scatter_s32offset_s32(simd_cast(data), pg.into(), base, offsets)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1b))]
pub unsafe fn svst1b_scatter_s32offset_u32(
    pg: svbool_t,
    base: *mut u8,
    offsets: svint32_t,
    data: svuint32_t,
) {
    svst1b_scatter_s32offset_s32(pg, base as *mut i32, offsets, data.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1h_scatter_s32offset_u32(
    pg: svbool_t,
    base: *mut u16,
    offsets: svint32_t,
    data: svuint32_t,
) {
    svst1h_scatter_s32offset_s32(pg, base as *mut i32, offsets, data.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1b))]
pub unsafe fn svst1b_scatter_s64offset_s64(
    pg: svbool_t,
    base: *mut i8,
    offsets: svint64_t,
    data: svint64_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.st1.scatter.nxv2i8"
        )]
        fn _svst1b_scatter_s64offset_s64(
            data: nxv2i8,
            pg: svbool2_t,
            base: *mut i8,
            offsets: svint64_t,
        );
    }
    _svst1b_scatter_s64offset_s64(simd_cast(data), pg.into(), base, offsets)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1h_scatter_s64offset_s64(
    pg: svbool_t,
    base: *mut i16,
    offsets: svint64_t,
    data: svint64_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.st1.scatter.nxv2i16"
        )]
        fn _svst1h_scatter_s64offset_s64(
            data: nxv2i16,
            pg: svbool2_t,
            base: *mut i16,
            offsets: svint64_t,
        );
    }
    _svst1h_scatter_s64offset_s64(simd_cast(data), pg.into(), base, offsets)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1w_scatter_s64offset_s64(
    pg: svbool_t,
    base: *mut i32,
    offsets: svint64_t,
    data: svint64_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.st1.scatter.nxv2i32"
        )]
        fn _svst1w_scatter_s64offset_s64(
            data: nxv2i32,
            pg: svbool2_t,
            base: *mut i32,
            offsets: svint64_t,
        );
    }
    _svst1w_scatter_s64offset_s64(simd_cast(data), pg.into(), base, offsets)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1b))]
pub unsafe fn svst1b_scatter_s64offset_u64(
    pg: svbool_t,
    base: *mut u8,
    offsets: svint64_t,
    data: svuint64_t,
) {
    svst1b_scatter_s64offset_s64(pg, base as *mut i64, offsets, data.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1h_scatter_s64offset_u64(
    pg: svbool_t,
    base: *mut u16,
    offsets: svint64_t,
    data: svuint64_t,
) {
    svst1h_scatter_s64offset_s64(pg, base as *mut i64, offsets, data.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1w_scatter_s64offset_u64(
    pg: svbool_t,
    base: *mut u32,
    offsets: svint64_t,
    data: svuint64_t,
) {
    svst1w_scatter_s64offset_s64(pg, base as *mut i64, offsets, data.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1b))]
pub unsafe fn svst1b_scatter_u32offset_s32(
    pg: svbool_t,
    base: *mut i8,
    offsets: svuint32_t,
    data: svint32_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.st1.scatter.uxtw.nxv4i8"
        )]
        fn _svst1b_scatter_u32offset_s32(
            data: nxv4i8,
            pg: svbool4_t,
            base: *mut i8,
            offsets: svint32_t,
        );
    }
    _svst1b_scatter_u32offset_s32(simd_cast(data), pg.into(), base, offsets.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1h_scatter_u32offset_s32(
    pg: svbool_t,
    base: *mut i16,
    offsets: svuint32_t,
    data: svint32_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.st1.scatter.uxtw.nxv4i16"
        )]
        fn _svst1h_scatter_u32offset_s32(
            data: nxv4i16,
            pg: svbool4_t,
            base: *mut i16,
            offsets: svint32_t,
        );
    }
    _svst1h_scatter_u32offset_s32(simd_cast(data), pg.into(), base, offsets.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1b))]
pub unsafe fn svst1b_scatter_u32offset_u32(
    pg: svbool_t,
    base: *mut u8,
    offsets: svuint32_t,
    data: svuint32_t,
) {
    svst1b_scatter_u32offset_s32(pg, base as *mut i32, offsets, data.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1h_scatter_u32offset_u32(
    pg: svbool_t,
    base: *mut u16,
    offsets: svuint32_t,
    data: svuint32_t,
) {
    svst1h_scatter_u32offset_s32(pg, base as *mut i32, offsets, data.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1b))]
pub unsafe fn svst1b_scatter_u64offset_s64(
    pg: svbool_t,
    base: *mut i8,
    offsets: svuint64_t,
    data: svint64_t,
) {
    svst1b_scatter_s64offset_s64(pg, base, offsets.as_signed(), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1h_scatter_u64offset_s64(
    pg: svbool_t,
    base: *mut i16,
    offsets: svuint64_t,
    data: svint64_t,
) {
    svst1h_scatter_s64offset_s64(pg, base, offsets.as_signed(), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1w_scatter_u64offset_s64(
    pg: svbool_t,
    base: *mut i32,
    offsets: svuint64_t,
    data: svint64_t,
) {
    svst1w_scatter_s64offset_s64(pg, base, offsets.as_signed(), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1b))]
pub unsafe fn svst1b_scatter_u64offset_u64(
    pg: svbool_t,
    base: *mut u8,
    offsets: svuint64_t,
    data: svuint64_t,
) {
    svst1b_scatter_s64offset_s64(pg, base as *mut i64, offsets.as_signed(), data.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1h_scatter_u64offset_u64(
    pg: svbool_t,
    base: *mut u16,
    offsets: svuint64_t,
    data: svuint64_t,
) {
    svst1h_scatter_s64offset_s64(pg, base as *mut i64, offsets.as_signed(), data.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1w_scatter_u64offset_u64(
    pg: svbool_t,
    base: *mut u32,
    offsets: svuint64_t,
    data: svuint64_t,
) {
    svst1w_scatter_s64offset_s64(pg, base as *mut i64, offsets.as_signed(), data.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1b))]
pub unsafe fn svst1b_scatter_u32base_offset_s32(
    pg: svbool_t,
    bases: svuint32_t,
    offset: i64,
    data: svint32_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.st1.scatter.scalar.offset.nxv4i8.nxv4i32"
        )]
        fn _svst1b_scatter_u32base_offset_s32(
            data: nxv4i8,
            pg: svbool4_t,
            bases: svint32_t,
            offset: i64,
        );
    }
    _svst1b_scatter_u32base_offset_s32(simd_cast(data), pg.into(), bases.as_signed(), offset)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1h_scatter_u32base_offset_s32(
    pg: svbool_t,
    bases: svuint32_t,
    offset: i64,
    data: svint32_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.st1.scatter.scalar.offset.nxv4i16.nxv4i32"
        )]
        fn _svst1h_scatter_u32base_offset_s32(
            data: nxv4i16,
            pg: svbool4_t,
            bases: svint32_t,
            offset: i64,
        );
    }
    _svst1h_scatter_u32base_offset_s32(simd_cast(data), pg.into(), bases.as_signed(), offset)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1b))]
pub unsafe fn svst1b_scatter_u32base_offset_u32(
    pg: svbool_t,
    bases: svuint32_t,
    offset: i64,
    data: svuint32_t,
) {
    svst1b_scatter_u32base_offset_s32(pg, bases, offset, data.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1h_scatter_u32base_offset_u32(
    pg: svbool_t,
    bases: svuint32_t,
    offset: i64,
    data: svuint32_t,
) {
    svst1h_scatter_u32base_offset_s32(pg, bases, offset, data.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1b))]
pub unsafe fn svst1b_scatter_u64base_offset_s64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
    data: svint64_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.st1.scatter.scalar.offset.nxv2i8.nxv2i64"
        )]
        fn _svst1b_scatter_u64base_offset_s64(
            data: nxv2i8,
            pg: svbool2_t,
            bases: svint64_t,
            offset: i64,
        );
    }
    _svst1b_scatter_u64base_offset_s64(simd_cast(data), pg.into(), bases.as_signed(), offset)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1h_scatter_u64base_offset_s64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
    data: svint64_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.st1.scatter.scalar.offset.nxv2i16.nxv2i64"
        )]
        fn _svst1h_scatter_u64base_offset_s64(
            data: nxv2i16,
            pg: svbool2_t,
            bases: svint64_t,
            offset: i64,
        );
    }
    _svst1h_scatter_u64base_offset_s64(simd_cast(data), pg.into(), bases.as_signed(), offset)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1w_scatter_u64base_offset_s64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
    data: svint64_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.st1.scatter.scalar.offset.nxv2i32.nxv2i64"
        )]
        fn _svst1w_scatter_u64base_offset_s64(
            data: nxv2i32,
            pg: svbool2_t,
            bases: svint64_t,
            offset: i64,
        );
    }
    _svst1w_scatter_u64base_offset_s64(simd_cast(data), pg.into(), bases.as_signed(), offset)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1b))]
pub unsafe fn svst1b_scatter_u64base_offset_u64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
    data: svuint64_t,
) {
    svst1b_scatter_u64base_offset_s64(pg, bases, offset, data.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1h_scatter_u64base_offset_u64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
    data: svuint64_t,
) {
    svst1h_scatter_u64base_offset_s64(pg, bases, offset, data.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1w_scatter_u64base_offset_u64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
    data: svuint64_t,
) {
    svst1w_scatter_u64base_offset_s64(pg, bases, offset, data.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1b))]
pub unsafe fn svst1b_scatter_u32base_s32(pg: svbool_t, bases: svuint32_t, data: svint32_t) {
    svst1b_scatter_u32base_offset_s32(pg, bases, 0, data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1h_scatter_u32base_s32(pg: svbool_t, bases: svuint32_t, data: svint32_t) {
    svst1h_scatter_u32base_offset_s32(pg, bases, 0, data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1b))]
pub unsafe fn svst1b_scatter_u32base_u32(pg: svbool_t, bases: svuint32_t, data: svuint32_t) {
    svst1b_scatter_u32base_offset_u32(pg, bases, 0, data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1h_scatter_u32base_u32(pg: svbool_t, bases: svuint32_t, data: svuint32_t) {
    svst1h_scatter_u32base_offset_u32(pg, bases, 0, data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1b))]
pub unsafe fn svst1b_scatter_u64base_s64(pg: svbool_t, bases: svuint64_t, data: svint64_t) {
    svst1b_scatter_u64base_offset_s64(pg, bases, 0, data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1h_scatter_u64base_s64(pg: svbool_t, bases: svuint64_t, data: svint64_t) {
    svst1h_scatter_u64base_offset_s64(pg, bases, 0, data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1w_scatter_u64base_s64(pg: svbool_t, bases: svuint64_t, data: svint64_t) {
    svst1w_scatter_u64base_offset_s64(pg, bases, 0, data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1b))]
pub unsafe fn svst1b_scatter_u64base_u64(pg: svbool_t, bases: svuint64_t, data: svuint64_t) {
    svst1b_scatter_u64base_offset_u64(pg, bases, 0, data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1h_scatter_u64base_u64(pg: svbool_t, bases: svuint64_t, data: svuint64_t) {
    svst1h_scatter_u64base_offset_u64(pg, bases, 0, data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1w_scatter_u64base_u64(pg: svbool_t, bases: svuint64_t, data: svuint64_t) {
    svst1w_scatter_u64base_offset_u64(pg, bases, 0, data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1b))]
pub unsafe fn svst1b_vnum_s16(pg: svbool_t, base: *mut i8, vnum: i64, data: svint16_t) {
    svst1b_s16(pg, base.offset(svcnth() as isize * vnum as isize), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1b))]
pub unsafe fn svst1b_vnum_s32(pg: svbool_t, base: *mut i8, vnum: i64, data: svint32_t) {
    svst1b_s32(pg, base.offset(svcntw() as isize * vnum as isize), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1h_vnum_s32(pg: svbool_t, base: *mut i16, vnum: i64, data: svint32_t) {
    svst1h_s32(pg, base.offset(svcntw() as isize * vnum as isize), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1b))]
pub unsafe fn svst1b_vnum_s64(pg: svbool_t, base: *mut i8, vnum: i64, data: svint64_t) {
    svst1b_s64(pg, base.offset(svcntd() as isize * vnum as isize), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1h_vnum_s64(pg: svbool_t, base: *mut i16, vnum: i64, data: svint64_t) {
    svst1h_s64(pg, base.offset(svcntd() as isize * vnum as isize), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1w_vnum_s64(pg: svbool_t, base: *mut i32, vnum: i64, data: svint64_t) {
    svst1w_s64(pg, base.offset(svcntd() as isize * vnum as isize), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1b))]
pub unsafe fn svst1b_vnum_u16(pg: svbool_t, base: *mut u8, vnum: i64, data: svuint16_t) {
    svst1b_u16(pg, base.offset(svcnth() as isize * vnum as isize), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1b))]
pub unsafe fn svst1b_vnum_u32(pg: svbool_t, base: *mut u8, vnum: i64, data: svuint32_t) {
    svst1b_u32(pg, base.offset(svcntw() as isize * vnum as isize), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1h_vnum_u32(pg: svbool_t, base: *mut u16, vnum: i64, data: svuint32_t) {
    svst1h_u32(pg, base.offset(svcntw() as isize * vnum as isize), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1b))]
pub unsafe fn svst1b_vnum_u64(pg: svbool_t, base: *mut u8, vnum: i64, data: svuint64_t) {
    svst1b_u64(pg, base.offset(svcntd() as isize * vnum as isize), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1h_vnum_u64(pg: svbool_t, base: *mut u16, vnum: i64, data: svuint64_t) {
    svst1h_u64(pg, base.offset(svcntd() as isize * vnum as isize), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1w_vnum_u64(pg: svbool_t, base: *mut u32, vnum: i64, data: svuint64_t) {
    svst1w_u64(pg, base.offset(svcntd() as isize * vnum as isize), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1h_scatter_s32index_s32(
    pg: svbool_t,
    base: *mut i16,
    indices: svint32_t,
    data: svint32_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.st1.scatter.sxtw.index.nxv4i16"
        )]
        fn _svst1h_scatter_s32index_s32(
            data: nxv4i16,
            pg: svbool4_t,
            base: *mut i16,
            indices: svint32_t,
        );
    }
    _svst1h_scatter_s32index_s32(simd_cast(data), pg.into(), base, indices)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1h_scatter_s32index_u32(
    pg: svbool_t,
    base: *mut u16,
    indices: svint32_t,
    data: svuint32_t,
) {
    svst1h_scatter_s32index_s32(pg, base as *mut i32, indices, data.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1h_scatter_s64index_s64(
    pg: svbool_t,
    base: *mut i16,
    indices: svint64_t,
    data: svint64_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.st1.scatter.index.nxv2i16"
        )]
        fn _svst1h_scatter_s64index_s64(
            data: nxv2i16,
            pg: svbool2_t,
            base: *mut i16,
            indices: svint64_t,
        );
    }
    _svst1h_scatter_s64index_s64(simd_cast(data), pg.into(), base, indices)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1w_scatter_s64index_s64(
    pg: svbool_t,
    base: *mut i32,
    indices: svint64_t,
    data: svint64_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.st1.scatter.index.nxv2i32"
        )]
        fn _svst1w_scatter_s64index_s64(
            data: nxv2i32,
            pg: svbool2_t,
            base: *mut i32,
            indices: svint64_t,
        );
    }
    _svst1w_scatter_s64index_s64(simd_cast(data), pg.into(), base, indices)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1h_scatter_s64index_u64(
    pg: svbool_t,
    base: *mut u16,
    indices: svint64_t,
    data: svuint64_t,
) {
    svst1h_scatter_s64index_s64(pg, base as *mut i64, indices, data.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1w_scatter_s64index_u64(
    pg: svbool_t,
    base: *mut u32,
    indices: svint64_t,
    data: svuint64_t,
) {
    svst1w_scatter_s64index_s64(pg, base as *mut i64, indices, data.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1h_scatter_u32index_s32(
    pg: svbool_t,
    base: *mut i16,
    indices: svuint32_t,
    data: svint32_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.st1.scatter.uxtw.index.nxv4i16"
        )]
        fn _svst1h_scatter_u32index_s32(
            data: nxv4i16,
            pg: svbool4_t,
            base: *mut i16,
            indices: svint32_t,
        );
    }
    _svst1h_scatter_u32index_s32(simd_cast(data), pg.into(), base, indices.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1h_scatter_u32index_u32(
    pg: svbool_t,
    base: *mut u16,
    indices: svuint32_t,
    data: svuint32_t,
) {
    svst1h_scatter_u32index_s32(pg, base as *mut i32, indices, data.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1h_scatter_u64index_s64(
    pg: svbool_t,
    base: *mut i16,
    indices: svuint64_t,
    data: svint64_t,
) {
    svst1h_scatter_s64index_s64(pg, base, indices.as_signed(), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1w_scatter_u64index_s64(
    pg: svbool_t,
    base: *mut i32,
    indices: svuint64_t,
    data: svint64_t,
) {
    svst1w_scatter_s64index_s64(pg, base, indices.as_signed(), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1h_scatter_u64index_u64(
    pg: svbool_t,
    base: *mut u16,
    indices: svuint64_t,
    data: svuint64_t,
) {
    svst1h_scatter_s64index_s64(pg, base as *mut i64, indices.as_signed(), data.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1w_scatter_u64index_u64(
    pg: svbool_t,
    base: *mut u32,
    indices: svuint64_t,
    data: svuint64_t,
) {
    svst1w_scatter_s64index_s64(pg, base as *mut i64, indices.as_signed(), data.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1h_scatter_u32base_index_s32(
    pg: svbool_t,
    bases: svuint32_t,
    index: i64,
    data: svint32_t,
) {
    svst1h_scatter_u32base_offset_s32(pg, bases, index.unchecked_shl(1), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1h_scatter_u32base_index_u32(
    pg: svbool_t,
    bases: svuint32_t,
    index: i64,
    data: svuint32_t,
) {
    svst1h_scatter_u32base_offset_u32(pg, bases, index.unchecked_shl(1), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1h_scatter_u64base_index_s64(
    pg: svbool_t,
    bases: svuint64_t,
    index: i64,
    data: svint64_t,
) {
    svst1h_scatter_u64base_offset_s64(pg, bases, index.unchecked_shl(1), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1w_scatter_u64base_index_s64(
    pg: svbool_t,
    bases: svuint64_t,
    index: i64,
    data: svint64_t,
) {
    svst1w_scatter_u64base_offset_s64(pg, bases, index.unchecked_shl(2), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1h_scatter_u64base_index_u64(
    pg: svbool_t,
    bases: svuint64_t,
    index: i64,
    data: svuint64_t,
) {
    svst1h_scatter_u64base_offset_u64(pg, bases, index.unchecked_shl(1), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1w_scatter_u64base_index_u64(
    pg: svbool_t,
    bases: svuint64_t,
    index: i64,
    data: svuint64_t,
) {
    svst1w_scatter_u64base_offset_u64(pg, bases, index.unchecked_shl(2), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st2w))]
pub unsafe fn svst2_f32(pg: svbool_t, base: *mut f32, data: svfloat32x2_t) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.st2.nxv4f32")]
        fn _svst2_f32(data0: svfloat32_t, data1: svfloat32_t, pg: svbool4_t, ptr: *mut f32);
    }
    _svst2_f32(
        svget2_f32::<0>(data),
        svget2_f32::<1>(data),
        pg.into(),
        base,
    )
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st2d))]
pub unsafe fn svst2_f64(pg: svbool_t, base: *mut f64, data: svfloat64x2_t) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.st2.nxv2f64")]
        fn _svst2_f64(data0: svfloat64_t, data1: svfloat64_t, pg: svbool2_t, ptr: *mut f64);
    }
    _svst2_f64(
        svget2_f64::<0>(data),
        svget2_f64::<1>(data),
        pg.into(),
        base,
    )
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st2b))]
pub unsafe fn svst2_s8(pg: svbool_t, base: *mut i8, data: svint8x2_t) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.st2.nxv16i8")]
        fn _svst2_s8(data0: svint8_t, data1: svint8_t, pg: svbool_t, ptr: *mut i8);
    }
    _svst2_s8(svget2_s8::<0>(data), svget2_s8::<1>(data), pg, base)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st2h))]
pub unsafe fn svst2_s16(pg: svbool_t, base: *mut i16, data: svint16x2_t) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.st2.nxv8i16")]
        fn _svst2_s16(data0: svint16_t, data1: svint16_t, pg: svbool8_t, ptr: *mut i16);
    }
    _svst2_s16(
        svget2_s16::<0>(data),
        svget2_s16::<1>(data),
        pg.into(),
        base,
    )
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st2w))]
pub unsafe fn svst2_s32(pg: svbool_t, base: *mut i32, data: svint32x2_t) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.st2.nxv4i32")]
        fn _svst2_s32(data0: svint32_t, data1: svint32_t, pg: svbool4_t, ptr: *mut i32);
    }
    _svst2_s32(
        svget2_s32::<0>(data),
        svget2_s32::<1>(data),
        pg.into(),
        base,
    )
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st2d))]
pub unsafe fn svst2_s64(pg: svbool_t, base: *mut i64, data: svint64x2_t) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.st2.nxv2i64")]
        fn _svst2_s64(data0: svint64_t, data1: svint64_t, pg: svbool2_t, ptr: *mut i64);
    }
    _svst2_s64(
        svget2_s64::<0>(data),
        svget2_s64::<1>(data),
        pg.into(),
        base,
    )
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st2b))]
pub unsafe fn svst2_u8(pg: svbool_t, base: *mut u8, data: svuint8x2_t) {
    svst2_s8(pg, base as *mut i8, data.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st2h))]
pub unsafe fn svst2_u16(pg: svbool_t, base: *mut u16, data: svuint16x2_t) {
    svst2_s16(pg, base as *mut i16, data.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st2w))]
pub unsafe fn svst2_u32(pg: svbool_t, base: *mut u32, data: svuint32x2_t) {
    svst2_s32(pg, base as *mut i32, data.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st2d))]
pub unsafe fn svst2_u64(pg: svbool_t, base: *mut u64, data: svuint64x2_t) {
    svst2_s64(pg, base as *mut i64, data.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st2w))]
pub unsafe fn svst2_vnum_f32(pg: svbool_t, base: *mut f32, vnum: i64, data: svfloat32x2_t) {
    svst2_f32(pg, base.offset(svcntw() as isize * vnum as isize), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st2d))]
pub unsafe fn svst2_vnum_f64(pg: svbool_t, base: *mut f64, vnum: i64, data: svfloat64x2_t) {
    svst2_f64(pg, base.offset(svcntd() as isize * vnum as isize), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st2b))]
pub unsafe fn svst2_vnum_s8(pg: svbool_t, base: *mut i8, vnum: i64, data: svint8x2_t) {
    svst2_s8(pg, base.offset(svcntb() as isize * vnum as isize), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st2h))]
pub unsafe fn svst2_vnum_s16(pg: svbool_t, base: *mut i16, vnum: i64, data: svint16x2_t) {
    svst2_s16(pg, base.offset(svcnth() as isize * vnum as isize), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st2w))]
pub unsafe fn svst2_vnum_s32(pg: svbool_t, base: *mut i32, vnum: i64, data: svint32x2_t) {
    svst2_s32(pg, base.offset(svcntw() as isize * vnum as isize), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st2d))]
pub unsafe fn svst2_vnum_s64(pg: svbool_t, base: *mut i64, vnum: i64, data: svint64x2_t) {
    svst2_s64(pg, base.offset(svcntd() as isize * vnum as isize), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st2b))]
pub unsafe fn svst2_vnum_u8(pg: svbool_t, base: *mut u8, vnum: i64, data: svuint8x2_t) {
    svst2_u8(pg, base.offset(svcntb() as isize * vnum as isize), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st2h))]
pub unsafe fn svst2_vnum_u16(pg: svbool_t, base: *mut u16, vnum: i64, data: svuint16x2_t) {
    svst2_u16(pg, base.offset(svcnth() as isize * vnum as isize), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st2w))]
pub unsafe fn svst2_vnum_u32(pg: svbool_t, base: *mut u32, vnum: i64, data: svuint32x2_t) {
    svst2_u32(pg, base.offset(svcntw() as isize * vnum as isize), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st2d))]
pub unsafe fn svst2_vnum_u64(pg: svbool_t, base: *mut u64, vnum: i64, data: svuint64x2_t) {
    svst2_u64(pg, base.offset(svcntd() as isize * vnum as isize), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st3w))]
pub unsafe fn svst3_f32(pg: svbool_t, base: *mut f32, data: svfloat32x3_t) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.st3.nxv4f32")]
        fn _svst3_f32(
            data0: svfloat32_t,
            data1: svfloat32_t,
            data2: svfloat32_t,
            pg: svbool4_t,
            ptr: *mut f32,
        );
    }
    _svst3_f32(
        svget3_f32::<0>(data),
        svget3_f32::<1>(data),
        svget3_f32::<2>(data),
        pg.into(),
        base,
    )
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st3d))]
pub unsafe fn svst3_f64(pg: svbool_t, base: *mut f64, data: svfloat64x3_t) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.st3.nxv2f64")]
        fn _svst3_f64(
            data0: svfloat64_t,
            data1: svfloat64_t,
            data2: svfloat64_t,
            pg: svbool2_t,
            ptr: *mut f64,
        );
    }
    _svst3_f64(
        svget3_f64::<0>(data),
        svget3_f64::<1>(data),
        svget3_f64::<2>(data),
        pg.into(),
        base,
    )
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st3b))]
pub unsafe fn svst3_s8(pg: svbool_t, base: *mut i8, data: svint8x3_t) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.st3.nxv16i8")]
        fn _svst3_s8(data0: svint8_t, data1: svint8_t, data2: svint8_t, pg: svbool_t, ptr: *mut i8);
    }
    _svst3_s8(
        svget3_s8::<0>(data),
        svget3_s8::<1>(data),
        svget3_s8::<2>(data),
        pg,
        base,
    )
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st3h))]
pub unsafe fn svst3_s16(pg: svbool_t, base: *mut i16, data: svint16x3_t) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.st3.nxv8i16")]
        fn _svst3_s16(
            data0: svint16_t,
            data1: svint16_t,
            data2: svint16_t,
            pg: svbool8_t,
            ptr: *mut i16,
        );
    }
    _svst3_s16(
        svget3_s16::<0>(data),
        svget3_s16::<1>(data),
        svget3_s16::<2>(data),
        pg.into(),
        base,
    )
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st3w))]
pub unsafe fn svst3_s32(pg: svbool_t, base: *mut i32, data: svint32x3_t) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.st3.nxv4i32")]
        fn _svst3_s32(
            data0: svint32_t,
            data1: svint32_t,
            data2: svint32_t,
            pg: svbool4_t,
            ptr: *mut i32,
        );
    }
    _svst3_s32(
        svget3_s32::<0>(data),
        svget3_s32::<1>(data),
        svget3_s32::<2>(data),
        pg.into(),
        base,
    )
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st3d))]
pub unsafe fn svst3_s64(pg: svbool_t, base: *mut i64, data: svint64x3_t) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.st3.nxv2i64")]
        fn _svst3_s64(
            data0: svint64_t,
            data1: svint64_t,
            data2: svint64_t,
            pg: svbool2_t,
            ptr: *mut i64,
        );
    }
    _svst3_s64(
        svget3_s64::<0>(data),
        svget3_s64::<1>(data),
        svget3_s64::<2>(data),
        pg.into(),
        base,
    )
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st3b))]
pub unsafe fn svst3_u8(pg: svbool_t, base: *mut u8, data: svuint8x3_t) {
    svst3_s8(pg, base as *mut i8, data.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st3h))]
pub unsafe fn svst3_u16(pg: svbool_t, base: *mut u16, data: svuint16x3_t) {
    svst3_s16(pg, base as *mut i16, data.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st3w))]
pub unsafe fn svst3_u32(pg: svbool_t, base: *mut u32, data: svuint32x3_t) {
    svst3_s32(pg, base as *mut i32, data.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st3d))]
pub unsafe fn svst3_u64(pg: svbool_t, base: *mut u64, data: svuint64x3_t) {
    svst3_s64(pg, base as *mut i64, data.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st3w))]
pub unsafe fn svst3_vnum_f32(pg: svbool_t, base: *mut f32, vnum: i64, data: svfloat32x3_t) {
    svst3_f32(pg, base.offset(svcntw() as isize * vnum as isize), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st3d))]
pub unsafe fn svst3_vnum_f64(pg: svbool_t, base: *mut f64, vnum: i64, data: svfloat64x3_t) {
    svst3_f64(pg, base.offset(svcntd() as isize * vnum as isize), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st3b))]
pub unsafe fn svst3_vnum_s8(pg: svbool_t, base: *mut i8, vnum: i64, data: svint8x3_t) {
    svst3_s8(pg, base.offset(svcntb() as isize * vnum as isize), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st3h))]
pub unsafe fn svst3_vnum_s16(pg: svbool_t, base: *mut i16, vnum: i64, data: svint16x3_t) {
    svst3_s16(pg, base.offset(svcnth() as isize * vnum as isize), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st3w))]
pub unsafe fn svst3_vnum_s32(pg: svbool_t, base: *mut i32, vnum: i64, data: svint32x3_t) {
    svst3_s32(pg, base.offset(svcntw() as isize * vnum as isize), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st3d))]
pub unsafe fn svst3_vnum_s64(pg: svbool_t, base: *mut i64, vnum: i64, data: svint64x3_t) {
    svst3_s64(pg, base.offset(svcntd() as isize * vnum as isize), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st3b))]
pub unsafe fn svst3_vnum_u8(pg: svbool_t, base: *mut u8, vnum: i64, data: svuint8x3_t) {
    svst3_u8(pg, base.offset(svcntb() as isize * vnum as isize), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st3h))]
pub unsafe fn svst3_vnum_u16(pg: svbool_t, base: *mut u16, vnum: i64, data: svuint16x3_t) {
    svst3_u16(pg, base.offset(svcnth() as isize * vnum as isize), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st3w))]
pub unsafe fn svst3_vnum_u32(pg: svbool_t, base: *mut u32, vnum: i64, data: svuint32x3_t) {
    svst3_u32(pg, base.offset(svcntw() as isize * vnum as isize), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st3d))]
pub unsafe fn svst3_vnum_u64(pg: svbool_t, base: *mut u64, vnum: i64, data: svuint64x3_t) {
    svst3_u64(pg, base.offset(svcntd() as isize * vnum as isize), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st4w))]
pub unsafe fn svst4_f32(pg: svbool_t, base: *mut f32, data: svfloat32x4_t) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.st4.nxv4f32")]
        fn _svst4_f32(
            data0: svfloat32_t,
            data1: svfloat32_t,
            data2: svfloat32_t,
            data3: svfloat32_t,
            pg: svbool4_t,
            ptr: *mut f32,
        );
    }
    _svst4_f32(
        svget4_f32::<0>(data),
        svget4_f32::<1>(data),
        svget4_f32::<2>(data),
        svget4_f32::<3>(data),
        pg.into(),
        base,
    )
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st4d))]
pub unsafe fn svst4_f64(pg: svbool_t, base: *mut f64, data: svfloat64x4_t) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.st4.nxv2f64")]
        fn _svst4_f64(
            data0: svfloat64_t,
            data1: svfloat64_t,
            data2: svfloat64_t,
            data3: svfloat64_t,
            pg: svbool2_t,
            ptr: *mut f64,
        );
    }
    _svst4_f64(
        svget4_f64::<0>(data),
        svget4_f64::<1>(data),
        svget4_f64::<2>(data),
        svget4_f64::<3>(data),
        pg.into(),
        base,
    )
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st4b))]
pub unsafe fn svst4_s8(pg: svbool_t, base: *mut i8, data: svint8x4_t) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.st4.nxv16i8")]
        fn _svst4_s8(
            data0: svint8_t,
            data1: svint8_t,
            data2: svint8_t,
            data3: svint8_t,
            pg: svbool_t,
            ptr: *mut i8,
        );
    }
    _svst4_s8(
        svget4_s8::<0>(data),
        svget4_s8::<1>(data),
        svget4_s8::<2>(data),
        svget4_s8::<3>(data),
        pg,
        base,
    )
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st4h))]
pub unsafe fn svst4_s16(pg: svbool_t, base: *mut i16, data: svint16x4_t) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.st4.nxv8i16")]
        fn _svst4_s16(
            data0: svint16_t,
            data1: svint16_t,
            data2: svint16_t,
            data3: svint16_t,
            pg: svbool8_t,
            ptr: *mut i16,
        );
    }
    _svst4_s16(
        svget4_s16::<0>(data),
        svget4_s16::<1>(data),
        svget4_s16::<2>(data),
        svget4_s16::<3>(data),
        pg.into(),
        base,
    )
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st4w))]
pub unsafe fn svst4_s32(pg: svbool_t, base: *mut i32, data: svint32x4_t) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.st4.nxv4i32")]
        fn _svst4_s32(
            data0: svint32_t,
            data1: svint32_t,
            data2: svint32_t,
            data3: svint32_t,
            pg: svbool4_t,
            ptr: *mut i32,
        );
    }
    _svst4_s32(
        svget4_s32::<0>(data),
        svget4_s32::<1>(data),
        svget4_s32::<2>(data),
        svget4_s32::<3>(data),
        pg.into(),
        base,
    )
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st4d))]
pub unsafe fn svst4_s64(pg: svbool_t, base: *mut i64, data: svint64x4_t) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.st4.nxv2i64")]
        fn _svst4_s64(
            data0: svint64_t,
            data1: svint64_t,
            data2: svint64_t,
            data3: svint64_t,
            pg: svbool2_t,
            ptr: *mut i64,
        );
    }
    _svst4_s64(
        svget4_s64::<0>(data),
        svget4_s64::<1>(data),
        svget4_s64::<2>(data),
        svget4_s64::<3>(data),
        pg.into(),
        base,
    )
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st4b))]
pub unsafe fn svst4_u8(pg: svbool_t, base: *mut u8, data: svuint8x4_t) {
    svst4_s8(pg, base as *mut i8, data.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st4h))]
pub unsafe fn svst4_u16(pg: svbool_t, base: *mut u16, data: svuint16x4_t) {
    svst4_s16(pg, base as *mut i16, data.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st4w))]
pub unsafe fn svst4_u32(pg: svbool_t, base: *mut u32, data: svuint32x4_t) {
    svst4_s32(pg, base as *mut i32, data.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st4d))]
pub unsafe fn svst4_u64(pg: svbool_t, base: *mut u64, data: svuint64x4_t) {
    svst4_s64(pg, base as *mut i64, data.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st4w))]
pub unsafe fn svst4_vnum_f32(pg: svbool_t, base: *mut f32, vnum: i64, data: svfloat32x4_t) {
    svst4_f32(pg, base.offset(svcntw() as isize * vnum as isize), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st4d))]
pub unsafe fn svst4_vnum_f64(pg: svbool_t, base: *mut f64, vnum: i64, data: svfloat64x4_t) {
    svst4_f64(pg, base.offset(svcntd() as isize * vnum as isize), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st4b))]
pub unsafe fn svst4_vnum_s8(pg: svbool_t, base: *mut i8, vnum: i64, data: svint8x4_t) {
    svst4_s8(pg, base.offset(svcntb() as isize * vnum as isize), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st4h))]
pub unsafe fn svst4_vnum_s16(pg: svbool_t, base: *mut i16, vnum: i64, data: svint16x4_t) {
    svst4_s16(pg, base.offset(svcnth() as isize * vnum as isize), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st4w))]
pub unsafe fn svst4_vnum_s32(pg: svbool_t, base: *mut i32, vnum: i64, data: svint32x4_t) {
    svst4_s32(pg, base.offset(svcntw() as isize * vnum as isize), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st4d))]
pub unsafe fn svst4_vnum_s64(pg: svbool_t, base: *mut i64, vnum: i64, data: svint64x4_t) {
    svst4_s64(pg, base.offset(svcntd() as isize * vnum as isize), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st4b))]
pub unsafe fn svst4_vnum_u8(pg: svbool_t, base: *mut u8, vnum: i64, data: svuint8x4_t) {
    svst4_u8(pg, base.offset(svcntb() as isize * vnum as isize), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st4h))]
pub unsafe fn svst4_vnum_u16(pg: svbool_t, base: *mut u16, vnum: i64, data: svuint16x4_t) {
    svst4_u16(pg, base.offset(svcnth() as isize * vnum as isize), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st4w))]
pub unsafe fn svst4_vnum_u32(pg: svbool_t, base: *mut u32, vnum: i64, data: svuint32x4_t) {
    svst4_u32(pg, base.offset(svcntw() as isize * vnum as isize), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st4d))]
pub unsafe fn svst4_vnum_u64(pg: svbool_t, base: *mut u64, vnum: i64, data: svuint64x4_t) {
    svst4_u64(pg, base.offset(svcntd() as isize * vnum as isize), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(stnt1w))]
pub unsafe fn svstnt1_f32(pg: svbool_t, base: *mut f32, data: svfloat32_t) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.stnt1.nxv4f32")]
        fn _svstnt1_f32(data: svfloat32_t, pg: svbool4_t, ptr: *mut f32);
    }
    _svstnt1_f32(data, pg.into(), base)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(stnt1d))]
pub unsafe fn svstnt1_f64(pg: svbool_t, base: *mut f64, data: svfloat64_t) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.stnt1.nxv2f64")]
        fn _svstnt1_f64(data: svfloat64_t, pg: svbool2_t, ptr: *mut f64);
    }
    _svstnt1_f64(data, pg.into(), base)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(stnt1b))]
pub unsafe fn svstnt1_s8(pg: svbool_t, base: *mut i8, data: svint8_t) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.stnt1.nxv16i8")]
        fn _svstnt1_s8(data: svint8_t, pg: svbool_t, ptr: *mut i8);
    }
    _svstnt1_s8(data, pg, base)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(stnt1h))]
pub unsafe fn svstnt1_s16(pg: svbool_t, base: *mut i16, data: svint16_t) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.stnt1.nxv8i16")]
        fn _svstnt1_s16(data: svint16_t, pg: svbool8_t, ptr: *mut i16);
    }
    _svstnt1_s16(data, pg.into(), base)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(stnt1w))]
pub unsafe fn svstnt1_s32(pg: svbool_t, base: *mut i32, data: svint32_t) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.stnt1.nxv4i32")]
        fn _svstnt1_s32(data: svint32_t, pg: svbool4_t, ptr: *mut i32);
    }
    _svstnt1_s32(data, pg.into(), base)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(stnt1d))]
pub unsafe fn svstnt1_s64(pg: svbool_t, base: *mut i64, data: svint64_t) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.stnt1.nxv2i64")]
        fn _svstnt1_s64(data: svint64_t, pg: svbool2_t, ptr: *mut i64);
    }
    _svstnt1_s64(data, pg.into(), base)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(stnt1b))]
pub unsafe fn svstnt1_u8(pg: svbool_t, base: *mut u8, data: svuint8_t) {
    svstnt1_s8(pg, base as *mut i8, data.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(stnt1h))]
pub unsafe fn svstnt1_u16(pg: svbool_t, base: *mut u16, data: svuint16_t) {
    svstnt1_s16(pg, base as *mut i16, data.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(stnt1w))]
pub unsafe fn svstnt1_u32(pg: svbool_t, base: *mut u32, data: svuint32_t) {
    svstnt1_s32(pg, base as *mut i32, data.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(stnt1d))]
pub unsafe fn svstnt1_u64(pg: svbool_t, base: *mut u64, data: svuint64_t) {
    svstnt1_s64(pg, base as *mut i64, data.as_signed())
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(stnt1w))]
pub unsafe fn svstnt1_vnum_f32(pg: svbool_t, base: *mut f32, vnum: i64, data: svfloat32_t) {
    svstnt1_f32(pg, base.offset(svcntw() as isize * vnum as isize), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(stnt1d))]
pub unsafe fn svstnt1_vnum_f64(pg: svbool_t, base: *mut f64, vnum: i64, data: svfloat64_t) {
    svstnt1_f64(pg, base.offset(svcntd() as isize * vnum as isize), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(stnt1b))]
pub unsafe fn svstnt1_vnum_s8(pg: svbool_t, base: *mut i8, vnum: i64, data: svint8_t) {
    svstnt1_s8(pg, base.offset(svcntb() as isize * vnum as isize), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(stnt1h))]
pub unsafe fn svstnt1_vnum_s16(pg: svbool_t, base: *mut i16, vnum: i64, data: svint16_t) {
    svstnt1_s16(pg, base.offset(svcnth() as isize * vnum as isize), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(stnt1w))]
pub unsafe fn svstnt1_vnum_s32(pg: svbool_t, base: *mut i32, vnum: i64, data: svint32_t) {
    svstnt1_s32(pg, base.offset(svcntw() as isize * vnum as isize), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(stnt1d))]
pub unsafe fn svstnt1_vnum_s64(pg: svbool_t, base: *mut i64, vnum: i64, data: svint64_t) {
    svstnt1_s64(pg, base.offset(svcntd() as isize * vnum as isize), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(stnt1b))]
pub unsafe fn svstnt1_vnum_u8(pg: svbool_t, base: *mut u8, vnum: i64, data: svuint8_t) {
    svstnt1_u8(pg, base.offset(svcntb() as isize * vnum as isize), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(stnt1h))]
pub unsafe fn svstnt1_vnum_u16(pg: svbool_t, base: *mut u16, vnum: i64, data: svuint16_t) {
    svstnt1_u16(pg, base.offset(svcnth() as isize * vnum as isize), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(stnt1w))]
pub unsafe fn svstnt1_vnum_u32(pg: svbool_t, base: *mut u32, vnum: i64, data: svuint32_t) {
    svstnt1_u32(pg, base.offset(svcntw() as isize * vnum as isize), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(stnt1d))]
pub unsafe fn svstnt1_vnum_u64(pg: svbool_t, base: *mut u64, vnum: i64, data: svuint64_t) {
    svstnt1_u64(pg, base.offset(svcntd() as isize * vnum as isize), data)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fsub))]
pub unsafe fn svsub_f32_m(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fsub.nxv4f32")]
        fn _svsub_f32_m(pg: svbool4_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svsub_f32_m(pg.into(), op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fsub))]
pub unsafe fn svsub_n_f32_m(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svfloat32_t {
    svsub_f32_m(pg, op1, svdup_n_f32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fsub))]
pub unsafe fn svsub_f32_x(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    svsub_f32_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fsub))]
pub unsafe fn svsub_n_f32_x(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svfloat32_t {
    svsub_f32_x(pg, op1, svdup_n_f32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fsub))]
pub unsafe fn svsub_f32_z(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    svsub_f32_m(pg.clone(), svsel_f32(pg, op1, svdup_n_f32(0.0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fsub))]
pub unsafe fn svsub_n_f32_z(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svfloat32_t {
    svsub_f32_z(pg, op1, svdup_n_f32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fsub))]
pub unsafe fn svsub_f64_m(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fsub.nxv2f64")]
        fn _svsub_f64_m(pg: svbool2_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svsub_f64_m(pg.into(), op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fsub))]
pub unsafe fn svsub_n_f64_m(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svfloat64_t {
    svsub_f64_m(pg, op1, svdup_n_f64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fsub))]
pub unsafe fn svsub_f64_x(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    svsub_f64_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fsub))]
pub unsafe fn svsub_n_f64_x(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svfloat64_t {
    svsub_f64_x(pg, op1, svdup_n_f64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fsub))]
pub unsafe fn svsub_f64_z(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    svsub_f64_m(pg.clone(), svsel_f64(pg, op1, svdup_n_f64(0.0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fsub))]
pub unsafe fn svsub_n_f64_z(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svfloat64_t {
    svsub_f64_z(pg, op1, svdup_n_f64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub unsafe fn svsub_s8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sub.nxv16i8")]
        fn _svsub_s8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t;
    }
    unsafe { _svsub_s8_m(pg, op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub unsafe fn svsub_n_s8_m(pg: svbool_t, op1: svint8_t, op2: i8) -> svint8_t {
    svsub_s8_m(pg, op1, svdup_n_s8(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub unsafe fn svsub_s8_x(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t {
    svsub_s8_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub unsafe fn svsub_n_s8_x(pg: svbool_t, op1: svint8_t, op2: i8) -> svint8_t {
    svsub_s8_x(pg, op1, svdup_n_s8(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub unsafe fn svsub_s8_z(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t {
    svsub_s8_m(pg.clone(), svsel_s8(pg, op1, svdup_n_s8(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub unsafe fn svsub_n_s8_z(pg: svbool_t, op1: svint8_t, op2: i8) -> svint8_t {
    svsub_s8_z(pg, op1, svdup_n_s8(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub unsafe fn svsub_s16_m(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sub.nxv8i16")]
        fn _svsub_s16_m(pg: svbool8_t, op1: svint16_t, op2: svint16_t) -> svint16_t;
    }
    unsafe { _svsub_s16_m(pg.into(), op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub unsafe fn svsub_n_s16_m(pg: svbool_t, op1: svint16_t, op2: i16) -> svint16_t {
    svsub_s16_m(pg, op1, svdup_n_s16(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub unsafe fn svsub_s16_x(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svint16_t {
    svsub_s16_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub unsafe fn svsub_n_s16_x(pg: svbool_t, op1: svint16_t, op2: i16) -> svint16_t {
    svsub_s16_x(pg, op1, svdup_n_s16(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub unsafe fn svsub_s16_z(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svint16_t {
    svsub_s16_m(pg.clone(), svsel_s16(pg, op1, svdup_n_s16(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub unsafe fn svsub_n_s16_z(pg: svbool_t, op1: svint16_t, op2: i16) -> svint16_t {
    svsub_s16_z(pg, op1, svdup_n_s16(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub unsafe fn svsub_s32_m(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sub.nxv4i32")]
        fn _svsub_s32_m(pg: svbool4_t, op1: svint32_t, op2: svint32_t) -> svint32_t;
    }
    unsafe { _svsub_s32_m(pg.into(), op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub unsafe fn svsub_n_s32_m(pg: svbool_t, op1: svint32_t, op2: i32) -> svint32_t {
    svsub_s32_m(pg, op1, svdup_n_s32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub unsafe fn svsub_s32_x(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    svsub_s32_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub unsafe fn svsub_n_s32_x(pg: svbool_t, op1: svint32_t, op2: i32) -> svint32_t {
    svsub_s32_x(pg, op1, svdup_n_s32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub unsafe fn svsub_s32_z(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    svsub_s32_m(pg.clone(), svsel_s32(pg, op1, svdup_n_s32(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub unsafe fn svsub_n_s32_z(pg: svbool_t, op1: svint32_t, op2: i32) -> svint32_t {
    svsub_s32_z(pg, op1, svdup_n_s32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub unsafe fn svsub_s64_m(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sub.nxv2i64")]
        fn _svsub_s64_m(pg: svbool2_t, op1: svint64_t, op2: svint64_t) -> svint64_t;
    }
    unsafe { _svsub_s64_m(pg.into(), op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub unsafe fn svsub_n_s64_m(pg: svbool_t, op1: svint64_t, op2: i64) -> svint64_t {
    svsub_s64_m(pg, op1, svdup_n_s64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub unsafe fn svsub_s64_x(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    svsub_s64_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub unsafe fn svsub_n_s64_x(pg: svbool_t, op1: svint64_t, op2: i64) -> svint64_t {
    svsub_s64_x(pg, op1, svdup_n_s64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub unsafe fn svsub_s64_z(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    svsub_s64_m(pg.clone(), svsel_s64(pg, op1, svdup_n_s64(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub unsafe fn svsub_n_s64_z(pg: svbool_t, op1: svint64_t, op2: i64) -> svint64_t {
    svsub_s64_z(pg, op1, svdup_n_s64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub unsafe fn svsub_u8_m(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    unsafe { svsub_s8_m(pg, op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub unsafe fn svsub_n_u8_m(pg: svbool_t, op1: svuint8_t, op2: u8) -> svuint8_t {
    svsub_u8_m(pg, op1, svdup_n_u8(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub unsafe fn svsub_u8_x(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    svsub_u8_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub unsafe fn svsub_n_u8_x(pg: svbool_t, op1: svuint8_t, op2: u8) -> svuint8_t {
    svsub_u8_x(pg, op1, svdup_n_u8(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub unsafe fn svsub_u8_z(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    svsub_u8_m(pg.clone(), svsel_u8(pg, op1, svdup_n_u8(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub unsafe fn svsub_n_u8_z(pg: svbool_t, op1: svuint8_t, op2: u8) -> svuint8_t {
    svsub_u8_z(pg, op1, svdup_n_u8(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub unsafe fn svsub_u16_m(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    unsafe { svsub_s16_m(pg, op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub unsafe fn svsub_n_u16_m(pg: svbool_t, op1: svuint16_t, op2: u16) -> svuint16_t {
    svsub_u16_m(pg, op1, svdup_n_u16(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub unsafe fn svsub_u16_x(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    svsub_u16_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub unsafe fn svsub_n_u16_x(pg: svbool_t, op1: svuint16_t, op2: u16) -> svuint16_t {
    svsub_u16_x(pg, op1, svdup_n_u16(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub unsafe fn svsub_u16_z(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    svsub_u16_m(pg.clone(), svsel_u16(pg, op1, svdup_n_u16(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub unsafe fn svsub_n_u16_z(pg: svbool_t, op1: svuint16_t, op2: u16) -> svuint16_t {
    svsub_u16_z(pg, op1, svdup_n_u16(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub unsafe fn svsub_u32_m(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    unsafe { svsub_s32_m(pg, op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub unsafe fn svsub_n_u32_m(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svsub_u32_m(pg, op1, svdup_n_u32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub unsafe fn svsub_u32_x(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    svsub_u32_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub unsafe fn svsub_n_u32_x(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svsub_u32_x(pg, op1, svdup_n_u32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub unsafe fn svsub_u32_z(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    svsub_u32_m(pg.clone(), svsel_u32(pg, op1, svdup_n_u32(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub unsafe fn svsub_n_u32_z(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svsub_u32_z(pg, op1, svdup_n_u32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub unsafe fn svsub_u64_m(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    unsafe { svsub_s64_m(pg, op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub unsafe fn svsub_n_u64_m(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svsub_u64_m(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub unsafe fn svsub_u64_x(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    svsub_u64_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub unsafe fn svsub_n_u64_x(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svsub_u64_x(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub unsafe fn svsub_u64_z(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    svsub_u64_m(pg.clone(), svsel_u64(pg, op1, svdup_n_u64(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub unsafe fn svsub_n_u64_z(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svsub_u64_z(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fsubr))]
pub unsafe fn svsubr_f32_m(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fsubr.nxv4f32")]
        fn _svsubr_f32_m(pg: svbool4_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svsubr_f32_m(pg.into(), op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fsubr))]
pub unsafe fn svsubr_n_f32_m(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svfloat32_t {
    svsubr_f32_m(pg, op1, svdup_n_f32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fsubr))]
pub unsafe fn svsubr_f32_x(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    svsubr_f32_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fsubr))]
pub unsafe fn svsubr_n_f32_x(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svfloat32_t {
    svsubr_f32_x(pg, op1, svdup_n_f32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fsubr))]
pub unsafe fn svsubr_f32_z(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    svsubr_f32_m(pg.clone(), svsel_f32(pg, op1, svdup_n_f32(0.0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fsubr))]
pub unsafe fn svsubr_n_f32_z(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svfloat32_t {
    svsubr_f32_z(pg, op1, svdup_n_f32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fsubr))]
pub unsafe fn svsubr_f64_m(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fsubr.nxv2f64")]
        fn _svsubr_f64_m(pg: svbool2_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svsubr_f64_m(pg.into(), op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fsubr))]
pub unsafe fn svsubr_n_f64_m(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svfloat64_t {
    svsubr_f64_m(pg, op1, svdup_n_f64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fsubr))]
pub unsafe fn svsubr_f64_x(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    svsubr_f64_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fsubr))]
pub unsafe fn svsubr_n_f64_x(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svfloat64_t {
    svsubr_f64_x(pg, op1, svdup_n_f64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fsubr))]
pub unsafe fn svsubr_f64_z(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    svsubr_f64_m(pg.clone(), svsel_f64(pg, op1, svdup_n_f64(0.0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fsubr))]
pub unsafe fn svsubr_n_f64_z(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svfloat64_t {
    svsubr_f64_z(pg, op1, svdup_n_f64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub unsafe fn svsubr_s8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.subr.nxv16i8")]
        fn _svsubr_s8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t;
    }
    unsafe { _svsubr_s8_m(pg, op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub unsafe fn svsubr_n_s8_m(pg: svbool_t, op1: svint8_t, op2: i8) -> svint8_t {
    svsubr_s8_m(pg, op1, svdup_n_s8(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub unsafe fn svsubr_s8_x(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t {
    svsubr_s8_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub unsafe fn svsubr_n_s8_x(pg: svbool_t, op1: svint8_t, op2: i8) -> svint8_t {
    svsubr_s8_x(pg, op1, svdup_n_s8(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub unsafe fn svsubr_s8_z(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t {
    svsubr_s8_m(pg.clone(), svsel_s8(pg, op1, svdup_n_s8(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub unsafe fn svsubr_n_s8_z(pg: svbool_t, op1: svint8_t, op2: i8) -> svint8_t {
    svsubr_s8_z(pg, op1, svdup_n_s8(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub unsafe fn svsubr_s16_m(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.subr.nxv8i16")]
        fn _svsubr_s16_m(pg: svbool8_t, op1: svint16_t, op2: svint16_t) -> svint16_t;
    }
    unsafe { _svsubr_s16_m(pg.into(), op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub unsafe fn svsubr_n_s16_m(pg: svbool_t, op1: svint16_t, op2: i16) -> svint16_t {
    svsubr_s16_m(pg, op1, svdup_n_s16(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub unsafe fn svsubr_s16_x(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svint16_t {
    svsubr_s16_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub unsafe fn svsubr_n_s16_x(pg: svbool_t, op1: svint16_t, op2: i16) -> svint16_t {
    svsubr_s16_x(pg, op1, svdup_n_s16(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub unsafe fn svsubr_s16_z(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svint16_t {
    svsubr_s16_m(pg.clone(), svsel_s16(pg, op1, svdup_n_s16(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub unsafe fn svsubr_n_s16_z(pg: svbool_t, op1: svint16_t, op2: i16) -> svint16_t {
    svsubr_s16_z(pg, op1, svdup_n_s16(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub unsafe fn svsubr_s32_m(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.subr.nxv4i32")]
        fn _svsubr_s32_m(pg: svbool4_t, op1: svint32_t, op2: svint32_t) -> svint32_t;
    }
    unsafe { _svsubr_s32_m(pg.into(), op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub unsafe fn svsubr_n_s32_m(pg: svbool_t, op1: svint32_t, op2: i32) -> svint32_t {
    svsubr_s32_m(pg, op1, svdup_n_s32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub unsafe fn svsubr_s32_x(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    svsubr_s32_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub unsafe fn svsubr_n_s32_x(pg: svbool_t, op1: svint32_t, op2: i32) -> svint32_t {
    svsubr_s32_x(pg, op1, svdup_n_s32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub unsafe fn svsubr_s32_z(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    svsubr_s32_m(pg.clone(), svsel_s32(pg, op1, svdup_n_s32(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub unsafe fn svsubr_n_s32_z(pg: svbool_t, op1: svint32_t, op2: i32) -> svint32_t {
    svsubr_s32_z(pg, op1, svdup_n_s32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub unsafe fn svsubr_s64_m(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.subr.nxv2i64")]
        fn _svsubr_s64_m(pg: svbool2_t, op1: svint64_t, op2: svint64_t) -> svint64_t;
    }
    unsafe { _svsubr_s64_m(pg.into(), op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub unsafe fn svsubr_n_s64_m(pg: svbool_t, op1: svint64_t, op2: i64) -> svint64_t {
    svsubr_s64_m(pg, op1, svdup_n_s64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub unsafe fn svsubr_s64_x(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    svsubr_s64_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub unsafe fn svsubr_n_s64_x(pg: svbool_t, op1: svint64_t, op2: i64) -> svint64_t {
    svsubr_s64_x(pg, op1, svdup_n_s64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub unsafe fn svsubr_s64_z(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    svsubr_s64_m(pg.clone(), svsel_s64(pg, op1, svdup_n_s64(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub unsafe fn svsubr_n_s64_z(pg: svbool_t, op1: svint64_t, op2: i64) -> svint64_t {
    svsubr_s64_z(pg, op1, svdup_n_s64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub unsafe fn svsubr_u8_m(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    unsafe { svsubr_s8_m(pg, op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub unsafe fn svsubr_n_u8_m(pg: svbool_t, op1: svuint8_t, op2: u8) -> svuint8_t {
    svsubr_u8_m(pg, op1, svdup_n_u8(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub unsafe fn svsubr_u8_x(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    svsubr_u8_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub unsafe fn svsubr_n_u8_x(pg: svbool_t, op1: svuint8_t, op2: u8) -> svuint8_t {
    svsubr_u8_x(pg, op1, svdup_n_u8(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub unsafe fn svsubr_u8_z(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    svsubr_u8_m(pg.clone(), svsel_u8(pg, op1, svdup_n_u8(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub unsafe fn svsubr_n_u8_z(pg: svbool_t, op1: svuint8_t, op2: u8) -> svuint8_t {
    svsubr_u8_z(pg, op1, svdup_n_u8(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub unsafe fn svsubr_u16_m(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    unsafe { svsubr_s16_m(pg, op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub unsafe fn svsubr_n_u16_m(pg: svbool_t, op1: svuint16_t, op2: u16) -> svuint16_t {
    svsubr_u16_m(pg, op1, svdup_n_u16(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub unsafe fn svsubr_u16_x(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    svsubr_u16_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub unsafe fn svsubr_n_u16_x(pg: svbool_t, op1: svuint16_t, op2: u16) -> svuint16_t {
    svsubr_u16_x(pg, op1, svdup_n_u16(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub unsafe fn svsubr_u16_z(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    svsubr_u16_m(pg.clone(), svsel_u16(pg, op1, svdup_n_u16(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub unsafe fn svsubr_n_u16_z(pg: svbool_t, op1: svuint16_t, op2: u16) -> svuint16_t {
    svsubr_u16_z(pg, op1, svdup_n_u16(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub unsafe fn svsubr_u32_m(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    unsafe { svsubr_s32_m(pg, op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub unsafe fn svsubr_n_u32_m(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svsubr_u32_m(pg, op1, svdup_n_u32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub unsafe fn svsubr_u32_x(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    svsubr_u32_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub unsafe fn svsubr_n_u32_x(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svsubr_u32_x(pg, op1, svdup_n_u32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub unsafe fn svsubr_u32_z(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    svsubr_u32_m(pg.clone(), svsel_u32(pg, op1, svdup_n_u32(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub unsafe fn svsubr_n_u32_z(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svsubr_u32_z(pg, op1, svdup_n_u32(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub unsafe fn svsubr_u64_m(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    unsafe { svsubr_s64_m(pg, op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub unsafe fn svsubr_n_u64_m(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svsubr_u64_m(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub unsafe fn svsubr_u64_x(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    svsubr_u64_m(pg, op1, op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub unsafe fn svsubr_n_u64_x(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svsubr_u64_x(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub unsafe fn svsubr_u64_z(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    svsubr_u64_m(pg.clone(), svsel_u64(pg, op1, svdup_n_u64(0)), op2)
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub unsafe fn svsubr_n_u64_z(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svsubr_u64_z(pg, op1, svdup_n_u64(op2))
}
#[inline]
#[target_feature(enable = "sve,i8mm")]
#[cfg_attr(test, assert_instr(sudot, IMM_INDEX = 0))]
pub unsafe fn svsudot_lane_s32<const IMM_INDEX: i32>(
    op1: svint32_t,
    op2: svint8_t,
    op3: svuint8_t,
) -> svint32_t {
    static_assert_range!(IMM_INDEX, 0, 3);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.sudot.lane.nxv4i32"
        )]
        fn _svsudot_lane_s32(
            op1: svint32_t,
            op2: svint8_t,
            op3: svint8_t,
            imm_index: i32,
        ) -> svint32_t;
    }
    unsafe { _svsudot_lane_s32(op1, op2, op3.as_signed(), IMM_INDEX) }
}
#[inline]
#[target_feature(enable = "sve,i8mm")]
#[cfg_attr(test, assert_instr(usdot))]
pub unsafe fn svsudot_s32(op1: svint32_t, op2: svint8_t, op3: svuint8_t) -> svint32_t {
    svusdot_s32(op1, op3, op2)
}
#[inline]
#[target_feature(enable = "sve,i8mm")]
#[cfg_attr(test, assert_instr(usdot))]
pub unsafe fn svsudot_n_s32(op1: svint32_t, op2: svint8_t, op3: u8) -> svint32_t {
    svsudot_s32(op1, op2, svdup_n_u8(op3))
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(tbl))]
pub unsafe fn svtbl_f32(data: svfloat32_t, indices: svuint32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.tbl.nxv4f32")]
        fn _svtbl_f32(data: svfloat32_t, indices: svint32_t) -> svfloat32_t;
    }
    unsafe { _svtbl_f32(data, indices.as_signed()) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(tbl))]
pub unsafe fn svtbl_f64(data: svfloat64_t, indices: svuint64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.tbl.nxv2f64")]
        fn _svtbl_f64(data: svfloat64_t, indices: svint64_t) -> svfloat64_t;
    }
    unsafe { _svtbl_f64(data, indices.as_signed()) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(tbl))]
pub unsafe fn svtbl_s8(data: svint8_t, indices: svuint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.tbl.nxv16i8")]
        fn _svtbl_s8(data: svint8_t, indices: svint8_t) -> svint8_t;
    }
    unsafe { _svtbl_s8(data, indices.as_signed()) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(tbl))]
pub unsafe fn svtbl_s16(data: svint16_t, indices: svuint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.tbl.nxv8i16")]
        fn _svtbl_s16(data: svint16_t, indices: svint16_t) -> svint16_t;
    }
    unsafe { _svtbl_s16(data, indices.as_signed()) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(tbl))]
pub unsafe fn svtbl_s32(data: svint32_t, indices: svuint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.tbl.nxv4i32")]
        fn _svtbl_s32(data: svint32_t, indices: svint32_t) -> svint32_t;
    }
    unsafe { _svtbl_s32(data, indices.as_signed()) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(tbl))]
pub unsafe fn svtbl_s64(data: svint64_t, indices: svuint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.tbl.nxv2i64")]
        fn _svtbl_s64(data: svint64_t, indices: svint64_t) -> svint64_t;
    }
    unsafe { _svtbl_s64(data, indices.as_signed()) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(tbl))]
pub unsafe fn svtbl_u8(data: svuint8_t, indices: svuint8_t) -> svuint8_t {
    unsafe { svtbl_s8(data.as_signed(), indices).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(tbl))]
pub unsafe fn svtbl_u16(data: svuint16_t, indices: svuint16_t) -> svuint16_t {
    unsafe { svtbl_s16(data.as_signed(), indices).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(tbl))]
pub unsafe fn svtbl_u32(data: svuint32_t, indices: svuint32_t) -> svuint32_t {
    unsafe { svtbl_s32(data.as_signed(), indices).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(tbl))]
pub unsafe fn svtbl_u64(data: svuint64_t, indices: svuint64_t) -> svuint64_t {
    unsafe { svtbl_s64(data.as_signed(), indices).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ftmad, IMM3 = 0))]
pub unsafe fn svtmad_f32<const IMM3: i32>(op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    static_assert_range!(IMM3, 0, 7);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ftmad.x.nxv4f32"
        )]
        fn _svtmad_f32(op1: svfloat32_t, op2: svfloat32_t, imm3: i32) -> svfloat32_t;
    }
    unsafe { _svtmad_f32(op1, op2, IMM3) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ftmad, IMM3 = 0))]
pub unsafe fn svtmad_f64<const IMM3: i32>(op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    static_assert_range!(IMM3, 0, 7);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ftmad.x.nxv2f64"
        )]
        fn _svtmad_f64(op1: svfloat64_t, op2: svfloat64_t, imm3: i32) -> svfloat64_t;
    }
    unsafe { _svtmad_f64(op1, op2, IMM3) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(trn1))]
pub unsafe fn svtrn1_b8(op1: svbool_t, op2: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.trn1.nxv16i1")]
        fn _svtrn1_b8(op1: svbool_t, op2: svbool_t) -> svbool_t;
    }
    unsafe { _svtrn1_b8(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(trn1))]
pub unsafe fn svtrn1_b16(op1: svbool_t, op2: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.trn1.nxv8i1")]
        fn _svtrn1_b16(op1: svbool8_t, op2: svbool8_t) -> svbool8_t;
    }
    unsafe { _svtrn1_b16(op1.into(), op2.into()).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(trn1))]
pub unsafe fn svtrn1_b32(op1: svbool_t, op2: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.trn1.nxv4i1")]
        fn _svtrn1_b32(op1: svbool4_t, op2: svbool4_t) -> svbool4_t;
    }
    unsafe { _svtrn1_b32(op1.into(), op2.into()).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(trn1))]
pub unsafe fn svtrn1_b64(op1: svbool_t, op2: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.trn1.nxv2i1")]
        fn _svtrn1_b64(op1: svbool2_t, op2: svbool2_t) -> svbool2_t;
    }
    unsafe { _svtrn1_b64(op1.into(), op2.into()).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(trn1))]
pub unsafe fn svtrn1_f32(op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.trn1.nxv4f32")]
        fn _svtrn1_f32(op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svtrn1_f32(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(trn1))]
pub unsafe fn svtrn1_f64(op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.trn1.nxv2f64")]
        fn _svtrn1_f64(op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svtrn1_f64(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(trn1))]
pub unsafe fn svtrn1_s8(op1: svint8_t, op2: svint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.trn1.nxv16i8")]
        fn _svtrn1_s8(op1: svint8_t, op2: svint8_t) -> svint8_t;
    }
    unsafe { _svtrn1_s8(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(trn1))]
pub unsafe fn svtrn1_s16(op1: svint16_t, op2: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.trn1.nxv8i16")]
        fn _svtrn1_s16(op1: svint16_t, op2: svint16_t) -> svint16_t;
    }
    unsafe { _svtrn1_s16(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(trn1))]
pub unsafe fn svtrn1_s32(op1: svint32_t, op2: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.trn1.nxv4i32")]
        fn _svtrn1_s32(op1: svint32_t, op2: svint32_t) -> svint32_t;
    }
    unsafe { _svtrn1_s32(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(trn1))]
pub unsafe fn svtrn1_s64(op1: svint64_t, op2: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.trn1.nxv2i64")]
        fn _svtrn1_s64(op1: svint64_t, op2: svint64_t) -> svint64_t;
    }
    unsafe { _svtrn1_s64(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(trn1))]
pub unsafe fn svtrn1_u8(op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    unsafe { svtrn1_s8(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(trn1))]
pub unsafe fn svtrn1_u16(op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    unsafe { svtrn1_s16(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(trn1))]
pub unsafe fn svtrn1_u32(op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    unsafe { svtrn1_s32(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(trn1))]
pub unsafe fn svtrn1_u64(op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    unsafe { svtrn1_s64(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(trn1))]
pub unsafe fn svtrn1q_f32(op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.trn1q.nxv4f32")]
        fn _svtrn1q_f32(op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svtrn1q_f32(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(trn1))]
pub unsafe fn svtrn1q_f64(op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.trn1q.nxv2f64")]
        fn _svtrn1q_f64(op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svtrn1q_f64(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(trn1))]
pub unsafe fn svtrn1q_s8(op1: svint8_t, op2: svint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.trn1q.nxv16i8")]
        fn _svtrn1q_s8(op1: svint8_t, op2: svint8_t) -> svint8_t;
    }
    unsafe { _svtrn1q_s8(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(trn1))]
pub unsafe fn svtrn1q_s16(op1: svint16_t, op2: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.trn1q.nxv8i16")]
        fn _svtrn1q_s16(op1: svint16_t, op2: svint16_t) -> svint16_t;
    }
    unsafe { _svtrn1q_s16(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(trn1))]
pub unsafe fn svtrn1q_s32(op1: svint32_t, op2: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.trn1q.nxv4i32")]
        fn _svtrn1q_s32(op1: svint32_t, op2: svint32_t) -> svint32_t;
    }
    unsafe { _svtrn1q_s32(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(trn1))]
pub unsafe fn svtrn1q_s64(op1: svint64_t, op2: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.trn1q.nxv2i64")]
        fn _svtrn1q_s64(op1: svint64_t, op2: svint64_t) -> svint64_t;
    }
    unsafe { _svtrn1q_s64(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(trn1))]
pub unsafe fn svtrn1q_u8(op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    unsafe { svtrn1q_s8(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(trn1))]
pub unsafe fn svtrn1q_u16(op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    unsafe { svtrn1q_s16(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(trn1))]
pub unsafe fn svtrn1q_u32(op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    unsafe { svtrn1q_s32(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(trn1))]
pub unsafe fn svtrn1q_u64(op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    unsafe { svtrn1q_s64(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(trn2))]
pub unsafe fn svtrn2_b8(op1: svbool_t, op2: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.trn2.nxv16i1")]
        fn _svtrn2_b8(op1: svbool_t, op2: svbool_t) -> svbool_t;
    }
    unsafe { _svtrn2_b8(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(trn2))]
pub unsafe fn svtrn2_b16(op1: svbool_t, op2: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.trn2.nxv8i1")]
        fn _svtrn2_b16(op1: svbool8_t, op2: svbool8_t) -> svbool8_t;
    }
    unsafe { _svtrn2_b16(op1.into(), op2.into()).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(trn2))]
pub unsafe fn svtrn2_b32(op1: svbool_t, op2: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.trn2.nxv4i1")]
        fn _svtrn2_b32(op1: svbool4_t, op2: svbool4_t) -> svbool4_t;
    }
    unsafe { _svtrn2_b32(op1.into(), op2.into()).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(trn2))]
pub unsafe fn svtrn2_b64(op1: svbool_t, op2: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.trn2.nxv2i1")]
        fn _svtrn2_b64(op1: svbool2_t, op2: svbool2_t) -> svbool2_t;
    }
    unsafe { _svtrn2_b64(op1.into(), op2.into()).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(trn2))]
pub unsafe fn svtrn2_f32(op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.trn2.nxv4f32")]
        fn _svtrn2_f32(op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svtrn2_f32(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(trn2))]
pub unsafe fn svtrn2_f64(op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.trn2.nxv2f64")]
        fn _svtrn2_f64(op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svtrn2_f64(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(trn2))]
pub unsafe fn svtrn2_s8(op1: svint8_t, op2: svint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.trn2.nxv16i8")]
        fn _svtrn2_s8(op1: svint8_t, op2: svint8_t) -> svint8_t;
    }
    unsafe { _svtrn2_s8(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(trn2))]
pub unsafe fn svtrn2_s16(op1: svint16_t, op2: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.trn2.nxv8i16")]
        fn _svtrn2_s16(op1: svint16_t, op2: svint16_t) -> svint16_t;
    }
    unsafe { _svtrn2_s16(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(trn2))]
pub unsafe fn svtrn2_s32(op1: svint32_t, op2: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.trn2.nxv4i32")]
        fn _svtrn2_s32(op1: svint32_t, op2: svint32_t) -> svint32_t;
    }
    unsafe { _svtrn2_s32(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(trn2))]
pub unsafe fn svtrn2_s64(op1: svint64_t, op2: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.trn2.nxv2i64")]
        fn _svtrn2_s64(op1: svint64_t, op2: svint64_t) -> svint64_t;
    }
    unsafe { _svtrn2_s64(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(trn2))]
pub unsafe fn svtrn2_u8(op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    unsafe { svtrn2_s8(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(trn2))]
pub unsafe fn svtrn2_u16(op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    unsafe { svtrn2_s16(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(trn2))]
pub unsafe fn svtrn2_u32(op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    unsafe { svtrn2_s32(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(trn2))]
pub unsafe fn svtrn2_u64(op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    unsafe { svtrn2_s64(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(trn2))]
pub unsafe fn svtrn2q_f32(op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.trn2q.nxv4f32")]
        fn _svtrn2q_f32(op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svtrn2q_f32(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(trn2))]
pub unsafe fn svtrn2q_f64(op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.trn2q.nxv2f64")]
        fn _svtrn2q_f64(op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svtrn2q_f64(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(trn2))]
pub unsafe fn svtrn2q_s8(op1: svint8_t, op2: svint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.trn2q.nxv16i8")]
        fn _svtrn2q_s8(op1: svint8_t, op2: svint8_t) -> svint8_t;
    }
    unsafe { _svtrn2q_s8(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(trn2))]
pub unsafe fn svtrn2q_s16(op1: svint16_t, op2: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.trn2q.nxv8i16")]
        fn _svtrn2q_s16(op1: svint16_t, op2: svint16_t) -> svint16_t;
    }
    unsafe { _svtrn2q_s16(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(trn2))]
pub unsafe fn svtrn2q_s32(op1: svint32_t, op2: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.trn2q.nxv4i32")]
        fn _svtrn2q_s32(op1: svint32_t, op2: svint32_t) -> svint32_t;
    }
    unsafe { _svtrn2q_s32(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(trn2))]
pub unsafe fn svtrn2q_s64(op1: svint64_t, op2: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.trn2q.nxv2i64")]
        fn _svtrn2q_s64(op1: svint64_t, op2: svint64_t) -> svint64_t;
    }
    unsafe { _svtrn2q_s64(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(trn2))]
pub unsafe fn svtrn2q_u8(op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    unsafe { svtrn2q_s8(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(trn2))]
pub unsafe fn svtrn2q_u16(op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    unsafe { svtrn2q_s16(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(trn2))]
pub unsafe fn svtrn2q_u32(op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    unsafe { svtrn2q_s32(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(trn2))]
pub unsafe fn svtrn2q_u64(op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    unsafe { svtrn2q_s64(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ftsmul))]
pub unsafe fn svtsmul_f32(op1: svfloat32_t, op2: svuint32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ftsmul.x.nxv4f32"
        )]
        fn _svtsmul_f32(op1: svfloat32_t, op2: svint32_t) -> svfloat32_t;
    }
    unsafe { _svtsmul_f32(op1, op2.as_signed()) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ftsmul))]
pub unsafe fn svtsmul_f64(op1: svfloat64_t, op2: svuint64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ftsmul.x.nxv2f64"
        )]
        fn _svtsmul_f64(op1: svfloat64_t, op2: svint64_t) -> svfloat64_t;
    }
    unsafe { _svtsmul_f64(op1, op2.as_signed()) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ftssel))]
pub unsafe fn svtssel_f32(op1: svfloat32_t, op2: svuint32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ftssel.x.nxv4f32"
        )]
        fn _svtssel_f32(op1: svfloat32_t, op2: svint32_t) -> svfloat32_t;
    }
    unsafe { _svtssel_f32(op1, op2.as_signed()) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ftssel))]
pub unsafe fn svtssel_f64(op1: svfloat64_t, op2: svuint64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ftssel.x.nxv2f64"
        )]
        fn _svtssel_f64(op1: svfloat64_t, op2: svint64_t) -> svfloat64_t;
    }
    unsafe { _svtssel_f64(op1, op2.as_signed()) }
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef2_f32() -> svfloat32x2_t {
    simd_reinterpret(())
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef2_f64() -> svfloat64x2_t {
    simd_reinterpret(())
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef2_s8() -> svint8x2_t {
    simd_reinterpret(())
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef2_s16() -> svint16x2_t {
    simd_reinterpret(())
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef2_s32() -> svint32x2_t {
    simd_reinterpret(())
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef2_s64() -> svint64x2_t {
    simd_reinterpret(())
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef2_u8() -> svuint8x2_t {
    simd_reinterpret(())
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef2_u16() -> svuint16x2_t {
    simd_reinterpret(())
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef2_u32() -> svuint32x2_t {
    simd_reinterpret(())
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef2_u64() -> svuint64x2_t {
    simd_reinterpret(())
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef3_f32() -> svfloat32x3_t {
    simd_reinterpret(())
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef3_f64() -> svfloat64x3_t {
    simd_reinterpret(())
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef3_s8() -> svint8x3_t {
    simd_reinterpret(())
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef3_s16() -> svint16x3_t {
    simd_reinterpret(())
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef3_s32() -> svint32x3_t {
    simd_reinterpret(())
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef3_s64() -> svint64x3_t {
    simd_reinterpret(())
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef3_u8() -> svuint8x3_t {
    simd_reinterpret(())
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef3_u16() -> svuint16x3_t {
    simd_reinterpret(())
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef3_u32() -> svuint32x3_t {
    simd_reinterpret(())
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef3_u64() -> svuint64x3_t {
    simd_reinterpret(())
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef4_f32() -> svfloat32x4_t {
    simd_reinterpret(())
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef4_f64() -> svfloat64x4_t {
    simd_reinterpret(())
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef4_s8() -> svint8x4_t {
    simd_reinterpret(())
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef4_s16() -> svint16x4_t {
    simd_reinterpret(())
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef4_s32() -> svint32x4_t {
    simd_reinterpret(())
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef4_s64() -> svint64x4_t {
    simd_reinterpret(())
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef4_u8() -> svuint8x4_t {
    simd_reinterpret(())
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef4_u16() -> svuint16x4_t {
    simd_reinterpret(())
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef4_u32() -> svuint32x4_t {
    simd_reinterpret(())
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef4_u64() -> svuint64x4_t {
    simd_reinterpret(())
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef_f32() -> svfloat32_t {
    simd_reinterpret(())
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef_f64() -> svfloat64_t {
    simd_reinterpret(())
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef_s8() -> svint8_t {
    simd_reinterpret(())
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef_s16() -> svint16_t {
    simd_reinterpret(())
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef_s32() -> svint32_t {
    simd_reinterpret(())
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef_s64() -> svint64_t {
    simd_reinterpret(())
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef_u8() -> svuint8_t {
    simd_reinterpret(())
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef_u16() -> svuint16_t {
    simd_reinterpret(())
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef_u32() -> svuint32_t {
    simd_reinterpret(())
}
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef_u64() -> svuint64_t {
    simd_reinterpret(())
}
#[inline]
#[target_feature(enable = "sve,i8mm")]
#[cfg_attr(test, assert_instr(usdot, IMM_INDEX = 0))]
pub unsafe fn svusdot_lane_s32<const IMM_INDEX: i32>(
    op1: svint32_t,
    op2: svuint8_t,
    op3: svint8_t,
) -> svint32_t {
    static_assert_range!(IMM_INDEX, 0, 3);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.usdot.lane.nxv4i32"
        )]
        fn _svusdot_lane_s32(
            op1: svint32_t,
            op2: svint8_t,
            op3: svint8_t,
            imm_index: i32,
        ) -> svint32_t;
    }
    unsafe { _svusdot_lane_s32(op1, op2.as_signed(), op3, IMM_INDEX) }
}
#[inline]
#[target_feature(enable = "sve,i8mm")]
#[cfg_attr(test, assert_instr(usdot))]
pub unsafe fn svusdot_s32(op1: svint32_t, op2: svuint8_t, op3: svint8_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.usdot.nxv4i32")]
        fn _svusdot_s32(op1: svint32_t, op2: svint8_t, op3: svint8_t) -> svint32_t;
    }
    unsafe { _svusdot_s32(op1, op2.as_signed(), op3) }
}
#[inline]
#[target_feature(enable = "sve,i8mm")]
#[cfg_attr(test, assert_instr(usdot))]
pub unsafe fn svusdot_n_s32(op1: svint32_t, op2: svuint8_t, op3: i8) -> svint32_t {
    svusdot_s32(op1, op2, svdup_n_s8(op3))
}
#[inline]
#[target_feature(enable = "sve,i8mm")]
#[cfg_attr(test, assert_instr(usmmla))]
pub unsafe fn svusmmla_s32(op1: svint32_t, op2: svuint8_t, op3: svint8_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.usmmla.nxv4i32")]
        fn _svusmmla_s32(op1: svint32_t, op2: svint8_t, op3: svint8_t) -> svint32_t;
    }
    unsafe { _svusmmla_s32(op1, op2.as_signed(), op3) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uzp1))]
pub unsafe fn svuzp1_b8(op1: svbool_t, op2: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uzp1.nxv16i1")]
        fn _svuzp1_b8(op1: svbool_t, op2: svbool_t) -> svbool_t;
    }
    unsafe { _svuzp1_b8(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uzp1))]
pub unsafe fn svuzp1_b16(op1: svbool_t, op2: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uzp1.nxv8i1")]
        fn _svuzp1_b16(op1: svbool8_t, op2: svbool8_t) -> svbool8_t;
    }
    unsafe { _svuzp1_b16(op1.into(), op2.into()).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uzp1))]
pub unsafe fn svuzp1_b32(op1: svbool_t, op2: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uzp1.nxv4i1")]
        fn _svuzp1_b32(op1: svbool4_t, op2: svbool4_t) -> svbool4_t;
    }
    unsafe { _svuzp1_b32(op1.into(), op2.into()).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uzp1))]
pub unsafe fn svuzp1_b64(op1: svbool_t, op2: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uzp1.nxv2i1")]
        fn _svuzp1_b64(op1: svbool2_t, op2: svbool2_t) -> svbool2_t;
    }
    unsafe { _svuzp1_b64(op1.into(), op2.into()).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uzp1))]
pub unsafe fn svuzp1_f32(op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uzp1.nxv4f32")]
        fn _svuzp1_f32(op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svuzp1_f32(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uzp1))]
pub unsafe fn svuzp1_f64(op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uzp1.nxv2f64")]
        fn _svuzp1_f64(op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svuzp1_f64(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uzp1))]
pub unsafe fn svuzp1_s8(op1: svint8_t, op2: svint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uzp1.nxv16i8")]
        fn _svuzp1_s8(op1: svint8_t, op2: svint8_t) -> svint8_t;
    }
    unsafe { _svuzp1_s8(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uzp1))]
pub unsafe fn svuzp1_s16(op1: svint16_t, op2: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uzp1.nxv8i16")]
        fn _svuzp1_s16(op1: svint16_t, op2: svint16_t) -> svint16_t;
    }
    unsafe { _svuzp1_s16(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uzp1))]
pub unsafe fn svuzp1_s32(op1: svint32_t, op2: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uzp1.nxv4i32")]
        fn _svuzp1_s32(op1: svint32_t, op2: svint32_t) -> svint32_t;
    }
    unsafe { _svuzp1_s32(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uzp1))]
pub unsafe fn svuzp1_s64(op1: svint64_t, op2: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uzp1.nxv2i64")]
        fn _svuzp1_s64(op1: svint64_t, op2: svint64_t) -> svint64_t;
    }
    unsafe { _svuzp1_s64(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uzp1))]
pub unsafe fn svuzp1_u8(op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    unsafe { svuzp1_s8(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uzp1))]
pub unsafe fn svuzp1_u16(op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    unsafe { svuzp1_s16(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uzp1))]
pub unsafe fn svuzp1_u32(op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    unsafe { svuzp1_s32(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uzp1))]
pub unsafe fn svuzp1_u64(op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    unsafe { svuzp1_s64(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(uzp1))]
pub unsafe fn svuzp1q_f32(op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uzp1q.nxv4f32")]
        fn _svuzp1q_f32(op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svuzp1q_f32(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(uzp1))]
pub unsafe fn svuzp1q_f64(op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uzp1q.nxv2f64")]
        fn _svuzp1q_f64(op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svuzp1q_f64(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(uzp1))]
pub unsafe fn svuzp1q_s8(op1: svint8_t, op2: svint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uzp1q.nxv16i8")]
        fn _svuzp1q_s8(op1: svint8_t, op2: svint8_t) -> svint8_t;
    }
    unsafe { _svuzp1q_s8(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(uzp1))]
pub unsafe fn svuzp1q_s16(op1: svint16_t, op2: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uzp1q.nxv8i16")]
        fn _svuzp1q_s16(op1: svint16_t, op2: svint16_t) -> svint16_t;
    }
    unsafe { _svuzp1q_s16(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(uzp1))]
pub unsafe fn svuzp1q_s32(op1: svint32_t, op2: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uzp1q.nxv4i32")]
        fn _svuzp1q_s32(op1: svint32_t, op2: svint32_t) -> svint32_t;
    }
    unsafe { _svuzp1q_s32(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(uzp1))]
pub unsafe fn svuzp1q_s64(op1: svint64_t, op2: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uzp1q.nxv2i64")]
        fn _svuzp1q_s64(op1: svint64_t, op2: svint64_t) -> svint64_t;
    }
    unsafe { _svuzp1q_s64(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(uzp1))]
pub unsafe fn svuzp1q_u8(op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    unsafe { svuzp1q_s8(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(uzp1))]
pub unsafe fn svuzp1q_u16(op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    unsafe { svuzp1q_s16(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(uzp1))]
pub unsafe fn svuzp1q_u32(op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    unsafe { svuzp1q_s32(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(uzp1))]
pub unsafe fn svuzp1q_u64(op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    unsafe { svuzp1q_s64(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uzp2))]
pub unsafe fn svuzp2_b8(op1: svbool_t, op2: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uzp2.nxv16i1")]
        fn _svuzp2_b8(op1: svbool_t, op2: svbool_t) -> svbool_t;
    }
    unsafe { _svuzp2_b8(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uzp2))]
pub unsafe fn svuzp2_b16(op1: svbool_t, op2: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uzp2.nxv8i1")]
        fn _svuzp2_b16(op1: svbool8_t, op2: svbool8_t) -> svbool8_t;
    }
    unsafe { _svuzp2_b16(op1.into(), op2.into()).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uzp2))]
pub unsafe fn svuzp2_b32(op1: svbool_t, op2: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uzp2.nxv4i1")]
        fn _svuzp2_b32(op1: svbool4_t, op2: svbool4_t) -> svbool4_t;
    }
    unsafe { _svuzp2_b32(op1.into(), op2.into()).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uzp2))]
pub unsafe fn svuzp2_b64(op1: svbool_t, op2: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uzp2.nxv2i1")]
        fn _svuzp2_b64(op1: svbool2_t, op2: svbool2_t) -> svbool2_t;
    }
    unsafe { _svuzp2_b64(op1.into(), op2.into()).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uzp2))]
pub unsafe fn svuzp2_f32(op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uzp2.nxv4f32")]
        fn _svuzp2_f32(op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svuzp2_f32(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uzp2))]
pub unsafe fn svuzp2_f64(op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uzp2.nxv2f64")]
        fn _svuzp2_f64(op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svuzp2_f64(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uzp2))]
pub unsafe fn svuzp2_s8(op1: svint8_t, op2: svint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uzp2.nxv16i8")]
        fn _svuzp2_s8(op1: svint8_t, op2: svint8_t) -> svint8_t;
    }
    unsafe { _svuzp2_s8(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uzp2))]
pub unsafe fn svuzp2_s16(op1: svint16_t, op2: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uzp2.nxv8i16")]
        fn _svuzp2_s16(op1: svint16_t, op2: svint16_t) -> svint16_t;
    }
    unsafe { _svuzp2_s16(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uzp2))]
pub unsafe fn svuzp2_s32(op1: svint32_t, op2: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uzp2.nxv4i32")]
        fn _svuzp2_s32(op1: svint32_t, op2: svint32_t) -> svint32_t;
    }
    unsafe { _svuzp2_s32(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uzp2))]
pub unsafe fn svuzp2_s64(op1: svint64_t, op2: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uzp2.nxv2i64")]
        fn _svuzp2_s64(op1: svint64_t, op2: svint64_t) -> svint64_t;
    }
    unsafe { _svuzp2_s64(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uzp2))]
pub unsafe fn svuzp2_u8(op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    unsafe { svuzp2_s8(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uzp2))]
pub unsafe fn svuzp2_u16(op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    unsafe { svuzp2_s16(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uzp2))]
pub unsafe fn svuzp2_u32(op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    unsafe { svuzp2_s32(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uzp2))]
pub unsafe fn svuzp2_u64(op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    unsafe { svuzp2_s64(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(uzp2))]
pub unsafe fn svuzp2q_f32(op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uzp2q.nxv4f32")]
        fn _svuzp2q_f32(op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svuzp2q_f32(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(uzp2))]
pub unsafe fn svuzp2q_f64(op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uzp2q.nxv2f64")]
        fn _svuzp2q_f64(op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svuzp2q_f64(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(uzp2))]
pub unsafe fn svuzp2q_s8(op1: svint8_t, op2: svint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uzp2q.nxv16i8")]
        fn _svuzp2q_s8(op1: svint8_t, op2: svint8_t) -> svint8_t;
    }
    unsafe { _svuzp2q_s8(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(uzp2))]
pub unsafe fn svuzp2q_s16(op1: svint16_t, op2: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uzp2q.nxv8i16")]
        fn _svuzp2q_s16(op1: svint16_t, op2: svint16_t) -> svint16_t;
    }
    unsafe { _svuzp2q_s16(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(uzp2))]
pub unsafe fn svuzp2q_s32(op1: svint32_t, op2: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uzp2q.nxv4i32")]
        fn _svuzp2q_s32(op1: svint32_t, op2: svint32_t) -> svint32_t;
    }
    unsafe { _svuzp2q_s32(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(uzp2))]
pub unsafe fn svuzp2q_s64(op1: svint64_t, op2: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uzp2q.nxv2i64")]
        fn _svuzp2q_s64(op1: svint64_t, op2: svint64_t) -> svint64_t;
    }
    unsafe { _svuzp2q_s64(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(uzp2))]
pub unsafe fn svuzp2q_u8(op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    unsafe { svuzp2q_s8(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(uzp2))]
pub unsafe fn svuzp2q_u16(op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    unsafe { svuzp2q_s16(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(uzp2))]
pub unsafe fn svuzp2q_u32(op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    unsafe { svuzp2q_s32(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(uzp2))]
pub unsafe fn svuzp2q_u64(op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    unsafe { svuzp2q_s64(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(whilele))]
pub unsafe fn svwhilele_b8_s32(op1: i32, op2: i32) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.whilele.nxv16i1.i32"
        )]
        fn _svwhilele_b8_s32(op1: i32, op2: i32) -> svbool_t;
    }
    unsafe { _svwhilele_b8_s32(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(whilele))]
pub unsafe fn svwhilele_b16_s32(op1: i32, op2: i32) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.whilele.nxv8i1.i32"
        )]
        fn _svwhilele_b16_s32(op1: i32, op2: i32) -> svbool8_t;
    }
    unsafe { _svwhilele_b16_s32(op1, op2).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(whilele))]
pub unsafe fn svwhilele_b32_s32(op1: i32, op2: i32) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.whilele.nxv4i1.i32"
        )]
        fn _svwhilele_b32_s32(op1: i32, op2: i32) -> svbool4_t;
    }
    unsafe { _svwhilele_b32_s32(op1, op2).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(whilele))]
pub unsafe fn svwhilele_b64_s32(op1: i32, op2: i32) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.whilele.nxv2i1.i32"
        )]
        fn _svwhilele_b64_s32(op1: i32, op2: i32) -> svbool2_t;
    }
    unsafe { _svwhilele_b64_s32(op1, op2).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(whilele))]
pub unsafe fn svwhilele_b8_s64(op1: i64, op2: i64) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.whilele.nxv16i1.i64"
        )]
        fn _svwhilele_b8_s64(op1: i64, op2: i64) -> svbool_t;
    }
    unsafe { _svwhilele_b8_s64(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(whilele))]
pub unsafe fn svwhilele_b16_s64(op1: i64, op2: i64) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.whilele.nxv8i1.i64"
        )]
        fn _svwhilele_b16_s64(op1: i64, op2: i64) -> svbool8_t;
    }
    unsafe { _svwhilele_b16_s64(op1, op2).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(whilele))]
pub unsafe fn svwhilele_b32_s64(op1: i64, op2: i64) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.whilele.nxv4i1.i64"
        )]
        fn _svwhilele_b32_s64(op1: i64, op2: i64) -> svbool4_t;
    }
    unsafe { _svwhilele_b32_s64(op1, op2).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(whilele))]
pub unsafe fn svwhilele_b64_s64(op1: i64, op2: i64) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.whilele.nxv2i1.i64"
        )]
        fn _svwhilele_b64_s64(op1: i64, op2: i64) -> svbool2_t;
    }
    unsafe { _svwhilele_b64_s64(op1, op2).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(whilels))]
pub unsafe fn svwhilele_b8_u32(op1: u32, op2: u32) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.whilels.nxv16i1.i32"
        )]
        fn _svwhilele_b8_u32(op1: i32, op2: i32) -> svbool_t;
    }
    unsafe { _svwhilele_b8_u32(op1.as_signed(), op2.as_signed()) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(whilels))]
pub unsafe fn svwhilele_b16_u32(op1: u32, op2: u32) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.whilels.nxv8i1.i32"
        )]
        fn _svwhilele_b16_u32(op1: i32, op2: i32) -> svbool8_t;
    }
    unsafe { _svwhilele_b16_u32(op1.as_signed(), op2.as_signed()).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(whilels))]
pub unsafe fn svwhilele_b32_u32(op1: u32, op2: u32) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.whilels.nxv4i1.i32"
        )]
        fn _svwhilele_b32_u32(op1: i32, op2: i32) -> svbool4_t;
    }
    unsafe { _svwhilele_b32_u32(op1.as_signed(), op2.as_signed()).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(whilels))]
pub unsafe fn svwhilele_b64_u32(op1: u32, op2: u32) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.whilels.nxv2i1.i32"
        )]
        fn _svwhilele_b64_u32(op1: i32, op2: i32) -> svbool2_t;
    }
    unsafe { _svwhilele_b64_u32(op1.as_signed(), op2.as_signed()).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(whilels))]
pub unsafe fn svwhilele_b8_u64(op1: u64, op2: u64) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.whilels.nxv16i1.i64"
        )]
        fn _svwhilele_b8_u64(op1: i64, op2: i64) -> svbool_t;
    }
    unsafe { _svwhilele_b8_u64(op1.as_signed(), op2.as_signed()) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(whilels))]
pub unsafe fn svwhilele_b16_u64(op1: u64, op2: u64) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.whilels.nxv8i1.i64"
        )]
        fn _svwhilele_b16_u64(op1: i64, op2: i64) -> svbool8_t;
    }
    unsafe { _svwhilele_b16_u64(op1.as_signed(), op2.as_signed()).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(whilels))]
pub unsafe fn svwhilele_b32_u64(op1: u64, op2: u64) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.whilels.nxv4i1.i64"
        )]
        fn _svwhilele_b32_u64(op1: i64, op2: i64) -> svbool4_t;
    }
    unsafe { _svwhilele_b32_u64(op1.as_signed(), op2.as_signed()).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(whilels))]
pub unsafe fn svwhilele_b64_u64(op1: u64, op2: u64) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.whilels.nxv2i1.i64"
        )]
        fn _svwhilele_b64_u64(op1: i64, op2: i64) -> svbool2_t;
    }
    unsafe { _svwhilele_b64_u64(op1.as_signed(), op2.as_signed()).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(whilelt))]
pub unsafe fn svwhilelt_b8_s32(op1: i32, op2: i32) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.whilelt.nxv16i1.i32"
        )]
        fn _svwhilelt_b8_s32(op1: i32, op2: i32) -> svbool_t;
    }
    unsafe { _svwhilelt_b8_s32(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(whilelt))]
pub unsafe fn svwhilelt_b16_s32(op1: i32, op2: i32) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.whilelt.nxv8i1.i32"
        )]
        fn _svwhilelt_b16_s32(op1: i32, op2: i32) -> svbool8_t;
    }
    unsafe { _svwhilelt_b16_s32(op1, op2).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(whilelt))]
pub unsafe fn svwhilelt_b32_s32(op1: i32, op2: i32) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.whilelt.nxv4i1.i32"
        )]
        fn _svwhilelt_b32_s32(op1: i32, op2: i32) -> svbool4_t;
    }
    unsafe { _svwhilelt_b32_s32(op1, op2).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(whilelt))]
pub unsafe fn svwhilelt_b64_s32(op1: i32, op2: i32) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.whilelt.nxv2i1.i32"
        )]
        fn _svwhilelt_b64_s32(op1: i32, op2: i32) -> svbool2_t;
    }
    unsafe { _svwhilelt_b64_s32(op1, op2).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(whilelt))]
pub unsafe fn svwhilelt_b8_s64(op1: i64, op2: i64) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.whilelt.nxv16i1.i64"
        )]
        fn _svwhilelt_b8_s64(op1: i64, op2: i64) -> svbool_t;
    }
    unsafe { _svwhilelt_b8_s64(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(whilelt))]
pub unsafe fn svwhilelt_b16_s64(op1: i64, op2: i64) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.whilelt.nxv8i1.i64"
        )]
        fn _svwhilelt_b16_s64(op1: i64, op2: i64) -> svbool8_t;
    }
    unsafe { _svwhilelt_b16_s64(op1, op2).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(whilelt))]
pub unsafe fn svwhilelt_b32_s64(op1: i64, op2: i64) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.whilelt.nxv4i1.i64"
        )]
        fn _svwhilelt_b32_s64(op1: i64, op2: i64) -> svbool4_t;
    }
    unsafe { _svwhilelt_b32_s64(op1, op2).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(whilelt))]
pub unsafe fn svwhilelt_b64_s64(op1: i64, op2: i64) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.whilelt.nxv2i1.i64"
        )]
        fn _svwhilelt_b64_s64(op1: i64, op2: i64) -> svbool2_t;
    }
    unsafe { _svwhilelt_b64_s64(op1, op2).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(whilelo))]
pub unsafe fn svwhilelt_b8_u32(op1: u32, op2: u32) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.whilelo.nxv16i1.i32"
        )]
        fn _svwhilelt_b8_u32(op1: i32, op2: i32) -> svbool_t;
    }
    unsafe { _svwhilelt_b8_u32(op1.as_signed(), op2.as_signed()) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(whilelo))]
pub unsafe fn svwhilelt_b16_u32(op1: u32, op2: u32) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.whilelo.nxv8i1.i32"
        )]
        fn _svwhilelt_b16_u32(op1: i32, op2: i32) -> svbool8_t;
    }
    unsafe { _svwhilelt_b16_u32(op1.as_signed(), op2.as_signed()).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(whilelo))]
pub unsafe fn svwhilelt_b32_u32(op1: u32, op2: u32) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.whilelo.nxv4i1.i32"
        )]
        fn _svwhilelt_b32_u32(op1: i32, op2: i32) -> svbool4_t;
    }
    unsafe { _svwhilelt_b32_u32(op1.as_signed(), op2.as_signed()).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(whilelo))]
pub unsafe fn svwhilelt_b64_u32(op1: u32, op2: u32) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.whilelo.nxv2i1.i32"
        )]
        fn _svwhilelt_b64_u32(op1: i32, op2: i32) -> svbool2_t;
    }
    unsafe { _svwhilelt_b64_u32(op1.as_signed(), op2.as_signed()).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(whilelo))]
pub unsafe fn svwhilelt_b8_u64(op1: u64, op2: u64) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.whilelo.nxv16i1.i64"
        )]
        fn _svwhilelt_b8_u64(op1: i64, op2: i64) -> svbool_t;
    }
    unsafe { _svwhilelt_b8_u64(op1.as_signed(), op2.as_signed()) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(whilelo))]
pub unsafe fn svwhilelt_b16_u64(op1: u64, op2: u64) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.whilelo.nxv8i1.i64"
        )]
        fn _svwhilelt_b16_u64(op1: i64, op2: i64) -> svbool8_t;
    }
    unsafe { _svwhilelt_b16_u64(op1.as_signed(), op2.as_signed()).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(whilelo))]
pub unsafe fn svwhilelt_b32_u64(op1: u64, op2: u64) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.whilelo.nxv4i1.i64"
        )]
        fn _svwhilelt_b32_u64(op1: i64, op2: i64) -> svbool4_t;
    }
    unsafe { _svwhilelt_b32_u64(op1.as_signed(), op2.as_signed()).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(whilelo))]
pub unsafe fn svwhilelt_b64_u64(op1: u64, op2: u64) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.whilelo.nxv2i1.i64"
        )]
        fn _svwhilelt_b64_u64(op1: i64, op2: i64) -> svbool2_t;
    }
    unsafe { _svwhilelt_b64_u64(op1.as_signed(), op2.as_signed()).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(wrffr))]
pub unsafe fn svwrffr(op: svbool_t) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.wrffr")]
        fn _svwrffr(op: svbool_t);
    }
    unsafe { _svwrffr(op) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(zip1))]
pub unsafe fn svzip1_b8(op1: svbool_t, op2: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.zip1.nxv16i1")]
        fn _svzip1_b8(op1: svbool_t, op2: svbool_t) -> svbool_t;
    }
    unsafe { _svzip1_b8(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(zip1))]
pub unsafe fn svzip1_b16(op1: svbool_t, op2: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.zip1.nxv8i1")]
        fn _svzip1_b16(op1: svbool8_t, op2: svbool8_t) -> svbool8_t;
    }
    unsafe { _svzip1_b16(op1.into(), op2.into()).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(zip1))]
pub unsafe fn svzip1_b32(op1: svbool_t, op2: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.zip1.nxv4i1")]
        fn _svzip1_b32(op1: svbool4_t, op2: svbool4_t) -> svbool4_t;
    }
    unsafe { _svzip1_b32(op1.into(), op2.into()).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(zip1))]
pub unsafe fn svzip1_b64(op1: svbool_t, op2: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.zip1.nxv2i1")]
        fn _svzip1_b64(op1: svbool2_t, op2: svbool2_t) -> svbool2_t;
    }
    unsafe { _svzip1_b64(op1.into(), op2.into()).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(zip1))]
pub unsafe fn svzip1_f32(op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.zip1.nxv4f32")]
        fn _svzip1_f32(op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svzip1_f32(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(zip1))]
pub unsafe fn svzip1_f64(op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.zip1.nxv2f64")]
        fn _svzip1_f64(op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svzip1_f64(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(zip1))]
pub unsafe fn svzip1_s8(op1: svint8_t, op2: svint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.zip1.nxv16i8")]
        fn _svzip1_s8(op1: svint8_t, op2: svint8_t) -> svint8_t;
    }
    unsafe { _svzip1_s8(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(zip1))]
pub unsafe fn svzip1_s16(op1: svint16_t, op2: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.zip1.nxv8i16")]
        fn _svzip1_s16(op1: svint16_t, op2: svint16_t) -> svint16_t;
    }
    unsafe { _svzip1_s16(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(zip1))]
pub unsafe fn svzip1_s32(op1: svint32_t, op2: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.zip1.nxv4i32")]
        fn _svzip1_s32(op1: svint32_t, op2: svint32_t) -> svint32_t;
    }
    unsafe { _svzip1_s32(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(zip1))]
pub unsafe fn svzip1_s64(op1: svint64_t, op2: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.zip1.nxv2i64")]
        fn _svzip1_s64(op1: svint64_t, op2: svint64_t) -> svint64_t;
    }
    unsafe { _svzip1_s64(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(zip1))]
pub unsafe fn svzip1_u8(op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    unsafe { svzip1_s8(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(zip1))]
pub unsafe fn svzip1_u16(op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    unsafe { svzip1_s16(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(zip1))]
pub unsafe fn svzip1_u32(op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    unsafe { svzip1_s32(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(zip1))]
pub unsafe fn svzip1_u64(op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    unsafe { svzip1_s64(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(zip1))]
pub unsafe fn svzip1q_f32(op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.zip1q.nxv4f32")]
        fn _svzip1q_f32(op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svzip1q_f32(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(zip1))]
pub unsafe fn svzip1q_f64(op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.zip1q.nxv2f64")]
        fn _svzip1q_f64(op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svzip1q_f64(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(zip1))]
pub unsafe fn svzip1q_s8(op1: svint8_t, op2: svint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.zip1q.nxv16i8")]
        fn _svzip1q_s8(op1: svint8_t, op2: svint8_t) -> svint8_t;
    }
    unsafe { _svzip1q_s8(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(zip1))]
pub unsafe fn svzip1q_s16(op1: svint16_t, op2: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.zip1q.nxv8i16")]
        fn _svzip1q_s16(op1: svint16_t, op2: svint16_t) -> svint16_t;
    }
    unsafe { _svzip1q_s16(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(zip1))]
pub unsafe fn svzip1q_s32(op1: svint32_t, op2: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.zip1q.nxv4i32")]
        fn _svzip1q_s32(op1: svint32_t, op2: svint32_t) -> svint32_t;
    }
    unsafe { _svzip1q_s32(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(zip1))]
pub unsafe fn svzip1q_s64(op1: svint64_t, op2: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.zip1q.nxv2i64")]
        fn _svzip1q_s64(op1: svint64_t, op2: svint64_t) -> svint64_t;
    }
    unsafe { _svzip1q_s64(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(zip1))]
pub unsafe fn svzip1q_u8(op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    unsafe { svzip1q_s8(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(zip1))]
pub unsafe fn svzip1q_u16(op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    unsafe { svzip1q_s16(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(zip1))]
pub unsafe fn svzip1q_u32(op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    unsafe { svzip1q_s32(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(zip1))]
pub unsafe fn svzip1q_u64(op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    unsafe { svzip1q_s64(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(zip2))]
pub unsafe fn svzip2_b8(op1: svbool_t, op2: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.zip2.nxv16i1")]
        fn _svzip2_b8(op1: svbool_t, op2: svbool_t) -> svbool_t;
    }
    unsafe { _svzip2_b8(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(zip2))]
pub unsafe fn svzip2_b16(op1: svbool_t, op2: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.zip2.nxv8i1")]
        fn _svzip2_b16(op1: svbool8_t, op2: svbool8_t) -> svbool8_t;
    }
    unsafe { _svzip2_b16(op1.into(), op2.into()).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(zip2))]
pub unsafe fn svzip2_b32(op1: svbool_t, op2: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.zip2.nxv4i1")]
        fn _svzip2_b32(op1: svbool4_t, op2: svbool4_t) -> svbool4_t;
    }
    unsafe { _svzip2_b32(op1.into(), op2.into()).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(zip2))]
pub unsafe fn svzip2_b64(op1: svbool_t, op2: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.zip2.nxv2i1")]
        fn _svzip2_b64(op1: svbool2_t, op2: svbool2_t) -> svbool2_t;
    }
    unsafe { _svzip2_b64(op1.into(), op2.into()).into() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(zip2))]
pub unsafe fn svzip2_f32(op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.zip2.nxv4f32")]
        fn _svzip2_f32(op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svzip2_f32(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(zip2))]
pub unsafe fn svzip2_f64(op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.zip2.nxv2f64")]
        fn _svzip2_f64(op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svzip2_f64(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(zip2))]
pub unsafe fn svzip2_s8(op1: svint8_t, op2: svint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.zip2.nxv16i8")]
        fn _svzip2_s8(op1: svint8_t, op2: svint8_t) -> svint8_t;
    }
    unsafe { _svzip2_s8(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(zip2))]
pub unsafe fn svzip2_s16(op1: svint16_t, op2: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.zip2.nxv8i16")]
        fn _svzip2_s16(op1: svint16_t, op2: svint16_t) -> svint16_t;
    }
    unsafe { _svzip2_s16(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(zip2))]
pub unsafe fn svzip2_s32(op1: svint32_t, op2: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.zip2.nxv4i32")]
        fn _svzip2_s32(op1: svint32_t, op2: svint32_t) -> svint32_t;
    }
    unsafe { _svzip2_s32(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(zip2))]
pub unsafe fn svzip2_s64(op1: svint64_t, op2: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.zip2.nxv2i64")]
        fn _svzip2_s64(op1: svint64_t, op2: svint64_t) -> svint64_t;
    }
    unsafe { _svzip2_s64(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(zip2))]
pub unsafe fn svzip2_u8(op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    unsafe { svzip2_s8(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(zip2))]
pub unsafe fn svzip2_u16(op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    unsafe { svzip2_s16(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(zip2))]
pub unsafe fn svzip2_u32(op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    unsafe { svzip2_s32(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(zip2))]
pub unsafe fn svzip2_u64(op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    unsafe { svzip2_s64(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(zip2))]
pub unsafe fn svzip2q_f32(op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.zip2q.nxv4f32")]
        fn _svzip2q_f32(op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svzip2q_f32(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(zip2))]
pub unsafe fn svzip2q_f64(op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.zip2q.nxv2f64")]
        fn _svzip2q_f64(op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svzip2q_f64(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(zip2))]
pub unsafe fn svzip2q_s8(op1: svint8_t, op2: svint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.zip2q.nxv16i8")]
        fn _svzip2q_s8(op1: svint8_t, op2: svint8_t) -> svint8_t;
    }
    unsafe { _svzip2q_s8(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(zip2))]
pub unsafe fn svzip2q_s16(op1: svint16_t, op2: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.zip2q.nxv8i16")]
        fn _svzip2q_s16(op1: svint16_t, op2: svint16_t) -> svint16_t;
    }
    unsafe { _svzip2q_s16(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(zip2))]
pub unsafe fn svzip2q_s32(op1: svint32_t, op2: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.zip2q.nxv4i32")]
        fn _svzip2q_s32(op1: svint32_t, op2: svint32_t) -> svint32_t;
    }
    unsafe { _svzip2q_s32(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(zip2))]
pub unsafe fn svzip2q_s64(op1: svint64_t, op2: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.zip2q.nxv2i64")]
        fn _svzip2q_s64(op1: svint64_t, op2: svint64_t) -> svint64_t;
    }
    unsafe { _svzip2q_s64(op1, op2) }
}
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(zip2))]
pub unsafe fn svzip2q_u8(op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    unsafe { svzip2q_s8(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(zip2))]
pub unsafe fn svzip2q_u16(op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    unsafe { svzip2q_s16(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(zip2))]
pub unsafe fn svzip2q_u32(op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    unsafe { svzip2q_s32(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(zip2))]
pub unsafe fn svzip2q_u64(op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    unsafe { svzip2q_s64(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
